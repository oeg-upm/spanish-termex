Contexto Sensible Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Inc. 701 First Avenue Sunnyvale, California 94089 {Fuchun, Nawaaz, Xinli, yumaolt.@yahoo-inc.com Resumen Tradicionalmente, se ha aplicado a las tareas de recuperación de información transformando palabras en documentos a su forma de raíz antes de indexar y aplicarUna transformación similar a los términos de consulta. Aunque aumenta el recuerdo, esta estrategia ingenua no funciona bien para la búsqueda web, ya que reduce la precisión y requiere una cantidad significativa de cálculo adicional. En este documento, proponemos un método de derivación sensible al contexto que aborde estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la búsqueda web. Primero, basado en el modelado de lenguaje estadístico, realizamos un análisis sensible de contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente el número de expansiones malas, lo que a su vez reduce el costo del cálculo adicional y mejora la precisión al mismo tiempo. En segundo lugar, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes expandidas. Esta estrategia conservadora sirve como una salvaguardia contra los siglos espurios, y resulta ser muy importante para mejorar la precisión. Utilizando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de Stemming, nuestros experimentos en un motor de búsqueda web importante muestran que la derivación de solo el 29% del tráfico de la consulta, podemos mejorar la relevancia medida por una ganancia acumulativa con descuento promedio (DCG5) en un 6.1% en estosconsultas y 1.8% sobre todo el tráfico de consultas. Categorías y descriptores de sujetos H.3.3 [Sistemas de información]: Algoritmos de Términos generales de almacenamiento de información y recuperación de la Cuidera. Introducción La búsqueda web se ha convertido en una herramienta importante en nuestra vida diaria para la búsqueda de información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están mejor formuladas para obtener resultados óptimos. Por ejemplo, la zapatilla de carrera es una consulta que ocurre con frecuencia en los registros de consultas. Sin embargo, es mucho más probable que las zapatillas para correr de consulta dan mejores resultados de búsqueda que la consulta original porque los documentos que coinciden con la intención de esta consulta generalmente contienen las palabras de las zapatillas. Formular correctamente una consulta requiere que el usuario predice con precisión qué forma de palabra se usa en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para los usuarios experimentados, y especialmente difícil para los oradores no nativos. Una solución tradicional es usar Stemming [16, 18], el proceso de transformación de palabras infectadas o derivadas en su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra carrera coincidirá con correr, correr, correr y zapatos combinará con zapatos y zapatos. Se puede realizar la derecha en los términos en un documento durante la indexación (y aplicar la misma transformación a los términos de consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. La derivación durante la indexación permite muy poca flexibilidad durante el procesamiento de la consulta, mientras que la expansión de la consulta permite el manejo de cada consulta de manera diferente y, por lo tanto, se prefiere. Aunque el retraso tradicional de los vallas aumenta el recuerdo de las variantes de palabras coincidentes [13], puede reducir la precisión al recuperar demasiados documentos que se han igualado incorrectamente. Al examinar los resultados de la aplicación de Stemming a una gran cantidad de consultas, generalmente se encuentra que la técnica [6] se da cuenta casi igual de consultas. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que coincidir con todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos las derivaciones del manejo de la pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, uno debe ser muy cauteloso al usar Stemming en los motores de búsqueda web. Un problema de los siglos tradicionales es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, The Word Book tiene cuatro formularios de libros, libros, reservas, reservas y tienda tiene cuatro formularios tiendas, tiendas, almacenamiento, almacenados. Para la librería de consultas, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de cálculo y duele la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar las librerías de las librerías para que las librerías estén bien, pero la tienda de almacenamiento o reserva de libros coincidentes no lo es. Un método de ponderación que proporciona palabras variantes más pequeñas pesas alivia los problemas en cierta medida si los pesos reflejan con precisión la importancia de la variante en esta consulta en particular. Sin embargo, la ponderación uniforme no va a funcionar y una ponderación dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema de la derivación tradicional es su coincidencia ciega de todos los sucesos en los documentos. Para la librería de consultas, una transformación que permite que las tiendas variantes coincidan causará que cada aparición de tiendas en el documento sea tratada equivalente a la tienda de términos de consulta. Por lo tanto, se combinará un documento que contenga el fragmento que lee un libro en las tiendas de café, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejarlos correctamente, con muchos más candidatos para clasificar, aumenta el riesgo de cometer errores. Para aliviar estos dos problemas, proponemos un enfoque derivado del contexto para la búsqueda web. Nuestra solución consta de dos análisis sensibles al contexto, uno en el lado de la consulta y el otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado de lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original para fines de búsqueda y expandir la consulta con solo esos formularios. En el lado del documento, proponemos una coincidencia sensible al contexto conservador para las variantes de palabras transformadas, solo ocurrencias de documentos coincidentes en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que hace que sea factible ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de la pluralización como un ejemplo de ejecución para nuestro enfoque de Stemming. La motivación para usar el manejo de la pluralización como ejemplo es mostrar que incluso tal simple tallo, si se maneja correctamente, puede dar beneficios significativos para la relevancia de búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda web. Como tenemos que señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica general de Stemming y también se puede aplicar a la expansión general de la consulta. Los experimentos sobre votación general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque no se informarán detalles en este documento. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método del trabajo anterior en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un motor de búsqueda web importante para respaldar nuestras afirmaciones en la Sección 4, seguidas de discusiones en la Sección 5. Finalmente, concluimos el documento en la Sección 6. 2. El trabajo relacionado con talla es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos taladros, como el Lovins Stemmer [16] y el Porter Stemmer [18]. El Porter Stemmer se usa ampliamente debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el Porter Stemming comete muchos errores porque sus reglas simples no pueden describir completamente la morfología inglesa. El análisis de corpus se usa para mejorar Porter Stemmer [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y ocurren en un contexto similar medido por la información mutua esperada [23]. Utilizamos un enfoque similar basado en el corpus para la derivación calculando la similitud entre dos palabras en función de sus características de contexto de distribución que pueden ser más que solo palabras adyacentes [15], y luego solo mantener las palabras morfológicamente similares a los candidatos. El uso de Stemming en la recuperación de la información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad de los sistemas de consultas de la consulta en inglés era bastante limitada. Lennon et al.[17] comparó los algoritmos Lovins y Porter y encontraron poca mejora en el rendimiento de la recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en los experimentos de recuperación de texto, incluida la entrega de pluralización (llamado S Stemmer en el documento). También propusieron una votación selectiva basada en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática de precisión (hasta 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y el pequeño tamaño de la colección, los resultados son difíciles de generalizar para la búsqueda web. Estos resultados mixtos, en su mayoría fallas, llevaron a los primeros investigadores IR a considerar irrelevantes en general para el inglés [4], aunque las investigaciones recientes han demostrado que las vistas tienen mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que las fallas anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. La derivación ciega, o una simple derecha selectiva basada en la longitud de consulta, como se usa en [9], no es suficiente. Se debe decidir sobre el caso por caso, no solo en el nivel de consulta sino también a nivel de documento. Como mostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con la reformulación de la consulta [3, 12] y la expansión de la consulta que amplía las palabras no solo con las variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras ampliadas usar, las personas a menudo usan la técnica de retroalimentación de pseudorelevancia, envíe la consulta original a un motor de búsqueda y recupere los documentos superiores, extraiga palabras relevantes de estos documentos superiores como palabras de consulta adicionales y vuelva a enviar la consulta ampliada nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de la consulta, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamada deriva de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlos a la consulta podría cambiar la intención de la consulta original. Por lo tanto, la expansión de la consulta basada en pseudorelevancia y reformulación de consultas puede proporcionar sugerencias a los usuarios para el refinamiento interactivo, pero difícilmente se puede usar directamente para la búsqueda web. Por otro lado, Stemming es mucho más conservador ya que la mayoría de las veces, STEMMing conserva la intención de búsqueda original. Si bien la mayoría del trabajo en la expansión de la consulta se centra en la mejora del recuerdo, nuestro trabajo se centra en aumentar el recuerdo y la precisión. El aumento en el retiro es obvio. Con la calidad de la calidad, buenos documentos que no fueron seleccionados antes de que sean empujados y esos documentos de baja calidad se degraden. En la expansión selectiva de consultas, Cronen-Townsend et al.[6] propuso un método para la expansión de la consulta selectiva basada en comparar la divergencia de Kullback-Leiber de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere una recuperación de múltiples pases. Si una palabra se puede ampliar en varias palabras, requiere ejecutar este proceso varias veces para decidir qué palabra expandida es útil. Es costoso implementar esto en los motores de búsqueda web de producción. Nuestro método predice la calidad de la expansión basada en información sobre la información sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para atacar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web, detrás. Nuestro enfoque es único en el sentido de que realiza la derivación predictiva sobre una base de consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace que el tiempo real sea factible para la búsqueda web. Nuestros resultados afirmarán a los investigadores de que Stemming es muy importante para la recuperación de información a gran escala.3. Context Sensitive Stemming 3.1 Descripción general Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: Generación de candidatos, segmentación de consultas y detección de palabras de cabeza, consulta sensible al contexto de consulta y coincidencia de documentos sensibles al contexto. La generación de candidatos (componente 1) se realiza o ﬄ ine y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, la primera consulta segmentaremos en conceptos y detectamos la palabra principal para cada concepto (componente 2). Luego usamos el modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3) y, finalmente, para las variantes expandidas, realizamos una coincidencia de documentos contextual (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: Consulta de entrada de coincidencia del documento sensible al contexto: y el componente de detección de palabras de la cabeza 2: Componente del segmento 1: Comparación de generación de candidatos −> Comparación de comparación 3: Decisión selectiva de expansión de palabras: comparaciones -> Ejemplo de comparación: Comparación de precios del hotel Salida: Hotel Hotel Hotel> Hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es usar el Porter Stemmer [18]. El Porter Stemmer simplemente usa reglas morfológicas para convertir una palabra en su forma base. No tiene conocimiento del significado semántico de las palabras y, a veces, comete serios errores, como ejecutivo para la ejecución, noticias a nuevas y pegar al pasado. Una forma más conservadora se basa en el uso del análisis de corpus para mejorar los resultados de Porter Stemmer [26]. El análisis del corpus que hacemos se basa en la similitud de distribución de palabras [15]. La justificación del uso de similitud de palabras de distribución es que las variantes verdaderas tienden a usarse en contextos similares. En el cálculo de similitud de palabras de distribución, cada palabra se representa con un vector de características derivado del contexto de la palabra. Utilizamos los BigRams a la izquierda y a la derecha de la palabra como características de contexto, minando un gran corpus web. La similitud entre dos palabras es la similitud cosena entre los dos vectores de características correspondientes. Las 20 palabras similares al desarrollo se muestran en la siguiente tabla.Rank Candidate Puntuación de rango Puntuación candidata 0 Desarrollar 1 10 Berts 0.119 1 Desarrollo de 0.339 11 Wads 0.116 2 Desarrollado 0.176 12 Desarrollador 0.107 3 Incubador 0.160 13 Promoción de 0.100 4 Desarrolla 0.150 14 Desarrollo 0.091 5 Desarrollo 0.148 15 Reengineing 0.090 6 Tutoría 0.138 16 Construir 0.083 7 Analización de análisis Analizante0.128 17 Construya 0.081 8 Desarrollo 0.128 18 Educational 0.081 9 Automatización 0.126 19 Instituto 0.077 Tabla 1: Los 20 candidatos más similares a Word se desarrollan. La puntuación de la columna es la puntuación de similitud. Para determinar a los candidatos de Stemming, aplicamos algunas reglas morfológicas de Porter Stemmer [18] a la lista de similitud. Después de aplicar estas reglas, para el desarrollo de la palabra, los candidatos derivados se desarrollan, desarrollan, desarrollan, desarrollo, desarrollo, desarrollador, desarrollo. Para el propósito de manejo de pluralización, solo se retiene el candidato. Una cosa que notamos al observar las palabras distributionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras pueden servir como candidatos para la expansión general de la consulta, un tema que investigaremos en el futuro.3.3 Segmentación e identificación de palabras de cabeza Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento que representa un concepto que normalmente es una frase nominal. Para cada una de las frases sustantivas, detectamos la palabra más importante que llamamos la palabra de la cabeza. La segmentación también se usa en la coincidencia sensible del documento (Sección 3.5) para hacer cumplir la proximidad. Para romper una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre palabras. Un método efectivo es usar información mutua como indicador sobre si dividir o no dos palabras [19]. Utilizamos un registro de consultas de 25 m y recolectamos las frecuencias BigRam y unigram de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes;Si pasa un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras está por debajo del umbral, luego creamos un límite de concepto aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es hacer un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que la oración [zapatilla de carrera] [mejor] [Nueva York] [Escuelas de medicina] [imágenes] [de] [Casa Blanca] [Cookies] [en] [San Francisco] [Hotel] [Comparación de precios] Table Table Table2: Segmentación de consulta: un segmento es entre paréntesis.Analizado ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador capacitado en oraciones de documentos a consultas tendrá un bajo rendimiento. En nuestra solución, solo utilizamos reglas de heurística simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal inglesa, la palabra de la cabeza es típicamente la última palabra sin parar, a menos que la frase sea de un patrón particular, como xyz de/in/at/from UVW. En tales casos, la palabra principal es típicamente la última palabra sin parar de XYZ.3.4 Expansión de palabras sensibles al contexto Después de detectar qué palabras son las palabras más importantes para expandir, tenemos que decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden transformarse mediante pluralización a través de ingenuos derivaciones. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (aproximadamente el 50%) no cambia sus 5 resultados principales, y el 25% restante funciona peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser derivadas con el fin de maximizar la mejora de la relevancia y minimizar el costo de los siglos. Además, para una consulta con múltiples palabras que se pueden transformar, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de la consulta como ejemplo, decidimos que la comparación de hoteles y precios son dos conceptos. El hotel y la comparación de palabras de cabeza se pueden ampliar a los hoteles y las comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta ampliada obtenga documentos más relevantes de la web, que puede cuantificarse por la probabilidad de que la consulta ocurra como una cadena en la web. La mayor probabilidad de que ocurra una consulta en la web, más documentos relevantes esta consulta puede devolver. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la web. Calcular la probabilidad de que ocurra una cadena en un corpus es un problema de modelado de idiomas bien conocido. El objetivo del modelado de idiomas es predecir la probabilidad de secuencias de palabras naturales, s = w1w2 ... wn;o más simplemente, para poner una alta probabilidad en las secuencias de palabras que realmente ocurren (y la baja probabilidad de las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado de idiomas todavía se basa en el modelo N-Gram. Por la regla de probabilidad de la cadena, se puede escribir la probabilidad de cualquier secuencia de palabras como PR (W1W2 ... Wn) = NY I = 1 PR (WI | W1 ... WI-1) (1) Un modelo N-Gram se aproximaEsta probabilidad suponiendo que las únicas palabras relevantes para predecir PR (wi | w1 ... wi - 1) son las palabras n - 1 anteriores;es decir. Pr (wi | w1 ... wi-1) = pr (wi | wi-n+1 ... wi-1) Una estimación de máxima verosimilitud sencilla de las probabilidades de N-gram de un corpus está dada por la frecuencia observada de cada unode los patrones pr (wi | wi - n+1 ... wi - 1) = #(wi - n+1 ... wi) #(wi - n+1 ... wi - 1) (2) donde#(.) Denota el número de ocurrencias de un gramo especificado en el corpus de entrenamiento. Aunque uno podría intentar usar modelos simples de N-Gram para capturar dependencias de largo alcance en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: usar gramos de longitud hasta N implica estimar la probabilidad de eventos WN, donde W es del tamañode la palabra vocabulario. Esto rápidamente abruma los recursos computacionales y de datos modernos para opciones incluso modestas de N (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, Ley ZIPFS) Es probable que se encuentre con nuevos N-Grams que nunca fueron presenciados durante la capacitación en ningún corpus de prueba, y por lo tanto, algún mecanismo para asignar una probabilidad no cero a NEVE NEWN N-Grams es un tema central e inevitable en el modelado de lenguaje estadístico. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a los problemas de datos dispersos (y hacer frente a los N-gramos potencialmente faltantes) es utilizar algún tipo de estimador de retroceso. Pr (wi | wi - n+1 ... wi - 1) = 8 >> <>>: ˆpr (wi | wi - n+1 ... wi - 1), si #(wi - n+1...wi)> 0 β (wi - n+1 ... wi - 1) × pr (wi | wi - n+2 ... wi - 1), de lo contrario (3) donde ˆpr (wi | wi - n+1 ... wi - 1) = descuento #(wi - n+1 ... wi) #(wi - n+1 ... wi - 1) (4) es la probabilidad y β con descuento (wi - n+1 ... wi - 1) es una constante de normalización β (wi - n+1 ... wi - 1) = 1 - x x∈ (wi - n+1 ... wi - 1x) ˆpr (x |wi - n+1 ... wi - 1) 1 - x x∈ (wi - n+1 ... wi - 1x) ˆpr (x | wi - n+2 ... wi - 1) (5) elLa probabilidad con descuento (4) se puede calcular con diferentes técnicas de suavizado, que incluyen suavizado absoluto, suavizado de buen turbulento, suavizado lineal y suavizado de pellado de Witten [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, PR (W1W2 ... WN), es un número muy pequeño y difícil de interpretar, usamos la entropía como se define a continuación a continuación para calificar la cadena. Entropía = - 1 n log2 pr (w1w2 ... wn) (6) Ahora vuelve al ejemplo de las comparaciones de precios del hotel de consulta, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada es comparaciones de precios del hotel, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada y, por lo tanto, debe ampliarse. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección a esas alternativas de consulta si sus puntajes están a cierta distancia (10% en nuestros experimentos) a la mejor puntuación. Variaciones de consulta Entropía Comparación de precios del hotel 6.177 Comparaciones de precios del hotel 6.597 Hoteles Comparación de precios 6.937 Comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta Comparación de precios del hotel clasificado por puntaje de entropía, con la consulta original en negrita.3.5 COMPORTACIÓN DE DOCUMENTES SENTICIONALES DEL CONTEXTO Incluso después de saber qué variantes de palabras probablemente sean útiles, debemos ser conservadores en la coincidencia de documentos para las variantes expandidas. Para las comparaciones de precios de la consulta, decidimos que las comparaciones de palabras se amplían para incluir la comparación. Sin embargo, no todas las ocurrencias de comparación en el documento son de interés. Una página que se trata de comparar el servicio al cliente puede contener todas las palabras comparaciones de precios del hotel. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, dañará la precisión de la recuperación y esta es una de las principales razones por las cuales la mayoría de los enfoques de Stemming no funcionan bien para la recuperación de la información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto en torno a la variante expandida en el documento. Una coincidencia variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original. El contexto es los segmentos sin parar izquierdo o derecho 1 de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después del precio de las palabras. Por lo tanto, solo debemos coincidir con esas ocurrencias de comparación en el documento si ocurren después del precio de la palabra. Teniendo en cuenta el hecho de que las consultas y los documentos pueden no representar la intención exactamente de la misma manera, relajamos esta restricción de proximidad para permitir ocurrencias de variantes dentro de una ventana de algún tamaño fijo. Si la comparación de palabras ampliada ocurre dentro del contexto del precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictivo es la coincidencia. Utilizamos un tamaño de ventana de 4, que generalmente captura contextos que incluyen las frases nominal de contención y adyacentes.4. Evaluación experimental 4.1 Métricas de evaluación Mediremos tanto la mejora de la relevancia como el costo vistoso requerido para lograr la relevancia.1 Un segmento de contexto no puede ser una sola palabra de parada.4.1.1 Medición de relevancia Utilizamos una variante de la ganancia acumulativa promedio con descuento (DCG), un esquema recientemente popularizado para medir la relevancia del motor de búsqueda [1, 11]. Dada una consulta y una lista clasificada de documentos k (k se establece en 5 en nuestros experimentos), la puntuación DCG (k) para esta consulta se calcula de la siguiente manera: DCG (k) = kx k = 1 GK log2 (1 + k).(7) donde GK es el peso para el documento en el rango k.Un mayor grado de relevancia corresponde a un peso más alto. Una página se califica en una de las cinco escalas: perfecta, excelente, buena, justa, mala, con pesas correspondientes. Usamos DCG para representar el DCG promedio (5) sobre un conjunto de consultas de prueba.4.1.2 Costo de Stemming Otra métrica es medir el costo adicional incurrido por Stemming. Dado el mismo nivel de mejora de relevancia, preferimos un método de punto de la derivación que tiene menos costo adicional. Medimos esto por el porcentaje de consultas que en realidad se sienten con votación, sobre todas las consultas que posiblemente podrían ser de STEMMed.4.2 Preparación de datos Muestra aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas mal escritas ya que las consultas mal escritas no son de interés para las derivaciones. También eliminamos todas las consultas de una palabra, ya que las consultas de una palabra de las palabras sin contexto tienen un alto riesgo de cambiar la intención de consultas, especialmente para palabras cortas. Al final, tenemos 529 consultas deletreadas correctamente con al menos 2 palabras.4.3 ingenuo derivado para la búsqueda web Antes de explicar los experimentos y los resultados en detalle, a Wed como para describir la forma tradicional de usar STEMMing para la búsqueda web, denominada modelo ingenuo. Esto es para tratar cada variante de palabras equivalente para todas las palabras posibles en la consulta. La librería de la consulta se transformará en (libros o libros) (tiendas o tiendas) al limitar solo el manejamiento de la pluralización, donde o es un operador que denota la equivalencia de los argumentos de izquierda y derecha.4.4 Configuración experimental El modelo de línea de base es el modelo sin STEMMing. Primero ejecutamos el modelo ingenuo para ver qué tan bien funciona sobre la línea de base. Luego mejoramos el modelo de vástago ingenuo mediante la coincidencia sensible del documento, denominado modelo de coincidencia sensible al documento. Este modelo hace que el mismo modelo sea el modelo ingenuo en el lado de la consulta, pero realiza una coincidencia conservadora en el lado del documento utilizando la estrategia descrita en la Sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento paran la mayoría de las consultas. De las 529 consultas, hay 408 consultas que surgen, correspondientes al 46.7% de tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia confidencial del documento del lado de la consulta con una palabra selectiva derivada basada en el modelado de lenguaje estadístico (Sección 3.4), denominado modelo selectivo de Stemming. Según la predicción del modelado de idiomas, este modelo se detiene solo un subconjunto de las consultas 408 vistas por el modelo de coincidencia sensible al documento. Experimentamos con el modelo de lenguaje unigram y el modelo de lenguaje BigRam. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo usaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derecha ingenuo) en los experimentos. Para tener una idea de cómo funcionan estos modelos, también tenemos un modelo Oracle que le da al rendimiento superior que un STEMMER puede lograr en estos datos. El modelo Oracle solo expande una palabra si la derivación dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos consultas en consultas cortas y consultas largas. Entre las 408 consultas surgidas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras.4.5 Resultados Resumimos los resultados generales en la Tabla 4 y presentamos los resultados en consultas cortas y consultas largas por separado en la Tabla 5. Cada fila de la Tabla 4 es una estrategia de Stemming descrita en la Sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia;Esta columna mide el costo de votación, y los números deben ser bajos para el mismo nivel de DCG. La tercera columna es la puntuación de DCG promedio en todas las consultas probadas en esta categoría (incluidas las que no fueron detectadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea de base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que la ingenuidad de Stemming solo obtiene una mejora estadísticamente insignificante de 1.5%. Mirando la Tabla 5, ofrece una mejora del 2.7% en consultas cortas. Sin embargo, también perjudica consultas largas en -2.4%. En general, la mejora se cancela. La razón por la que mejora consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que puede ser derivada. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente segura. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener múltiples palabras que pueden ser pluralizadas. Expandirlos a todos sin selección dañará significativamente la precisión. El contexto del documento Sensitive Stemming da un aumento significativo al rendimiento, de 2.7% a 4.2% para consultas cortas y de -2.4% a -1.6% para consultas largas, con un aumento general de 1.5% a 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra ampliada es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchos partidos espurios. Sin embargo, todavía notamos que para consultas largas, la derecha sensible al contexto no puede mejorar el rendimiento porque todavía selecciona demasiados documentos y le da a la función de clasificación un problema difícil. Si bien el tamaño de la ventana elegido de 4 funciona mejor entre todas las opciones, todavía permite coincidencias espurias. Es posible que el tamaño de la ventana deba ser elegido por consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases de sustantivos. La pluralización de palabras selectivas ayuda aún más a resolver el problema que enfrenta el contexto del documento sensible a la derivación. No detiene todas las palabras que colocan toda la carga en el algoritmo de clasificación, pero trata de eliminar innecesarias las derivaciones innecesarias en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras de tallo, mejorando así tanto el recuerdo como la precisión. Con el modelo de lenguaje unigram, podemos reducir el costo de las medidas en un 26.7% (de 408/408 a 300/408) y levantar la mejora general de DCG de 2.8% a 3.4%. En particular, ofrece mejoras significativas en consultas largas. La ganancia de DCG se convierte de negativa a positiva, de −1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora de precisión. Para consultas cortas también, observamos tanto la mejora de DCG como la reducción de costos con el modelo de idioma unigram. Las ventajas de la expansión de palabras predictivas con un modelo de idioma se impulsan aún más con un mejor modelo de idioma BigRam. La ganancia general de DCG se eleva del 3.4% al 3.9%, y el costo de las medidas se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora general de 1.8% DCG en generalTodo el tráfico de consulta. Para consultas cortas, el modelo de lenguaje BigRam mejora la ganancia de DCG de 4.4% a 4.7%, y reduce el costo de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje BigRam mejora la ganancia de DCG de 1.1% a 2.5%, y reduce el costo de edad de 136/136 a 100/136. Observamos que el modelo de lenguaje BigRam ofrece un ascensor más grande para consultas largas. Esto se debe a que la incertidumbre en consultas largas es más grande y se necesita un modelo de lenguaje más poderoso. Presumimos que un modelo de lenguaje Trigram daría un mayor ascensor para consultas largas y dejaría esto para futuras investigaciones. Teniendo en cuenta el ajuste de 2 en la parte superior en la mejora que se obtendrá del manejo de la pluralización (a través del modelo Oracle), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas cortas, la ganancia DCG superior es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de idioma BigRam. Para consultas largas, la ganancia DCG superior es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de idioma BigRam. Podemos obtener un beneficio adicional con un modelo de idioma más poderoso para consultas largas. Sin embargo, las dificultades de consultas largas provienen de muchos otros aspectos, incluida la proximidad y el problema de segmentación. Estos problemas deben abordarse por separado. Mirando la reducción superior de la reducción de la cabeza para Oracle Stemming, el 75% (308/408) de los tallos ingenuos son un desperdicio. Actualmente capturamos aproximadamente la mitad de ellos. Una reducción adicional de la sobrecarga requiere sacrificar la ganancia de DCG. Ahora podemos comparar las estrategias derivadas de un aspecto diferente. En lugar de observar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de Stemming se vuelve más precisa (mejora de DCG). Para el modelo de idioma BigRam, durante las consultas de stemmed 250/408, la mejora de DCG es del 6.1%. Una observación interesante es que el DCG promedio disminuye con un mejor modelo, lo que indica una mejor estrategia de Stemming Salta consultas más difíciles (consultas bajas de DCG).5. Discusiones 5.1 Modelos de lenguaje de la consulta frente a la web Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la web. El modelo de idioma debe describir la aparición de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso.2 Tenga en cuenta que este conflicto superior es solo para el manejo de la pluralización, no para el punto de vista general. General Stemming da un 8% de fusión superior, que es bastante sustancial en términos de nuestras métricas. Consultas afectadas DCG DCG Mejora de valor P-Valor P-Valor 0/408 7.102 N/A N/A Modelo ingenuo 408/408 7.206 1.5% 0.22 Contexto del documento Contexto Sensitivo Modelo 408/408 7.302 2.8% 0.014 Modelo selectivo: Unigram LM 300/408 7.321 3.4% 0.001Modelo selectivo: BigRam LM 250/408 7.381 3.9% 0.001 Oracle Model 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de vástago sobre todas las consultas afectadas por ingenuos resultados de consultas cortas afectadas por las consultas de DCG P-Value P-Value 0/////////////////////////////////////////////272 N/A N/A Modelo ingenuo 272/272 2.7% 0.48 Documento Contexto Sensitivo Modelo 272/272 4.2% 0.002 Modelo selectivo: Unigram LM 185/272 4.4% 0.001 Modelo selectivo: BigRam LM 150/272 4.7% 0.001 Oracle Model 71/272 6.3% 0.001 Resultados de consultas largas afectadas consultas DCG DCG Valor de P -Baselija 0/136 N/A N/A Modelo ingenuo 136/136 -2.4% 0.25 Documento Contexto Sensitivo Modelo 136/136 -1.6% 0.27 Modelo selectivo: Unigram LM 115/136 1.1% 0.001 Modelo selectivo: BigRam LM 100/136 2.5% 0.001 Oracle Model 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de Stemming consultas cortas y de consultas largas reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados para obtener buenos resultados para obtener buenos resultados para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables del registro de consultas, capacitamos un modelo de lenguaje de las mismas consultas de la misma consulta Top 25m que se usa para aprender segmentación, y lo usamos para predicción. Observamos una ligera disminución del rendimiento en comparación con el modelo capacitado en frecuencias web. En particular, el rendimiento para unigram LM no se vio afectado, pero la ganancia de DCG para BigRam LM cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web.5.2 Cómo la lingüística ayuda a algunos conocimientos lingüísticos es útil para las vistas. Para el caso de manejo de pluralización, la pluralización y la desluralización no son simétricas. Una palabra plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta de New York Hotels está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría ser un hotel ubicado en California. Una simple equivalencia del hotel a los hoteles podría impulsar una página en particular sobre el hotel de Nueva York hasta el mejor rango. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Hacemos esto al requerir que los hoteles de la palabra plural aparezcan en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general de DCG, aunque no estadísticamente significativa, para el contexto del documento sensible a la derivación si no consideramos esta propiedad asimétrica.5.3 Análisis de errores Un tipo de errores que notamos, aunque raro pero gravemente perjudicial, la relevancia, es el cambio de intención de búsqueda después de la derivación. En términos generales, la pluralización o la defluiización mantienen la intención original. Sin embargo, la intención podría cambiar en algunos casos. Para un ejemplo de tal consulta, trabajo en Apple, pluralizamos el trabajo a los trabajos. Este Stemming hace que la consulta original sea ambigua. El trabajo de consulta o trabajos en Apple tiene dos intentos. Una es las oportunidades de empleo en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la compañía. Por lo tanto, los resultados posteriores a la consulta devuelven Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención se cambia. Esto es similar a la retroalimentación de relevancia y requiere una clasificación de segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidad/concepto, estos incluyen dos tipos. Una es que la variante de palabra Stemmed ahora coincide con parte de una entidad o concepto. Por ejemplo, las galletas de consulta en San Francisco están pluralizadas para galletas o galletas en San Francisco. Los resultados coincidirán con el frasco de galletas en San Francisco. Aunque Cookie todavía significa lo mismo que las galletas, el frasco de galletas es un concepto diferente. Otro tipo es que la palabra inexplicable coincide con una entidad o concepto debido a la derivación de las otras palabras. Por ejemplo, cita el hielo se pluralizan para citar o cita el hielo. La intención original para esta consulta es buscar cotización de existencias para Ticker Ice. Sin embargo, notamos que entre los mejores resultados, uno de los resultados son las citas de alimentos: helado. Esto coincide con consultas afectadas DCG New DCG DCG Mejora DCG Modelo ingenuo 408/408 7.102 7.206 1.5% Documento Contexto Sensible Modelo 408/408 7.102 7.302 2.8% Modelo selectivo: Unigram LM 300/408 5.904 6.187 4.8% Selective Model: BigRam LM250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas con tallo: la columna antigua/nueva DCG es la puntuación DCG sobre las consultas afectadas antes/después de aplicar las citas de palabras pluralizadas. La palabra de hielo sin cambios coincide con parte del helado de frase nominal aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer el frasco y el helado de galletas como conceptos en lugar de dos palabras independientes. Se produce un tercer tipo de errores en consultas largas. Para el software del lector de códigos de barras de consulta, se pluralizan dos palabras.código a códigos y lector a lectores. De hecho, el lector de códigos de barras en la consulta original es un concepto fuerte y las palabras internas no deben cambiarse. Este es la segmentación y el problema de detección de frases de entidad y sustantivo en consultas, que activamente estamos atacando. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto.6. Conclusiones y trabajos futuros hemos presentado una forma simple pero elegante de detener la búsqueda web. Mejora la votación ingenua en dos aspectos: expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de palabras en el lado del documento. Utilizando el manejo de la pluralización como ejemplo, los experimentos en un importante motor de búsqueda web muestran que mejora significativamente la relevancia web y reduce el costo de consumo. También mejora significativamente la tasa de clics web (detalles no informados en el documento). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de coincidencia de la entidad y frase nominal y la segmentación mejorada.7. Referencias [1] E. Agichtein, E. Brill y S. T. Dumais. Mejora de la clasificación de búsqueda web incorporando información de comportamiento del usuario. En Sigir, 2006. [2] E. airio. Normalización de palabras y descomposición en IR mono y bilingüe. Recuperación de información, 9: 249-271, 2006. [3] P. Anick. Uso de comentarios terminológicos para el refinamiento de búsqueda web: un estudio basado en registros. En Sigir, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de las técnicas de suavizado para el modelado de idiomas. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión de consultas selectivas. En Cikm, 2004. [7] H. Fang y C. Zhai. Matriota de término semántico en enfoques axiomáticos para la recuperación de información. En Sigir, 2006. [8] W. B. Frakes. Término de combinación para la recuperación de información. En C. J. Rijsbergen, editor, investigación y desarrollo en recuperación de información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijo? Jasis, 42 (1): 7-15, 1991. [10] D. Hull. Algoritmos de Stemming: un estudio de caso para una evaluación detallada. Jasis, 47 (1): 70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación de evaluación basada en ganancias acumuladas de técnicas IR. ACM TOIS, 20: 422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generación de sustituciones de consulta. En www, 2006. [13] W. Kraaij y R. Pohlmann. Visualización de la derivación como mejora del recuerdo. En Sigir, 1996. [14] R. Krovetz. Ver la morfología como un proceso de inferencia. En Sigir, 1993. [15] D. Lin. Recuperación automática y agrupación de palabras similares. En Coling-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo Stemming. Traducción mecánica y lingüística computacional, II: 22-31, 1968. [17] M. Lennon y D. Peirce y B. Tarry y P. Willett. Una evaluación de algunos algoritmos de combinación para la recuperación de información. Journal of Information Science, 3: 177-188, 1981. [18] M. Porter. Un algoritmo para extracción sufijo. Programa, 14 (3): 130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consulta para la búsqueda web. En www, 2003. [20] S. E. Robertson. Selección de término para la expansión de la consulta. Journal of Documation, 46 (4): 359-364, 1990. [21] G. Salton y C. Buckley. Mejora del rendimiento de la recuperación por retroalimentación relevante. Jasis, 41 (4): 288 - 297, 1999. [22] R. Sun, C.-H.Ong y T.-S.Chua. Relaciones de dependencia minera para la expansión de la consulta en la recuperación del pasaje. En Sigir, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. V´Elez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consulta rápido y efectivo. En Sigir, 1997. [25] J. Xu y B. Croft. Expansión de consulta utilizando análisis de documentos locales y globales. En Sigir, 1996. [26] J. Xu y B. Croft. Peque basado en el corpus utilizando la coocción de variantes de palabras. ACM TOIS, 16 (1): 61-81, 1998.