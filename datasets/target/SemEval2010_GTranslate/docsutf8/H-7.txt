Modelado de usuarios jerárquicos bayesianos eficientes para sistemas de recomendaciones Yi Zhang, Jonathan Koren School of Engineering University of California Santa Cruz Santa Cruz, CA, EE. UU. {Yiz, jonathanh.@soe.ucsc.edu Resumen Un sistema de recomendación personalizado basado en el contenido Aprende perfiles específicos del usuario del usuario Aprende usuarios de los usuarios.desde los comentarios de los usuarios para que pueda entregar información adaptada al interés de cada usuarios individuales. Un sistema que sirve a millones de usuarios puede aprender un mejor perfil de usuario para un nuevo usuario, o un usuario con pocos comentarios, tomando prestada información de otros usuarios mediante el uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la probabilidad de datos conjuntos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de los datos en aplicaciones IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender una gran cantidad de perfiles de usuarios individuales. La teoría de la eficacia y eficiencia del algoritmo propuesto se justifican por la teoría y se demuestran en los datos reales del usuario de Netflix y Movielens. Categorías y descriptores de asignaturas: B.3.3 [Búsqueda y recuperación de información]: Filtrado de información Términos generales: Algoritmos 1. La personalización de la introducción es el futuro de la web, y ha logrado un gran éxito en las aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, proporcionan recomendaciones personalizadas para productos o servicios adicionales basados en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de los usuarios de su historial. Un tema de personalización importante estudiado en la comunidad de recuperación de información son los sistemas de recomendación personal basados en contenido1. Estos sistemas aprenden perfiles específicos del usuario de los comentarios de los usuarios para que puedan recomendar información adaptada al interés de cada usuarios individuales sin requerir que el usuario haga una consulta explícita. Aprender los perfiles del usuario es el problema central para estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica cuán relevante es un documento para el usuario. Un desafío importante de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione comentarios suficientes de ese usuario para aprender un perfil de usuario confiable. Ha habido mucha investigación sobre la mejora de la precisión de la clasificación cuando la cantidad de datos de capacitación etiquetados es pequeña. El enfoque de aprendizaje semi-supervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es usar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como Na¨ıvebayes [17], regresión logística [7] y SVM [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque es tomar prestados datos de capacitación de otros recursos [5] [7]. La efectividad de estos diferentes enfoques es mixta, debido a qué tan bien, la suposición del modelo subyacente se ajusta a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque se cotiza efectivamente entre la información compartida y específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario [27] [25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente trata de encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica de uso común para el aprendizaje de parámetros debido a su garantía de simplicidad y convergencia. Sin embargo, un sistema de recomendación basado en el contenido a menudo maneja documentos en un espacio dimensional muy alto, en el que cada documento está representado por un vector muy escaso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM Tering o el filtrado colaborativo basado en elementos. En este artículo, las palabras filtrado y recomendación se utilizan indistintamente.El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración EM también es costosa con la complejidad computacional de O (MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, que llamamos el algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M usamos la solución analítica en lugar de la solución numérica estimada para Eesos parámetros. Esto reduce en gran medida el cálculo en una sola iteración EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: la Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizada para recomendaciones basadas en contenido. La Sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este documento. La configuración y los resultados experimentales utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La Sección 7 resume y ofrece comentarios finales.2. El trabajo relacionado que proporciona recomendaciones personalizadas a los usuarios se ha identificado como un problema muy importante en la comunidad IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea una secuencia de documentos y presiona documentos que coinciden con un perfil de usuario con el usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar comentarios de relevancia explícita, que el sistema de filtrado utiliza para actualizar el perfil de los usuarios utilizando modelos de recuperación de retroalimentación relevante (p. Ej. Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (p. Ej. Soporte de máquinas vectoriales (SVM), K Vecinos más cercanos (K-NN) Agrupación, redes neuronales, regresión logística o Winnow [16] [4] [23]). El filtrado colaborativo va más allá del simplemente usar contenido de documento para recomendar elementos a un usuario aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. La heurística basada en la memoria y los enfoques basados en modelos se han utilizado en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este documento contribuye a la investigación de recomendación basada en el contenido al mejorar la eficiencia y la efectividad de los modelos lineales jerárquicos bayesianos, que tienen una sólida base teórica y un buen rendimiento empírico en las tareas de recomendación [27] [25]. Este documento no tiene la intención de comparar el filtrado basado en contenido con filtrado colaborativo o afirmar cuál es mejor. Creemos que cada uno complementa al otro, y ese filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/elementos con poco o ningún comentario de los usuarios. Similar a algunos otros investigadores [18] [1] [21], encontramos que un sistema de recomendación será más efectivo cuando se combinen ambas técnicas. Sin embargo, esto está más allá del alcance de este documento y, por lo tanto, no se discute aquí.3. La regresión lineal jerárquica bayesiana supone que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario del historial de usuarios. En el resto de este documento, utilizaremos las siguientes anotaciones para representar las variables en el sistema.M = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios.WM: El parámetro del modelo de usuario asociado con el usuario m.WM es un vector dimensional K.J = 1, 2, ..., JM: el índice para un conjunto de datos para el usuario m.JM es el número de datos de capacitación para el usuario m.Dm = {(xm, j, ym, j)}: un conjunto de datos asociados con el usuario m.XM, J es un vector dimensional K que representa el MTH Usuarios JTH Training Document.2 ym, J es un escalar que representa la etiqueta del documento XM, j.k = 1, 2, ..., k: el índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano se ha utilizado ampliamente en aplicaciones de recuperación de información del mundo real. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, se usan comúnmente y han logrado un buen rendimiento en el filtrado colaborativo [25] y las tareas de filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio WM. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P (W | φ). El sistema puede predecir la etiqueta del usuario y de un documento X dada una estimación de WM (o distribución de WMS) utilizando una función y = f (x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando Y = F (WT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario WM, el sistema puede pedir prestada información de otros usuarios a través del anterior φ = (µ, σ). Ahora observamos un modelo comúnmente utilizado donde y = wt x +, donde ∼ n (0, σ2) es un ruido aleatorio [25] [27]. Suponga que cada modelo de usuario WM es un sorteo independiente de una distribución de población P (W | φ), que se rige por algún hiperparámetro desconocido φ. Deje que la distribución previa del modelo de usuario W sea una distribución gaussiana con el parámetro φ = (µ, σ), que es el previo comúnmente utilizado para modelos lineales.µ = (µ1, µ2, ..., µK) es un vector k dimensional que representa la media de la distribución gaussiana, y σ es la matriz de covarianza del gaussiano. Por lo general, una distribución normal n (0, ai) y una distribución inversa de wishart p (σ) ∝ | σ | - 1 2 b exp (−1 2 ctr (σ - 1)) se usan como hiperprior para modelar la distribución previa deµ y σ respectivamente. I es la matriz de identidad dimensional K, y A, B y C son números reales. Con estas configuraciones, tenemos el siguiente modelo para el sistema: 1. µ y σ se muestrean a partir de n (0, ai) e iwν (ai), respectivamente.2 La primera dimensión de X es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionado en el documento y el modelo de usuario, WM, asociado con el usuario m.Los usuarios comparten información sobre sus modelos a través del anterior, φ = (µ, σ).2. Para cada usuario M, WM se muestrean aleatoriamente a partir de una distribución normal: WM ∼ N (µ, σ2) 3. Para cada ítem XM, J, YM, J se muestrean aleatoriamente de una distribución normal: YM, J ∼ N (WT MXM, J, σ2). Deje θ = (φ, w1, w2, ..., wm) representan los parámetros de este sistema que deben estimarse. La probabilidad conjunta para todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P (D, θ) = P (φ) M P (Wm | φ) J P (YM, J | XM, J, wm) (1) Por simplicidad, suponemos que A, B, C y σ se proporcionan al sistema.4. Aprendizaje de parámetros del modelo Si se conoce el φ anterior, encontrar el WM óptimo es sencillo: es una regresión lineal simple. Por lo tanto, nos centraremos en estimar φ. La solución a priori máxima de φ viene dada por φmap = arg max φ p (φ | d) (2) = arg max φ p (φ, d) p (d) (3) = arg max φ p (d | φ) P (φ) (4) = arg max φ w p (d | w, φ) p (w | φ) p (φ) dw (5) Encontrar la solución óptima para el problema anterior es un desafío, ya que necesitamosIntegrar sobre todo W = (W1, W2, ..., WM), que son variables ocultas no observadas.4.1 Algoritmo EM para modelos lineales jerárquicos bayesianos en la ecuación 5, φ es el parámetro que debe estimarse, y el resultado depende de variables latentes no observadas w.Este tipo de problema de optimización generalmente se resuelve mediante el algoritmo EM. Aplicando Em al problema anterior, el conjunto de modelos de usuario W son las variables ocultas no observables y tenemos: Q = W P (W | µ, σ2, DM) log P (µ, σ2, W, D) DW basado en elDerivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de maximización de expectativas para encontrar los hiperparámetros óptimos. Para las consideraciones de espacio, omitimos la derivación en este documento, ya que no es el foco de nuestro trabajo. E PASO: Para cada usuario m, estime la distribución del modelo de usuario P (WM | DM, φ) = N (Wm; ¯wm, σ2 m) basado en la estimación actual del anterior φ = (µ, σ2).¯WM = (((σ2) −1 + sxx, m σ2) −1 (sxy, m σ2 + (σ2) −1 µ)(7) Donde SXX, M = J XM, JXT M, J SXY, M = J XM, JYM, J M Paso: Optimice el anterior φ = (µ, σ2) en función de la estimación del último paso E.µ = 1 m m ¯wm (8) σ2 = 1 m m σ2 m + (¯wm - µ) (¯wm - µ) t (9) Muchos sistemas IR impulsados por el aprendizaje automático usan una estimación puntual de los parámetros en diferentes etapasen el sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de WM a los datos de los usuarios en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10].4.2 Nuevo algoritmo: EM modificado Aunque el algoritmo EM está ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizando el proceso EM anterior para resolver modelos lineales jerárquicos bayesianos en los sistemas de recuperación de información a gran escala todavía es demasiado costoso. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introduce una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje se basará en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza σ2, σ2 m generalmente son demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre las características. Por lo tanto, aproximamos estas matrices con k dimensionales matrices diagonales. En el resto del documento, usamos estos símbolos para representar sus aproximaciones diagonales: σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 k    σ2 m =     σ2 m, 1 0 .. 0 0 σ2 m, 2 .. 0 .. .. .. 0 0 .. σ2 m, k    en segundo lugar, y la mayoríaEs importante destacar que el espacio de entrada es muy escaso y hay muchas dimensiones que no están relacionadas con un usuario en particular en una aplicación IR real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada X que representa una película en particular. Para la película JTH que el usuario M ha visto, Let XM, J, K = 1 si el director de la película es Jean-Pierre Jeunet (indexado por K). Aquí suponemos que si este director dirigió o no una película específica está representada por la dimensión KTH. Si el usuario M nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente es siempre cero (xm, j, k = 0 para todo j). Un gran inconveniente del algoritmo EM es que la importancia de una característica, µK, puede estar muy dominada por usuarios que nunca han encontrado esta característica (es decir, J XM, J, K = 0) en el paso M (Ecuación 8). Suponga que 100 de 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, es un buen director y el peso para él (µK) debería ser alto. Antes de la iteración EM, el valor inicial de µ generalmente se establece en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (W1, K, W2, K, ..., Wm, K ..., W999900, k) para ese director sería muy pequeño inicialmente. Por lo tanto, el peso correspondiente del director en el µK anterior en el primer paso m sería muy bajo, y la varianza σm, K será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyen tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lento. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin una pérdida de generalidad, supongamos que la dimensión KTH de la variable de entrada x no está relacionada con un usuario en particular m.Por lo que queremos decir, xm, j, k = 0 para todos j = 1, ..., jm. Es sencillo demostrar que la fila KTH y la columna KTH de SXX, M están completamente llenas de ceros, y que la dimensión KTH de SXY, M también está a cero. Por lo tanto, la dimensión KTH correspondiente de los modelos de usuario significa, ¯wm, debe ser igual a la del anterior: ¯wm, k = µK, con la covarianza correspondiente de σm, k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P (WM | DM, φ) estimada en E PASO (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm, k y σm, k cuando la dimensión KTH no está relacionada con el usuario MTH. Un mejor enfoque es utilizar las soluciones analíticas ¯wm, k = µK y σm, k = σk para los pares no relacionados (M, K), junto con la solución numérica estimada en el paso E para los otros pares (M, K). Por lo tanto, obtenemos el siguiente nuevo algoritmo similar a EM: paso E modificado: para cada usuario m, estimar la distribución del modelo de usuario P (WM | DM, φ) = n (Wm; ¯wm, σ2 m) basado en la estimación actual deσ, µ, σ2.¯wm = ((σ2) −1 + sxx, m σ2) −1 (sxy, m σ2 + (σ2) −1 µ) (10) σ2 m, k = ((σ2 k) −1 + sxx, m,k σ2) −1 (11) donde sxx, m, k = j x2 m, j, k y sxy, m, k = j xm, j, kym, j paso modificado M paso optimizar el anterior φ = (µ, σ2)Basado en la estimación del último paso E para pares de información de usuario relacionados. El paso M utiliza implícitamente la solución analítica para pares de características de usuario no relacionadas.µk = 1 mk m: ¯wm relacionado, k (12) σ2 k = 1 mk m: relacionado σ2 m, k +(¯wm, k - µk) (¯wm, k - µK) t (13) donde mk esEl número de usuarios relacionados con la característica K solo estimamos la diagonal de σ2 m y σ ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones relacionadas con el usuario m.Para estimar σ2 K y µK, solo resumimos a los usuarios relacionados con la función KTH. Hay dos beneficios principales del nuevo algoritmo. Primero, debido a que solo se necesitan los pares relacionados (M, K) en el paso M modificado, la complejidad computacional en una sola iteración EM es mucho menor cuando los datos son escasos, y muchos de los pares (M, K) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque las soluciones analíticas exactas ¯wm, k = µK y σm, k = σk para los no relacionados (M, k) Se usaron pares en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar.5. Metodología experimental 5.1 Conjunto de datos de evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de Movielens: este conjunto de datos se creó combinando los juicios de relevancia del conjunto de datos de Movielens [9] con documentos delBase de datos de películas de Internet (IMDB). Movielens permite a los usuarios clasificar cuánto disfrutó de una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medición de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos documentos con puntajes de simpatía de 4 o 5 como relevantes, y documentos con un puntaje de 1 a 3 como irrelevante para el usuario. Movielens proporcionó juicios de relevancia en 3.057 documentos de 6.040 usuarios separados. En promedio, cada usuario calificó 151 películas, de estas 87 se consideró relevante. El puntaje promedio para un documento fue de 3.58. Los documentos que representan cada película se construyeron a partir de la parte de la base de datos IMDB que está disponible para la descarga pública [13]. Según esta base de datos, creamos un documento por película que contenía la información relevante al respecto (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificación para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Usuarios de datos Documentos de documentos por usuario MOVIELENS 6,040 3,057 151 Netflix-All 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Esto: esto: ESTO: ESTO: ESTO INTERIOR DE LA VEUTERS-1632 REUTERS-G 33 100,000 2222 REUTERS-M 10 100,000 6529 DATOS NETFLIX: ESTO: ESTO: ESTO ESTO: ESTO ESTO: ESTO ESTA CONTERECTORES DELEl conjunto de datos se construyó combinando documentos sobre películas que se arrastran desde la web con un conjunto de juicios de relevancia del cliente de alquiler de películas reales de Netflix [19]. Netflix proporciona públicamente los juicios de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala de 1 a 5 para 17,770 documentos. Similar a Movielens, consideramos documentos con puntajes de simpatía de 4 o 5 como relevantes. Este número se redujo a 1000 clientes a través de un muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, y 70 se consideran relevantes. El puntaje promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 historias de noticias en inglés Reuters del 20 de agosto de 1996 al 19 de agosto de 1997. Solo se usaron las primeras 100,000 noticias en nuestros experimentos. El Corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a uno de varios lugares en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este documento, el árbol se cortó en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño.: Reuters-e Reuters-C, Reutersm y Reuters-G.Para cada pequeño conjunto de datos, creamos varios perfiles, un perfil para cada nodo en un sub-árbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Se supone que todos los perfiles de usuario en un sub-árbol comparten la misma distribución del modelo anterior. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes.5.2 Evaluación diseñamos los experimentos para responder las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo para usar un enfoque bayesiano y aprender un anterior de otros usuarios?2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano?3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuarios? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con modelos de regresión lineal regularizados de normas-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración em. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde se deben aprender juntos aproximadamente medio millón de modelos de usuarios. Para los conjuntos de datos de Movielens y Netflix, la efectividad del algoritmo se midió por error medio cuadrado, mientras que en el error de clasificación de datos de Reuters se utilizó porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual y luego estimamos el promedio macro en todos los usuarios. Las pruebas estadísticas (pruebas t) se llevaron a cabo para ver si los resultados son significativos. Para los experimentos en los conjuntos de datos de Movielens y Netflix, utilizamos una muestra aleatoria de 90% de cada usuario para capacitación y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para la capacitación y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecemos (A, B, C, σ) = (0.1, 10, 0.1, 1) manualmente.6. Resultados experimentales La Figura 2, la Figura 3 y la Figura 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadística significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. El análisis posterior muestra una correlación negativa entre el número de datos de capacitación para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información de préstamo de otros usuarios tiene mejoras más significativas para los usuarios con menos datos de capacitación, lo cual es el esperado. Sin embargo, la fuerza de la correlación difiere sobre los conjuntos de datos, y la cantidad de datos de entrenamiento no son las únicas características que influirán en el rendimiento final. La Figura 2 y la Figura 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y Movielens. Esto no es sorprendente ya que el número de pares de usuarios de características relacionados es mucho menor que el número de pares de funciones no relacionados en estos dos conjuntos de datos, y por lo tanto se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis posterior muestra que solo el 58% de los pares de características de usuario no están relacionados con este conjunto de datos. Dado que el número de pares de funciones de usuario no relacionados no es extremadamente grande, la escasez no es un problema grave en el conjunto de datos de Reuters. Así, los dos algoritmos de aprendizaje funcionan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares de funciones de usuario no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se mantiene, el nuevo algoritmo no perjudica el rendimiento. Aunque la técnica propuesta es más rápida que la Figura 2 estándar: rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadístico significativamente mejor que el algoritmo EM en las iteraciones 2 - 10. Los modelos lineales regularizados de Norm-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticas significativamente peores que los modelos jerárquicos bayesianos.0 2 4 6 8 10 1 1.05 1.1 1.15 1.2 1.25 1.3 1.35 1.4 iteraciones Subles Significador Nuevo algoritmo tradicional EM 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Clasificación de iteraciones Sorror Nuevo Algoritmo tradicional EM Figura 3: rendimiento en unMOVIELENS subconjunto con 1,000 usuarios. El nuevo algoritmo es estadístico significativamente mejor que el algoritmo EM en la iteración 2 a 17 (evaluado con un error cuadrado medio).1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iterations significa Curar algoritmo nuevo tradicional EM 1 6 11 16 21 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Clasificación de iteraciones El nuevo algoritmo tradicional EM Figura 4: rendimiento en un subconjunto de reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares.1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 iteraciones significa QuarareRor nuevo algoritmo tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 clasificaciones de iteraciones Strensor New algoritmo EMM tradicional EM, ¿puede realmente aprender? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2 a 3 iteraciones EM modificadas darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de calificaciones) que se ejecutan en una sola PC de CPU (memoria de 2 GB, P4 3GHz). El sistema terminó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente un sistema a gran escala como Netflix.7. Conclusión El aprendizaje de perfil de usuario basado en contenido es un problema importante y es la clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un importante enfoque de aprendizaje de perfil de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de los otros usuarios a través de hiperpriors. Este documento examinó la debilidad del popular enfoque de aprendizaje basado en EM para los modelos lineales jerárquicos bayesianos y propuso una mejor técnica de aprendizaje llamada Modified EM. Mostramos que la nueva técnica es teóricamente más computacionalmente eficiente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de Movielens y Netflix demostró la efectividad de la nueva técnica cuando los datos son escasos, por lo que nos referimos a la relación de pares de características de usuario relacionadas con pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica se realizó de manera similar al algoritmo EM estándar cuando la condición de escasez no se mantiene. En general, es mejor usar el nuevo algoritmo ya que es tan simple como EM estándar, el rendimiento es mejor o similar al EM, y la complejidad del cálculo es menor en cada iteración. Vale la pena mencionar que incluso si el espacio de problemas original no es escaso, la escasez se puede crear artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo de usuario. La técnica propuesta también se puede adaptar para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario de 100 millones de calificaciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores cuando utilizan el enfoque de modelado lineal jerárquico bayesiano para construir un sistema práctico de gran escala, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas y, por lo tanto, acelerar aún más el proceso de aprendizaje para manejar un sistema de mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas que usan el algoritmo EM en muchos otros problemas de IR, así como problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático de uso común. Se utiliza para encontrar parámetros del modelo en muchos problemas IR donde los datos de entrenamiento son muy escasos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para la recomendación y el filtrado, la nueva idea de usar una solución analítica en lugar de una solución numérica para pares de características de usuario no relacionadas en el paso M podría adaptarse a muchos otros problemas.8. Agradecimientos Agradecemos a Wei Xu, David Lewis y revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este documento. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos de Petascale y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgos, conclusiones o recomendaciones expresadas en este material son las de los autores, y no reflejan necesariamente las de los patrocinadores.9. Referencias [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: utilizando información social y basada en el contenido en recomendación. En Actas de la Decimocuarta Conferencia Nacional sobre Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para el filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Décima Décima Conferencia Internacional Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte,T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Textos (TREC11). Instituto Nacional de Normas y Tecnología, Publicación Especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: pequeños datos pueden ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional.[6] B. Croft y J. Lafferty, editores. Modelado de idiomas para la recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construcción de distribuciones previas informativas a partir del conocimiento del dominio en la clasificación de texto. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press.[8] J. Delgado y N. Ishii. Predicción de modificación ponderada basada en la memoria para sistemas de recomendación. En el taller ACM SIGIR99 en Sistemas de recomendación, 1999. [9] Grouplens. Movielens.http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre aprendizaje con redes bayesianas. En M. Jordan, editor, aprendizaje en modelos gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar un filtrado colaborativo. En Sigir 99: Actas de la 22a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press.[12] T. Hofmann y J. Puzicha. Modelos de clase latente para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas de Internet.http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para el filtrado colaborativo. En Sigir 04: Actas de la 27ª Conferencia Anual Internacional de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press.[15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. Grouplens: aplicando filtrado colaborativo a Usenet News. Comunicaciones de la ACM, 40 (3): 77-87, 1997. [16] D. Lewis. Aplicación de máquinas de vectores de soporte a las tareas de filtrado y enrutamiento de lotes TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Textos (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto etiquetando palabras. En Actas de la Decimonovena Conferencia Nacional sobre Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo estimado por contenido para obtener recomendaciones mejoradas. En Actas de la Decimura Conferencia Nacional sobre Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix.http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, Volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificación de enfoques de filtrado colaborativo basados en el usuario y basados en elementos por fusión de similitud. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press.[22] X. Wu y R. K. Srihari. Incorporando conocimiento previo con máquinas de vectores de soporte de margen ponderado. En Proc. ACM Knowledge Discovery Data Mining Conf.(ACM Sigkdd 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de bencillo. En Actas de la 28ª Conferencia Internacional de ACM Sigir sobre investigación y desarrollo en recuperación de información, 2005. [24] K. Yu, V. Tresp y A. Schwaighfer. Aprender procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª Conferencia Internacional sobre Aprendizaje Autor, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press.[25] K. Yu, V. Tresp y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En Sigir 04: Actas de la 27ª Conferencia Internacional de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. Encuesta de literatura de aprendizaje semi-supervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. zigoris e Y. Zhang. Profiles de usuarios adaptativos bayesianos con retroalimentación explícita e implícita. En Conferencias sobre Información y Mangment de Conocimiento 2006, 2006.