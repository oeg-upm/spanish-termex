Modelado de usuario implícito para la búsqueda personalizada Xuehua Shen, Bin Tan, Chengxiang Zhai Departamento de Ciencias de la Computación de la Universidad de Illinois en Urbana-Champaign Sistemas de recuperación de información de resúmenes (por ejemplo, motores de búsqueda web) son críticos para superar la sobrecarga de información. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuarios y no se adaptan a los usuarios individuales, lo que resulta en un rendimiento de recuperación inherentemente no óptimo. Por ejemplo, un turista y un programador pueden usar la misma palabra Java para buscar información diferente, pero los sistemas de búsqueda actuales devolverían los mismos resultados. En este documento, estudiamos cómo inferir el interés de los usuarios en el contexto de búsqueda de usuarios y utilizar el modelo de usuario implícito inferido para la búsqueda personalizada. Presentamos un marco teórico de decisión y desarrollamos técnicas para el modelado implícito de usuarios en la recuperación de información. Desarrollamos un agente de búsqueda web inteligente del lado del cliente (UCAIR) que puede realizar comentarios ansiosos implícitos, por ejemplo, expansión de consultas basada en consultas anteriores y resultados de resultados inmediatos en función de la información de clics. Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en el popular motor de búsqueda de Google. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: modelos de recuperación, retroalimentación de relevancia, proceso de búsqueda de términos generales Algoritmos 1. Introducción Aunque muchos sistemas de recuperación de información (por ejemplo, motores de búsqueda web y sistemas de biblioteca digital) se han implementado con éxito, los sistemas de recuperación actuales están lejos de ser óptimos. Una deficiencia importante de los sistemas de recuperación existentes es que generalmente carecen de modelado de usuarios y no se adaptan a los usuarios individuales [17]. Esta no óptima inherente se ve claramente en los siguientes dos casos: (1) diferentes usuarios pueden usar exactamente la misma consulta (por ejemplo, Java) para buscar información diferente (por ejemplo, la isla Java en Indonesia o el lenguaje de programación de Java),Pero los sistemas IR existentes devuelven los mismos resultados para estos usuarios. Sin considerar al usuario real, es imposible saber a qué sentido se refiere Java en una consulta.(2) Las necesidades de información de los usuarios pueden cambiar con el tiempo. El mismo usuario puede usar Java a veces para significar la isla Java en Indonesia y otras veces para significar el lenguaje de programación. Sin reconocer el contexto de búsqueda, sería nuevamente imposible reconocer el sentido correcto. Para optimizar la precisión de la recuperación, claramente necesitamos modelar al usuario de manera adecuada y personalizar la búsqueda de acuerdo con cada usuario individual. El objetivo principal del modelado de usuarios para la recuperación de la información es modelar con precisión una necesidad de información de los usuarios, lo cual es, desafortunadamente, una tarea muy difícil. De hecho, es difícil para un usuario describir con precisión cuál es su información. ¿Qué información está disponible para un sistema para inferir la necesidad de la información del usuario? Obviamente, la consulta de usuarios proporciona la evidencia más directa. De hecho, la mayoría de los sistemas de recuperación existentes dependen únicamente de la consulta para modelar una necesidad de información del usuario. Sin embargo, dado que una consulta a menudo es extremadamente corta, el modelo de usuario construido en función de una consulta de palabras clave está inevitablemente empobrecida. Una forma efectiva de mejorar el modelado de los usuarios en la recuperación de la información es pedirle al usuario que especifique explícitamente qué documentos son relevantes (es decir, útiles para satisfacer su necesidad de información) y luego mejorar el modelado del usuario en función de tales ejemplos de documentos relevantes. Esto se llama retroalimentación de relevancia, que se ha demostrado que es bastante efectivo para mejorar la precisión de la recuperación [19, 20]. Desafortunadamente, en las aplicaciones del mundo real, los usuarios generalmente son reacios a hacer el esfuerzo adicional para proporcionar ejemplos relevantes para la retroalimentación [11]. Por lo tanto, es muy interesante estudiar cómo inferir la necesidad de la información de los usuarios en función de cualquier información de retroalimentación implícita, que naturalmente existe a través de las interacciones del usuario y, por lo tanto, no requiere ningún esfuerzo adicional del usuario. De hecho, varios estudios anteriores han demostrado que el modelado implícito de los usuarios puede mejorar la precisión de la recuperación. En [3], se desarrolla un navegador web (navegador curioso) para registrar las clasificaciones de relevancia explícita de los usuarios de las páginas web (retroalimentación de relevancia) y el comportamiento de navegación al ver una página, como la hora de la vivienda, el clic del mouse, el movimiento del mouse y el desplazamiento (implícitocomentario). Se muestra que el tiempo de vivienda en una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una fuerte correlación con calificaciones de relevancia explícita, lo que sugiere que la retroalimentación implícita puede ser útil para inferir la necesidad de la información del usuario. En [10], los datos de clics del usuario se recopilan como datos de capacitación para aprender una función de recuperación, que se utiliza para producir una clasificación personalizada de resultados de búsqueda que se adapte a un grupo de preferencias de usuarios. En [25], los datos de clics recopilados durante un largo período de tiempo se explotan a través de la expansión de la consulta para mejorar la precisión de la recuperación.824 Si bien un usuario puede tener intereses y preferencias generales a largo plazo por información, a menudo está buscando documentos para satisfacer una necesidad de información ad-hoc, que solo dura un corto período de tiempo;Una vez que se satisfaga la necesidad de la información, el usuario generalmente ya no estaría interesado en dicha información. Por ejemplo, un usuario puede estar buscando información sobre los automóviles usados para comprar uno, pero una vez que el usuario ha comprado un automóvil, generalmente ya no está interesado en dicha información. En tales casos, es poco probable que la información de retroalimentación implícita recopilada durante un largo período de tiempo sea muy útil, pero se puede esperar que el contexto de búsqueda inmediata y la información de retroalimentación, como cuáles de los resultados de búsqueda para la información actual.mucho más útil. Considere la consulta Java nuevamente. Cualquiera de la siguiente información de comentarios inmediatos sobre el usuario podría ayudar a determinar el significado previsto de Java en la consulta: (1) La consulta anterior presentada por el usuario es hashtable (a diferencia de, por ejemplo, Viaje Indonesia).(2) En los resultados de la búsqueda, el usuario vio una página donde las palabras como la programación, el software y el applet ocurren muchas veces. Hasta donde sabemos, cómo explotar dicho contexto de búsqueda inmediata y a corto plazo para mejorar la búsqueda hasta ahora no se ha abordado bien en el trabajo anterior. En este documento, estudiamos cómo construir y actualizar un modelo de usuario basado en el contexto de búsqueda inmediata y la información de retroalimentación implícita y usar el modelo para mejorar la precisión de la recuperación ad-hoc. Para beneficiar al tanto al usuario de un sistema de recuperación a través del modelado implícito de los usuarios, proponemos realizar comentarios ansiosos implícitos. Es decir, tan pronto como observamos cualquier nueva evidencia del usuario, actualizaríamos la creencia de los sistemas sobre la necesidad de la información de los usuarios y respondemos con resultados de recuperación mejorados basados en el modelo de usuario actualizado. Presentamos un marco teórico de decisión para optimizar la recuperación de información interactiva basada en una actualización de modelo de usuario ansiosa, en el que el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. En un paradigma de recuperación tradicional, el problema de recuperación es igualar una consulta con documentos y documentos de rango de acuerdo con sus valores de relevancia. Como resultado, el proceso de recuperación es un ciclo independiente simple de consulta y visualización de resultados. En el nuevo paradigma de recuperación propuesto, el contexto de búsqueda de usuarios juega un papel importante y el modelo de usuario implícito inferido se explota de inmediato para beneficiar al usuario. El nuevo paradigma de recuperación es, por lo tanto, fundamentalmente diferente del paradigma tradicional, y es inherentemente más general. Además, proponemos técnicas específicas para capturar y explotar dos tipos de información de retroalimentación implícita: (1) Identificar la consulta inmediatamente anterior y utilizada de la consulta y los resultados de búsqueda correspondientes para seleccionar los términos apropiados para expandir la consulta actual, y (2) explotar la vista vistaDocumente resúmenes para volver a revisar inmediatamente cualquier documento que el usuario aún no haya visto. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente UCAIR (recuperación de información adaptativa centrada en el usuario) además de un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de búsqueda en Google. Dado que la información implícita que explotamos ya existe naturalmente a través de las interacciones del usuario, el usuario no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de búsqueda web existente sin un esfuerzo adicional del usuario. Las secciones restantes se organizan de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, presentamos un marco de recuperación interactiva teórica de decisión para el modelado implícito de usuarios. En la Sección 4, presentamos el diseño e implementación de un agente de búsqueda web inteligente del lado del cliente (UCAIR) que realiza comentarios ansiosos implícitos. En la Sección 5, informamos los resultados de nuestros experimentos utilizando el agente de búsqueda. La Sección 6 concluye nuestro trabajo.2. Trabajo relacionado Modelado implícito de usuarios para búsqueda personalizada se ha estudiado en trabajos anteriores, pero nuestro trabajo difiere de todos los trabajos anteriores en varios aspectos: (1) enfatizamos la explotación del contexto de búsqueda inmediata, como la consulta inmediatamente anterior.La misma sesión, mientras que la mayoría del trabajo anterior se basa en la recopilación a largo plazo de información de retroalimentación implícita [25].(2) Realizamos comentarios ansiosos y brindamos el beneficio del modelado implícito de los usuarios tan pronto como cualquier nueva información de retroalimentación implícita esté disponible, mientras que el trabajo anterior explota principalmente comentarios implícitos a largo plazo [10].(3) Proponemos un marco de recuperación para integrar el modelado implícito de los usuarios con el proceso de recuperación interactivo, mientras que el trabajo anterior estudia modelado implícito de usuarios por separado de la recuperación [3] o solo estudia modelos de recuperación específicos para explotar la retroalimentación implícita para igualar una consulta con una consulta conDocumentos [23, 27, 22].(4) Desarrollamos y evaluamos un agente de búsqueda web personalizado con estudios de usuarios en línea, mientras que la mayoría del trabajo existente evalúa los algoritmos fuera de línea sin interacciones reales del usuario. Actualmente, algunos motores de búsqueda proporcionan personalización rudimentaria, como la búsqueda web personalizada de Google [6], que permite a los usuarios describir explícitamente sus intereses seleccionando de temas predefinidos, de modo que esos resultados que coincidan con sus intereses se llevan a la cima y mi Yahoo!Buscar [16], que brinda a los usuarios la opción de guardar los sitios web que les gustan y bloquear a los que no les gustan. En contraste, UCAIR personaliza la búsqueda web a través del modelado de usuarios implícito sin ningún esfuerzo de usuario adicional. Además, la personalización de UCAIR se proporciona en el lado del cliente. Hay dos ventajas notables sobre esto. Primero, el usuario no necesita preocuparse por la infracción de privacidad, lo cual es una gran preocupación para la búsqueda personalizada [26]. En segundo lugar, tanto el cálculo de la personalización como el almacenamiento del perfil de usuario se realizan en el lado del cliente para que la carga del servidor se reduzca drásticamente [9]. Ha habido muchos trabajos que estudian registros de consultas de usuario [1] o dinámica de consultas [13]. UCAIR hace un uso directo de un historial de consultas de usuarios para beneficiar al mismo usuario inmediatamente en la misma sesión de búsqueda. UCAIR primero juzga si dos consultas vecinas pertenecen a la misma sesión de información y, de ser así, selecciona los términos de la consulta anterior para realizar la expansión de la consulta. Nuestro enfoque de expansión de la consulta es similar a la expansión automática de consultas [28, 15, 5], pero en lugar de usar pseudo retroalimentación para expandir la consulta, utilizamos la información de retroalimentación implícita de los usuarios para expandir la consulta actual. Estas dos técnicas pueden combinarse.3. Optimización en IR interactivo en IR Interactive, un usuario interactúa con el sistema de recuperación a través de un diálogo de acción, en el que el sistema responde a cada acción del usuario con alguna acción del sistema. Por ejemplo, la acción de los usuarios puede estar enviando una consulta y la respuesta de los sistemas puede devolver una lista de 10 resúmenes de documentos. En general, el espacio de las acciones del usuario y las respuestas del sistema y sus granularidades dependerían de la interfaz de un sistema de recuperación particular. En principio, cada acción del usuario puede proporcionar una nueva evidencia para ayudar al sistema a inferir mejor que la necesidad de la información del usuario. Por lo tanto, para responder de manera óptima, el sistema debe usar toda la evidencia recopilada hasta ahora sobre el usuario al elegir una respuesta. Cuando se ve de esta manera, la mayoría de los motores de búsqueda existentes son claramente no óptimos. Por ejemplo, si un usuario ha visto algunos documentos en la primera página de los resultados de búsqueda, cuando el usuario hace clic en el siguiente enlace para obtener más resultados, un sistema de recuperación existente aún devolvería la siguiente página de resultados recuperados en función de la consulta original sinTeniendo en cuenta la nueva evidencia de que el usuario ha visto un resultado particular.825 Proponemos optimizar el rendimiento de la recuperación mediante la adaptación de las respuestas del sistema en función de cada acción que haya tomado un usuario, y emitir el problema de optimización como una tarea de decisión. Específicamente, en cualquier momento, el sistema intentaría hacer dos tareas: (1) Actualización del modelo de usuario: monitoree cualquier evidencia útil del usuario con respecto a su necesidad de información y actualice el modelo de usuario tan pronto como dicha evidencia esté disponible;(2) Mejora de los resultados de la búsqueda: vuelva a estar inmediatamente todos los documentos que el usuario aún no ha visto, tan pronto como se actualiza el modelo de usuario. Hacemos hincapié en la actualización ansiosa y la resonancia, lo que hace que nuestro trabajo sea bastante diferente de cualquier trabajo existente. A continuación presentamos un marco teórico de decisión formal para optimizar el rendimiento de la recuperación a través del modelado implícito de usuarios en la recuperación de información interactiva.3.1 Un marco teórico de decisión de que A sea el conjunto de todas las acciones del usuario y r (a) sea el conjunto de todas las respuestas del sistema posibles a una acción del usuario a ∈ A. En cualquier momento, deje que AT = (a1, ..., at) sea la secuencia observada de acciones del usuario hasta ahora (hasta el punto de tiempo t) y rt - 1 = (r1, ..., rt - 1) ser elRespuestas que el sistema ha respondido a las acciones del usuario. El objetivo de los sistemas es elegir una respuesta óptima rt ∈ R (AT) para la acción del usuario actual AT. Sea M el espacio de todos los modelos de usuarios posibles. Definimos además una función de pérdida l (a, r, m) ∈, donde a ∈ A es una acción del usuario, r ∈ R (a) es una respuesta del sistema, y m ∈ M es un modelo de usuario. L (A, R, M) codifica nuestras preferencias de decisión y evalúa la optimización de responder con R cuando el modelo de usuario actual es M y la acción actual del usuario es a. Según la teoría de la decisión bayesiana, la decisión óptima en el momento t es elegir una respuesta que minimice el riesgo de Bayes, es decir, r ∗ t = argmin r∈R (at) m l (at, r, mt) p (mt | u,D, at, rt - 1) dmt (1) donde p (mt | u, d, at, rt - 1) es la probabilidad posterior del modelo de usuario mt dada todas las observaciones sobre el usuario que hemos hecho hasta el tiempot.Para simplificar el cálculo de la ecuación 1, supongamos que la masa de probabilidad posterior P (mt | u, d, at, rt - 1) se concentra principalmente en el modo m ∗ t = argmaxmt p (mt | u, d, at, a, Rt - 1). Luego podemos aproximar la integral con el valor de la función de pérdida en m ∗ t. Es decir, r ∗ t ≈ argminr∈R (at) l (at, r, m ∗ t) (2) donde m ∗ t = argmaxmt p (mt | u, d, at, rt - 1). Dejando de lado cómo definir y estimar estos modelos probabilísticos y la función de pérdida, podemos ver que dicha formulación teórica de decisión sugiere que, para elegir la respuesta óptima a AT, el sistema debe realizar dos tareas: (1) Calcule laModelo de usuario actual y obtener M ∗ T basado en toda la información útil.(2) Elija una respuesta RT para minimizar el valor de la función de pérdida L (AT, RT, M ∗ T). Cuando AT no afecta nuestra creencia sobre M ∗ t, el primer paso se puede omitir y podemos reutilizar M ∗ t - 1 para m ∗ t. Tenga en cuenta que nuestro marco es bastante general ya que podemos modelar cualquier tipo de acciones de usuario y respuestas del sistema. En la mayoría de los casos, como esperamos, la respuesta de los sistemas es una clasificación de documentos, es decir, para la mayoría de las acciones A, R (a) consiste en todas las clasificaciones posibles de los documentos invisibles, y el problema de decisión se reduce a elegir lo mejorClasificación de documentos invisibles basados en el modelo de usuario más actual. Cuando A es la acción de enviar una consulta de palabras clave, dicha respuesta es exactamente lo que haría un sistema de recuperación actual. Sin embargo, podemos imaginar fácilmente que un motor de búsqueda web más inteligente respondería a los usuarios haciendo clic en el siguiente enlace (para obtener resultados más invisibles) con una clasificación más optimizada de documentos basados en cualquier documento visto en la página actual de resultados. De hecho, de acuerdo con nuestra ansiosa estrategia de actualización, incluso podemos permitir que un sistema responda a los usuarios que hacen clic en el botón de retroceso de los navegadores después de ver un documento de la misma manera, para que el usuario pueda beneficiarse al máximo de la retroalimentación implícita. Estos son precisamente lo que hace nuestro sistema UCAIR.3.2 Modelos de usuario Un modelo de usuario M ∈ M representa lo que sabemos sobre el usuario U, por lo que, en principio, puede contener cualquier información sobre el usuario que deseamos modelar. Ahora discutimos dos componentes importantes en un modelo de usuario. El primer componente es un modelo de componente de la necesidad de información del usuario. Presumiblemente, el factor más importante que afecta la optimización de la respuesta de los sistemas es qué tan bien la respuesta aborda la información de los usuarios que necesita. De hecho, en cualquier momento, podemos suponer que el sistema cree en lo que el usuario está interesado, que modelamos a través de un término vector x = (x1, ..., x | v |), donde v = {w1, ..., W | V |} es el conjunto de todos los términos (es decir, vocabulario) y xi es el peso del término wi. Tal vector de término se usa comúnmente en la recuperación de información para representar consultas y documentos. Por ejemplo, el modelo Vector-Space, supone que tanto la consulta como los documentos se representan como vectores de término y la puntuación de un documento con respecto a una consulta se calcula en función de la similitud entre el vector de consulta y el vector de documento [21]. En un enfoque de modelado de idiomas, también podemos considerar el modelo de lenguaje unigram de consulta [12, 29] o el modelo de relevancia [14] como una representación vectorial de término de la necesidad de información de los usuarios. Intuitivamente, X asignaría altos pesos a los términos que caracterizan los temas que el usuario está interesado. El segundo componente que podemos incluir en nuestro modelo de usuario son los documentos que el usuario ya ha visto. Obviamente, incluso si un documento es relevante, si el usuario ya ha visto el documento, no sería útil presentar el mismo documento nuevamente. Por lo tanto, introducimos otra variable S ⊂ D (d es el conjunto completo de documentos en la colección) para denotar el subconjunto de documentos en los resultados de búsqueda que el usuario ya ha visto/visto. En general, en el momento t, podemos representar un modelo de usuario como mt = (s, x, at, rt - 1), donde s es los documentos vistos, x es la comprensión de los sistemas de la necesidad de información de los usuarios y (at, en,RT - 1) representa el historial de interacción de los usuarios. Tenga en cuenta que un modelo de usuario aún más general también puede incluir otros factores, como el nivel de lectura de los usuarios y la ocupación. Si suponemos que la incertidumbre de un modelo de usuario MT se debe únicamente a la incertidumbre de X, el cálculo de nuestra estimación actual del modelo de usuario M ∗ t implicará principalmente calcular nuestra mejor estimación de x. Es decir, el sistema elegiría una respuesta de acuerdo con r ∗ t = argminr∈R (at) l (at, r, s, x ∗, at, rt - 1) (3) donde x ∗ = argmaxx p (x |U, d, at, rt - 1). Este es el mecanismo de decisión implementado en el sistema UCAIR que se describirá más adelante. En este sistema, evitamos especificar el modelo probabilístico P (X | U, D, AT, RT - 1) calculando X ∗ directamente con algún método de retroalimentación existente.3.3 Funciones de pérdida La definición exacta de la función de pérdida L depende de las respuestas, por lo tanto, es inevitablemente específico de la aplicación. Ahora discutimos brevemente algunas posibilidades cuando la respuesta es clasificar todos los documentos invisibles y presentar el Top K de ellos. Sea r = (d1, ..., dk) los principales documentos k, s como el conjunto de documentos vistos por parte del usuario y x ∗ sea la mejor suposición de los sistemas que la información de los usuarios necesita. 826 podemos simplemente definir la pérdida asociada con R como la suma negativa de la probabilidad de que cada DI sea relevante, es decir, L (a, r, m) = - k i = 1 p (relevante | di, m). Claramente, para minimizar esta función de pérdida, la respuesta óptima R contendría los documentos K con la mayor probabilidad de relevancia, que es intuitivamente razonable. Una deficiencia de esta función de pérdida de Top-K es que no es sensible al orden interno de los documentos K superiores seleccionados, por lo que cambiar el orden de clasificación de un documento no relevante y uno relevante no afectaría la pérdida, lo cual no es razonable. Para la clasificación del modelo, podemos introducir un factor del modelo de usuario: la probabilidad de que cada uno de los documentos K vistas por el usuario, p (Ver | DI) y definir la siguiente función de pérdida de ranking: L (A, R, M) = - k i = 1 p (ver | di) p (relevante | di, m) ya que en general, si di se clasifica arriba dj (es decir, i <j), p (ver | di)> p (ver | dj), esta función de pérdida favorecería la decisión de clasificar los documentos relevantes por encima de los no relevantes, como de lo contrario, siempre podríamos cambiar DI con DJ para reducir el valor de pérdida. Por lo tanto, el sistema debe simplemente realizar una recuperación regular y clasificar documentos de acuerdo con la probabilidad de relevancia [18]. Dependiendo de las preferencias de recuperación de los usuarios, puede haber muchas otras posibilidades. Por ejemplo, si el usuario no desea ver documentos redundantes, la función de pérdida debe incluir una medida de redundancia en R basada en los documentos ya vistos S. Por supuesto, cuando la respuesta no es elegir una lista clasificada de documentos, lo haríamos.Necesita una función de pérdida diferente. Discutimos un ejemplo de este tipo que es relevante para el agente de búsqueda que implementamos. Cuando un usuario ingresa a una consulta QT (acción actual), nuestro agente de búsqueda se basa en algún motor de búsqueda existente para llevar a cabo realmente la búsqueda. En tal caso, a pesar de que el agente de búsqueda no tiene control del algoritmo de recuperación, aún puede intentar optimizar los resultados de búsqueda mediante la refinación de la consulta enviada al motor de búsqueda y/o volver a hacer los resultados obtenidos del motor de búsqueda. Las funciones de pérdida para el rehabilitación ya se discuten anteriormente;Ahora echamos un vistazo a las funciones de pérdida para el refinamiento de la consulta. Sea f la función de recuperación del motor de búsqueda que usa nuestro agente para que F (Q) nos dé los resultados de búsqueda utilizando la consulta q. Dado que la acción actual del usuario está ingresando una consulta Qt (es decir, AT = Qt), nuestra respuesta sería f (q) para algunos q. Como no tenemos otra opción de F, nuestra decisión es elegir una buena q. Formalmente, r ∗ t = argminrt l (a, rt, m) = argminf (q) l (a, f (q), m) = f (argMinql (qt, f (q), m)) que muestra que nuestro nuestroEl objetivo es encontrar Q ∗ = ArgMinql (Qt, F (Q), M), es decir, una consulta óptima que nos daría lo mejor F (Q). Una opción diferente de la función de pérdida L (Qt, F (Q), M) conduciría a una estrategia de refinamiento de consulta diferente. En UCAIR, calculamos heurísticamente Q ∗ expandiendo el QT con términos extraídos de RT - 1 siempre que QT - 1 y QT tengan una alta similitud. Tenga en cuenta que RT - 1 y QT - 1 están contenidos en M como parte del historial de interacción de los usuarios.3.4 Modelado implícito de usuarios El modelado de usuarios implícitos se captura en nuestro marco a través del cálculo de x ∗ = argmaxx p (x | u, d, at, rt - 1), es decir, la creencia actual de los sistemas de lo que la información de los usuarios necesita es. Aquí nuevamente puede haber muchas posibilidades, lo que lleva a diferentes algoritmos para el modelado de usuarios implícitos. Ahora discutimos algunos de ellos. Primero, cuando se relacionan dos consultas consecutivas, la consulta anterior se puede explotar para enriquecer la consulta actual y proporcionar más contexto de búsqueda para ayudar a la desambiguación. Para este propósito, en lugar de realizar la expansión de la consulta como lo hicimos en la sección anterior, también podríamos calcular una X ∗ actualizada basada en los resultados de consulta y recuperación anteriores. El nuevo modelo de usuario calculado se puede utilizar para clasificar los documentos con un modelo de recuperación de información estándar. En segundo lugar, también podemos inferir el interés de los usuarios en función de los resúmenes de los documentos vistos. Cuando se presenta a un usuario una lista de resúmenes de los documentos clasificados, si el usuario elige omitir los primeros documentos n y ver el documento (n+1), podemos inferir que el usuario no está interesado en la muestra que se muestraResúmenes para los primeros n documentos, pero se siente atraído por el resumen mostrado del documento (n + 1) -th. Por lo tanto, podemos usar estos resúmenes como ejemplos negativos y positivos para aprender un modelo de usuario más preciso X ∗. Aquí se pueden explotar muchas técnicas de retroalimentación de relevancia estándar [19, 20]. Tenga en cuenta que debemos usar los resúmenes mostrados, a diferencia del contenido real de esos documentos, ya que es posible que el resumen mostrado del documento visto sea relevante, pero el contenido del documento en realidad no lo es. Del mismo modo, un resumen mostrado puede engañar a un usuario para omitir un documento relevante. Inferir modelos de usuario basados en dicha información mostrada, en lugar del contenido real de un documento es una diferencia importante entre UCAIR y algunos otros sistemas similares. En UCAIR, se implementan ambas estrategias para inferir un modelo de usuario implícito.4. UCAIR: un diseño de agente de búsqueda personalizado 4.1 En esta sección, presentamos un agente de búsqueda web del lado del cliente llamado UCAIR, en el que implementamos algunos de los métodos discutidos en la sección anterior para realizar una búsqueda personalizada a través del modelado de usuarios implícito. UCAIR es un complemento de navegador web que actúa como un proxy para los motores de búsqueda web. Actualmente, solo se implementa para Internet Explorer y Google, pero es una cuestión de ingeniería hacer que se ejecute en otros navegadores web e interactuar con otros motores de búsqueda. El problema de la privacidad es un obstáculo principal para implementar cualquier aplicación del mundo real que involucre modelos de usuarios serios, como la búsqueda personalizada. Por esta razón, UCAIR se ejecuta estrictamente como agente de búsqueda del lado del cliente, a diferencia de una aplicación del lado del servidor. De esta manera, la información del usuario capturada siempre reside en la computadora que el usuario está utilizando, por lo que el usuario no necesita divulgar ninguna información al exterior. La personalización del lado del cliente también permite al sistema observar fácilmente una gran cantidad de información del usuario que puede no estar fácilmente disponible para un servidor. Además, realizar una búsqueda personalizada en el lado del cliente es más escalable que en la servidor, ya que la sobrecarga de cálculo y almacenamiento se distribuye entre los clientes. Como se muestra en la Figura 1, la barra de herramientas de UCAIR tiene 3 componentes principales: (1) el módulo de modelado de usuario (implícito) captura la información de la búsqueda y el historial de los usuarios, incluidas las consultas enviadas y los resultados de búsqueda de búsqueda e infiere límites de sesión de búsqueda.(2) El módulo de modificación de la consulta mejora selectivamente la formulación de la consulta de acuerdo con el modelo de usuario actual.(3) El módulo de re-rango de resultados vuelve a clasificar inmediatamente cualquier resultado de búsqueda invisible siempre que se actualice el modelo de usuario. En UCAIR, consideramos cuatro acciones básicas del usuario: (1) enviar una consulta de palabras clave;(2) ver un documento;(3) hacer clic en el botón Atrás;(4) Haga clic en el siguiente enlace en una página de resultados. Para cada una de estas cuatro acciones, el sistema responde con, respectivamente, (1) 1 Ucair está disponible en: http://sifaka.cs.uiuc.edu/ir/ucair/download.html 827 Motor de búsqueda (por ejemplo, Google)Registro de historial de búsqueda (por ejemplo, consultas anteriores, resultados de consulta) Modificación de la consulta Resultado Re-raning Modelado de usuarios Buffer de resultados UCAIR Resultados de Usquery Haga clic en ...(2) actualizar la información necesita el modelo X;(3) Rerantir los resultados invisibles en la página de resultados actual basado en el modelo X actual;y (4) volver a ver las páginas invisibles y generar la siguiente página de resultados basado en el modelo actual X. Detrás de estas respuestas, hay tres tareas básicas: (1) decida si la consulta anterior está relacionada con la consulta actual y, de ser así, expandir la consulta actual con términos útiles de la consulta anterior o los resultados de la consulta anterior.(2) Actualice la información necesidad del Modelo X basado en un resumen de documentos recientemente haciendo clic.(3) Vuelva a hacer un conjunto de documentos invisibles basados en el modelo actual X. A continuación describimos nuestros algoritmos para cada uno de ellos.4.2 Detección de límites de sesión y expansión de la consulta para explotar efectivamente las consultas anteriores y su información de clic correspondiente, UCAIR debe juzgar si dos consultas adyacentes pertenecen a la misma sesión de búsqueda (es decir, detectar los límites de la sesión). El trabajo existente en la detección de límites de sesión se encuentra principalmente en el contexto del análisis de registro web (por ejemplo, [8]), y utiliza información estadística en lugar de características textuales. Dado que nuestro agente de Clientide no tiene acceso a los registros de consultas de servidor, tomamos decisiones límite de sesión basadas en la similitud textual entre dos consultas. Debido a que las consultas relacionadas no necesariamente comparten las mismas palabras (por ejemplo, isla de Java e Indonesia de viajes), no es suficiente usar solo texto de consulta. Por lo tanto, utilizamos los resultados de búsqueda de las dos consultas para ayudar a decidir si están relacionadas tópicamente. Por ejemplo, para las consultas anteriores Java Island y Travel Indonesia, las palabras Java, Bali, Island, Indonesia y viajes pueden ocurrir con frecuencia en ambas consultas, lo que produce un puntaje de alta similitud. Solo usamos los títulos y resúmenes de los resultados de búsqueda para calcular la similitud ya que están disponibles en la página de resultados de búsqueda recuperada y obtener el texto completo de cada página de resultados ralentizaría significativamente el proceso. Para compensar la parte de los títulos y resúmenes, recuperamos más resultados de los que un usuario normalmente vería con el fin de detectar límites de sesión (típicamente 50 resultados). La similitud entre la consulta anterior Q y la consulta actual Q se calcula de la siguiente manera. Sea {S1, S2 ,..., Sn} y {S1, S2 ,..., Sn} Sea el conjunto de resultados para las dos consultas. Utilizamos la fórmula de ponderación TF-IDF de normalización TF-IDF [24] para calcular un término Vector de peso SI para cada resultado SI. Definimos que el resultado promedio SAVG sea el centroide de todos los vectores de resultados, es decir, (S1 + S2 + ... + Sn)/N. La similitud cosena entre los dos resultados promedio se calcula como S AVG · Savg/ S 2 AVG · S2 AVG Si el valor de similitud excede un umbral predefinido, las dos consultas se considerarán en la misma sesión de información. Si se encuentra que la consulta anterior y la consulta actual pertenecen a la misma sesión de búsqueda, UCAIR intentaría expandir la consulta actual con los términos de la consulta anterior y sus resultados de búsqueda. Específicamente, para cada término en la consulta anterior o los resultados de búsqueda correspondientes, si su frecuencia en los resultados de la consulta actual es mayor que un umbral preestablecido (por ejemplo, 5 resultados de 50), el término se agregaría a la consulta actual aformar una consulta ampliada. En este caso, Ucair enviaría esta consulta ampliada en lugar de la original al motor de búsqueda y devolvería los resultados correspondientes a la consulta expandida. Actualmente, Ucair solo utiliza la consulta anterior inmediata para la expansión de la consulta;En principio, podríamos explotar todas las consultas pasadas relacionadas.4.3 Información Necesita la actualización del modelo Supongamos que en el momento T, hemos observado que el usuario ha visto documentos K cuyos resúmenes son S1, ..., SK. Actualizamos nuestro modelo de usuario calculando un nuevo vector de necesidad de información con un método de retroalimentación estándar en la recuperación de información (es decir, Rocchio [19]). De acuerdo con el modelo de recuperación de espacio vectorial, cada resumen de SI se puede representar por un término Vector de peso SI con cada término ponderado por una fórmula de ponderación de TF-IDF [21]. Rocchio calcula el vector centralide de todos los resúmenes y lo interpola con el vector de consulta original para obtener un vector de término actualizado. Es decir, x = αq + (1 - α) 1 k k i = 1 si donde q es el vector de consulta, k es el número de resúmenes que el usuario hace clic inmediatamente después de la consulta actual y α es un parámetro que controla la influencia de los clics deResúmenes en el modelo de necesidad de información inferida. En nuestros experimentos, α se establece en 0.5. Tenga en cuenta que actualizamos el modelo de necesidad de información siempre que el usuario ve un documento.4.4 Resultados Reranking En general, queremos volver a ser todos los resultados invisibles tan pronto como se actualice el modelo de usuario. Actualmente, UCAIR implementa la rescisión en dos casos, correspondiente al usuario haciendo clic en el botón Atrás y el siguiente enlace en el Explorador de Internet. En ambos casos, el modelo de usuario actual (actualizado) se utilizaría para volver a revisar los resultados invisibles para que el usuario vea mejores resultados de búsqueda de inmediato. Para volver a revisar los resúmenes de documentos invisibles, UCAIR utiliza el modelo de recuperación de espacio vectorial estándar y obtiene cada resumen en función de la similitud del resultado y la información actual del usuario necesita el vector X [21]. Dado que la retroalimentación implícita no es completamente confiable, mencionamos solo un pequeño número (por ejemplo, 5) de los resultados mejorados más altos para ser seguidos por cualquier resultado originalmente de alto rango.828 Resultado de Google (consulta de usuario = mapa Java) Resultado de Ucair (consulta de usuario = mapa java) consulta anterior = viajar indonesia consulta anterior = hashtable expandido de usuario consulta = mapa java indonesia consulta de usuario expandida = mapa java clase 1 proyecciones de mapa de java del mundo... Lonely Planet - Indonesia Map Map (Java 2 Platform SE V1.4.2) www.btinternet.com/ se16/js/mapproj.htm www.lonelyplanet.com/mapshells/... java.sun.com/j2se/1.4.2/Docs/... 2 Proyecciones de mapa de Java del mundo ... Indonesia Turismo: Java central - Map Java 2 Platform SE V1.3.1: Interface Map www.btinternet.com/ SE16/JS/Oldmapproj.htm www.Indonesia-tourism.com/... java.sun.com/j2se/1.3/docs/api/java/... 3 mapa de java Indonesia Turismo: West Java - Map una introducción a las clases de colección de mapas de Java java.sun.com/Developer/... www.indonesia-tourism.com/ ... www.oracle.com/technology/... 4 Java Technology Concept Map Indostreets - Java Map, una introducción a las clases de colección de mapas de Java Java.sun.com/desarrollador/onlinetraining/... www.indostreets.com/maps/java/ www.theserverside.com/news/... 5 science@nasa home indonesia regions e islas mapas, bali, java, ... koders - mapeos.java science.nasa.gov/realtime/... www.maps2anywhere.com/maps/... www.koders.com/java/ 6 Una introducción a las clases de colección de mapas de Java Mapa de la calle Indonesia City, ... Hibernate simplifica la herenciamapeo www.oracle.com/technology/... www.maps2anywhere.com/maps/... www.ibm.com/developerworks/java/... 7 Lonely Planet - Java Map Maps of Indonesia TMAP 30.Map ClassJerarquía www.lonelyplanet.com/mapshells/ www.embassyworld.com/maps/... tmap.pmel.noaa.gov/... 8 onjava.com: mapas de mapas de la API de Java de Indonesia por Peter Loud Class alcance www.onjava.com/pub/a/onjava/api map/users.powernet.co.uk/... jalbum.net/api/se/datadosen/util/scope.html 9 GTA San Andreas: Sam Maps of Indonesia por Peter LoudClase printSafeHashmap www.gtasanandreas.net/sam/ users.powernet.co.uk/mkmarina/indonesia/ jalbum.net/api/se/datadosen/... 10 Indonesia Turismo: Java Occidental - Map indonesiaphoto.com Java pro - Uniony mapeo vertical de clases www.indonesia-tourism.com/... www.indonesiaphoto.com/... www.fawcette.com/javapro/... Tabla 1: Resultados de muestra de la expansión de la consulta 5. Evaluación de UCAIR Ahora presentamos algunos resultados sobre la evaluación de las dos funciones principales de UCAIR: expansión de consultas selectivas y resultados de resultados basados en datos de clics del usuario.5.1 Resultados de la muestra La estrategia de expansión de consulta implementada en UCAIR es intencionalmente conservadora para evitar la interpretación errónea de los modelos de usuario implícitos. En la práctica, cada vez que elige expandir la consulta, la expansión generalmente tiene sentido. En la Tabla 1, mostramos cómo UCAIR puede distinguir con éxito dos contextos de búsqueda diferentes para el mapa Java de consulta, correspondiente a dos consultas anteriores diferentes (es decir, Travel Indonesia vs. Hashtable). Debido al modelado implícito de usuarios, Ucair se resuelve inteligentemente para agregar Indonesia y clase, respectivamente, al mapa de Java de consulta de los usuarios, que de otro modo sería ambiguo como se muestra en los resultados originales de Google el 21 de marzo de 2005. Los resultados de Ucairs son mucho más precisos que los resultados de Googles y reflejan la personalización en la búsqueda. El ansioso componente de retroalimentación implícita está diseñado para responder inmediatamente a la actividad de los usuarios, como ver un documento. En la Figura 2, mostramos cómo Ucair puede desambiguar con éxito una consulta ambigua Jaguar explotando un resumen de documentos visto. En este caso, los resultados iniciales de recuperación utilizando Jaguar (que se muestra en el lado izquierdo) contienen dos resultados sobre los autos Jaguar seguidos de dos resultados sobre el software Jaguar. Sin embargo, después de que el usuario ve el contenido de la página web del segundo resultado (sobre el automóvil Jaguar) y vuelve a la página de resultados de búsqueda haciendo clic en el botón Atrás, UCAIR nomina automáticamente dos nuevos resultados de búsqueda sobre los automóviles Jaguar (que se muestran en el lado derecho), mientras queLos dos resultados originales sobre el software Jaguar se empujan hacia abajo en la lista (sin ser visto de la imagen).5.2 Evaluación cuantitativa Para evaluar más a fondo cuantitativamente, realizamos un estudio de usuario sobre la efectividad del ansioso componente de retroalimentación implícita. Es un desafío evaluar cuantitativamente la mejora potencial del rendimiento de nuestro modelo propuesto y UCAIR sobre Google de una manera imparcial [7]. Aquí, diseñamos un estudio de usuarios, en el que los participantes realizarían una búsqueda web normal y juzgarían un conjunto de resultados mixto aleatorio y anónimo de Google y Ucair al final de la sesión de búsqueda;Los participantes no saben si un resultado proviene de Google o Ucair. Reclutamos 6 estudiantes de posgrado para este estudio de usuarios, que tienen diferentes antecedentes (3 informática, 2 biología y 1 chem <pot> <um> Número: 716 <title> spammer arrestado demanda <descremisión> Descripción: se han arrestado a los spammerso demandado por enviar correos electrónicos no solicitados? <Narr> Narrativa: los casos de arrestos, enjuiciamientos, condenas y castigos de spammers y demandas contra ellos son relevantes. Los documentos que describen las leyes para limitar el spam sin dar detalles de demandas o juicios penales no son relevantes.</pop> Figura 3: Un ejemplo de tema de consulta de TREC, expresado en una forma que podría entregarse a un asistente humano o bibliotecario). Utilizamos temas de consulta de TREC 2 2004 Terabyte Track [2] y TREC 2003 Web Track [4] Tarea de destilación de temas en la forma que se describirá a continuación. Un tema de ejemplo de Trec 2004 Terabyte Track aparece en la Figura 3. El título es una frase corta y puede usarse como una consulta para el sistema de recuperación. El campo de descripción proporciona una declaración ligeramente más larga del requisito del tema, generalmente expresado como una sola oración o pregunta completa. Finalmente, la narrativa proporciona información adicional necesaria para especificar completamente el requisito, expresado en forma de un párrafo corto. Inicialmente, cada participante exploraría 50 temas de Terabyte Track o Web Track y elegiría 5 o 7 temas más interesantes. Para cada tema seleccionado, el participante hará esencialmente la búsqueda web normal utilizando UCAIR para encontrar muchas páginas web relevantes utilizando el título del tema de consulta como la consulta de palabras clave inicial. Durante este proceso, el participante puede ver los resultados de búsqueda y posiblemente hacer clic en algunos interesantes para ver las páginas web, al igual que en una búsqueda web normal. No hay requisito ni restricción sobre cuántas consultas debe enviar el participante o cuándo el participante debe detener la búsqueda de un tema. Cuando el participante planea cambiar el tema de búsqueda, él/ella simplemente presionará una conferencia de recuperación de texto del botón 2: http://trec.nist.gov/ 829 Figura 2: capturas de pantalla para que el resultado vuelva a evaluar los resultados de búsqueda antes de cambiar realmenteal siguiente tema. En el momento de la evaluación, 30 resultados clasificados de Google y UCAIR (algunos se superponen) se mezclan aleatoriamente para que el participante no sepa si un resultado proviene de Google o UCAIR. El participante juzgaría la relevancia de estos resultados. Medimos la precisión en los documentos TOP N (N = 5, 10, 20, 30) de Google y Ucair. También evaluamos las precisiones en diferentes niveles de retiro. En total, 368 documentos juzgados como relevantes de los resultados de búsqueda de Google y 429 documentos juzgados como relevantes de UCAIR por los participantes. Los gráficos de dispersión de precisión en los 10 documentos top 10 y principales se muestran en la Figura 4 y la Figura 5 respectivamente (el gráfico de dispersión de precisión en los 30 documentos principales es muy similar a la precisión en los 20 documentos principales). Cada punto de los gráficos de dispersión representa las precisiones de Google y Ucair en un tema de consulta. La Tabla 2 muestra la precisión promedio en los documentos Top N entre 32 temas. De la Figura 4, Figura 5 y Tabla 2, vemos que los resultados de búsqueda de UCAIR son consistentemente mejores que los de Google por todas las medidas. Además, la mejora del rendimiento es más dramática para la precisión en los 20 documentos principales que en la precisión en los 10 documentos principales. Una explicación para esto es que cuanta más interacción tenga el usuario con el sistema, más datos de clics se puede esperar que recopile UCAIR. Por lo tanto, el sistema de recuperación puede construir modelos de usuario implícitos más precisos, lo que conduce a una mejor precisión de recuperación. Método de clasificación prec@5 prec@10 prec@20 prec@30 google 0.538 0.472 0.377 0.308 UCAIR 0.581 0.556 0.453 0.375 Mejora 8.0% 17.8% 20.2% 21.8% Tabla 2: Tabla de precisión promedio en los documentos TOP N para 32 Temas de consulta La trama la tramaEn la Figura 6, muestra las curvas de recolección de precisión para UCAIR y Google, donde se ve claramente que el rendimiento de UCAIR 0 0.2 0.4 0.6 0.6 0.8 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Ucair prec@10 GooglePREC@10 SEPTURTPrecisión en los 10 documentos principales Figura 4: Precisión en los 10 documentos principales de UCAIR y Google es consistente y considerablemente mejor que el de Google en todos los niveles de recuperación.6. Conclusiones En este documento, estudiamos cómo explotar el modelado implícito de los usuarios para personalizar de manera inteligente la recuperación de información y mejorar la precisión de la búsqueda. A diferencia de la mayoría de los trabajos anteriores, enfatizamos el uso del contexto de búsqueda inmediata y la información de retroalimentación implícita, así como la actualización ansiosa de los resultados de búsqueda para beneficiar al máximo a un usuario. Presentamos un marco teórico de decisión para optimizar la recuperación de información interactiva basada en una actualización de modelo de usuario ansiosa, en el que el sistema responde a cada acción del usuario eligiendo una acción del sistema para optimizar una función de utilidad. Además, proponemos técnicas específicas para capturar y explotar dos tipos de información de retroalimentación implícita: (1) Identificar la consulta inmediatamente precedente relacionada y usar la consulta y los resultados de búsqueda correspondientes para seleccionar los términos apropiados para expandir la consulta actual, y (2) explotar la vista vistaDocumente resúmenes para volver a revisar inmediatamente cualquier documento que el usuario aún no haya visto. Usando estas técnicas, desarrollamos un agente de búsqueda web del lado del cliente (UCAIR) además de un motor de búsqueda popular (Google). Los experimentos en la búsqueda web muestran que nuestro agente de búsqueda puede mejorar la precisión de la búsqueda en más de 830 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.4 0.5 0.7 0.7 0.9 1 1 Ucair prec@20 GooglePREC@20 Disperso de precisión en los 20 documentos Top Figura 5: Precisión: Precisión: Precisión 5En los 20 documentos principales de UCAIR y Google 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 0.4 0.45 0.5 0.5 0.55 0.6 0.6 0.7 0.75 0.8 0.85 0.9 Recuerda Precisión Precisión - Recuerda Curvas de Google Resultado de UCAIR Figura 6: Precisión a 20 Resultados de UCAIR de UCAIR de UCAIy Google Google. Dado que la información implícita que explotamos ya existe naturalmente a través de las interacciones del usuario, el usuario no necesita hacer ningún esfuerzo adicional. Por lo tanto, el agente de búsqueda desarrollado puede mejorar el rendimiento de búsqueda web existente sin ningún esfuerzo adicional del usuario.7. Reconocimiento Agradecemos a los seis participantes de nuestros experimentos de evaluación. Este trabajo fue apoyado en parte por la National Science Foundation otorga IIS-0347933 e IIS-0428472.8. Referencias [1] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman y O. Frieder. Análisis por hora de un registro de consulta web web muy grande categorizado. En Actas de Sigir 2004, páginas 321-328, 2004. [2] C. Clarke, N. Craswell e I. Soboroff. Descripción general de la pista de Terabyte TREC 2004. En Actas de Trec 2004, 2004. [3] M. Claypool, P. Le, M. Waseda y D. Brown. Indicadores de interés implícitos. En Actas de Interfaces de usuario inteligentes 2001, páginas 33-40, 2001. [4] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Descripción general de la pista web TREC 2003. En Proceedings of Trec 2003, 2003. [5] W. B. Croft, S. Cronen-Townsend y V. Larvrenko. Comentarios y personalización de relevancia: una perspectiva de modelado de idiomas. En las precedentes del Segundo Taller de Delos: Sistemas de personalización y recomendación en bibliotecas digitales, 2001. [6] Google Personalized.http://labs.google.com/personalized.[7] D. Hawking, N. Craswell, P. B. Thistlewaite y D. Harman. Resultados y desafíos en la evaluación de la búsqueda web. Computer Networks, 31 (11-16): 1321-1330, 1999. [8] X. Huang, F. Peng, A. An, y D. Schuurmans. Identificación de sesión de registro web dinámico con modelos de lenguaje estadístico. Journal of the American Society for Information Science and Technology, 55 (14): 1290-1303, 2004. [9] G. Jeh y J. Widom. Escala de búsqueda web personalizada. En Actas de WWW 2003, páginas 271-279, 2003. [10] T. Joachims. Optimización de los motores de búsqueda utilizando datos de clics. En Actas de Sigkdd 2002, páginas 133-142, 2002. [11] D. Kelly y J. Teevan. Comentarios implícitos para inferir la preferencia del usuario: una bibliografía. Sigir Forum, 37 (2): 18-28, 2003. [12] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de Sigir01, páginas 111-119, 2001. [13] T. Lau y E. Horvitz. Patrones de búsqueda: análisis y modelado de refinamiento de consultas web. En Actas de la Séptima Conferencia Internacional sobre Modelado de Usuarios (UM), páginas 145-152, 1999. [14] V. Lavrenko y B. Croft. Modelos de idiomas basados en relevancia. En Actas de Sigir01, páginas 120-127, 2001. [15] M. Mitra, A. Singhal y C. Buckley. Mejora de la expansión automática de consultas. En Proceedings of Sigir 1998, páginas 206-214, 1998. [16] My Yahoo!http://mysearch.yahoo.com.[17] G. Nunberg. Como Google va, así va la nación. New York Times, mayo de 2003. [18] S. E. Robertson. El principio de clasificación de probabilidad en ı˚. Journal of Documation, 33 (4): 294-304, 1977. [19] J. J. Rocchio. Comentarios de relevancia en la recuperación de información. En el sistema de recuperación inteligente: experimentos en el procesamiento automático de documentos, páginas 313-323. Prentice-Hall Inc., 1971. [20] G. Salton y C. Buckley. Mejora del rendimiento de la recuperación por retroalimentación de recuperación. Journal of the American Society for Information Science, 41 (4): 288-297, 1990. [21] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, 1983. [22] X. Shen, B. Tan y C. Zhai. Recuperación de información sensible al contexto utilizando comentarios implícitos. En Actas de Sigir 2005, páginas 43-50, 2005. [23] X. Shen y C. Zhai. Explotación del historial de consultas para la clasificación de documentos en la recuperación de información interactiva (póster). En Actas de Sigir 2003, páginas 377-378, 2003. [24] A. Singhal. Recuperación de información moderna: una breve descripción. Boletín del Comité Técnico de Ingeniería de Datos de la Sociedad de Computaciones IEEE, 24 (4): 35-43, 2001. [25] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil de usuario construido sin ningún esfuerzo de los usuarios. En Actas de WWW 2004, páginas 675-684, 2004. [26] E. Volokh. Personalización y privacidad. Comunicaciones de la ACM, 43 (8): 84-88, 2000. [27] R. W. White, J. M. José, C. J. Van Rijsbergen e I. Ruthven. Un estudio simulado de modelos de retroalimentación implícitos. En Actas de ECIR 2004, páginas 311-326, 2004. [28] J. Xu y W. B. Croft. Expansión de consulta utilizando análisis de documentos locales y globales. En Actas de Sigir 1996, páginas 4-11, 1996. [29] C. Zhai y J. Lafferty. Comentarios basados en modelos en el modelo de recuperación de divergencia KL. En Actas del CIKM 2001, páginas 403-410, 2001. 831