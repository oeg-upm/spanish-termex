Complejidad de la comunicación de las reglas de votación comunes ∗ Vincent Conitzer Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, EE. UU. Conitzer@cs.cmu.edu tuomas sandholm Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213, USA Sandholm@cs.cmu.Edu RESSGUDeterminamos la complejidad de comunicación de las reglas de votación comunes. Las reglas (ordenadas por su complejidad de comunicación de baja a alta) son pluralidad, pluralidad con escorrentía, voto único transferible (STV), condorcet, aprobación, Bucklin, Cup, Maximin, Borda, Copeland y parejas clasificadas. Para cada regla, primero damos un protocolo de comunicación determinista y un límite superior en el número de bits comunicados en él;Luego, damos un límite inferior (incluso los requisitos de comunicación no deterministas) de la regla de votación. Los límites coinciden con todas las reglas de votación, excepto STV y Maximin. Categorías y descriptores de sujetos F.2 [Teoría de la computación]: Análisis de algoritmos y complejidad del problema;J.4 [Aplicaciones informáticas]: Ciencias sociales y conductuales-economía Algoritmos de términos generales, Economía, Teoría 1. Introducción Un factor clave en la practicidad de cualquier regla de agregación de preferencias es su carga de comunicación. Para agregar con éxito las preferencias de los agentes, generalmente no es necesario que todos los agentes denuncien toda su información de preferencias. Los protocolos inteligentes que provocan las preferencias de los agentes parcial y secuencialmente tienen el potencial de reducir drásticamente la comunicación requerida. Esto tiene al menos las siguientes ventajas: • Puede hacer que la agregación de preferencias sea factible en los entornos donde la cantidad total de información de preferencias es demasiado grande para comunicarse.• Incluso cuando comunicar toda la información de preferencia es factible, la reducción de los requisitos de comunicación disminuye la carga colocada en los agentes. Esto es especialmente cierto cuando los agentes, en lugar de conocer todas sus preferencias de antemano, necesitan invertir un esfuerzo (como el cálculo o la recopilación de información) para determinar sus preferencias [16].• Preserva (algunos de) la privacidad de los agentes. La mayor parte del trabajo para reducir la carga de comunicación en la agregación de preferencias se ha centrado en la configuración de asignación de recursos, como las subastas combinatorias, en las que un subastador subasta varios elementos (posiblemente distintos) en un solo evento. Debido a que en una subasta combinatoria, los postores pueden tener valoraciones separadas para cada uno de un número exponencial de posibles paquetes de artículos, este es un entorno en el que reducir la carga de comunicación es especialmente crucial. Esto se puede lograr suplementando al subastador con un iniciador que provoca de forma incremental de las preferencias de los licitantes según sea necesario, en función de lo que los licitadores han revelado sobre sus preferencias hasta el momento, como sugería Conen y Sandholm [5]. Por ejemplo, el iniciador puede solicitar un valor de los licitadores para un paquete específico (consultas de valor), cuál de los dos paquetes prefiere el postor (consultas de pedidos), qué paquete clasifica el kth o cuál es el rango de un paquete de un bulto (consultas de rango), qué paquete compraría dado un vector particular de precios (consultas de demanda), etc., hasta (al menos) la asignación final se puede determinar. Experimentalmente, esto produce ahorros drásticos en la revelación de preferencias [11]. Además, si las funciones de valoración de los agentes se extraen de ciertas subclases naturales, el problema de obtención se puede resolver utilizando solo muchas consultas polinomialmente incluso en el peor de los casos [23, 4, 13, 18, 14]. Para una revisión de la obtención de preferencias en subastas combinatorias, ver [17]. Las subastas combinatorias ascendentes son una forma especial de obtención de preferencias bien conocida, donde el impulsor solicita consultas de demanda con precios crecientes [15, 21, 1, 9]. Finalmente, los problemas de asignación de recursos 78 también se han estudiado desde el punto de vista de la complejidad de la comunicación, derivando así los límites más bajos en la comunicación requerida. Por ejemplo, Nisan y Segal muestran que se requiere una comunicación exponencial incluso para obtener un excedente mayor que el obtenido al subastar todos los objetos como un solo paquete [14]. Segal también estudia las reglas de elección social en general, y muestra que para una gran clase de reglas de elección social, el apoyo a los conjuntos de presupuestos debe revelarse de tal manera que si cada agente prefiere el mismo resultado en su conjunto presupuestario, esto demuestra la optimización de ese resultado. Segal luego usa esta caracterización para probar los límites de la comunicación requerida en la asignación de recursos, así como la configuración de coincidencia [20]. En este documento, nos centraremos en los requisitos de comunicación de una subclase generalmente aplicable de reglas de elección social, comúnmente conocidas como reglas de votación. En un entorno de votación, hay un conjunto de resultados de candidatos sobre los cuales los votantes expresan sus preferencias al presentar un voto (generalmente, una clasificación de los candidatos), y el ganador (es decir, el resultado elegido) se determina en base a estos votos. La comunicación requerida por las reglas de votación puede ser grande, ya sea porque el número de votantes es grande (como, por ejemplo, en las elecciones nacionales), o porque el número de candidatos es grande (por ejemplo, los agentes pueden votar por asignaciones de un númerode recursos), o ambos. El trabajo anterior [8] ha estudiado la obtención de la votación, estudiando cuán computacionalmente duro es decidir si un ganador puede determinarse con la información provocada hasta ahora, así como lo difícil que es encontrar la secuencia óptima de consultas dadas las sospechas perfectasLas preferencias de los votantes. Además, ese documento discute cuestiones estratégicas (teóricas del juego) introducidas por la obtención. Por el contrario, en este documento, nos preocupa el peor número de bits que deben comunicarse para ejecutar una regla de votación dada, cuando nada se sabe de antemano sobre las preferencias de los votantes. Determinamos la complejidad de comunicación de las reglas de votación comunes. Para cada regla, primero damos un límite superior en la complejidad de comunicación (determinista) al proporcionar un protocolo de comunicación para ella y analizar cuántos bits deben transmitirse en este protocolo.(Los resultados de Segals [20] no se aplican a la mayoría de las reglas de votación porque la mayoría de las reglas de votación no son intersectionmonotonic (o incluso monotónicas) .1) Para muchas de las reglas de votación en estudio, resulta que uno no puede hacerlo mejor que simplemente dejar que cada votanteComunique inmediatamente toda su información (potencialmente relevante). Sin embargo, para algunas reglas (como la pluralidad con escorrentía, STV y CUP) existe un protocolo de comunicación de etapas múltiples directas que, con algún análisis, puede demostrar que supera significativamente la comunicación inmediata de toda la información (potencialmente relevante). Finalmente, para algunas reglas (como las reglas de Condorcet y Bucklin), necesitamos introducir un protocolo de comunicación más complejo para lograr el mejor 1 superior posible para dos de las reglas que estudiamos que son intersectionmonotonic, a saber, las reglas de aprobación y condorcet, a saberLos resultados de Segals pueden usarse de hecho para dar pruebas alternativas de nuestros límites inferiores. Solo damos pruebas directas para estas reglas aquí porque 1) estas pruebas directas se encuentran entre las más fáciles en este documento, 2) las pruebas alternativas no son triviales incluso los resultados de los Segals, y 3) se aplica una restricción de espacio. Sin embargo, esperamos incluir también las pruebas alternativas en una versión posterior.atado. Después de obtener los límites superiores, mostramos que son apretados al dar a los límites inferiores coincidentes en la complejidad de la comunicación (incluso no determinista) de cada regla de votación. Hay dos excepciones: STV, para las cuales nuestros límites superior e inferior están separados por un factor log m;y Maximin, para el cual nuestro mejor límite superior determinista también es un factor log m por encima del límite inferior (no determinista), aunque damos un límite superior no determinista que coincide con el límite inferior.2. Revisión de las reglas de votación En esta sección, revisamos las reglas de votación comunes que estudiamos en este documento. Una regla de votación2 2 es una función que mapea un vector de los n votos de los votantes (es decir, preferencias sobre los candidatos) a uno de los m candidatos (el ganador) en el conjunto de candidatos C. En algunos casos (como la regla del condorcet), la regla puedeTambién declare que no existe ningún ganador. No nos preocupamos por lo que sucede en caso de un empate entre candidatos (nuestros límites inferiores se mantienen independientemente de cómo se rompan los lazos y los protocolos de comunicación utilizados para nuestros límites superiores no intentan romper los lazos). Todas las reglas que estudiamos son reglas basadas en rango, lo que significa que un voto se define como un orden de los candidatos (con la excepción de la regla de pluralidad, para la cual un voto es un candidato único y la regla de aprobación, paraque un voto es un subconjunto de los candidatos). Consideraremos las siguientes reglas de votación.(Para las reglas que definen un puntaje, el candidato con el puntaje más alto gana). • Reglas de puntuación. Sea α = α1 ,..., αm será un vector de enteros tal que α1 ≥ α2...≥ αm. Para cada votante, un candidato recibe puntos α1 si el votante clasifica primero, α2 si se clasifica en segundo lugar, etc. La puntuación Sα de un candidato es el número total de puntos que recibe el candidato. La regla de Borda es la regla de puntuación con α = m - 1, m - 2 ,..., 0. La regla de pluralidad es la regla de puntuación con α = 1, 0 ,..., 0.• Voto único transferible (STV). La regla continúa a través de una serie de rondas M - 1. En cada ronda, el candidato con el puntaje de pluralidad más bajo (es decir, el menor número de votantes que lo clasifica primero entre los candidatos restantes) se elimina (y cada uno de los votos para ese candidato se transfiere al próximo candidato restante en el orden en el orden enese voto). El ganador es el último candidato restante.• Pluralidad con escorrentía. En esta regla, una primera ronda elimina a todos los candidatos, excepto los dos con los puntajes de pluralidad más altos. Los votos se transfieren a estos como en la regla STV, y una segunda ronda determina al ganador de estos dos.• aprobación. Cada votante etiqueta a cada candidato como aprobado o desaprobado. El candidato aprobado por el mayor número de votantes gana.• Condorcet. Para los dos candidatos I y J, Sea n (i, j) el número de votantes que prefieren i a j. Si hay un candidato I que es preferido a cualquier otro candidato por la mayoría de los votantes (es decir, n (i, j)> n (j, i) para todos j = i-es decir, gana todas las elecciones por pares), entonces candidato i gana.2 El término protocolo de votación a menudo se usa para describir el mismo concepto, pero buscamos dibujar una fuerte distinción entre las preferencias de mapeo de reglas a los resultados y el protocolo de comunicación/obtitación utilizado para implementar esta regla.79 • Maximin (también conocido como. Simpson). La puntuación máxima de I es s (i) = minj = i n (i, j) -Se es el peor rendimiento en una elección por pares. El candidato con la puntuación máxima más alta gana.• Copeland. Para dos candidatos distintos I y J, vamos a c (i, j) = 1 si n (i, j)> n (j, i), c (i, j) = 1/2 si n (i, j)= N (j, i) y c (i, j) = 0 if n (i, j) <n (j, i). El puntaje de Copeland del candidato I es s (i) = j = i c (i, j).• Copa (comparaciones binarias secuenciales). La regla de la copa se define por un árbol binario equilibrado 3 con una hoja por candidato, y una asignación de candidatos a las hojas (cada hoja obtiene un candidato). A cada nodo no hojado se le asigna el ganador de la elección por pares de los nodos niños;El candidato asignado a la raíz gana.• Bucklin. Para cualquier candidato I e Integer L, Sea B (I, L) el número de votantes que clasifican al candidato I entre los principales candidatos L. El ganador es arg mini (min {l: b (i, l)> n/2}). Es decir, si decimos que un votante aprueba a sus principales candidatos L, entonces aumentamos repetidamente L por 1 hasta que algún candidato sea aprobado por más de la mitad de los votantes, y este candidato es el ganador.• Pares clasificados. Esta regla determina un orden sobre todos los candidatos, y el ganador es el candidato en la parte superior de este orden. Ordena todos los pares ordenados de candidatos (i, j) por n (i, j), el número de votantes que prefieren i a j. Comenzando con el par (i, j) con la n (i, j) más alta, bloqueamos el resultado de su elección por pares (i j). Luego, pasamos al siguiente par, y bloqueamos el resultado de su elección por pares. Continuamos bloqueando todos los resultados por pares que no contradicen el orden establecido hasta ahora. Hacemos hincapié en que estas definiciones de reglas de votación no se preocupan por cómo se obtienen los votos de los votantes;Todas las reglas de votación, incluidas las que se definen sugerentemente en términos de rondas, son en realidad solo funciones que mapean el vector de todos los votantes votos a un ganador. Sin embargo, siempre hay muchas formas diferentes de provocar los votos (o las partes relevantes) de los votantes. Por ejemplo, en la pluralidad con la regla de escorrentía, una forma de obtener los votos es pedir a cada votante que declare su orden completo de los candidatos por adelantado. Alternativamente, primero podemos pedirle a cada votante que declare solo a su candidato más preferido;Luego, conoceremos a los dos candidatos en la escorrentía, y podemos preguntarnos a cada votante cuál de estos dos candidatos prefiere. Por lo tanto, distinguimos entre la regla de votación (el mapeo de los vectores de los votos a los resultados) y el protocolo de comunicación (que determina cómo las partes relevantes de los votos realmente se obtienen de los votantes). El objetivo de este documento es dar protocolos de comunicación eficientes para las reglas de votación que se acaba de definir, y demostrar que no existen protocolos de comunicación más eficientes. Es interesante observar que la elección del protocolo de comunicación puede afectar el comportamiento estratégico de los votantes. Los protocolos de comunicación de varias etapas pueden revelar a los votantes cierta información sobre cómo votan los otros votantes (por ejemplo, en el protocolo de comunicación de dos etapas que acaba de dar pluralidad con la escorrentía, en la segunda etapa, los votantes 3 equilibrados significa que la diferencia en profundidad entre dosLas hojas pueden ser como máximo una. Sabrá qué dos candidatos tienen los puntajes de pluralidad más altos). En general, cuando los votantes reciben dicha información, puede darles incentivos para votar de manera diferente de lo que tendrían en un protocolo de comunicación de una sola etapa en el que todos los votantes declaran sus votos completos simultáneamente. Por supuesto, incluso el protocolo de comunicación de una sola etapa no es a prueba de estrategia4 para ninguna regla de votación razonable, por el teorema de Gibbard-Satterthwaite [10, 19]. Sin embargo, esto no significa que no debamos preocuparnos por agregar aún más oportunidades para la votación estratégica. De hecho, muchos de los protocolos de comunicación introducidos en este documento introducen oportunidades adicionales para la votación estratégica, pero no tenemos el espacio para discutir esto aquí.(En el trabajo previo [8], damos un ejemplo en el que un protocolo de obtención para la regla de votación de aprobación introduce la votación estratégica y otorga principios para diseñar protocolos de obtención que no introduzcan problemas estratégicos). Ahora que hemos revisado las reglas de votación, pasamos a una breve revisión de la teoría de la complejidad de la comunicación.3. Revisión de alguna teoría de la complejidad de la comunicación En esta sección, revisamos el modelo básico de un problema de comunicación y la técnica de límite inferior para construir un conjunto de engaño.(El modelo básico de un problema de comunicación se debe a Yao [22]; para una visión general, ver Kushilevitz y Nisan [12].) Cada jugador 1 ≤ I ≤ n sabe (solo) entrada XI. Juntos, buscan calcular f (x1, x2, ..., xn). En un protocolo determinista para calcular F, en cada etapa, uno de los jugadores anuncia (a todos los demás jugadores) un poco de información basada en su propio aporte y los bits anunciados hasta ahora. Finalmente, la comunicación termina y todos los jugadores saben F (x1, x2, ..., xn). El objetivo es minimizar el número de bits peores (en todos los vectores de entrada) enviados. La complejidad de comunicación determinista de un problema es el peor número de bits enviados en el mejor (correcto) protocolo determinista para él. En un protocolo no determinista, el siguiente bit que se enviará se puede elegir de manera no determinista. Para los fines de este documento, consideraremos un protocolo no determinista correcto si para cada vector de entrada, hay alguna secuencia de opciones no deterministas que los jugadores pueden hacer para que los jugadores conozcan el valor de F cuando el protocolo termina. La complejidad de la comunicación no determinista de un problema es el peor número de bits enviados en el mejor (correcto) protocolo no determinista para él. Ahora estamos listos para dar la definición de un conjunto de engaño. Definición 1. Un conjunto de tonterías es un conjunto de vectores de entrada {(x1 1, x1 2, ..., x1 n), (x2 1, x2 2, ..., x2 n) ,..., (xk 1, xk 2, ..., xk n) tal que para cualquier i, f (xi 1, xi 2, ..., xi n) = f0 para alguna constante f0, pero para cualquier i = j,Existe algunos vectores (R1, R2, ..., Rn) ∈ {i, J} n tal que f (xr1 1, xr2 2, ..., xrn n) = f0.(Es decir, podemos mezclar las entradas de los dos vectores de entrada para obtener un vector con un valor de función diferente). Se sabe que si existe un conjunto de tamaño K, entonces log K es un límite inferior en la complejidad de la comunicación (incluso la complejidad de la comunicación no determinista) [12].4 Un protocolo a prueba de estrategia es aquel en el que es lo mejor interés de los jugadores informar sus preferencias con sinceridad.80 Para los propósitos de este documento, F es la regla de votación que asigna los votos al candidato ganador, y XI es votante es voto (la información que la regla de votación requeriría del votante si no hubiera posibilidad de comunicación múltiple-es.El candidato más preferido (pluralidad), los candidatos aprobados (aprobación) o la clasificación de todos los candidatos (todos los demás protocolos)). Sin embargo, cuando derivamos nuestros límites inferiores, F solo significará si un candidato distinguido A gana.(Es decir, F es 1 si A gana, y 0 de lo contrario). Esto fortalecerá nuestros resultados límite más bajos (porque implica que incluso descubrir si uno de los candidatos dado es difícil) .5 Por lo tanto, un conjunto de engaño en nuestro contexto es un conjunto de vectores de votos para que un gana (no gane) concada uno de ellos;Pero para cualquier dos vectores de voto diferentes en el set, hay una forma de tomar algunos votos de los votantes del primer vector y los otros votos del segundo vector, para que A no gana (gana). Para simplificar las pruebas de nuestros límites inferiores, hacemos suposiciones como el número de votantes n es impar en muchas de estas pruebas. Por lo tanto, técnicamente, no probamos el límite inferior para los pares (número de candidatos, número de votantes) (M, n) que no satisfacen estos supuestos (por ejemplo, si hacemos la suposición anterior, entonces técnicamente no probamosel límite inferior para cualquier par (m, n) en el que n está par). Sin embargo, siempre demostramos el límite inferior para un conjunto representativo de pares (M, N). Por ejemplo, para cada uno de nuestros límites inferiores es el caso que para infinitamente muchos valores de M, hay infinitamente muchos valores de N de tal manera que el límite inferior se demuestra para el par (M, N).4. Resultados ahora estamos listos para presentar nuestros resultados. Para cada regla de votación, primero damos un protocolo de comunicación determinista para determinar el ganador de establecer un límite superior. Luego, damos un límite inferior a la complejidad de la comunicación no determinista (incluso en la complejidad de decidir si un candidato dado gana, lo cual es una pregunta más fácil). Los límites inferiores coinciden con los límites superiores en todos menos dos casos: la regla STV (límite superior O (n (log m) 2); límite inferior ω (n log m)) y la regla máxima (límite superior o (nm log m m), aunque damos un protocolo no determinista que es O (nm); límite inferior ω (nm)). Cuando discutimos una regla de votación en la que los votantes clasifican a los candidatos, representaremos una clasificación en la que el candidato C1 se clasifica primero, C2 ocupa el segundo lugar, etc. como C1 C2...cm.5 Una posible preocupación es que en el caso de que sea posible lazos, puede requerir mucha comunicación para verificar si un candidato específico A se encuentra entre los ganadores, pero poca comunicación para producir uno de los ganadores. Sin embargo, todos los conjuntos de engaño que usamos en las pruebas tienen la propiedad de que si una gana, entonces A es el ganador único. Por lo tanto, en estos conjuntos de engaño, si uno conoce a alguno de los ganadores, entonces uno sabe si A es un ganador. Por lo tanto, calcular a uno de los ganadores requiere al menos tanta comunicación como verificar si A está entre los ganadores. En general, cuando un problema de comunicación permite múltiples respuestas correctas para un vector dado de entradas, esto se conoce como calcular una relación en lugar de una función [12]. Sin embargo, según lo anterior, podemos restringir nuestra atención a un subconjunto del dominio donde la regla de votación realmente es una función (de un solo valor) y, por lo tanto, las técnicas de límite más bajas para las funciones en lugar de las relaciones serán suficientes. A veces, para fines de una prueba, la clasificación interna de un subconjunto de los candidatos no importa, y en este caso no lo especificaremos. Por ejemplo, si S = {C2, C3}, entonces C1 S C4 indica que la clasificación C1 C2 C3 C4 o la clasificación C1 C3 C2 C4 se pueden usar para la prueba. Primero damos un límite superior universal. Teorema 1. La complejidad de comunicación determinista de cualquier regla de votación basada en rango es O (NM log M). Prueba. Este límite se logra simplemente haciendo que todos comuniquen todo su orden de los candidatos (lo que indica que el rango de un candidato individual requiere solo O (log m) bits, por lo que cada uno de los n votantes puede indicar el rango de cada uno de los m candidatos). El próximo lema será útil en algunas de nuestras pruebas. Lema 1. Si M divide n, entonces log (n!) −m log ((n/m)!) ≥ n (log m - 1)/2. Prueba. Si n/M = 1 (es decir, n = m), entonces esta expresión se simplifica para registrar (n!). Tenemos log (n!) = N i = 1 log i ≥ n x = 1 log (i) dx, que, usando integración por piezas, es igual a n log n - (n - 1)> n (log n - 1)= n (log m - 1)> n (log m - 1)/2. Entonces, podemos suponer que N/M ≥ 2. Observamos que log (n!) = N i = 1 log i = n/m - 1 i = 0 m j = 1 log (im+j) ≥ n/m - 1 i = 1 m j = 1 log (im) = m n/m - 1 i = 1 log (im), y que m log ((n/m)!) = m n/m i = 1 log (i). Por lo tanto, log (n!) - m log ((n/m)!) ≥ m n/m - 1 i = 1 log (im) - m n/m i = 1 log (i) = m ((n/m - 1i = 1 log (im/i)) - log (n/m)) = m ((n/m− 1) log m - log n+log m) = n log m - m log n.Ahora, utilizando el hecho de que N/M ≥ 2, tenemos m log n = n (m/n) log m (n/m) = n (m/n) (log m + log (n/m)) ≤n (1/2) (log M + log 2). Por lo tanto, log (n!) - m log ((n/m)!) ≥ n log m - m log n ≥ n log m - n (1/2) (log m + log 2) = n (log m -m -m -m -1)/2. Teorema 2. La complejidad de comunicación determinista de la regla de pluralidad es O (n log m). Prueba. Indicar que uno de los candidatos solo requiere bits o (log m), para que cada votante simplemente pueda indicar a su candidato más preferido. Teorema 3. La complejidad de la comunicación no determinista de la regla de pluralidad es Ω (n log m) (incluso para decidir si un candidato determinado A gana). Prueba. ¡Exhibiremos un conjunto de tamaño de tamaño!((n m)!) M donde n = (n - 1)/2. Tomar el logaritmo de esto le da log (n!) - m log ((n /m)!), Por lo que el resultado se deduce de Lemma 1. El conjunto de engaños consistirá en todos los vectores de votos que satisfacen las siguientes limitaciones: • Para cualquier 1 ≤ i ≤ n, los votantes 2i - 1 y 2 votan lo mismo.81 • Cada candidato recibe igualmente muchos votos de los primeros votantes 2n = n - 1.• El último votante (votante n) vota para a. El candidato A gana con cada uno de estos vectores de voto debido al voto adicional para A de la última votante. Dado que m divide n, veamos cuántos vectores de voto hay en el conjunto de engaño. Necesitamos distribuir N pares de votantes de manera uniforme sobre M candidatos, para un total de pares de votantes N /M por candidato;¡Y hay precisamente n!((¡(n m)!) M formas de hacer esto.6 Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores en talforma en que una pierde. Que yo sea un número de tal manera que los dos vectores de voto no estén de acuerdo sobre el candidato para el que votan los votantes 2i - 1 y 2. Sin pérdida de generalidad, suponga que en el primer vector de voto, estos votantes no votan por A (sino por algún otro candidato, B, en su lugar). Ahora, construya un nuevo vector de voto tomando votos 2i - 1 y 2i a partir del primer vector de voto, y los votos restantes del segundo vector de voto. Luego, B recibe votos de 2n /m + 2 en este vector de voto recientemente construido, mientras que A recibe como máximo votos 2N /M + 1. Entonces, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de engaños correcto. Teorema 4. La complejidad de comunicación determinista de la pluralidad con la regla de escorrentía es o (n log m). Prueba. Primero, deje que cada votante indique a su candidato más preferido utilizando bits log M. Después de esto, se conocen los dos candidatos en la escorrentía, y cada votante puede indicar cuál ella prefiere usar un solo bit adicional. Teorema 5. La complejidad de la comunicación no determinista de la pluralidad con la regla de escorrentía es ω (n log m) (incluso para decidir si un candidato determinado A gana). Prueba. ¡Exhibiremos un conjunto de tamaño de tamaño!((n m)!) M donde m = m/2 y n = (n - 2)/4. Tomar el logaritmo de esto le da log (n!) - m log ((n /m)!), Por lo que el resultado se deduce de Lemma 1. Divida a los candidatos en M pares: (C1, D1), (C2, D2) ,..., (cm, dm) donde c1 = a y d1 = b. El conjunto de engaño consistirá en todos los vectores de votos que satisfacen las siguientes limitaciones: • Para cualquier 1 ≤ i ≤ n, los votantes 4i - 3 y 4i - 2 clasifican los candidatos ck (i) a c - {a, ck (i)}, para algún candidato CK (i).(Si ck (i) = a, entonces el voto es simplemente un c - {a}.) • Para cualquier 1 ≤ i ≤ n, los votantes 4i - 1 y 4i clasifican los candidatos dk (i) a c - {a, dk(i)} (es decir, su candidato más preferido es el candidato que se combina con el candidato que votan los dos votantes anteriores).6 Una prueba intuitiva de esto es la siguiente. Podemos contar el número de permutaciones de n elementos de la siguiente manera. Primero, divida los elementos en m cubos de tamaño N /M, de modo que si X se coloca en un cubo de índice inferior que y, entonces X se indexará más bajo en la permutación eventual. Luego, decida la permutación dentro de cada cubo (para el cual hay (n /m)! Opciones por cubo). Se deduce que n!es igual al número de formas de dividir n elementos en m cubos de tamaño n /m, tiempos ((n /m)!) M.• Cada candidato se clasifica en la parte superior de igualmente muchos de los primeros votos 4n = n - 2.• El votante 4n +1 = n - 1 clasifica a los candidatos a c− {a}.• El votante 4n + 2 = n clasifica a los candidatos B C - {B}. El candidato A gana con cada uno de estos vectores de voto: debido a los dos últimos votos, los candidatos A y B están un voto por delante de todos los demás candidatos y continúan con la segunda vuelta, y en este punto todos los votos que tenían otro candidato clasificado enLa parte superior se transfiere a A, de modo que A gana la escorrentía. Dado que m divide n, veamos cuántos vectores de voto hay en el conjunto de engaño. Necesitamos distribuir n grupos de cuatro votantes de manera uniforme sobre los pares de candidatos, y (como en la prueba del teorema 3) hay n!(((n m)!) M formas de hacer esto. Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Sea un número de tal que CK (i) no es lo mismo en estos dos vectores de voto, es decir, C1 k (i) (CK (i) en el primer vector de voto) no es igual a C2 K (i) (ck (i) en el segundo vector de voto). Sin pérdida de generalidad, suponga que C1 k (i) = a. Ahora, construya un nuevo vector de voto tomando votos 4i - 3, 4i - 2, 4i - 1, 4i desde el primer vector de voto y los votos restantes del segundo vector de voto. En este vector de voto recientemente construido, C1 K (I) y D1 K (i) reciben votos 4N /M+2 en la primera ronda, mientras que A recibe como máximo los votos 4N /M+1. Entonces, A no continúa hasta la escorrentía en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de engaño correcto. Teorema 6. La complejidad de la comunicación no determinista de la regla Borda es ω (NM log m) (incluso para decidir si un candidato determinado A gana). Prueba. Exhibiremos un conjunto de tamaño (M!) N donde m = m - 2 y n = (n - 2)/4. Esto demostrará el teorema porque M!es Ω (M log m), de modo que log (((m!) n) = n log (m!) Es Ω (NM log m). Para cada vector (π1, π2, ..., πn) que consiste en n ordenados de todos los candidatos que no sean A y otro candidato fijo B (técnicamente, los ordenamientos toman la forma de una función uno a uno πi: {1,2, ..., M} → C - {a, b} con πi (j) = c indicando que el candidato C es el jTh en el orden representado por πi), que el siguiente vector de votos sea un elemento de la engañadaConjunto: • Para 1 ≤ i ≤ n, dejen que los votantes 4i - 3 y 4i - 2 clasifiquen los candidatos a b πi (1) πi (2)...πi (m).• Para 1 ≤ i ≤ n, que los votantes 4i - 1 y 4i clasifiquen a los candidatos πi (m) πi (m - 1)...πi (1) B a.• Deje que el votante 4n + 1 = n - 1 clasifique los candidatos a b π0 (1) π0 (2)...π0 (m) (donde π0 es un orden arbitrario de los candidatos distintos de A y B, que es el mismo para cada elemento del conjunto de engaño).• Deje que el votante 4n + 2 = n clasifique los candidatos π0 (m) π0 (m - 1)...π0 (1) a b. Observamos que este conjunto de tonterías tiene tamaño (M!), Y que el candidato gana en cada vector de votos en el conjunto de engaños (a 82 ver por qué, observamos que para cualquier 1 ≤ i ≤ n, votos 4i - 3 y4i-2 clasifica a los candidatos en la manera exacto de lo contrario de los votos 4i-1 y 4i, lo que bajo la regla de Borda significa que cancelan; y los dos últimos votos dan un punto más a A que a cualquier otro candidato que se obtengados puntos menos que a). Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector (π1 1, π1 2, ..., π1 n), y el segundo vector de voto corresponda al vector (π2 1, π2 2, ..., π2 n). Para algunos i, debemos tener π1 i = π2 i, de modo que para algún candidato c /∈ {a, b}, (π1 i) −1 (c) <(π2 i) −1 (c) (es decir,C se clasifica más alto en π1 I que en π2 i). Ahora, construya un nuevo vector de voto tomando votos 4i - 3 y 4i - 2 desde el primer vector de voto, y los votos restantes del segundo vector de voto.Como el puntaje de Borda permanece sin cambios. Sin embargo, debido a que C se clasifica más alto en π1 I que en π2 I, C recibe al menos 2 puntos más de los votos 4i - 3 y 4i - 2 en el vector de voto recién construido que en el segundo vector de voto. Se deduce que C tiene una puntuación Borda más alta que A en el vector de voto recientemente construido. Entonces, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de tonterías correcto. Teorema 7. La complejidad de la comunicación no determinista de la regla de Copeland es Ω (NM log m) (incluso para decidir si un candidato dado gana). Prueba. Exhibiremos un conjunto de tamaño de tamaño (M!) N donde m = (m - 2)/2 y n = (n - 2)/2. Esto demostrará el teorema porque M!es Ω (M log m), de modo que log (((m!) n) = n log (m!) Es Ω (NM log m). Escribimos el conjunto de candidatos como la siguiente unión disjunta: c = {a, b} ∪ l ∪ r donde l = {l1, l2 ,..., lm} y r = {r1, r2 ,..., rm}. Para cada vector (π1, π2, ..., πn) que consiste en n permutaciones de los enteros 1 a m (πi: {1, 2, ..., m} → {1, 2, .., m}), deje que el siguiente vector de votos sea un elemento del conjunto de endultos: • para 1 ≤ i ≤ n, que el votante 2i - 1 clasifique los candidatos a b lπi (1) rπi (1) lπi (2) rπi (2)...lπi (m) rπi (m).• Para 1 ≤ i ≤ n, que el votante 2i clasifique a los candidatos rπi (m) lπi (m) rπi (m −1) lπi (m −1)...rπi (1) lπi (1) b a.• Deje que el votante n - 1 = 2n + 1 clasifique los candidatos a b l1 r1 l2 r2...lm rm.• Deje que el votante n = 2n +2 clasifique los candidatos RM LM RM −1 LM −1...r1 l1 a b. Observamos que este conjunto de tonterías tiene tamaño (¡m!), Y ese candidato A gana en cada vector de votos en el conjunto de engaños (cada par de candidatos está vinculado en sus elecciones por pares, con la excepción de que A derrota B, para queA gana las elecciones por medio punto). Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector (π1 1, π1 2, ..., π1 n), y el segundo vector de voto corresponda al vector (π2 1, π2 2, ..., π2 n). Para algunos i, debemos tener π1 i = π2 i, de modo que para algunos j ∈ {1, 2 ,..., m}, tenemos (π1 i) −1 (j) <(π2 i) −1 (j). Ahora, construya un nuevo vector de voto tomando el voto 2i - 1 desde el primer vector de voto, y los votos restantes del segundo vector de voto.A medida que el puntaje de Copeland permanece sin cambios. Consideremos el puntaje de LJ. Primero observamos que el rango de LJ en la votación 2i - 1 en el vector de voto recientemente construido es al menos 2 más alto que en el segundo vector de voto, porque (π1 i) −1 (j) <(π2 i) −1(J). Sea D1 (LJ) el conjunto de candidatos en L ∪ R que el votante 2i - 1 se clasificó más bajo que LJ en el primer vector de voto (D1 (LJ) = {c ∈ L ∪ R: LJ 1 2i - 1 C}),y que D2 (lj) sea el conjunto de candidatos en L ∪ R que el votante 2i - 1 se clasificó más bajo que LJ en el segundo vector de voto (D2 (LJ) = {C ∈ L ∪ R: LJ 2 2i - 1 C}). Luego, se deduce que en el vector de voto recientemente construido, LJ derrota a todos los candidatos en D1 (LJ) - D2 (LJ) en sus elecciones por pares (porque LJ recibe un voto adicional en cada una de estas elecciones por pares en relación con la segunda votaciónVector), y pierde a todos los candidatos en D2 (LJ) - D1 (LJ) (porque LJ pierde un voto en cada una de estas elecciones por pares en relación con el segundo vector de voto), y se vincula con todos los demás. Pero | d1 (lj) | - | d2 (lj) |≥ 2, y por lo tanto | d1 (lj) - d2 (lj) |- | d2 (lj) - d1 (lj) |≥ 2. Por lo tanto, en el vector de voto recientemente construido, LJ tiene al menos dos victorias por pares más que las pérdidas por pares, y por lo tanto tiene al menos 1 punto más que si LJ hubiera vinculado todas sus elecciones por pares. Por lo tanto, LJ tiene un puntaje de Copeland más alto que A en el vector de voto recientemente construido. Entonces, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de tonterías correcto. Teorema 8. La complejidad de la comunicación no determinista de la regla Maximin es O (NM). Prueba. El protocolo no determinista adivinará qué candidato W es el ganador y, para el candidato C, qué candidato O (c) es el candidato contra quien C recibe su puntaje más bajo en una elección por pares. Luego, deje que cada votante comunique lo siguiente: • Para cada candidato C = W, ya sea que prefiera C a W;• Para cada candidato C = W, ya sea que prefiera C a O (C). Observamos que esto requiere la comunicación de bits 2n (m− 1). Si las suposiciones eran correctas, entonces, dejar que n (d, e) sea el número de votantes que prefieren el candidato d al candidato E, deberíamos tener n (c, o (c)) <n (w, c) para cualquier c =W, C = W, que demostrará que W gana las elecciones. Teorema 9. La complejidad de la comunicación no determinista de la regla Maximin es Ω (nm) (incluso para decidir si un candidato dado gana). Prueba. Exhibiremos un conjunto de tamaño de tamaño 2n m donde m = m - 2 y n = (n - 1)/4. Sea B un candidato que no sea a. Para cada vector (S1, S2, ..., Sn) que consiste en n subconjuntos si ⊆ c - {a, b}, deje que el siguiente vector de votos sea un elemento del conjunto de engaños: • para 1 ≤ i ≤ n,Deje que los votantes 4i - 3 y 4i - 2 clasifiquen los candidatos si a c - (si ∪ {a, b}) b.• Para 1 ≤ i ≤ n, que los votantes 4i - 1 y 4i clasifiquen a los candidatos b c - (si ∪ {a, b}) a si.83 • Deje que el votante 4n + 1 = n clasifique a los candidatos a b c - {a, b}. Observamos que este conjunto de engaño tiene tamaño (2m) n = 2n m, y que el candidato A gana en cada vector de votos en el conjunto de engaños (en cada una de las elecciones por pares, A se clasifica más alto que su oponente por 2n +1= (n+1)/2> n/2 votos). Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector (S1 1, S1 2, ..., S1 n), y el segundo vector de voto corresponda al vector (S2 1, S2 2, ..., S2 n). Para algunos i, debemos tener S1 i = S2 I, de modo que S1 I S2 I o S2 I S1 I. Sin pérdida de generalidad, suponga que S1 I S2 I, y deje que C sea un candidato en S1 I - S2 I. Ahora, construya un nuevo vector de voto tomando votos 4i - 3 y 4i - 2 desde el primer vector de voto, y los votos restantes del segundo vector de voto. En este vector de voto recientemente construido, A se clasifica más alto que C por solo 2n -1 votantes, por la siguiente razón. Mientras que los votantes 4i - 3 y 4i - 2 no clasifican C más alto que A en el segundo vector de voto (porque c /∈ S2 I), los votantes 4i - 3 y 4i - 2 hacen el rango C más alto que A en el primer vector de voto (porque c ∈ S1 i). Además, en cada una de las elecciones de BS por pares, B ocupa un lugar más alto que su oponente por al menos 2n votantes. Por lo tanto, A tiene un puntaje máximo más bajo que B, por lo tanto, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de engaño correcto. Teorema 10. La complejidad de comunicación determinista de la regla STV es O (N (log m) 2). Prueba. Considere el siguiente protocolo de comunicación. Deje que cada votante primero anuncie su candidato más preferido (O (N log m) comunicación). En las rondas restantes, realizaremos un seguimiento de los candidatos más preferidos de cada votantes entre los candidatos restantes, lo que será suficiente para implementar la regla. Cuando se elimina el candidato C, deje que cada uno de los votantes cuyos candidatos más preferidos entre los candidatos restantes anunciaran a su candidato más preferido entre los candidatos restantes después de la eliminación de CS. Si el candidato C era el candidato ésimo a eliminar (es decir, había m - i + 1 candidatos restantes antes de la eliminación de CS), se deduce que, como máximo, los votantes n/(m - i + 1) tenían el candidato C como el más preferidocandidato entre los candidatos restantes y, por lo tanto, el número de bits que se comunicarán después de la eliminación del candidato ésimo es O ((n/(m - i+1)) log m) .7 Por lo tanto, la comunicación total en este protocolo de comunicaciónes o (n log m + m - 1 i = 1 (n/(m - i + 1)) log m). Por supuesto, m - 1 i = 1 1/(m - i + 1) = m i = 2 1/i, que es o (log m). Sustituyendo en la expresión anterior, encontramos que la complejidad de la comunicación es O (n (log m) 2). Teorema 11. La complejidad de la comunicación no determinista de la regla STV es ω (n log m) (incluso para decidir si un candidato dado g gana). Prueba. Omitimos esta prueba debido a la restricción de espacio.7 en realidad, o ((n/(m - i + 1) log (m - i + 1)) también es correcto, pero no mejorará el límite. Teorema 12. La complejidad de la comunicación determinista de la regla de aprobación es O (nm). Prueba. La aprobación o desaprobación de un candidato requiere solo un poco de información, por lo que cada votante simplemente puede aprobar o desaprobar a cada candidato para una comunicación total de los bits NM. Teorema 13. La complejidad de la comunicación no determinista de la regla de aprobación es Ω (nm) (incluso para decidir si un candidato dado gana). Prueba. Exhibiremos un conjunto de tamaño de tamaño 2n m donde m = m - 1 y n = (n - 1)/4. Para cada vector (S1, S2, ..., Sn) que consiste en n subconjuntos si ⊆ c - {a}, que el siguiente vector de votos sea un elemento del conjunto de engaño: • Para 1 ≤ i ≤ n, deje que los votantes4i - 3 y 4i - 2 aprueban Si ∪ {a}.• Para 1 ≤ i ≤ n, que los votantes 4i - 1 y 4i aprueben c - (si ∪ {a}).• Deje que el votante 4n + 1 = n apruebe {a}. Observamos que este conjunto de tonterías tiene tamaño (2m) n = 2n m, y que el candidato A gana en cada vector de votos en el conjunto de engaño (a está aprobado por 2n + 1 votantes, mientras que el candidato es aprobado por 2N Votantes). Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector (S1 1, S1 2, ..., S1 n), y el segundo vector de voto corresponda al vector (S2 1, S2 2, ..., S2 n). Para algunos i, debemos tener S1 i = S2 I, de modo que S1 I S2 I o S2 I S1 I. Sin pérdida de generalidad, suponga que S1 I S2 I, y deje que B sea un candidato en S1 I - S2 I. Ahora, construya un nuevo vector de voto tomando votos 4i - 3 y 4i - 2 desde el primer vector de voto, y los votos restantes del segundo vector de voto. En este vector de voto recientemente construido, A todavía está aprobado por 2n + 1 votos. Sin embargo, B se aprueba por 2n + 2 votos, por la siguiente razón. Mientras que los votantes 4i - 3 y 4i - 2 no aprueban B en el segundo vector de voto (porque b /∈ S2 I), los votantes 4i - 3 y 4i - 2 aprueban B en el primer vector de voto (porque b ∈ S1 i). Se deduce que la puntuación de BS en el vector de voto recientemente construido es BS Score en el segundo vector de voto (2n), más dos. Entonces, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de engaños correcto. Curiosamente, se puede obtener un límite inferior ω (m) incluso para el problema de encontrar un candidato que sea aprobado por más de un votante [20]. Teorema 14. La complejidad de la comunicación determinista de la regla del condorcet es O (nm). Prueba. Mantenemos un conjunto de candidatos activos que se inicializan a C. En cada etapa, elegimos dos de los candidatos activos (por ejemplo, los dos candidatos con los índices más bajos), y dejamos que cada votante comunique cuál de los dos candidatos que prefiere..(Tal etapa requiere la comunicación de n bits, uno por votante). El candidato preferido por menos 84 votantes (el perdedor de las elecciones por pares) se elimina de S. (si las elecciones por pares están atadas, ambos candidatos se eliminan). Después de la mayoría de las iteraciones M - 1, solo queda un candidato (o cero candidatos a los que quedan, en cuyo caso no hay ganador de Condorcet). Que A sea el candidato restante. Para averiguar si el candidato A es el ganador del Condorcet, deje que cada votante se comunique, por cada candidato C = A, si prefiere A a C.(Esto requiere la comunicación de a lo sumo a los bits n (m - 1)). Esto es suficiente para establecer si A ganó cada una de sus elecciones por pares (y por lo tanto, si A es el ganador del Condorcet). Teorema 15. La complejidad de la comunicación no determinista de la regla del condorcet es ω (nm) (incluso para decidir si un candidato dado gana). Prueba. Exhibiremos un conjunto de tamaño de tamaño 2n m donde m = m - 1 y n = (n - 1)/2. Para cada vector (S1, S2, ..., Sn) que consiste en n subconjuntos si ⊆ c - {a}, que el siguiente vector de votos sea un elemento del conjunto de engaño: • Para 1 ≤ i ≤ n, votante2i - 1 clasifica a los candidatos si a c - si.• Para 1 ≤ i ≤ n, deje que el votante 2i clasifique a los candidatos c - si a si.• Deje que el votante 2n +1 = n clasifique a los candidatos a c - {a}. Observamos que este conjunto de tonterías tiene tamaño (2m) n = 2n m, y que el candidato se gana en cada vector de votos en el conjunto de engaños (un gana cada una de sus elecciones por pares por un solo voto). Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector (S1 1, S1 2, ..., S1 n), y el segundo vector de voto corresponda al vector (S2 1, S2 2, ..., S2 n). Para algunos i, debemos tener S1 i = S2 I, de modo que S1 i S2 I o S2 I S1 I. Sin pérdida de generalidad, suponga que S1 I S2 I, y deje que B sea un candidato en S1 I - S2 I. Ahora, construya un nuevo vector de voto tomando el voto 2i - 1 desde el primer vector de voto, y los votos restantes del segundo vector de voto. En este vector de voto recientemente construido, B gana su elección por pares contra A por un voto (el voto 2i - 1 clasifica B por encima de A en el vector de voto recientemente construido porque b ∈ S1 I, mientras que en el segundo voto vector de vector 2i - 1 clasificó A Aarriba b porque b /∈ S2 I). Entonces, A no es el ganador de Condorcet en el vector de voto recientemente construido, y por lo tanto tenemos un conjunto de engaños correcto. Teorema 16. La complejidad de comunicación determinista de la regla de la copa es O (nm). Prueba. Considere el siguiente protocolo de comunicación simple. Primero, deje que todos los votantes se comuniquen, por cada uno de los enfrentamientos en la primera ronda, cuáles de sus dos candidatos prefieren. Después de esto, se conocen los enfrentamientos para la segunda ronda, así que deje que todos los votantes comuniquen qué candidato prefieren en cada enfrentamiento en la segunda ronda-ETC. Debido a que la comunicación de cuál de los dos candidatos se prefiere requiere solo un bit por votante, y debido a que solo hay enfrentamientos de M - 1 en total, este protocolo de comunicación requiere la comunicación O (NM). Teorema 17. La complejidad de la comunicación no determinista de la regla de la copa es Ω (nm) (incluso para decidir si un candidato dado gana). Prueba. Exhibiremos un conjunto de tamaño de tamaño 2n m donde m = (m - 1)/2 y n = (n - 7)/2. Dado que M + 1 es un poder de 2, por lo que un candidato recibe un adiós (es decir, no enfrenta a un oponente) en la primera ronda, que sea el candidato con el adiós. De los enfrentamientos de primera ronda, deje que LJ denote al candidato (izquierda) en el enfrentamiento JTH, y RJ sea el otro candidato (a la derecha). Sea l = {lj: 1 ≤ j ≤ m} y r = {rj: 1 ≤ j ≤ m}, de modo que c = l ∪ r ∪ {a}..........l r l r l r a m1 1 2 2 m Figura 1: El horario para la regla de la copa utilizada en la prueba del teorema 17. Para cada vector (S1, S2, ..., Sn) que consiste en n subconjuntos si ⊆ r, deje que el siguiente vector de votos sea un elemento del conjunto de endultos: • Para 1 ≤ i ≤ n, deje que el votante 2i - 1Los candidatos si l a r - si.• Para 1 ≤ i ≤ n, que el votante 2i clasifique a los candidatos r - si l a si.• Que los votantes 2n +1 = n - 6, 2n +2 = n - 5, 2n +3 = n - 4 clasifiquen a los candidatos l a R. • Que los votantes 2n +4 = n - 3, 2n +5 = n −2 Rango de los candidatos un R1 L1 R2 L2...RM LM.• Deje que los votantes 2n + 6 = n - 1, 2n + 7 = n clasifiquen los candidatos rm lm rm −1 lm −1...R1 L1 a. Observamos que este conjunto de engaño tiene tamaño (2m) n = 2n m. Además, el candidato se gana en cada vector de votos en el conjunto de engaños, por las siguientes razones. Cada candidato RJ derrota a su oponente LJ en la primera ronda.(Para cualquier 1 ≤ i ≤ n, el efecto neto de los votos 2i - 1 y 2i en la elección por pares entre RJ y LJ es cero; votos n - 6, n - 5, n - 4 prefieren LJ a RJ, pero los votos n- 3, n - 2, n - 1, n prefieren rj a lj.) Además, una derrota a cada RJ en sus elecciones por pares.(Para cualquier 1 ≤ i ≤ n, el efecto neto de los votos 2i - 1 y 2i en la elección por pares entre A y RJ es cero; los votos n - 1, N prefieren Rj a A, pero los votos n - 6, N - 5, n - 4, n - 3, n - 2 prefieren a a rj.) Se deduce que una voluntad derrotará a todos los candidatos que enfrenta. Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector 85 (S1 1, S1 2, ..., S1 n), y el segundo vector de voto corresponda al vector (S2 1, S2 2, ..., S2 N). Para algunos i, debemos tener S1 i = S2 I, de modo que S1 I S2 I o S2 I S1 I. Sin pérdida de generalidad, suponga que S1 I S2 I, y deje que RJ sea un candidato en S1 I - S2 I. Ahora, construya un nuevo vector de voto tomando el voto 2i del primer vector de voto y los votos restantes del segundo vector de voto. Observamos que, mientras que en el segundo voto el vector vector 2i prefería RJ a LJ (porque rj ∈ R - S2 I), en el vector de voto recientemente construido, este ya no es el caso (porque rj ∈ S1 i). Se deduce que, mientras que en el segundo vector de voto, RJ derrotó a LJ en la primera ronda por una votación, en el vector de voto recientemente construido, LJ derrota a RJ en la primera ronda. Por lo tanto, al menos un LJ avanza a la segunda ronda después de derrotar a su oponente RJ. Ahora, observamos que en el vector de voto recientemente construido, cualquier LK gana su elección por pares contra cualquier RQ con q = k.Esto se debe a que entre los primeros votos 2n, al menos n - 1 prefiere LK a RQ;votos n - 6, n - 5, n - 4 prefieren lk a rq;y, porque q = k, los votos n - 3, n - 2 prefieren lk a rq (si k <q), o votos n - 1, n prefieren lk a rq (si k> q). Por lo tanto, al menos n + 4 = (n + 1)/2> n/2 votos prefieren LK a RQ. Además, cualquier LK gana su elección por pares contra a. Esto se debe a que solo los votos n - 3 y N - 2 prefieren A a LK. Se deduce que, después de la primera ronda, cualquier candidato sobreviviente LK solo puede perder un enfrentamiento contra otro LK sobreviviente, por lo que uno de los LK debe ganar las elecciones. Entonces, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de engaños correcto. Teorema 18. La complejidad de la comunicación determinista de la regla Bucklin es O (nm). Prueba. Sea L el entero mínimo para el que hay un candidato que está clasificado entre los principales candidatos L por más de la mitad de los votos. Haremos una búsqueda binaria de l.En cada punto, tendremos una LL límite inferior que es más pequeña que L (inicializada a 0), y una LH de límite superior que está al menos L (inicializado a M). Mientras que LH - LL> 1, continuamos descubriendo si (LH - L)/2 es más pequeño que L, después de lo cual podemos actualizar los límites. Para averiguar si un número K es más pequeño que L, determinamos todos los votantes K más preferidos a los candidatos. Cada votante puede comunicar qué candidatos se encuentran entre sus K candidatos más preferidos que usan bits (para cada candidato, indican si el candidato se encuentra entre los mejores K o no), pero debido ade o ((log m) nm), que no es lo suficientemente fuerte. Sin embargo, si ll <k <lh, y ya conocemos a los votantes de los candidatos preferidos más, así como sus candidatos más preferidos de LH, entonces el votante ya no necesita comunicar si los candidatos más preferidos de LL se encuentran entre sus K candidatos más preferidos(porque deben ser), y ella ya no necesita comunicar si los candidatos menos preferidos de M -LH se encuentran entre sus K candidatos más preferidos (porque no pueden ser). Por lo tanto, el votante necesita comunicarse solo m - ll - (m - lh) = bits lh −ll en cualquier etapa dada. Debido a que cada etapa, LH - LL está (aproximadamente) a la mitad, cada votante en total solo comunica (aproximadamente) m + m/2 + m/4 +...≤ 2m bits. Teorema 19. La complejidad de la comunicación no determinista de la regla Bucklin es Ω (nm) (incluso para decidir si un candidato dado gana). Prueba. Exhibiremos un conjunto de tamaño de tamaño 2n m donde m = (m - 1)/2 y n = n/2. Escribimos el conjunto de candidatos como la siguiente unión disjunta: c = {a} ∪ l ∪ r donde l = {l1, l2 ,..., lm} y r = {r1, r2 ,..., rm}. Para cualquier subconjunto S ⊆ {1, 2 ,..., M}, Sea l (s) = {li: i ∈ S} y vamos r (s) = {ri: i ∈ S}. Para cada vector (S1, S2, ..., Sn) que consiste en n conjuntos si ⊆ {1, 2 ,..., m}, que el siguiente vector de votos sea un elemento del conjunto de engaños: • para 1 ≤ i ≤ n, que el votante 2i - 1 clasifique los candidatos l (si) r - r (si) a l - l (Si (Si) R (Si).• Para 1 ≤ i ≤ n, que el votante 2i clasifique a los candidatos l - l (Si) r (Si) a L (Si) R - R (Si). Observamos que este conjunto de tonterías tiene tamaño (2m) n = 2n m, y que el candidato se gana en cada vector de votos en el conjunto de engaños, por la siguiente razón. Cada candidato en C - {a} se clasifica entre los principales candidatos M por exactamente la mitad de los votantes (que no es suficiente para ganar). Por lo tanto, necesitamos mirar a los votantes principales candidatos M +1, y A está clasificado M +1º por todos los votantes. Todo lo que queda por mostrar es que para dos vectores distintos de votos en el conjunto de engaño, podemos dejar que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que pierda. Deje que el primer vector de voto corresponda al vector (S1 1, S1 2, ..., S1 n), y el segundo vector de voto corresponda al vector (S2 1, S2 2, ..., S2 n). Para algunos i, debemos tener S1 i = S2 I, de modo que S1 I S2 I o S2 I S1 I. Sin pérdida de generalidad, supongamos S1 i S2 I, y deje que J sea un entero en S1 I - S2 I. Ahora, construya un nuevo vector de voto tomando el voto 2i - 1 desde el primer vector de voto, y los votos restantes del segundo vector de voto. En este vector de voto recientemente construido, A todavía se clasifica en M + 1 por todos los votos. Sin embargo, LJ se clasifica entre los principales candidatos M por N + 1 = N/2 + 1 votos. Esto se debe a que, mientras que el voto 2i - 1 no clasifica a LJ entre los mejores candidatos en el segundo vector de voto (porque j /∈ S2 I, tenemos lj /∈ L (S2 I)), el voto 2i - 1 clasifica LJ entreLos principales candidatos M en el primer vector de voto (porque j ∈ S1 I, tenemos lj ∈ L (S1 I)). Entonces, A no es el ganador en el vector de voto recientemente construido y, por lo tanto, tenemos un conjunto de tonterías correcto. Teorema 20. La complejidad de la comunicación no determinista de la regla de pares clasificados es ω (NM log m) (incluso para decidir si un candidato determinado A gana). Prueba. Omitimos esta prueba debido a la restricción de espacio.5. Discusión Un obstáculo clave para usar la votación para la agregación de preferencias es la carga de comunicación que una elección impone a los votantes. Al reducir esta carga, puede ser factible realizar más elecciones sobre más problemas. En el límite, esto podría conducir a un cambio de gobierno representativo a un sistema en el que la mayoría de los problemas se decidan por referirse a una verdadera democracia electrónica. En este documento, analizamos la complejidad de la comunicación de las reglas de votación comunes. Saber qué reglas de votación requieren poca comunicación es especialmente importante cuando el problema a votar es de baja importancia que lo siguiente es verdadero: las partes involucradas están dispuestas a aceptar una regla que tiende a producir resultados que son ligeramente menos representativos de losPreferencias de los votantes, si esta regla reduce significativamente la carga de comunicación para los votantes. La siguiente tabla resume los resultados que obtuvimos. Regla de límite inferior Pluralidad de límite superior ω (n log m) o (n log m) pluralidad con escorrentía Ω (n log m) o (n log m) stv Ω (n log m) o (n (log m) 2)Condorcet Ω (NM) O (NM) Aprobación Ω (NM) O (NM) Bucklin Ω (NM) O (NM) Copa Ω (NM) O (NM) Maximin ω (NM) O (NM) Borda ω (NM Log (NM Logm) O (NM log M) Copeland Ω (NM log M) O (NM log M) Pares clasificados ω (NM log m) o (NM log m) Complejidad de comunicación de las reglas de votación, ordenadas de baja a alta. Todos los límites superiores son deterministas (con la excepción de Maximin, para lo cual el mejor límite superior determinista que probamos es O (NM log m)). Todos los límites inferiores se mantienen incluso para la comunicación no determinista e incluso para determinar si un candidato A es el ganador. Un área de investigación futura es estudiar lo que sucede cuando restringimos nuestra atención a los protocolos de comunicación que no revelan ninguna información estratégicamente útil. Esta restricción puede invalidar algunos de los límites superiores que derivamos utilizando protocolos de comunicación de varias etapas. Además, todos nuestros límites son los peores límites. Puede ser posible superar estos límites cuando la distribución de votos tiene una estructura adicional. Al decidir qué regla de votación usar para una elección, hay muchas consideraciones a tener en cuenta. Las reglas de votación que estudiamos en este documento son las más comunes que han sobrevivido a la prueba del tiempo. Una forma de seleccionar entre estas reglas es considerar los resultados recientes sobre la complejidad. La tabla anterior muestra que desde una perspectiva de complejidad de comunicación, la pluralidad, la pluralidad con la escorrentía y el STV son preferibles. Sin embargo, la pluralidad tiene la propiedad indeseable que es computacionalmente fácil de manipular votando estratégicamente [3, 7]. La pluralidad con la escorrentía es difícil de manipular mediante una coalición de votantes ponderados, o por un individuo que enfrenta incertidumbre correlacionada sobre los votos de los demás [7, 6]. STV también es difícil de manipular en esos entornos [7], pero también por un individuo con un conocimiento perfecto de los votos de los demás (cuando el número de candidatos está ilimitado) [2]. Por lo tanto, STV es más robusto, aunque puede requerir una comunicación un poco más en el peor de los casos según la tabla anterior. Sin embargo, otros criterios de selección son la complejidad computacional de determinar si se ha provocado suficiente información para declarar un ganador y la de determinar la secuencia óptima de consultas [8].6. Referencias [1] Lawrence Ausubel y Paul Milgrom. Subastas ascendentes con ofertas de paquetes. Fronteras de la economía teórica, 1, 2002. No. 1, Artículo 1. [2] John Bartholdi, III y James Orlin. El voto único transferible resiste la votación estratégica. Social Choice and Welfare, 8 (4): 341-354, 1991. [3] John Bartholdi, III, Craig Tovey y Michael Trick. La dificultad computacional de manipular una elección. Social Choice and Welfare, 6 (3): 227-241, 1989. [4] Avrim Blum, Jeffrey Jackson, Tuomas Sandholm y Martin Zinkevich. PREVERSIÓN DE PREFERENCIA Y APRENDIZAJE DE CONSULTA. Journal of Machine Learning Research, 5: 649-667, 2004. [5] Wolfram Conen y Tuomas Sandholm. PREVENTACIÓN DE PREFERENCIA EN SUBASTAS COMBINATORIALES: Resumen extendido. En Actas de la Conferencia ACM sobre Comercio Electrónico (ACM-EC), páginas 256-259, 2001. [6] Vincent Conitzer, Jerome Lang y Tuomas Sandholm. ¿Cuántos candidatos se necesitan para hacer que las elecciones sean difíciles de manipular? En Aspectos teóricos de la racionalidad y el conocimiento (Tark), páginas 201-214, 2003. [7] Vincent Conitzer y Tuomas Sandholm. Complejidad de manipular las elecciones con pocos candidatos. En Actas de la Conferencia Nacional sobre Inteligencia Artificial (AAAI), páginas 314-319, 2002. [8] Vincent Conitzer y Tuomas Sandholm. Elicitación de voto: complejidad y a prueba de estrategia. En Actas de la Conferencia Nacional sobre Inteligencia Artificial (AAAI), páginas 392-397, 2002. [9] Sven de Vries, James Schummer y Rakesh V. Vohra. En subastas ascendentes para objetos heterogéneos, 2003. Borrador.[10] Allan Gibbard. Manipulación de esquemas de votación. Econometrica, 41: 587-602, 1973. [11] Benoit Hudson y Tuomas Sandholm. Efectividad de los tipos de consultas y políticas para la obtención de preferencias en subastas combinatorias. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas de Multi-Agentes (AAMAS), páginas 386-393, 2004. [12] E Kushilevitz y N Nisan. Complexidad de comunicación. Cambridge University Press, 1997. [13] Sebasti´en Lahaie y David Parkes. Aplicación de algoritmos de aprendizaje a la obtención de preferencias. En Actas de la Conferencia ACM sobre Comercio Electrónico, 2004. [14] Noam Nisan e Ilya Segal. Los requisitos de comunicación de asignaciones eficientes y precios de apoyo. Journal of Economic Theory, 2005. Próximo.[15] David Parkes.Ibundle: una subasta eficiente de paquete de precios ascendentes. En Actas de la Conferencia ACM sobre Comercio Electrónico (ACM-EC), páginas 148-157, 1999. [16] Tuomas Sandholm. Una implementación del protocolo NET del contrato basado en cálculos de costos marginales. En Actas de la Conferencia Nacional sobre Inteligencia Artificial (AAAI), páginas 256-262, 1993. [17] Tuomas Sandholm y Craig Boutilier. PREVENTACIÓN DE PREFERENCIA EN SUBASTAS COMBINATORIALES. En Peter Cramton, Yoav Shoham y Richard Steinberg, editores, Subastas Combinatoriales, Capítulo 10. MIT Press, 2005. [18] Paolo Santi, Vincent Conitzer y Tuomas Sandholm. Hacia una caracterización de la obtención de preferencia polinomial con consultas de valor en subastas combinatorias. En Conference on Learning Theory (Colt), páginas 1-16, 2004. [19] Mark Satterthwaite. Condiciones a prueba de estrategias y flechas: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social. Journal of Economic Theory, 10: 187-217, 1975. [20] Ilya Segal. Los requisitos de comunicación de las reglas de elección social y los conjuntos de presupuestos de apoyo, 2004. Borrador. Presentado en el Taller DIMACS sobre temas computacionales en diseño de subastas, Universidad de Rutgers, Nueva Jersey, EE. UU.[21] Peter Wurman y Michael Wellman. AKBA: una subasta combinatoria progresiva de precio anónimo. En Actas de la Conferencia ACM sobre Comercio Electrónico (ACM-EC), páginas 21-29, 2000. [22] A. C. Yao. Algunas preguntas de complejidad relacionadas con la computación distribuida. En Actas del 11º Simposio ACM sobre Teoría de la Computación (STOC), páginas 209-213, 1979. [23] Martin Zinkevich, Avrim Blum y Tuomas Sandholm. Sobre la obtención de preferencias de tiempo polinómico con consultas de valor. En Actas de la Conferencia ACM sobre Comercio Electrónico (ACM-EC), páginas 176-185, 2003. 87