Estimación del PageRank global de las comunidades web Jason V. Davis Dept. de la Universidad de Ciencias de la Computación de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu Resumen Los emprendimientos localizados son pequeños empotrados son pequeños empotrados de la búsqueda son pequeños empotrados pequeños-Scale sistemas que indexan una comunidad particular en la web. Ofrecen varios beneficios sobre sus contrapartes a gran escala, ya que son relativamente económicos de construir, y pueden proporcionar una capacidad de búsqueda más precisa y completa sobre sus dominios relevantes. Una desventaja de que tales sistemas tienen sobre los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Dicha información es necesaria para evaluar el valor de las páginas en el dominio de búsqueda localizado dentro del contexto de la web en su conjunto. En este artículo, presentamos algoritmos bien motivados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables porque, dado un dominio local de tamaño N, utilizan recursos O (N) que incluyen tiempo de cálculo, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluidos los dominios específicos del sitio y los dominios específicos del tema. Demostramos que al rastrear tan solo N o 2n Páginas adicionales, nuestros métodos pueden dar excelentes estimaciones globales de PageRank. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información;G.1.3 [Análisis numérico]: Álgebra lineal numérica;G.3 [Probabilidad y estadísticas]: Markov procesa términos generales PageRank, cadena de Markov, complementación estocástica 1. Introducción Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad de la web. Dichas comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio Cs.Utexas.edu, o comunidades relacionadas con el tema, por ejemplo, sitios web políticos. En comparación con el gráfico web rastreado e indexado por motores de búsqueda a gran escala, el tamaño de tales comunidades locales suele ser pedidos de magnitud más pequeños. En consecuencia, los recursos computacionales necesarios para construir dicho motor de búsqueda también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la Web, los motores de búsqueda localizados también pueden proporcionar capacidades de búsqueda más precisas y completas sobre sus respectivos dominios. Un inconveniente de los índices localizados es la falta de información global necesaria para calcular las clasificaciones basadas en enlaces. El algoritmo de PageRank [3] ha demostrado ser una medida efectiva de tal manera. En general, el PageRank de una página determinada depende de las páginas en todo el gráfico web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafio local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la Web en su conjunto. Por ejemplo, considere un motor de búsqueda localizado que indexa páginas políticas con opiniones conservadoras. Una persona que desea investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrar numerosas opiniones de este tipo en varios sitios web. Si solo los valores locales de PageRank están disponibles, los resultados de búsqueda reflejarán solo creencias fuertemente sostenidas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados también pueden reflejar las opiniones de los extraños de la comunidad conservadora (aquellos documentos a los que los liberales tienen más acceso dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas un índice de motor de búsqueda local suele ser pedidos de magnitud más pequeños que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o el poder computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local mientras solo utilizamos recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafio local. Nuestro método propuesto busca un supergraph de nuestro subgraph local, de modo que los PageRanks locales dentro de este supergrafio están cerca de los verdaderos PageRanks globales. Construimos este supergraph rastreando iterativamente las páginas globales en la actual Web Frontier-I.E., Páginas globales con inclacas de páginas que ya se han rastreado. Para proporcionar al documento de seguimiento de 116 una buena aproximación a los PageRanks globales, se debe tener cuidado al elegir qué páginas se arrastrará a continuación;En este artículo, presentamos un algoritmo de selección de página bien motivado que también funciona bien empíricamente. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos a través de varios tipos de subgraphs locales, incluidas cuatro comunidades relacionadas con temas y varios dominios separados por site. Para evaluar el rendimiento, medimos la diferencia entre la estimación global de PageRank actual y el PageRank global, en función del número de páginas que se arrastran. Comparamos nuestro algoritmo con varias heurísticas y también con un algoritmo de referencia que elige páginas al azar, y mostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño N, podemos proporcionar buenas aproximaciones a los valores globales de PageRank mediante el rastreo a lo máximo de N o 2n Páginas adicionales. El papel está organizado de la siguiente manera. La Sección 2 ofrece una visión general de los motores de búsqueda localizados y describe sus ventajas sobre la búsqueda global. La Sección 3 proporciona antecedentes sobre el algoritmo de PageRank. La Sección 4 define formalmente nuestro problema, y la Sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La Sección 6 proporciona resultados experimentales, la Sección 7 ofrece una visión general del trabajo relacionado y, finalmente, se dan conclusiones en la Sección 8. 2. Los motores de búsqueda localizados Los motores de búsqueda localizados indexan una comunidad única de la web, generalmente una comunidad específica del sitio o una comunidad específica de temas. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa sobre su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 de Lyman et al.[13] encontraron que la Surface Web (sitios estáticos disponibles públicamente) consta de 8.900 millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesitan aproximadamente 167 terabytes de espacio. Para un investigador que desea construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un pequeño servidor, el almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional requerida para admitir consultas de búsqueda en una base de datos de este tamaño también es más manejable. Observamos que, para los motores de búsqueda específicos del tema, la comunidad relevante puede identificarse y descargar eficientemente mediante el uso de un rastreador enfocado [21, 4]. Para los dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastrear o araña, y se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, que sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de los robots. Esto prohíbe que los motores de búsqueda externos rastreen de descargar contenido del dominio, y un motor de búsqueda externo debe confiar en enlaces externos y anclar el texto para indexar estas páginas restringidas. Al restringirse solo a un dominio específico de Internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considere la consulta de búsqueda ambigua canónica, Jaguar, que puede referirse al fabricante de automóviles o al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener un mejor éxito utilizando un motor de búsqueda de zoología finamente ajustado que consultando Google con múltiples búsquedas de palabras clave y vadeando resultados irrelevantes. Radlinski y Joachims [19] propusieron recientemente un método para aprender mejores funciones de clasificación para la recuperación y se ha aplicado a varios dominios locales, incluido el sitio web de las universidades de Cornell [8].3. Descripción general de PageRank El algoritmo de PageRank define la importancia de las páginas web analizando la estructura de hipervínculo subyacente de un gráfico web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlace del gráfico web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución limitante de una caminata aleatoria sobre la cadena. Por lo tanto, el algoritmo de PageRank utiliza lo que a veces se conoce como el modelo de surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un ambiente de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Deje que seas una matriz de adyacencia M × M para un gráfico web determinado de tal manera que UJI = 1 si la página I se vincula a la página J y Uji = 0 de lo contrario. Definimos que la matriz de PageRank PU sea: PU = αud - 1 u + (1 - α) veterinario, (1) donde du es la matriz diagonal (única) de tal manera que UD - 1 U es estocástico de columna, α es un escalar dadode tal manera que 0 ≤ α ≤ 1, E es el vector de todos, y V es un vector no negativo, L1Normalizado, a veces llamado vector de surfista aleatorio. Tenga en cuenta que la matriz D-1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero. En presencia de tales nodos colgantes que no tienen indirectos, una solución comúnmente utilizada, propuesta por Brin et al.[3], es reemplazar cada columna cero de u por un vector no negativo y normalizado L1. El vector de PageRank R es el vector propio dominante de la matriz de PageRank, r = Pu r.Asumiremos, sin pérdida de generalidad, que R tiene una norma L1 de una. Computacionalmente, R se puede calcular utilizando el método de encendido. Este método primero elige un vector de inicio aleatorio R (0), y multiplica iterativamente el vector actual por la matriz de PageRank PU;Ver algoritmo 1. En general, cada iteración del método de energía puede tomar operaciones O (M2) cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un gráfico web será del orden del número de páginas. Al explotar la escasez de la matriz de PageRank, el trabajo por iteración se puede reducir a O (km), donde K es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del gráfico web [11, 7]. Finalmente, el espacio total necesario también es O (km), principalmente para almacenar el algoritmo de papel de seguimiento de la matriz U. 117 1: un algoritmo de tiempo lineal (por iteración) para calcular PageRank. ComputerPr (U) Entrada: U: Matriz de adyacencia. Salida: R: PageRank Vector. Elija (al azar) un vector inicial no negativo R (0) tal que R (0) 1 = 1. I ← 0 Repita i ← i + 1 ν ← αud-1 u r (i-1) {α es el aleatorioprobabilidad de surf} r (i) ← ν + (1 - α) V {V es el vector de surfista aleatorio.} hasta r (i) - r (i - 1) <Δ {δ es el umbral de convergencia.} r ← r ← r ←(i) 4. Definición del problema Dada un dominio local l, que sea una matriz de adyacencia n × n para todo el componente conectado de la web que contiene l, de modo que gji = 1 si la página i se vincula a la página j y gji = 0 de lo contrario. Sin pérdida de generalidad, dividiremos G AS: G = L gout lout gwithin, (2) donde l es el subgrafio local n × n correspondiente a los enlaces dentro del dominio local, lout es el subgrafio que corresponde a los enlaces del dominio localSeñala al dominio global, la gota es el subgrafio que contiene enlaces del dominio global al dominio local, y Gwithin contiene enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo las páginas dentro del dominio local se rastrean, y los vínculos entre estas páginas están representados por el subgraph L. Los enlaces en lo lut.a páginas sin rayos en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del gráfico global G, y definimos el vector de PageRank global de este gráfico para ser g.Deje que el vector N de longitud P ∗ sea el vector normalizado L1 correspondiente al PageRank global de las páginas en el dominio local L: P ∗ = El G ELG 1, donde el = [i |0] es la matriz de restricción que selecciona los componentes de G correspondientes a los nodos en L. Deje que P denote el vector de PageRank construido a partir del subgrafio de dominio local L. En la práctica, el PageRank local observado y el PageRank global P ∗ será bastante diferente. Uno esperaría que, a medida que el tamaño de la matriz local se acerca al tamaño de Global Matrix G, el PageRank global y el PageRank local observado se volverán más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n n, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, el rastreo de todas las páginas globales agotará rápidamente todos los recursos locales (computación, almacenamiento y ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafio ˆf de nuestro subgrafio local con tamaño O (n). Nuestro algoritmo de meta 2: el algoritmo Findglobalpr. FindGlobalpr (L, LOUT, T, K) Entrada: L: matriz de adyacencia cero para el dominio local, lout: matriz de salida de cero y un subgrafio global como en (2), t: número de iteraciones, k: k:Número de páginas para rastrear por iteración. Salida: ˆP: Una estimación mejorada del PageRank global de L. F ← L fout ← Lout f ← ComputerPr (f) para (i = 1 a t) {Determine qué páginas se arrastrará a continuación} páginas ← SelectNodes (F, Fout,f, k) Páginas de rastreo, Aumento F y modifique Fout {actualizar PageRanks para el nuevo dominio local} F ← ComputerPr (f) End {extraer PageRanks de dominio local original y normalizar} ˆp ← Elf Elf 1 es encontrar tal supergraph ˆf conPageRank ˆf, de modo que ˆf cuando se limita a L está cerca de P ∗. Formalmente, buscamos minimizar GlobalDiff (ˆf) = el ˆf el ˆf 1 - p ∗ 1.(3) Elegimos la norma L1 para medir el error, ya que no coloca un peso excesivo en los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más utilizada en la literatura para comparar los vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, dado en el Algoritmo 2, para construir ˆf. Inicialmente, F se establece en el subgraph L local, y se calcula el PageRank F de este gráfico. El algoritmo continúa de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de K nodos para rastrear a continuación desde el conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados se arrastran para expandir el subgrafio local, F, y los PageRanks de este gráfico expandido se recomputan. Estos pasos se repiten para cada una de las teraciones. Finalmente, se devuelve el Vector PageRank ˆp, que está restringido a páginas dentro del dominio local original. Dado nuestro cálculo, ancho de banda y restricciones de memoria, asumiremos que el algoritmo se arrastrará como máximo las páginas O (n). Dado que los PageRanks se calculan en cada iteración del algoritmo, que es una operación O (n), también asumiremos que el número de iteraciones t es una constante. Por supuesto, el principal desafío aquí es seleccionar qué conjunto de K nodos para rastrear a continuación. En la siguiente sección, definimos formalmente el problema y damos algoritmos eficientes.5. Selección de nodos En esta sección, presentamos algoritmos de selección de nodos que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de la página y proporcionamos evidencia experimental de que este criterio puede identificar efectivamente páginas que optimizan nuestro objetivo del problema (3). Luego presentamos nuestra contribución gorítmica del documento de pista de investigación AL118 principal del documento, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, damos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de página ampliamente utilizada [6].5.1 Formulación para una página J dada J En el dominio global, definimos el gráfico local expandido FJ: FJ = F S Ut J 0, (4) donde UJ es el vector cero que contiene los ataques de F en la página J, y SContiene los ingresos de la página J al dominio local. Tenga en cuenta que no permitimos autoinks en este marco. En la práctica, a menudo se eliminan los autocontrol, ya que solo sirven para inflar las páginas dadas PageRank. Observe que los inlinks en F desde el nodo J no se conocen hasta que el nodo J se rastree. Por lo tanto, estimamos este vector de entrada como la expectativa sobre el engranaje cuenta entre el conjunto de páginas ya rastreadas, s = f t e f t e 1.(5) En la práctica, para cualquier página, esta estimación puede no reflejar las verdaderas inslinks de esa página. Además, esta expectativa se muestrea del conjunto de enlaces dentro del dominio rastreo, mientras que una mejor estimación también usaría enlaces del dominio global. Sin embargo, la última distribución no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Deje que el PageRank de f sea f.Expresamos el PageRank f+ J del gráfico local expandido FJ como f+ j = (1-xj) fj xj, (6) donde xj es el pagerank del nodo global candidato j, y fj es el vector de PageRank normalizado en L1 restringido alas páginas en f. Dado que optimizar directamente nuestro objetivo de problemas requiere conocer el PageRank Global P ∗, en su lugar proponemos rastrear esos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: Influencia (J) = k∈L | FJ [k] - f [k] |(7) = EL (FJ - F) 1. Experimentalmente, la puntuación de influencia es un muy buen predictor de nuestro objetivo de problema (3). Para cada nodo global candidato J, la Figura 1 (a) muestra el valor de función objetivo Global Diff (FJ) en función de la influencia de la página J. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la Sección 6);Observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar efectivamente páginas que mejoran la estimación global de PageRank. Como línea de base, la Figura 1 (b) compara nuestro objetivo con un criterio alternativo, el recuento de ataques. El conteo de enlaces de enlace se define como el número de ataques al dominio local a la página j. La correlación aquí es mucho más débil..00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Objetivo de recuento de salida (a) (b) Figura 1: (a) La correlación entre nuestro criterio de selección de página de influencia (7) y elLa función objetivo real (3) el valor es bastante fuerte.(b) Esto contrasta con otros criterios, como el conteo de contorno, que exhiben una correlación mucho más débil.5.2 Computación Como se describe, para cada Página Global Candidato J, se debe calcular el puntaje de influencia (7). Si FJ se calcula exactamente para cada página J Global J, entonces el algoritmo de PageRank debería ejecutarse para cada una de las Páginas Globales J Global que consideramos, lo que resulta en un costo computacional O (N2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de FJ conducirá a un algoritmo cuadrático y, en cambio, debemos recurrir a los métodos para aproximar este vector. El algoritmo presentamos obras realizando una iteración de método de energía utilizada por el algoritmo de PageRank (algoritmo 1). Se ha demostrado que la tasa de convergencia para el algoritmo de PageRank es igual a la probabilidad de surfista aleatorio α [7, 11]. Dado un vector inicial x (0), si se realizan k iteraciones de pagerank, la solución actual de PageRank x (k) satisface: x (k) - x ∗ 1 = o (αk x (0) - x ∗ 1), (8) donde x ∗ es el vector PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Participamos la matriz de PageRank PFJ, correspondiente al × subgrafio FJ como: pfj = ˜f ˜s ˜ut j w, (9) donde ˜f = αf (df + diag (uJ)) - 1 + (1 - α) e+ 1 et, ˜s = αS + (1 - α) e + 1, ˜uj = α (df + diag (uj)) - 1 UJ + (1 - α) e + 1, w = 1 - α + 1, y diag (UJ) es la matriz diagonal con la entrada (i, i) igual a una si el elemento ésimo de UJ es igual a uno, y es cero de lo contrario. Hemos asumido aquí que el vector de surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estos supuestos no son necesarios y solo sirven para simplificar la discusión y el análisis. Un enfoque simple para estimar FJ es el siguiente. Primero, estime el PageRank F+ J de FJ calculando una iteración de PageRank sobre la matriz PFJ, utilizando el vector inicial ν = f 0. Luego, estime FJ eliminando el último componente de papel de seguimiento de 119 de nuestra estimación de F+ J (es decir, el componente correspondiente al nodo J) y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde de (6) que XJ es el PageRank del nodo agregado j. La diferencia entre el PageRank real F + J de PFJ y el vector inicial ν es ν - F + J 1 = XJ + F - (1 - XJ) FJ 1 ≥ XJ + |f 1 - (1 - xj) fj 1 |= xj + | xj |= 2xj. Por lo tanto, por (8), después de una iteración de PageRank, esperamos que nuestra estimación de F+ J todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos J con PageRank XJ relativamente alto, este método producirá resultados más inexactos. Luego presentaremos un método que elimina este sesgo y se ejecuta en el tiempo O (n).5.2.1 Complementación estocástica Dado que F+ J, como se dio en (6) es el PageRank de la matriz Pfj, tenemos: fj (1 - xj) xj = ˜f ˜s ˜ut j w fj (1 - xj) xj = ˜F fj (1 - xj) + ˜sxj ˜ut j fj (1 - xj) + wxj. Se puede demostrar que la resolución del sistema anterior para FJ produce fj = (˜f + (1 - w) −1 ˜s˜ut j) fj.(10) La matriz S = ˜f +(1 - W) −1 ˜s˜ut j se conoce como el complemento estocástico de la columna Pfj de matriz estocástica con respecto a la submatriz ˜f. La teoría de la complementación estocástica está bien estudiada, y se puede mostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, también tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el valor propio subdominante de S es como máximo +1 α, donde es el tamaño de F. Para lo suficientemente grande, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo de PageRank, especialmente la sensibilidad de los algoritmos, dependen de este valor [11]. En este método, estimamos el vector de longitud FJ calculando una iteración de PageRank sobre el complemento × estocástico S, comenzando en el vector F: FJ ≈ SF.(11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre el ( + 1) × ( + 1) Matrix PFJ para estimar F + J, y luego elimina el último componente de la estimación y renormaliza aFJ aproximado. El problema con el último método está en la elección del ( + 1) vector de inicio de longitud, ν.En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank por al menos 2αxj, donde XJ es el PageRank de la página J. Al usar el complemento estocástico, podemos establecer un límite inferior ajustado de cero para esta diferencia. Para ver esto, considere el caso en el que se agrega un nodo K a F para formar el subgrafio local aumentado FK, y que el PageRank de este nuevo gráfico es (1 - XK) F XK. Específicamente, la adición de la página K no cambia los PageRanks de las páginas en F, y por lo tanto Fk = F.Mediante la construcción del complemento estocástico, FK = SFK, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad FJ −f 1 en todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj −f, donde el vector fj se estima como en (11), fj - f ≈ sf - f = αF (df + diag (uJ)) - 1 f + (1 - α) e + +1 et f +(1 - w) −1 (˜ut j f) ˜s - f.(12) Tenga en cuenta que la matriz (DF +diag (UJ)) - 1 es diagonal. Dejar que o [k] sea el recuento de ataques para la página k en f, podemos expresar el elemento diagonal kth como: (df + diag (uj)) - 1 [k] = 1 o [k] +1 si UJ [k] = 1 1 o [k] si UJ [k] = 0 señalando que (o [k] + 1) −1 = o [k] −1 - (o [k] (o [k] + 1))−1 y reescribir esto en los rendimientos de la forma de matriz (DF +diag (UJ)) - 1 = D - 1 F −D - 1 F (DF +diag (UJ)) - 1 diag (UJ).(13) Usamos la misma identidad para expresar E + 1 = E - E ( + 1).(14) Recuerde que, por definición, tenemos PF = αF D - 1 F +(1 - α) e. Sustitutación (13) y (14) en (12) produce FJ - F ≈ (pf F - F) −αF D - 1 F (DF + diag (UJ)) - 1 diag (UJ) F - (1 - α)e ( + 1) + (1 - w) −1 (˜ut j f) ˜s = x + y + (˜ut j f) z, (15) señalando que, por definición, f = pf f, y definiendo los vectores x, y y z para ser x = −αf d - 1 f (df + diag (uj)) - 1 diag (uj) f (16) y = - (1 - α) e ( + 1) (17) z= (1 - w) −1 ˜s.(18) El primer término X es un vector disperso y toma valores distintos de cero solo para páginas locales k que son hermanos de la página global j. Definimos (i, j) ∈ F if y solo si f [j, i] = 1 (de manera equivalente, la página I enlace a la página j) y expresamos el valor del componente x [k] como: x [k] = −α k: (k, k) ∈F, uj [k] = 1 f [k] o [k] (o [k] + 1), (19) donde o [k], como antes, es el número deOutlinks de la página K en el dominio local. Tenga en cuenta que los últimos dos términos, y y z no dependen del nodo global actual j. Dada la función hj (f) = y + (˜ut j f) z 1, la cantidad fj - f 1 120 papel de pista de investigación se puede expresar como fj - f 1 = k x [k] + y [k] + (˜utj f) z [k] = k: x [k] = 0 y [k] + (i j f) z [k] + k: x [k] = 0 x [k] + y [k] + (˜ut j f) z [k] = hj (f) - k: x [k] = 0 y [k] + (˜ut j f) z [k] + k: x [k] = 0 x [k] + y[k] + (˜ut j f) z [k].(20) Si podemos calcular la función HJ en tiempo lineal, entonces podemos calcular cada valor de FJ - F 1 usando una cantidad adicional de tiempo que es proporcional al número de componentes distintos de cero en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Tenga en cuenta que (20) calcula la diferencia entre todos los componentes de F y FJ, mientras que nuestros criterios de selección de nodo, dados en (7), está restringido a los componentes correspondientes a los nodos en el dominio local L.detalle. Primero, el algoritmo calcula los recuentos externos para cada página en el dominio local. El algoritmo calcula la cantidad ˜ut j f para cada página global conocida j. Este producto interno se puede escribir como (1 - α) 1 + 1 + α K: (k, j) ∈Fout f [k] o [k] + 1, donde el segundo término resume sobre el conjunto de páginas locales que enlazana la página j. Dado que se suponía que el número total de bordes en Fout tenía el tamaño O () (recuerde que es el número de páginas en F), el tiempo de ejecución de este paso también es O (). El algoritmo calcula los vectores Y y Z, como se da en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de El (y + (˜ut j f) z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜ut j f se discretizan uniformemente en valores C {a1, ..., ac}. La cantidad El (y + aiz) 1 se calcula para cada valor discretizado de AI y se almacena en una tabla. Para evaluar el (y + AZ) 1 para algunos a ∈ [A1, AC], se determina el valor discretizado más cercano ai y se utiliza la entrada correspondiente en la tabla. El tiempo de ejecución total para este método es lineal y el parámetro de discretización C (que consideramos una constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en el tiempo O (log) que no se describe aquí. En el bucle principal, calculamos el vector X, como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanos de la página j. Típicamente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página J, el vector de puntajes se actualiza sobre el conjunto de componentes distintos de cero k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página J, y es un subconjunto deEl número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal lleva tiempo constante, y el tiempo de ejecución total del bucle principal es o (). Dado que hemos asumido que el tamaño de F no crecerá más grande que O (N), el tiempo de ejecución total para el algoritmo es O (N). Algoritmo 3: Selección de nodo mediante complementación estocástica. SC-SELECT (F, FOUT, F, K) Entrada: F: Matriz de tamaño de adyacencia cero-una correspondiente al subgrafio local actual, Fout: matriz de aluminio cero de F a Subgraph Global, F: PageRank de F, K: Número de páginas para devolver la salida: páginas: conjunto de k páginas para rastrear a continuación {Calcule las sumas de aire libre para el subgrafio local} foreach (página j ∈ F) o [j] ← k: (j) ∈F f [j, k] End {Compute Scalar ˜ut J F para cada nodo global j} foreach (página j ∈ Fout) g [j] ← (1 - α) 1 +1 foreach (página k: (k, j) ∈ Fout) g [j] ← g [j] +α f [k] o [k] +1 end end {calcular vectores y y z como en (17) y (18)} y ← (1 - α) e (+1) z← (1 - w) −1 ˜s {aproximado y + g [j] ∗ z 1 para todos los valores g [j]} norma diffs ← l1normdiffs (g, ely, elz) foreach (página j ∈ Fout) {comput spleachvector x como en (19)} x ← 0 foreach (página k: (k, j) ∈ Fout) foreach (página k: (k, k) ∈ F)) x [k] ← x [k] - f [k] o [k] (o [k] +1) fin final x ← αx puntajes [j] ← norma difiere [j] foreach (k: x [k]> 0 y página k ∈ L) puntajes [j] ← ←puntajes [j] - | y [k] + g [j] ∗ z [k] |+| x [k]+y [k]+g [j] ∗ z [k]) |End End Return K Páginas con puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan en la página global j. Los flujos están representados por el vector no negativo (˜ut j f) z (ecuaciones (15) y (18)). Se puede considerar que el escalar J F es la cantidad total de flujo de PageRank que la página J tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local;El flujo al que recibe la página K local es proporcional (dentro de un factor constante debido al vector de surfista aleatorio) el número esperado de sus inlinks. Las fugas de PageRank representan la disminución en PageRank resultante de la adición de la página J. La fuga se puede cuantificar en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector X, podemos ver de la ecuación (19) que la cantidad de PageRank filtrada por una página local es proporcional a la suma ponderada de los rangos de papel de pista de investigación de Page121 de sus hermanos. Por lo tanto, las páginas que tienen hermanos con pageranks más altos (y bajos recuentos de ataques) experimentarán más fugas. La fuga causada por Y es un artefacto del vector surfista aleatorio. A continuación, mostraremos que si solo se considera el término de flujo, (˜ut j f) z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al.[6] que se ha utilizado ampliamente para el rastreo a través del problema de pedido de URL. Esta heurística es computacionalmente más barata, pero como veremos más adelante, no tan efectivo como el método de complementación estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima usando solo flujos, el nodo óptimo J ∗ es: j ∗ = argmaxj el ˜ut j fz 1 = argmaxj ˜ut j f el z 1 = argmaxj ˜ut j f = argmaxj α (df + diag (uJ)))−1 UJ + (1 - α) E + 1, F = Argmaxjft (DF + diag (UJ)) - 1 UJ. El puntaje de selección de página resultante se puede expresar como una suma de los PageRanks de cada página K local que se vincula a J, donde cada valor de PageRank se normaliza mediante O [k] +1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], que se normaliza por o [k]. El algoritmo PF-selecto, que se omite debido a la falta de espacio, primero calcula la cantidad FT (DF +Diag (UJ))-1 UJ para cada página J Global J, y luego devuelve las páginas con los K más grandes. Para ver que el tiempo de ejecución para este algoritmo es O (n), tenga en cuenta que el cálculo involucrado en este método es un subconjunto de lo necesario para el método SC-select (algoritmo 3), que se demostró que tenía un tiempo de ejecución de o(norte).6. Experimentos En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego proporcionamos resultados en una variedad de dominios locales.6.1 Metodología dados los recursos limitados disponibles en una institución académica, rastreando una sección de la web que es de la misma magnitud que la indexada por Google o Yahoo!es claramente inviable. Por lo tanto, para un dominio local dado, aproximamos el gráfico global al rastrear un vecindario local alrededor del dominio que es varias órdenes de magnitud más grandes que el subgrafio local. A pesar de que dicho gráfico todavía es órdenes de magnitud más pequeñas que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas muy influyentes que están muy lejos de nuestro dominio local, no es realista para cualquier algoritmo de selección de nodo local para encontrara ellos. Dichas páginas también tienden a no estar relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la Sección 5, hicimos la suposición simplificadora de que nuestro gráfico local no contenía nodos colgantes. Esta suposición solo se hizo para aliviar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna cero de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también contra los siguientes métodos de referencia: • Aleatorio: los nodos se eligen uniformemente al azar entre los nodos globales conocidos.• OutlinkCount: se eligen los nodos globales con el mayor número de indirectos del dominio local. En cada iteración del algoritmo FindGlobalpr, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELF 1 y el Pagerank global del dominio local ELG 1. Todos los cálculos de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecemos el parámetro de surfista aleatorio α, para que sea .85, y utilizamos un umbral de convergencia de 10-6. Evaluamos la diferencia entre los vectores de PageRank locales y globales utilizando tres métricas diferentes: las normas L1 y L∞, y Kendalls tau. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. Kendalls Tau Metric es una medida de correlación de rango popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que están de acuerdo en la clasificación y restando de eso el número de pares de pares que no están de acuerdo en la clasificación. El valor final se normaliza luego por el número total de n 2 de dichos pares, lo que resulta en un rango [−1, 1], donde una puntuación negativa significa anticorrelación entre las clasificaciones, y los valores cercanos a uno corresponden a una fuerte correlación de rango.6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto de Nutch [18]. Todos los rastreos estaban restringidos a solo páginas HTTP, y a limitar el número de páginas generadas dinámicamente que rastreamos, ignoramos todas las páginas con URL que contienen cualquiera de los caracteres?, *, @O =. El primer Crawl, al que nos referiremos como el conjunto de datos EDU, fue sembrado por las páginas de inicio de los 100 principales departamentos de informática de posgrado en los Estados Unidos, según lo calificado por el informe de News and World Report [16], y también por las páginas de inicio desus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .Edu, lo que resultó en un gráfico con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue sembrado por el conjunto de páginas bajo la jerarquía de política en el Proyecto de Directorio Open DMOZ [17]. Nos arrastramos por todas las páginas hasta cuatro enlaces de distancia, lo que produjo un gráfico con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo EDU, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de informática de posgrado, según lo clasificado por los Estados Unidos y el Informe Mundial. Esto produjo dominios locales de varios tamaños, de 10,626 (UIUC) a 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño N, realizamos 50 iteraciones del algoritmo Findglobalpr para rastrear un total de 2n nodos adicionales. La Figura 2 (a) da la diferencia (L1) de la estimación de PageRank en cada iteración al PageRank global, para el dominio local de Berkeley. El desempeño de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales separados por la informática. Inicialmente, la diferencia L1 entre los PageRanks globales y locales varió de .0469 (Stanford) a .149 (MIT). For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 4050 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de iteraciones GlobalandlocalPageRankDiFference (L1) Complemento estocástico PageRank Flow Outlink Conteation 0 5 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de iteraciones Global y LocalPagerAgerAncera (l1)Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: L1 Diferencia entre los Pageranks globales estimados y verdaderos para (a) Sitio web de Berkeleys Computer Science, (b) elDominio específico del sitio, www.enterstageright.com, y (c) el dominio de la política específica del tema. El método del complemento estocástico supera a todos los demás métodos en varios dominios.Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva (o incluso un rendimiento superior, como en el dominio local de Berkeley) el conteo de enlaces y las heurísticas de flujo de PageRank. En todas las pruebas, el método de complementación estocástica superó o fue competitiva con los otros métodos. La Tabla 1 da la diferencia promedio entre los PageRanks globales estimados finales y los verdaderos PageRanks globales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Stoch. Comp..0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 aleatorio .0407 .00204 .9086 Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de ciencias de informática específicos del sitio. Tenga en cuenta que Kendalls Tau mide la similitud, mientras que las otras métricas son medidas de disimilitud. La complementación estocástica supera claramente los otros métodos en todas las métricas. Dentro del conjunto de datos de la política, también realizamos dos pruebas de sitios para los sitios web más grandes en The Crawl: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres y www.enterstageright.com, una revista conservadora en línea. Al igual que con los dominios locales de EDU, ejecutamos nuestro algoritmo para 50 iteraciones, arrastrando un total de nodos 2N. La Figura 2 (b) traza los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de EDU, los métodos aleatorios y de salida al aire libre no eran competitivos con los métodos SC-select o PF-select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue más impresionante en este conjunto de datos, realizando una estimación final que difería solo .0279 del Global Pagerank, una mejora de diez veces sobre la diferencia de PageRank local inicial de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales dadas por los métodos SC-Select, PF-select, OutlinkCount y aleatorios fueron .0208, .0193, .0222,.y .0356, respectivamente. Dentro del conjunto de datos de la política, construimos cuatro dominios locales específicos de temas. El primer dominio consistió en todas las páginas en la categoría de política DMOZ, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se dan en la Figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo para solo 25 iteraciones para rastrear un total de N nodos. También creamos dominios específicos del tema a partir de tres subtópicos políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías DMOZ correspondientes. Para cada sub-tope, establecemos que el dominio local sea todas las páginas dentro de tres enlaces de las páginas de categoría DMOZ correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, y también el dominio político más grande. Para cuantificar un efecto global de página JS en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página JS para que sea su valor de PageRank, g [j], normalizado por la fracción de sus ataques que apuntan al dominio local: impacto ((((j) = ol [j] o [j] · g [j], donde, ol [j] es el número de ataques de la página j a las páginas en el dominio local l, y o [j] es el número total de jsOutlinks. En términos del modelo de surfista aleatorio, el impacto de la página J es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página J Global J en su caminata aleatoria y (2) lleva un juego de enlace a una página local, dado que ya lo ha hecho.decidió no saltar a una página al azar. Para el dominio local de la política, descubrimos que muchas de las páginas con alto impacto eran páginas políticas que deberían haberse incluido en el tema de la política de DMOZ, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda política www.askhenry.com y la página de inicio de la revista política en línea, www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue más influyente. La revista está disponible gratuitamente en línea y contiene artículos sobre varios aspectos de la educación K-12 en Estados Unidos. Para proporcionar cierta evidencia anecdótica de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-select eligió 11 páginas dentro del dominio www.educationNext.org, el método PF-select descubrió 7 páginas de este tipo, mientras que los métodos al aire libre y al azarencontró solo 6 páginas cada una. Para el dominio local conservador local, el sitio web socialista www.orry.org tuvo un puntaje de impacto muy alto. Este 123 Documento de pista de investigación All Politics: Algorithm L1 L2 Kendall Stoch. Comp..1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 aleatorio .2055 .00203 .8271 Conservativismo: algoritmo L1 L2 Kendall Stoch. Comp..0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 aleatorio .1197 .00102 .8843 Liberalismo: algoritmo L1 L2 Kendall Stoch. Comp..0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Stoch. Comp..04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 aleatorio .0631 .005123 .9350 Tabla 2: rendimiento final entre las estrategias de selección de nodo para los cuatro rastreos de temas políticos específicos. Tenga en cuenta que Kendalls Tau mide la similitud, mientras que las otras métricas son medidas de disimilitud.se debió en gran medida a un enlace de la portada de este sitio a un artículo sobre el calentamiento global publicado por el Centro Nacional de Investigación de Políticas Públicas, un grupo de investigación conservadora en Washington, DC. No es sorprendente que el PageRank global de este artículo (que está en la página de inicio del NCCPR, www.nationalresearch.com), fue aproximadamente .002, mientras que el Pagerank local de esta página fue de solo .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos aleatorios y externos arrojaron valores de .01522 y .00171, respectivamente.7. Trabajo relacionado El marco de selección de nodos que hemos propuesto es similar al orden de URL para el problema de rastreo propuesto por Cho et al.en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente (a nivel mundial). Proponen varios algoritmos de selección de nodos, incluido el conteo de aluminio heurístico, así como una variante de nuestro algoritmo de selección de PF al que se refieren como la métrica de pedido de PageRank. Encontraron que este método es más efectivo para optimizar su objetivo, al igual que una encuesta reciente de estos métodos de Baeza-Yates et al.[1]. Boldi et al.También experimente dentro de un marco de rastreo similar en [2], pero cuantifique sus resultados comparando la correlación de rango de Kendalls entre los PageRanks del conjunto actual de páginas rastreadas y las de todo el gráfico global. Descubrieron que las estrategias de selección de nodos que se arrastraban con el PageRank global más alto primero se desempeñaron (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias de primera o de amplitud de profundidad básica. Sin embargo, sus experimentos difieren de nuestro trabajo, ya que nuestros algoritmos de selección de nodos no usan (o tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si tales algoritmos se utilizan para calcular los PageRanks globales de nuestro dominio local, todos requerirían o (n) cálculo, almacenamiento y ancho de banda, donde n es el tamaño del dominio global. Esto contrasta con nuestro método, que se aproxima al PageRank global y escala linealmente con el tamaño del dominio local. Wang y DeWitt [22] proponen un sistema donde el conjunto de servidores web que comprenden el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja las páginas n, los requisitos de computación, ancho de banda y almacenamiento también son lineales en n.Un inconveniente de este sistema es que el número de servidores web distintos que comprenden el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos EDU contiene sitios web de más de 3.200 universidades diferentes;Coordinar tal sistema entre una gran cantidad de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que usa solo ancho de banda constante, cálculo y espacio. Su enfoque se basa en la disponibilidad de un servidor de conectividad remoto que puede suministrar el conjunto de inslinques a una página determinada, una suposición no utilizada en nuestro marco. Muestran experimentalmente que una estimación razonable de los nodos PageRank se puede obtener visitando como máximo unos pocos cientos de nodos. Usar su algoritmo para nuestro problema requeriría que se descargue primero todo el dominio global o se use un servidor de conectividad, lo que conduciría a gráficos web muy grandes.8. Conclusiones y trabajo futuro de Internet está creciendo exponencialmente, y para navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la ubicuidad de estos motores de búsqueda a gran escala viene un aumento en las expectativas de los usuarios de la búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web en particular, los motores de búsqueda localizados son una salida efectiva para localizar rápidamente el contenido que de otro modo podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodo iterativo donde seleccionamos qué páginas de la frontera global se arrastrarán a continuación. Nuestra contribución principal es nuestro algoritmo de selección de página de complementación estocástica. Este método rastrea los nodos que afectarán más significativamente el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, incluidos siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear páginas N o 2N adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que solo usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera constantemente a otras heurísticas existentes.124 Documento de seguimiento de la investigación Muchas veces, los dominios específicos del tema se descubren utilizando un rastreador web enfocado que considera un contenido de páginas junto con el texto de anclaje de enlace para decidir qué páginas gatear a continuación [4]. Aunque tales rastreadores han demostrado ser bastante efectivos para descubrir contenido relacionado con el tema, muchas páginas irrelevantes también se rastrean en el proceso. Por lo general, estas páginas son eliminadas y no indexadas por el motor de búsqueda localizado. Por supuesto, estas páginas pueden proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco es iniciar el algoritmo FindGlobalpr con el subgrafio actual F igual al conjunto de páginas que fueron arrastradas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, todos requieren o (n) cálculo por iteración y ancho de banda proporcional al número de páginas que se arrastran, TK. Si el número de iteraciones t es relativamente pequeño en comparación con el número de páginas que se arrastran por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que aumenta el número de iteraciones (en relación con K), el cuello de botella residirá en el cálculo de selección de nodo. En este caso, nuestros algoritmos se beneficiarían de las optimizaciones de factores constantes. Recuerde que el algoritmo FindGlobalpr (algoritmo 2) requiere que los PageRanks del dominio local expandido actual sean recomputados en cada iteración. El trabajo reciente de Langville y Meyer [12] ofrece un algoritmo para recomputar rápidamente los PageRanks de una gigraph dada si se agrega un pequeño número de nodos. Se demostró que este algoritmo da aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esta y otras optimizaciones como el trabajo futuro. En este documento, hemos evaluado objetivamente nuestros métodos midiendo cuán cerca están nuestras estimaciones globales de PageRank para los PageRanks globales reales. Para determinar el beneficio de usar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pide a los usuarios que califiquen la calidad de los resultados de búsqueda de varias consultas de búsqueda. Para algunas consultas, solo se usan los PageRanks locales en la clasificación, y para las consultas restantes, los PageRanks locales y los PageRanks globales aproximados, según lo calculan nuestros algoritmos. Los resultados de dicho estudio se pueden analizar para determinar el beneficio adicional de usar los PageRanks globales calculados por nuestros métodos, solo utilizando los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por NSF Grant CCF-0431257, el Premio de Carrera de NSF ACI-0093404 y una subvención de Saber, Inc. 9. Referencias [1] R. Baeza-Yates, M. Marin, C. Castillo y A. Rodríguez. Gurra un país: mejores estrategias que la amplitud primero para el pedido de la página web. Conferencia web mundial, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haga lo mejor para hacer lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller en gráficos web, 3243: 168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes informáticas y sistemas ISDN, 33 (1-7): 107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rabeo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos del tema. World Wide Web Conference, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de PageRank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. García-Molina y L. Page. Realización eficiente a través del pedido de URL. Conferencia web mundial, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Funciones de recuperación de aprendizaje de la retroalimentación implícita.http://www.cs.cornell.edu/people/tj/career.[9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloque de la web para calcular PageRank. Conferencia web mundial, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia web mundial, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Internet Mathematics, 2004. [12] A. N. Langville y C. D. Meyer. Actualización del vector estacionario de una cadena irreducible de Markov con un ojo en Googles PageRank. Siam Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información 2003? Escuela de Gestión de Información y Sistema, Universidad de California en Berkely, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia web mundial, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de las cadenas de Markov y la teoría de sistemas casi reducibles. Siam Review, 31: 240-272, 1989. [16] US News and World Report.http://www.usnews.com.[17] Proyecto DMOZ Open Directory.http://www.dmoz.org.[18] Motor de búsqueda de código abierto de Nutch.http://www.nutch.org.[19] F. Radlinski y T. Joachims. Cadenas de consulta: Aprender a clasificarse a partir de comentarios implícitos. ACM Sigkdd Conferencia Internacional sobre Discovery y Minería de datos, 2005. [20] S. Raghavan y H. García-Molina. Arrastrando la web oculta. En Actas de la Vigésima Séptima Conferencia Internacional sobre bases de datos muy grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Se enfocó el rastreo tanto para la relevancia tópica como para la calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Computación de PageRank en un sistema de búsqueda de Internet distribuido. Actas de la 30ª Conferencia VLDB, 2004. 125 Documento de pista de investigación