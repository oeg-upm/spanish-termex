Extracción automática de títulos de documentos generales utilizando el aprendizaje automático Yunhua Hu1 Departamento de Ciencias de la Computación Xian Jiaotong Universidad No 28, Xianning West Road Xian, China, 710049 Yunhuahu@mail.xjtu.edu.cn Hang Li, Yunbo Cao Microsoft Research Asia 5f Sigma Center,,No. 49 Zhichun Road, Haidian, Beijing, China, 100080 {Hangli, Yucao}@Microsoft.com Qinghua de Departamento de Ciencias de la Computación Xian Jiaotong No.Microsoft Corporation One Microsoft Way Redmond, WA, EE. UU., 98052 dmitriym@microsoft.com Resumen En este documento, proponemos un enfoque de aprendizaje automático para la extracción de títulos de documentos generales. Por documentos generales, nos referimos a documentos que pueden pertenecer a cualquiera de varios géneros específicos, incluidas presentaciones, capítulos de libros, documentos técnicos, folletos, informes y cartas. Anteriormente, los métodos se han propuesto principalmente para la extracción del título de los trabajos de investigación. No ha estado claro si podría ser posible realizar una extracción automática de títulos de documentos generales. Como estudio de caso, consideramos la extracción de la oficina, incluidas Word y PowerPoint. En nuestro enfoque, anotamos títulos en documentos de muestra (para Word y PowerPoint, respectivamente) y los tomamos como datos de entrenamiento, entrenan modelos de aprendizaje automático y realizamos la extracción de títulos utilizando los modelos capacitados. Nuestro método es único en el sentido de que utilizamos principalmente información de formato como el tamaño de la fuente como características en los modelos. Resulta que el uso de información de formato puede conducir a una extracción bastante precisa de los documentos generales. La precisión y el recuerdo para la extracción del título de Word es 0.810 y 0.837 respectivamente, y la precisión y el recuerdo para la extracción del título de PowerPoint es 0.875 y 0.895 respectivamente en un experimento sobre datos de intranet. Otros nuevos hallazgos importantes en este trabajo incluyen que podemos entrenar modelos en un dominio y aplicarlos a otro dominio, y más sorprendentemente podemos incluso capacitar a los modelos en un idioma y aplicarlos a otro idioma. Además, podemos mejorar significativamente los resultados de clasificación de búsqueda en la recuperación de documentos mediante el uso de los títulos extraídos. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información - Proceso de búsqueda;H.4.1 [Aplicaciones de sistemas de información]: Automatización de Office - Procesamiento de textos;D.2.8 [Ingeniería de software]: Métricas: medidas de complejidad, algoritmos de términos generales de medidas de rendimiento, experimentación, rendimiento.1. Los metadatos de introducción de documentos son útiles para muchos tipos de procesamiento de documentos, como búsqueda, navegación y filtrado. Idealmente, los metadatos son definidos por los autores de los documentos y luego los utilizan varios sistemas. Sin embargo, las personas rara vez definen metadatos de documentos por sí mismas, incluso cuando tienen herramientas de definición de metadatos convenientes [26]. Por lo tanto, cómo extraer automáticamente los metadatos de los cuerpos de los documentos resulta ser un problema de investigación importante. Se han propuesto métodos para realizar la tarea. Sin embargo, el enfoque se centró principalmente en la extracción de trabajos de investigación. Por ejemplo, Han et al.[10] propuso un método basado en el aprendizaje automático para realizar la extracción de los trabajos de investigación. Formalizaron el problema como el de la clasificación y el empleado de las máquinas de vectores de soporte como clasificador. Utilizaron principalmente características lingüísticas en el modelo.1 En este documento, consideramos la extracción de metadatos de los documentos generales. Por documentos generales, nos referimos a documentos que pueden pertenecer a cualquiera de varios géneros específicos. Los documentos generales están más ampliamente disponibles en bibliotecas digitales, intranets e Internet, y por lo tanto, se necesita una investigación sobre la extracción de ellos. Los trabajos de investigación generalmente tienen estilos bien formados y características notables. En contraste, los estilos de documentos generales pueden variar mucho. No se ha aclarado si un enfoque basado en el aprendizaje automático puede funcionar bien para esta tarea. Hay muchos tipos de metadatos: título, autor, fecha de creación, etc. Como estudio de caso, consideramos la extracción del título en este documento. Los documentos generales pueden estar en muchos formatos de archivo diferentes: Microsoft Office, PDF (PS), etc. Como estudio de caso, consideramos la extracción de la oficina, incluidas Word y PowerPoint. Tomamos un enfoque de aprendizaje automático. Anotamos títulos en documentos de muestra (para Word y PowerPoint respectivamente) y los tomamos como datos de entrenamiento para capacitar a varios tipos de modelos, y realizamos la extracción de títulos utilizando cualquier tipo de modelos capacitados. En los modelos, utilizamos principalmente información de formato como el tamaño de la fuente como características. Empleamos los siguientes modelos: modelo de entropía máxima, perceptrones con márgenes desiguales, modelo de entropía máxima Markov y perceptrón votado. En este documento, también investigamos los siguientes tres problemas, que no parecían haber sido examinados anteriormente.(1) Comparación entre modelos: entre los modelos anteriores, qué modelo funciona mejor para la extracción de título;(2) Generalidad del modelo: si es posible entrenar un modelo en un dominio y aplicarlo a otro dominio, y si es posible entrenar un modelo en un idioma y aplicarlo a otro idioma;(3) Utilidad de los títulos extraídos: si los títulos extraídos pueden mejorar el procesamiento de documentos, como la búsqueda. Los resultados experimentales indican que nuestro enfoque funciona bien para la extracción del título de documentos generales. Nuestro método puede superar significativamente las líneas de base: una que siempre usa las primeras líneas como títulos y el otro que siempre usa las líneas en los tamaños de fuentes más grandes como títulos. La precisión y el recuerdo para la extracción del título de Word son 0.810 y 0.837 respectivamente, y la precisión y el recuerdo para la extracción del título de PowerPoint son 0.875 y 0.895 respectivamente. Resulta que el uso de características de formato es la clave para una extracción de título exitosa.(1) Hemos observado que los modelos basados en Perceptron funcionan mejor en términos de precisiones de extracción.(2) Hemos verificado empíricamente que los modelos entrenados con nuestro enfoque son genéricos en el sentido de que pueden ser entrenados en un dominio y aplicados a otro, y pueden ser entrenados en un idioma y aplicarse a otro.(3) Hemos encontrado que utilizando los títulos extraídos podemos mejorar significativamente la precisión de la recuperación de documentos (en un 10%). Concluimos que de hecho podemos realizar una extracción de título confiable de documentos generales y usar los resultados extraídos para mejorar las aplicaciones reales. El resto del documento está organizado de la siguiente manera. En la Sección 2, presentamos un trabajo relacionado, y en la Sección 3, explicamos la motivación y el establecimiento de problemas de nuestro trabajo. En la Sección 4, describimos nuestro método de extracción de título, y en la Sección 5, describimos nuestro método de recuperación de documentos utilizando títulos extraídos. La Sección 6 da nuestros resultados experimentales. Hacemos comentarios finales en la Sección 7. 2. Trabajo relacionado 2.1 Se han propuesto métodos de extracción de metadatos del documento para realizar la extracción automática de metadatos de los documentos;Sin embargo, el enfoque principal fue la extracción de los trabajos de investigación. Los métodos propuestos se dividen en dos categorías: el enfoque basado en reglas y el enfoque basado en el aprendizaje automático. Giuffrida et al.[9], por ejemplo, desarrolló un sistema basado en reglas para extraer automáticamente metadatos de trabajos de investigación en PostScript. Usaron reglas como títulos generalmente ubicados en las partes superiores de las primeras páginas y generalmente se encuentran en los tamaños de fuentes más grandes. Liddy et al.[14] y Yilmazel El Al.[23] realizó la extracción de metadatos de materiales educativos utilizando tecnologías de procesamiento del lenguaje natural basadas en reglas. Mao et al.[16] también realizó extracción de metadatos automáticos de trabajos de investigación utilizando reglas sobre el formato de información. El enfoque basado en reglas puede lograr un alto rendimiento. Sin embargo, también tiene desventajas. Es menos adaptativo y robusto en comparación con el enfoque de aprendizaje automático. Han et al.[10], por ejemplo, realizó extracción de metadatos con el enfoque de aprendizaje automático. Vieron el problema como el de clasificar las líneas en un documento en las categorías de metadatos y propusieron usar máquinas de vectores de soporte como clasificador. Principalmente utilizaron información lingüística como características. Informaron una alta precisión de extracción de trabajos de investigación en términos de precisión y retiro.2.2 La extracción de metadatos de extracción de información se puede ver como una aplicación de extracción de información, en la que dada una secuencia de instancias, identificamos una subsecuencia que representa información en la que estamos interesados. Modelo oculto de Markov [6], modelo de entropía máxima [1, 4], modelo de entropía máxima [17], máquinas de vectores de soporte [3], campo aleatorio condicional [12] y perceptrón votado [2] son modelos de extracción de información ampliamente utilizados. La extracción de información se ha aplicado, por ejemplo, al etiquetado de parto de expresión [20], nombrado reconocimiento de entidad [25] y extracción de tabla [19].2.3 Búsqueda utilizando la información del título La información del título es útil para la recuperación de documentos. En el sistema CitaSeer, por ejemplo, Giles et al.Se las arregló para extraer títulos de los trabajos de investigación y hacer uso de los títulos extraídos en la búsqueda de documentos de metadatos [8]. En la búsqueda web, los campos de título (es decir, las propiedades del archivo) y los textos de anclaje de las páginas web (documentos HTML) pueden verse como títulos de las páginas [5]. Muchos motores de búsqueda parecen utilizarlos para la recuperación de la página web [7, 11, 18, 22]. Zhang et al., Descubrieron que las páginas web con metadatos bien definidos se recuperan más fácilmente que aquellas sin metadatos bien definidos [24]. Hasta donde sabemos, no se ha realizado investigaciones sobre el uso de títulos extraídos de documentos generales (por ejemplo, documentos de oficina) para la búsqueda de los documentos.146 3. Motivación y configuración de problemas Consideramos el problema de extraer automáticamente títulos de documentos generales. Por documentos generales, nos referimos a documentos que pertenecen a uno de cualquier número de géneros específicos. Los documentos pueden ser presentaciones, libros, capítulos de libros, documentos técnicos, folletos, informes, notas, especificaciones, cartas, anuncios o currículums. Los documentos generales están más ampliamente disponibles en bibliotecas digitales, intranets e Internet, y por lo tanto, es muy necesaria la investigación sobre la extracción del título de ellos. La Figura 1 muestra una estimación de las distribuciones de formatos de archivo en Intranet e Internet [15]. Office y PDF son los formatos de archivo principales en la intranet. Incluso en Internet, los documentos en los formatos aún no son insignificantes, dado su tamaño extremadamente grande. En este documento, sin pérdida de generalidad, tomamos documentos de la oficina como ejemplo. Figura 1. Distribuciones de formatos de archivo en Internet e Intranet. Para los documentos de oficina, los usuarios pueden definir títulos como propiedades del archivo utilizando una característica proporcionada por la oficina. Sin embargo, en un experimento, encontramos que los usuarios rara vez usan la función y, por lo tanto, los títulos en las propiedades del archivo suelen ser muy inexactos. Es decir, los títulos en las propiedades del archivo generalmente son inconsistentes con los títulos verdaderos en los cuerpos de archivo creados por los autores y son visibles para los lectores. Recopilamos 6,000 palabras y 6,000 documentos de PowerPoint de una intranet e Internet y examinamos cuántos títulos en las propiedades del archivo son correctos. Descubrimos que sorprendentemente la precisión era solo 0.265 (cf., sección 6.3 para más detalles). Se pueden considerar varias razones. Por ejemplo, si uno crea un nuevo archivo copiando un archivo anterior, entonces la propiedad del archivo del nuevo archivo también se copiará del archivo anterior. En otro experimento, encontramos que Google usa los títulos en las propiedades del archivo de los documentos de oficina en la búsqueda y la navegación, pero los títulos no son muy precisos. Creamos 50 consultas para buscar documentos de Word y PowerPoint y examinamos los 15 resultados principales de cada consulta devuelta por Google. Descubrimos que casi todos los títulos presentados en los resultados de búsqueda eran de las propiedades del archivo de los documentos. Sin embargo, solo 0.272 de ellos eran correctos. En realidad, los verdaderos títulos generalmente existen al comienzo de los cuerpos de los documentos. Si podemos extraer con precisión los títulos de los cuerpos de los documentos, entonces podemos explotar la información de título confiable en el procesamiento de documentos. Este es exactamente el problema que abordamos en este documento. Más específicamente, dado un documento de Word, debemos extraer el título de la región superior de la primera página. Dado un documento de PowerPoint, debemos extraer el título de la primera diapositiva. Un título a veces consiste en un título principal y uno o dos subtítulos. Solo consideramos la extracción del título principal. Como líneas de base para la extracción del título, lo usamos de siempre usar las primeras líneas como títulos y el de usar siempre las líneas con tamaños de fuentes más grandes como títulos. Figura 2. Extracción de título del documento de Word. Figura 3. Extracción de título del documento PowerPoint. A continuación, definimos una especificación para los juicios humanos en la anotación de datos de título. Los datos anotados se utilizarán en la capacitación y prueba de los métodos de extracción de título. Resumen de la especificación: el título de un documento debe identificarse sobre la base del sentido común, si no hay dificultad en la identificación. Sin embargo, hay muchos casos en los que la identificación no es fácil. Hay algunas reglas definidas en la especificación que guían la identificación de tales casos. Las reglas incluyen un título generalmente en líneas consecutivas en el mismo formato, un documento no puede tener título, no se consideran los títulos en las imágenes, un título no debe contener palabras como borrador, 147 documentos técnicos, etc., si es difícil determinar cuáles el título, seleccione el del tamaño de fuente más grande, y si aún es difícil determinar cuál es el título, seleccione el primer candidato.(La especificación cubre todos los casos que hemos encontrado en la anotación de datos). Las Figuras 2 y 3 muestran ejemplos de documentos de oficina de los cuales realizamos extracción de título. En la Figura 2, las diferencias en las implementaciones de la API WIN32 entre los sistemas operativos de Windows es el título del documento Word. Microsoft Windows en la parte superior de esta página es una imagen y, por lo tanto, se ignora. En la Figura 3, construir ventajas competitivas a través de una infraestructura ágil es el título del documento de PowerPoint. Hemos desarrollado una herramienta para la anotación de títulos de anotadores humanos. La Figura 4 muestra una instantánea de la herramienta. Figura 4. Herramienta de anotación de título.4. Método de extracción de título 4.1 Esquema la extracción de títulos basada en el aprendizaje automático consiste en capacitación y extracción. El mismo paso de preprocesamiento ocurre antes del entrenamiento y la extracción. Durante el preprocesamiento, desde la región superior de la primera página de un documento de Word o la primera diapositiva de un documento de PowerPoint se extraen varias unidades para el procesamiento. Si una línea (las líneas están separadas por símbolos de retorno) solo tiene un solo formato, entonces la línea se convertirá en una unidad. Si una línea tiene varias partes y cada una de ellas tiene su propio formato, entonces cada parte se convertirá en una unidad. Cada unidad será tratada como una instancia en el aprendizaje. Una unidad contiene no solo información de contenido (información lingüística) sino también formateo de información. La entrada al preprocesamiento es un documento y la salida del preprocesamiento es una secuencia de unidades (instancias). La Figura 5 muestra las unidades obtenidas del documento en la Figura 2. Figura 5. Ejemplo de unidades. En el aprendizaje, la entrada son secuencias de unidades donde cada secuencia corresponde a un documento. Tomamos las unidades etiquetadas (etiquetadas como Title_Begin, Title_end u otra) en las secuencias como datos de entrenamiento y construimos modelos para identificar si una unidad es Title_Begin Title_end u otro. Empleamos cuatro tipos de modelos: perceptrón, entropía máxima (ME), modelo Perceptron Markov (PMM) y modelo de entropía máxima Markov (MEMM). En extracción, la entrada es una secuencia de unidades de un documento. Empleamos un tipo de modelo para identificar si una unidad es Title_Begin, Title_end u otro. Luego extraemos unidades de la unidad etiquetada con Title_Begin a la unidad etiquetada con Title_end. El resultado es el título extraído del documento. La característica única de nuestro enfoque es que utilizamos principalmente información de formato para la extracción de título. Suponemos que aunque los documentos generales varían en los estilos, sus formatos tienen ciertos patrones y podemos aprender y utilizar los patrones para la extracción de título. Esto contrasta con el trabajo de Han et al., En el que solo se utilizan características lingüísticas para la extracción de los trabajos de investigación.4.2 Modelos Los cuatro modelos en realidad pueden considerarse en el mismo marco de extracción de metadatos. Es por eso que los aplicamos a nuestro problema actual. Cada entrada es una secuencia de instancias KXXX L21 junto con una secuencia de etiquetas Kyyy L21.IX e IY representan una instancia y su etiqueta, respectivamente (ki ,, 2,1 l =). Recuerde que una instancia aquí representa una unidad. Una etiqueta representa Title_Begin, Title_end u otra. Aquí, K es el número de unidades en un documento. En el aprendizaje, capacitamos un modelo que generalmente se puede denotar como una distribución de probabilidad condicional) | (11 kk xxyyp ll donde ix e iy denotan variables aleatorias que toman instancia ix y etiqueta como valores, respectivamente (ki ,, 2,1 l =). Herramienta de extracción de herramientas de aprendizaje 21121 22222122221 1121111211 nknnnn kk kk yyyxxx yyyxxxx yyyxxx ll ll ll ll → → →) | (maxarg 11 mkmmkm xxyyp ll) | (11 kk xxyip ll distribución condicional mkmm xx xx figura 6. Modelo de extracción de metadatos. Podemos hacer suposiciones sobre el modelo general para hacerlo lo suficientemente simple para el entrenamiento.148 Por ejemplo, podemos suponer que Kyy, 1 L son independientes entre sí, dado Kxx ,, 1 l. Por lo tanto, tenemos) | () | () | (11 11 kk kk xypxyp xxyyp l ll = De esta manera, descomponemos el modelo en varios clasificadores. Entrenamos a los clasificadores localmente utilizando los datos etiquetados. Como clasificador, empleamos el modelo Perceptron o de entropía máxima. También podemos suponer que la propiedad de primer pedido de Markov es válida para Kyy, 1 L dada Kxx ,, 1 l. Por lo tanto, tenemos) | () | () | (111 11 KKK KK XYYPXYP XXYYP - = L LL nuevamente, obtenemos una serie de clasificadores. Sin embargo, los clasificadores están condicionados en la etiqueta anterior. Cuando empleamos la percepción del modelo de entropía máxima como clasificador, los modelos se convierten en un modelo de percepción de Markov o modelo de entropía máxima Markov, respectivamente. Es decir, los dos modelos son más precisos. En extracción, dada una nueva secuencia de instancias, recurrimos a uno de los modelos construidos para asignar una secuencia de etiquetas a la secuencia de instancias, es decir, realizar extracción. Para Perceptron y para mí, asignamos etiquetas localmente y combinamos los resultados a nivel mundial mediante la heurística. Específicamente, primero identificamos el Title_Begin más probable. Luego encontramos el Title_end más probable dentro de tres unidades después del Title_Begin. Finalmente, extraemos como título las unidades entre el Title_Begin y el Title_end. Para PMM y MEMM, empleamos el algoritmo Viterbi para encontrar la secuencia de etiqueta globalmente óptima. En este artículo, para Perceptron, en realidad empleamos una variante mejorada, llamada Perceptron con margen desigual [13]. Esta versión de Perceptron puede funcionar bien, especialmente cuando el número de instancias positivas y el número de instancias negativas difieren enormemente, lo cual es exactamente el caso en nuestro problema. También empleamos una versión mejorada del modelo Perceptron Markov en el que el modelo Perceptron es el llamado Perceptron votado [2]. Además, en el entrenamiento, los parámetros del modelo se actualizan a nivel mundial en lugar de localmente.4.3 Características Hay dos tipos de características: características de formato y características lingüísticas. Principalmente usamos el primero. Las características se utilizan tanto para el título de Begin como para los clasificadores de fin de título.4.3.1 Características del formato Tamaño de fuente: Hay cuatro características binarias que representan el tamaño de fuente normalizado de la unidad (recuerde que una unidad tiene solo un tipo de fuente). Si el tamaño de fuente de la unidad es el más grande en el documento, la primera característica será 1, de lo contrario 0. Si el tamaño de fuente es el más pequeño en el documento, entonces la cuarta característica será 1, de lo contrario 0. Si el tamaño de fuente está por encima del tamaño de fuente promedio y no es el más grande del documento, entonces la segunda característica será 1, de lo contrario 0. Si el tamaño de la fuente está por debajo del tamaño de fuente promedio y no el más pequeño, la tercera característica será 1, de lo contrario 0. Es necesario realizar la normalización en tamaños de fuente. Por ejemplo, en un documento, el tamaño de fuente más grande podría ser 12pt, mientras que en otro el más pequeño podría ser 18pt. Boldface: esta característica binaria representa si la unidad actual está en negrita o no. Alineación: hay cuatro características binarias que representan respectivamente la ubicación de la unidad actual: alineación izquierda, central, derecha y desconocida. Las siguientes características del formato con respecto al contexto juegan un papel importante en la extracción de título. Unidad vecina vacía: hay dos características binarias que representan, respectivamente, si la unidad anterior y la unidad actual son líneas en blanco. Cambio de tamaño de fuente: hay dos características binarias que representan, respectivamente, ya sea que el tamaño de fuente de la unidad anterior y el tamaño de fuente de la siguiente unidad difieran del de la unidad actual. Cambio de alineación: hay dos características binarias que representan, respectivamente, ya sea que la alineación de la unidad anterior y la alineación de la siguiente unidad difieran de la de la actual. El mismo párrafo: hay dos características binarias que representan, respectivamente, ya sea que la unidad anterior y la siguiente unidad estén en el mismo párrafo que la unidad actual.4.3.2 Características lingüísticas Las características lingüísticas se basan en palabras clave. Palabra positiva: esta característica binaria representa si la unidad actual comienza o no con una de las palabras positivas. Las palabras positivas incluyen Título:, Asunto:, por ejemplo, por ejemplo, en algunos documentos, las líneas de títulos y autores tienen los mismos formatos. Sin embargo, si las líneas comienzan con una de las palabras positivas, entonces es probable que sean líneas de título. Palabra negativa: esta característica binaria representa si la unidad actual comienza o no con una de las palabras negativas. Las palabras negativas incluyen, por, creadas por, actualizadas por, etc. Hay más palabras negativas que palabras positivas. Las características lingüísticas anteriores dependen del lenguaje. Recuento de palabras: un título no debe ser demasiado largo. Creamos heurísticamente cuatro intervalos: [1, 2], [3, 6], [7, 9] y [9, ∞) y definimos una característica para cada intervalo. Si el número de palabras en un título cae en un intervalo, la característica correspondiente será 1;de lo contrario 0. Carácter final: esta característica representa si la unidad termina con :, -u otros caracteres especiales. Un título generalmente no termina con tal personaje.5. Método de recuperación de documentos Describimos nuestro método de recuperación de documentos utilizando títulos extraídos. Por lo general, en la recuperación de la información, un documento se divide en varios campos, incluidos el cuerpo, el título y el texto de anclaje. Una función de clasificación en la búsqueda puede usar diferentes pesos para diferentes campos de 149 el documento. Además, los títulos generalmente se les asigna altos pesos, lo que indica que son importantes para la recuperación de documentos. Como se explicó anteriormente, nuestro experimento ha demostrado que un número significativo de documentos en realidad tiene títulos incorrectos en las propiedades del archivo y, por lo tanto, además de usarlos usamos los títulos extraídos como un campo más del documento. Al hacer esto, intentamos mejorar la precisión general. En este documento, empleamos una modificación de BM25 que permite la ponderación de campo [21]. Como campos, utilizamos el cuerpo, el título, el título extraído y el ancla. Primero, para cada término en la consulta contamos el término frecuencia en cada campo del documento;Cada frecuencia de campo se pondera de acuerdo con el parámetro de peso correspondiente: ∑ = f tfft tfwwtf De manera similar, calculamos la longitud del documento como una suma ponderada de longitudes de cada campo. La longitud promedio del documento en el corpus se convierte en el promedio de todas las longitudes de documentos ponderadas.∑ = f ff dlwwdl En nuestros experimentos usamos 75.0,8.11 == bk. El peso para el contenido fue de 1.0, el título fue de 10.0, el ancla fue de 10.0 y el título extraído fue de 5.0.6. Resultados experimentales 6.1 Conjuntos de datos y medidas de evaluación Utilizamos dos conjuntos de datos en nuestros experimentos. Primero, descargamos y seleccionamos al azar 5,000 documentos de Word y 5,000 documentos de PowerPoint de una intranet de Microsoft. Lo llamamos Sra. En adelante. En segundo lugar, descargamos y seleccionamos al azar 500 Word y 500 Documentos de PowerPoint de los dominios DOTGOV y DOTCOM en Internet, respectivamente. La Figura 7 muestra las distribuciones de los géneros de los documentos. Vemos que los documentos son de hecho documentos generales tal como los definimos. Figura 7. Distribuciones de géneros de documentos. Tercero, un conjunto de datos en chino también se descargó de Internet. Incluye 500 documentos de Word y 500 documentos de PowerPoint en chino. Relacionamos manualmente los títulos de todos los documentos, sobre la base de nuestra especificación. No todos los documentos en los dos conjuntos de datos tienen títulos. La Tabla 1 muestra los porcentajes de los documentos que tienen títulos. Vemos que Dotcom y Dotgov tienen más documentos de PowerPoint con títulos que MS. Esto podría deberse a que los documentos de PowerPoint publicados en Internet son más formales que los de la intranet. Tabla 1. La parte de los documentos con títulos Tipo de dominio MS Dotcom Dotgov Word 75.7% 77.8% 75.6% PowerPoint 82.1% 93.4% 96.4% En nuestros experimentos, realizamos evaluaciones sobre la extracción del título en términos de precisión, recuperación y medición F. Las medidas de evaluación se definen de la siguiente manera: Precisión: P = A / (A + B) Recuerde: R = A / (A + C) F-Medición: F1 = 2Pr / (P + R) aquí, A, B, Cy D son números de documentos como los definidos en la Tabla 2. Tabla 2. La tabla de contingencia con respecto a la extracción del título es el título no se extrae el título A B No se extrae C D 6.2 Basas Base Probamos las precisiones de las dos líneas de base descritas en la Sección 4.2. Se denotan como un tamaño de fuente más grande y primera línea respectivamente.6.3 Precisión de los títulos en las propiedades del archivo Investigamos cuántos títulos en las propiedades del archivo de los documentos son confiables. Vemos los títulos anotados por humanos como títulos verdaderos y probamos cuántos títulos en las propiedades del archivo pueden coincidir aproximadamente con los títulos verdaderos. Utilizamos la distancia de edición para realizar la coincidencia aproximada.(La coincidencia aproximada solo se usa en esta evaluación). Esto se debe a que a veces los títulos anotados humanos pueden ser ligeramente diferentes de los títulos en las propiedades del archivo en la superficie, por ejemplo, contienen espacios adicionales). Dada la cadena A y String B: if ((d == 0) o (d / (la + lb) <θ)) luego cadena a = cadena B D: Editar distancia entre la cadena A y la cadena B La: Longitud de la cadena A LB: Longitud de la cadena b θ: 0.1 ∑ × ++ - += t t n n wtf avwdl wdl bbk kwtf fbm) log ()) 1 (() 1 (25 1 1 150 Tabla 3. Preciosas de los títulos en propiedades de archivo Tipo de archivo Dominio Precisión Recarga F1 MS 0.299 0.311 0.305 DOTCOM 0.210 0.214 0.212 Word Dotgov 0.182 0.177 0.180 ms 0.229 0.245 0.237 Dotcom 0.185 0.186 0.186Power Dotgov 0.180 0.182 6. los primeros datosEstablecer (Word y PowerPoint en MS). Como modelo, utilizamos Perceptron. Realizamos una validación cruzada de 4 veces. Por lo tanto, todos los resultados informados aquí son los promediados en más de 4 ensayos. Las tablas 4 y 5 muestran los resultados. Vemos que Perceptron supera significativamente las líneas de base. En la evaluación, utilizamos una coincidencia exacta entre los verdaderos títulos anotados por humanos y los títulos extraídos. Tabla 4. Precisiones de extracción del título con el modelo de precisión de palabras F1 Modelo Perceptron 0.810 0.837 0.823 Tamaño de fuente más grande 0.700 0.758 0.727 Líneas de base Primera línea 0.707 0.767 0.736 Tabla 5. Precisiones de extracción del título con PowerPoint Precision Retiro F1 Modelo Perceptron 0.875 0. 895 0.885 Tamaño de fuente más grande 0.844 0.887 0.865 líneas de base Primera línea 0.639 0.671 0.655 Vemos que el enfoque de aprendizaje automático puede lograr un buen rendimiento en la extracción del título. Para los documentos de Word, tanto la precisión como el recuerdo del enfoque son un 8 por ciento más altos que los de las líneas de base. Para PowerPoint, tanto la precisión como el recuerdo del enfoque son un 2 por ciento más altos que los de las líneas de base. Realizamos pruebas de significancia. Los resultados se muestran en la Tabla 6. Aquí, la más grande denota la línea de base de usar el tamaño de fuente más grande, primero denota la línea de base de usar la primera línea. Los resultados indican que las mejoras del aprendizaje automático sobre las líneas de base son estadísticamente significativas (en el sentido del valor p <0.05) Tabla 6. Sign Resultado de la prueba Documentos Tipo de prueba de signo entre el valor p de perceptrón frente a 3.59e-26 Word Perceptron vs. Primer 7.12e-10 perceptrón frente a 0.010 PowerPoint Perceptron vs. Primero 5.13e-40 que vemos, de los resultados, que, queLas dos líneas de base pueden funcionar bien para la extracción del título, lo que sugiere que el tamaño de la fuente y la información de posición son las características más útiles para la extracción de título. Sin embargo, también es obvio que usar solo estas dos características no es suficiente. Hay casos en los que todas las líneas tienen el mismo tamaño de fuente (es decir, el tamaño de fuente más grande), o casos en los que las líneas con el tamaño de fuente más grande solo contienen descripciones generales como confidencial, papel blanco, etc. Para esos casos, el método de tamaño de fuente más grande no puede funcionar bien. Por razones similares, el método de primera línea por sí solo no puede funcionar bien. Con la combinación de diferentes características (evidencia en el juicio del título), Perceptron puede superar más grande y primero. Investigamos el rendimiento de utilizar únicamente características lingüísticas. Descubrimos que no funciona bien. Parece que las características del formato juegan papeles importantes y las características lingüísticas son suplementos. Figura 8. Un documento de palabras de ejemplo. Figura 9. Un ejemplo de documento de PowerPoint. Realizamos un análisis de error sobre los resultados de Perceptron. Descubrimos que los errores cayeron en tres categorías.(1) Aproximadamente un tercio de los errores estaban relacionados con casos duros. En estos documentos, los diseños de las primeras páginas fueron difíciles de entender, incluso para los humanos. La Figura 8 y 9 muestra ejemplos.(2) Casi una cuarta parte de los errores fueron de los documentos que no tienen títulos verdaderos pero solo contienen balas. Dado que realizamos la extracción de las principales regiones, es difícil deshacerse de estos errores con el enfoque actual.(3). Las confusiones entre los títulos principales y los subtítulos fueron otro tipo de error. Dado que solo etiquetamos los títulos principales como títulos, las extracciones de ambos títulos se consideraron incorrectas. Sin embargo, este tipo de error hace poco daño al procesamiento de documentos como la búsqueda.6.5 Comparación entre modelos Para comparar el rendimiento de diferentes modelos de aprendizaje automático, realizamos otro experimento. Nuevamente, realizamos una validación de 4 veces 151 en el primer conjunto de datos (MS). La Tabla 7, 8 muestra los resultados de los cuatro modelos. Resulta que Perceptron y PMM realizan lo mejor, seguido de MEMM, y yo realiza lo peor. En general, los modelos de Markovian funcionan mejor que o sus homólogos clasificadores. Esto parece deberse a que los modelos de Markovian están entrenados a nivel mundial, mientras que los clasificadores están entrenados localmente. Los modelos basados en Perceptron funcionan mejor que las contrapartes basadas en ME. Esto parece deberse a que los modelos basados en Perceptron se crean para hacer mejores clasificaciones, mientras que los modelos ME se construyen para una mejor predicción. Tabla 7. Comparación entre diferentes modelos de aprendizaje para la extracción del título con el modelo de Word Precision Record F1 Perceptron 0.810 0.837 0.823 MEMM 0.797 0.824 0.810 PMM 0.827 0.823 0.825 ME 0.801 0.621 0.699 Tabla 8. Comparación entre diferentes modelos de aprendizaje para la extracción de título con el modelo PowerPoint Precision Recording F1 Perceptron 0.875 0. 895 0. 885 MEMM 0.841 0.861 0.851 PMM 0.873 0.896 0.885 ME 0.753 0.766 0.759 6.6 Adaptación de dominio Aplicamos el modelo entrenado con el primer conjunto de datos (MS)al segundo conjunto de datos (DOTCOM y DOTGOV). Las tablas 9-12 muestran los resultados. Tabla 9. Precisiones de extracción del título con Word en el modelo de recuerdo de precisión de Dotgov F1 Perceptron 0.716 0.759 0.737 Tamaño de fuente más grande 0.549 0.619 0.582BASELINES Primera línea 0.462 0.521 0.490 Tabla 10. Precisiones de extracción del título con PowerPoint en el modelo de recuerdo de precisión de Dotgov F1 Perceptron 0.900 0.906 0.903 Tamaño de fuente más grande 0.871 0.888 0.879BASELINES Primera línea 0.554 0.564 0.559 Tabla 11. Precisiones de extracción del título con Word en Dotcom Precision Recording F1 Modelo Perceptron 0.832 0.880 0.855 Tamaño de fuente más grande 0.676 0.753 0.712BASELINES Primera línea 0.577 0.643 0.608 Tabla 12. Rendimiento de la extracción del título del documento de PowerPoint en el modelo de precisión de DOTCOM Perceptron 0.910 0.903 0.907 Tamaño de fuente más grande 0.864 0.886 0.875BASELINES Primera línea 0.570 0.585 0.577 De los resultados, vemos que los modelos se pueden adaptar bien a diferentes dominios. Casi no hay caída en la precisión. Los resultados indican que los patrones de formatos de título existen en diferentes dominios, y es posible construir un modelo independiente del dominio mediante el uso principalmente de información de formato.6.7 Adaptación del idioma Aplicamos el modelo capacitado con los datos en inglés (MS) al conjunto de datos en chino. Las tablas 13-14 muestran los resultados. Tabla 13. Precisiones de extracción del título con Word en el modelo de recuerdo de precisión chino F1 Perceptron 0.817 0.805 0.811 Tamaño de fuente más grande 0.722 0.755 0.738BASELINES Primera línea 0.743 0.777 0.760 Tabla 14. Precisiones de extracción del título con PowerPoint en el modelo de precisión chino F1 Modelo Perceptron 0.766 0.812 0.789 Tamaño de fuente más grande 0.753 0.813 0.782BASELINES Primera línea 0.627 0.676 0.650 Nosotros vemos que los modelos pueden adaptarse a un idioma diferente. Solo hay pequeñas gotas en precisión. Obviamente, las características lingüísticas no funcionan para los chinos, pero el efecto de no usarlos es insignificante. Los resultados indican que los patrones de formatos de título existen en diferentes idiomas. De la adaptación del dominio y los resultados de la adaptación del lenguaje, concluimos que el uso de información de formato es la clave para una extracción exitosa de documentos generales.6.8 Búsqueda con títulos extraídos realizamos experimentos sobre el uso de la extracción de título para la recuperación de documentos. Como línea de base, empleamos BM25 sin usar títulos extraídos. El mecanismo de clasificación fue como se describe en la Sección 5. Los pesos se establecieron heurísticamente. No realizamos optimización en los pesos. La evaluación se realizó en un corpus de documentos 1.3 m rastreados de la intranet de Microsoft utilizando 100 consultas de evaluación obtenidas de estos registros de consultas de motores de búsqueda de intranets.50 consultas eran del set más popular, mientras que 50 consultas otras fueron elegidas al azar. Se pidió a los usuarios que proporcionaran juicios sobre el grado de relevancia del documento de una escala de 1 a 5 (1 que significa perjudicial, 2 - malo, 3 - justo, 4 - bueno y 5 - excelente).152 La Figura 10 muestra los resultados. En la tabla, se obtuvieron dos conjuntos de resultados de precisión considerando documentos buenos o excelentes como relevantes (izquierda 3 barras con umbral de relevancia 0.5), o considerando solo documentos excelentes como relevantes (derecha 3 barras con umbral de relevancia 1.0) 0 0.05 0.1 0.150.2 0.25 0.3 0.35 0.4 0.45 P@10 P@5 Recíproco P@10 P@5 Recíproco 0.5 1 BM25 Anchor, Título, Ancla BM25 BM25, Título, Cuerpo, Nombre ExtractedTitle All RelevancTethresshold Data Descripción Figura 10. Resultados de clasificación de búsqueda. La Figura 10 muestra diferentes resultados de recuperación de documentos con diferentes funciones de clasificación en términos de precisión @10, precisión @5 y rango recíproco: • Barra azul - BM25 que incluye el cuerpo de campos, el título (propiedad del archivo) y el texto de anclaje.• Purple Bar: BM25, incluido el cuerpo de campos, el título (propiedad del archivo), el texto de anclaje y el título extraído. Con el campo adicional del título extraído incluido en BM25, la precisión @10 aumentó de 0.132 a 0.145, o en ~ 10%. Por lo tanto, es seguro decir que el uso del título extraído puede mejorar la precisión de la recuperación de documentos.7. Conclusión En este documento, hemos investigado el problema de extraer automáticamente títulos de documentos generales. Hemos intentado usar un enfoque de aprendizaje automático para abordar el problema. El trabajo anterior mostró que el enfoque de aprendizaje automático puede funcionar bien para la extracción de metadatos de los trabajos de investigación. En este documento, demostramos que el enfoque también puede funcionar para la extracción de documentos generales. Nuestros resultados experimentales indicaron que el enfoque de aprendizaje automático puede funcionar significativamente mejor que las líneas de base en la extracción del título de los documentos de la oficina. Trabajo previo sobre la extracción de metadatos utilizó principalmente características lingüísticas en documentos, mientras que utilizamos principalmente información de formato. Parecía que usar información de formato es una clave para realizar con éxito la extracción de título de los documentos generales. Probamos diferentes modelos de aprendizaje automático que incluyen perceptrones, entropía máxima, modelo de entropía máxima Markov y perceptrón votado. Descubrimos que el rendimiento de los modelos de perceptornio era el mejor. Aplicamos modelos construidos en un dominio a otro dominio y aplicamos modelos capacitados en un idioma a otro idioma. Descubrimos que las precisiones no cayeron sustancialmente en diferentes dominios y en diferentes idiomas, lo que indica que los modelos eran genéricos. También intentamos usar los títulos extraídos en la recuperación de documentos. Observamos una mejora significativa en el rendimiento de clasificación de documentos para la búsqueda cuando se utilizan información de título extraída. Todas las investigaciones anteriores no se realizaron en trabajos anteriores, y a través de nuestras investigaciones verificamos la generalidad y la importancia del enfoque de extracción de título.8. Agradecimientos Agradecemos a Chunyu Wei y Bojuan Zhao por su trabajo en la anotación de datos. Reconocemos a Jinzhu Li por su ayuda para realizar los experimentos. Agradecemos a Ming Zhou, John Chen, Jun Xu y los revisores anónimos de JCDL05 por sus valiosos comentarios en este documento.9. Referencias [1] Berger, A. L., Della Pietra, S. A. y Della Pietra, V. J. Un enfoque de entropía máxima para el procesamiento del lenguaje natural. Computational Linguistics, 22: 39-71, 1996. [2] Collins, M. Métodos de entrenamiento discriminativo para modelos ocultos de Markov: teoría y experimentos con algoritmos de percepción. En Actas de la Conferencia sobre Métodos Empíricos en Procesamiento del Lenguaje Natural, 1-8, 2002. [3] Cortes, C. y Vapnik, V. Redes de soporte-vector. Machine Learning, 20: 273-297, 1995. [4] Chieu, H. L. y Ng, H. T. Un enfoque de entropía máxima para la extracción de información de texto semiestructurado y libre. En Actas de la Decimura Conferencia Nacional sobre Inteligencia Artificial, 768-791, 2002. [5] Evans, D. K., Klavans, J. L. y McKeown, K. R. Columbia Newsblaster: resumen de noticias multilingües en la Web. En Actas de la Conferencia de Tecnología del Lenguaje Humano / Capítulo de América del Norte de la Reunión Anual de la Asociación para la Lingüística Computacional, 1-4, 2004. [6] Ghahramani, Z. y Jordan, M. I. Modelos Factoriales Hidden Markov. Machine Learning, 29: 245-273, 1997. [7] Gheel, J. y Anderson, T. Datos y metadatos para encontrar y recordar, en Actas de la Conferencia Internacional de Visualización de la Información de 1999, 446-451,1999.[8] Giles, C. L., Petinot, Y., Teregowda P. B., Han, H., Lawrence, S., Rangaswamy, A. y Pal, N. Ebizsearch: un motor de búsqueda de nicho para e-Business. En Actas de la 26ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, 413414, 2003. [9] Giuffrida, G., Shek, E. C. y Yang, J. Extracción de metadatos basados en el conocimiento de archivos PostScript. En Actas de la Quinta Conferencia ACM sobre Bibliotecas Digitales, 77-84, 2000. [10] Han, H., Giles, C. L., Manavoglu, E., Zha, H., Zhang, Z. y Fox, E. A. Extracción de metadatos automáticos del documento utilizando máquinas de vectores de soporte. En Actas de la tercera conferencia conjunta de ACM/IEEE-CS sobre bibliotecas digitales, 37-48, 2003. [11] Kobayashi, M. y Takeda, K. Recuperación de información en la web. ACM Computing Surveys, 32: 144-173, 2000. [12] Lafferty, J., McCallum, A. y Pereira, F. Campos aleatorios condicionales: modelos probabilísticos para segmentación y 153 datos de secuencia de etiquetado. En Actas de la Decimoctava Conferencia Internacional sobre Aprendizaje Autor, 282-289, 2001. [13] Li, Y., Zaragoza, H., Herbrich, R., Shawe-Taylor J. y Kandola, J. S. El algoritmo Perceptron con desigualmárgenes. En Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Autor, 379-386, 2002. [14] Liddy, E. D., Sutton, S., Allen, E., Harwell, S., Corieri, S., Yilmazel, O., Ozgencil, N. E., Diekema, A., McCracken, N. y Silverstein, J. Generación y evaluación automática de metadatos. En Actas de la 25ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, 401-402, 2002. [15] Littlefield, A. Recuperación de información empresarial efectiva en nuevos formatos de contenido. En Actas de la Séptima Conferencia de motores de búsqueda, http://www.infonortics.com/searchengines/sh02/02prog.html, 2002. [16] Mao, S., Kim, J. W. y Thoma, G. R. Un sistema de generación dinámica de característicaspara la extracción de metadatos automatizados en la conservación de materiales digitales. En Actas del primer taller internacional sobre el análisis de imágenes de documentos para bibliotecas, 225-232, 2004. [17] McCallum, A., Freitag, D. y Pereira, F. Modelos máximos de entropía Markov para extracción y segmentación de información. En Actas de la Decimoséptima Conferencia Internacional sobre Aprendizaje Machine, 591-598, 2000. [18] Murphy, L. D. Metadatos de documentos digitales en organizaciones: roles, enfoques analíticos y futuras direcciones de investigación. En Actas de la trigésima primera conferencia internacional anual de Hawaii sobre Ciencias del Sistema, 267-276, 1998. [19] Pinto, D., McCallum, A., Wei, X. y Croft, W. B. Extracción de tabla utilizando campos aleatorios condicionales. En Actas de la 26ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, 235242, 2003. [20] Ratnaparkhi, A. Modelos estadísticos no supervisados para el apego de frases preposicionales. En Actas de la Decimoséptima Conferencia Internacional sobre Lingüística Computacional.1079-1085, 1998. [21] Robertson, S., Zaragoza, H. y Taylor, M. Extensión simple de BM25 a múltiples campos ponderados, en Actas de la Decimotercera Conferencia sobre Gestión de Información y Conocimiento, 42-49, 2004.[22] Yi, J. y Sundaresan, N. Minería web basada en metadatos por relevancia, en Actas del Simposio Internacional 2000 sobre Ingeniería y Aplicaciones de Base de Datos, 113121, 2000. [23] Yilmazel, O., Finneran, C. M. y Liddy, E. D. MetaExtract: un sistema NLP para asignar automáticamente metadatos. En Actas de la Conferencia Conjunta ACM/IEEE 2004 sobre Bibliotecas Digitales, 241-242, 2004. [24] Zhang, J. y Dimitroff, A. Respuesta de motores de búsqueda de Internet a la implementación central de Dublín de metadatos. Journal of Information Science, 30: 310-320, 2004. [25] Zhang, L., Pan, Y. y Zhang, T. Reconocimiento y uso de entidades con nombre: reconocimiento de entidades con nombre enfocado utilizando aprendizaje automático. En Actas de la 27ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, 281-288, 2004. [26] http://dublincore.org/groups/corporate/seattle/ 154