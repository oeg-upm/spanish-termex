Gestión distribuida de horarios de tiempos flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein, el Instituto de Robótica, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh PA 15024 {SFS, Anthonyg, Wizim, Laurabar, Zbr} @cs.Resumen de cmu.edu Consideramos el problema de administrar los horarios en un entorno incierto y distribuido. Asumimos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario globalmente preestablecido, pero ninguna posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, los eventos inesperados forzarán los cambios a algunas actividades prescritas y reducirán la utilidad de ejecutar otros. Describimos una arquitectura de agente para resolver este problema que combina dos mecanismos básicos: (1) una representación de tiempos flexibles del cronograma de agentes (usando una red temporal simple) y (2) un procedimiento de reprogramación incremental. Los antiguos setos contra la incertidumbre temporal al permitir que la ejecución proceda de un conjunto de soluciones factibles, y el último actúa para revisar el cronograma de los agentes cuando la ejecución se ve forzada fuera de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de solución factible. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de programación a aquellos agentes con actividades interdependientes. Luego, según lo permita el tiempo, la infraestructura local de resolución de problemas locales se utiliza para impulsar una generación de opciones entre agentes y un proceso de consulta, destinado a identificar oportunidades para mejorar las soluciones a través del cambio conjunto. Usando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema de múltiples agentes con el de un solucionador MDP centralizado óptimo (pero no escalable) esperado. Categorías y descriptores de sujetos I.2.11 [Metodologías de computación]: inteligencia artificial artificial inteligencia artificial Algoritmos de términos generales, diseño 1. Introducción Las limitaciones prácticas de muchos entornos de aplicación requieren una gestión distribuida de la ejecución de planes y horarios. Factores tales como la separación geográfica de los agentes ejecutivos, las limitaciones en el ancho de banda de comunicación, las limitaciones relacionadas con la cadena de mando y el alto tempo de la dinámica de ejecución pueden impedir que cualquier agente solo obtenga una visión global completa del problema y, por lo tanto, necesite necesitar una planificación colaborativa pero localizada pero localizada de planificación localizaday decisiones de programación. En este documento, consideramos el problema de administrar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el Programa de Coordinadores de DARPA. Asumimos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario preestablecido globalmente, pero ninguna posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que los eventos inesperados forzarán los cambios a las actividades previamente programadas y alterar la utilidad de ejecutar a otros a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. Cada agente también recibe un conjunto precomputado de opciones de contingencia local (caída). Central para nuestro enfoque para resolver este problema de múltiples agentes es un marco incremental de programación de veces flexible. En una representación de los tiempos flexibles de un cronograma de agentes, los intervalos de ejecución asociados con las actividades programadas no se fijan, sino que se permiten flotar dentro de las restricciones de secuenciación de tiempo y actividad impuesta. Esta representación permite el uso explícito de la holgura como cobertura contra formas simples de incertidumbre de ejecución (por ejemplo, duraciones de actividad), y su implementación subyacente como un modelo de red temporal simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Las ventajas de los marcos de tiempos flexibles se han demostrado en varios contextos centralizados de planificación y programación (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en la configuración de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y los enfoques anteriores para la programación de múltiples agentes (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de agentes de tiempo fijo del agentehorarios. Definimos una arquitectura de agente centrada en la gestión incremental de un horario de tiempos flexibles. La representación basada en STN subyacente se usa (1) para aflojar el acoplamiento entre los hilos del ejecutor y el planificador, (2) para retener una capacidad básica para absorber retrasos de ejecución inesperados (o aceleraciones) y (3) para proporcionar un criterio básico para detectarla necesidad de cambio de horario. El cambio local es AC484 978-81-904262-7-5 (RPS) C 2007 Ifaamas Figura 1: un problema de dos agentes C de Cems.Cumplido por un programador incremental, diseñado para maximizar la calidad al intentar minimizar el cambio de horario. A este cronograma de infraestructura de gestión, agregamos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la comunicación simple de los cambios de horario local a otros agentes con actividades interdependientes. En capas sobre esto es un proceso de generación y evaluación de opciones no local (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para la mejora global a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en el STN como base para generar opciones. El resto del documento se organiza de la siguiente manera. Comenzamos resumiendo brevemente el problema de programación distribuido general de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y dibujar su operación. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez problemas relacionados con la ejecución de los horarios de los agentes, revisando incrementalmente los horarios de los agentes y coordinando los cambios de programación entre múltiples agentes. Luego damos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión sobre los planes de investigación actuales.2. El problema de los coordinadores como se indica anteriormente el problema de gestión del cronograma distribuido que abordamos en este documento es el presentado por el Programa de Coordinadores de DARPA. El problema de los coordinadores se refiere generalmente a la ejecución colaborativa de una misión conjunta por parte de un equipo de agentes en un entorno altamente dinámico. Una misión está formulada como una red de tareas, que se distribuyen entre los agentes por el simulador de masas de modo que ningún agente tiene una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene solo la parte de la red de tareas que se relaciona con tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precomputado también se distribuye a los agentes, y cada horario de agentes indica cuál de sus tareas locales debe ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar ante resultados inesperados (por ejemplo, retrasos en las tareas, fallas) y cambios en la misión (por ejemplo, nuevas tareas, cambios de fecha límite) generados por el simulador, reconocen cuándo las tareas programadas ya no son factibles o deseables, y coordinadas, y coordinadascon el uno al otro para tomar acciones de reprogramación correctivas y maximizadas de calidad que mantienen la ejecución de la misión general en el futuro. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (análisis de tareas, modelado de entorno y simulación) [4] llamado C TAEMS [1]. Dentro de los Cems, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, que pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen en el nivel de la hoja de las estructuras de tareas de Caems y son aquellos que son directamente ejecutables en el mundo. Cada método declarado M solo puede ser ejecutado por un agente especificado (denotado por AG: AgentN en la Figura 1) y cada agente puede ejecutar como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad de unidad). Las duraciones y la calidad del método generalmente se especifican como distribuciones de probabilidad discretas y, por lo tanto, se conocen con certeza solo después de haber sido ejecutadas.1 También es posible que un método falle inesperadamente en la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad QAF, que especifica cuándo y cómo una tarea acumula la calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un MIN QAF acumulará la calidad de su hijo con la más baja calidad si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con Sum o Max QAFS adquieren calidad tan pronto como un niño se ejecuta con calidad positiva;Como sugieren sus nombres QAF, sus valores respectivos, en última instancia, serán la calidad total o máxima de todos los niños que se ejecutaron. Una tarea de sincronización de suma acumulará calidad solo para aquellos niños que comienzan la ejecución simultáneamente con el primer niño que se ejecuta, mientras que una tarea exactamente una acumulación de calidad solo, si es precisamente, uno de sus niños se ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (NLE). Se pueden especificar dos tipos de NLES: duro y suave. Las nleses duras expresan 1 para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad y duración del método. El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 485 condiciones previas causales: por ejemplo, el NLE en la Figura 1 estipula que el método objetivo M5 no puede ejecutarse hasta que la fuente M4 acumule la calidad. No se requieren restricciones para facilitar y los obstáculos, no se requieren restricciones;Sin embargo, cuando están en juego, amplifican (o amortiguan) la calidad y la duración de la tarea objetivo. Cualquier tarea o método A también puede estar limitado por una hora de inicio más temprana y una fecha límite, especificando la ventana en la que A se puede ejecutar de manera factible.A también puede heredar estas restricciones de las tareas de antepasados en cualquier nivel superior en la estructura de tareas, y su ventana de ejecución efectiva se definirá por la más ajustada de estas restricciones. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el Agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirse genéricamente a los nodos de tareas y métodos.3. Descripción general del enfoque Nuestro marco de soluciones combina dos principios básicos para hacer frente al problema de administrar los horarios de múltiples agentes en un entorno de ejecución incierto y estresado por el tiempo. Primero es el uso de una representación de tiempos flexibles basados en STN de restricciones de solución, lo que permite que la ejecución sea impulsada por un conjunto de horarios en lugar de una solución de un solo punto. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede usarse para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según lo permita el tiempo, explorar opciones no locales (es decir, opciones que involucran el cambio en 2 o más agentes) para la mejora global de soluciones. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo gastado en una mejora de soluciones múltiples más global en el tiempo disponible. El tiempo de resolución de problemas local y no local se minimiza aún más mediante el uso de un procedimiento de programación incremental central. Figura 3: Arquitectura del agente. Nuestro marco de soluciones se hace concreto en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente comprende cuatro componentes principales: un albacea, un programador, un administrador estatal distribuido (DSM) y un administrador de opciones, todo lo cual comparten un modelo común del problema actual y la solución que combina un nivel de dominioRepresentación de la estructura de tareas subjetivas de Caems a un STN subyacente. En cualquier momento durante la operación, el programa instalado actualmente dicta el tiempo y la secuencia de actividades a nivel de dominio que el agente iniciará. El albacea, que se ejecuta en su propio hilo, monitorea continuamente las condiciones habilitadoras de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se cumplan todas sus limitaciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o los cambios a las restricciones externas supuestas se reciben de otros agentes, se actualiza el modelo de estado de los agentes del estado actual. En los casos en que esta actualización conduce a la inconsistencia en el STN o se reconoce que el horario local actual ahora podría mejorarse, el programador, ejecutándose en un hilo separado, se invoca para revisar la solución actual e instalar un nuevo horario. Cada vez que las limitaciones del horario local cambian en respuesta a una actualización de estado actual o mediante la manipulación del programador, el DSM se invoca para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización estatal dada y consecuencias de comunicación, el agente utilizará cualquier tiempo de cálculo restante para explorar las posibilidades de mejora a través del cambio conjunto. El administrador de opciones utiliza el planificador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el cronograma de uno o más agentes que permitirán al agente local aumentar la calidad de su cronograma. Estas opciones se formulan y comunican como consultas a los agentes remotos apropiados, que a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica la mejora global, se comprometen los cambios conjuntos. En las siguientes secciones consideramos la mecánica de estos componentes con más detalle.4. El planificador como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento ajustado de ejecución del programador: en lugar de recomputar un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución al localizar los cambios y hacer ajustes al horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del cronograma que proporciona un mejor soporte para la continuidad en la ejecución. Esta última propiedad también es ventajosa en la configuración de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la onda en diferentes horarios de agentes. El acoplamiento de la programación incremental con la programación de tiempos flexibles agrega apalancamiento adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede usar como una cobertura contra los tiempos de ejecución de métodos inciertos. También proporciona una base para ablandar el impacto de las interdependencias entre los agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los coordinadores. En secciones posteriores, discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes.4.1 Representación de la solución STN para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en un agente determinado SCHED486 el sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07), todas las limitaciones de problemas y programación que afectan estos tiempos están codificados en una red temporal simple subyacente (STN) [3]. Un STN representa las restricciones temporales como un gráfico G <n, E>, donde los nodos en n representan el conjunto de puntos de tiempo de interés, y los bordes en E son distancias entre pares de puntos de tiempo en N. un punto de tiempo especial, llamado calendario ceromotiva la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, el tiempo de liberación, el tiempo de debido, la duración) y las relaciones entre las actividades (por ejemplo, la relación de ParentChild, habilitan) se representan uniformemente como restricciones temporales (es decir, bordes) entre los puntos de tiempo de inicio y finalización relevantes. Un cronograma de agentes se designa como un orden total de los métodos seleccionados al publicar restricciones de precedencia entre el final y los puntos de inicio de cada par ordenado. Como se insertan nuevos métodos en un horario o actualizaciones de estado externos requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de una fecha límite), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos de tiempo en la red. Esto se logra de manera eficiente mediante el uso de un algoritmo de ruta más corto estándar de todos los pares;En nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo asegura la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto, y es necesaria cierta cantidad de retracción de restricción para restaurar la viabilidad.4.2 Mantenimiento de horarios de alta calidad El planificador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que funciona en un bucle estrictamente integrado. El propagador de calidad analiza la jerarquía de actividad y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos;En esencia, el propagador de calidad resuelve de manera óptima un problema relajado donde los agentes son capaces de realizar un número infinito de actividades a la vez. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. De lo contrario, reinvoca el propagador de calidad con la actividad problemática excluida. El propagador de calidad: el propagador de calidad realiza las siguientes acciones en la estructura de tareas de los caems: • Calcula la calidad de todas las actividades en la estructura de tareas: la calidad de calidad esperada de un método m se calcula a partir de la distribución de probabilidad de la ejecuciónresultados. La calidad cual (t) de una tarea t se calcula aplicando su QAF a la calidad evaluada de sus hijos.• Genera una lista de contribuyentes para cada tarea: los métodos que, si están programados, maximizarán la calidad obtenida por la tarea.• Genera una lista de activadores para cada tarea: los métodos que, si están programados, son suficientes para calificar la tarea según lo programado. Se eligen métodos en la lista de activadores para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas posteriores al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: falla del asignador para instalar un método hace que el propagador recompute una nueva lista de contribuyentes y activadores. El asignador de actividades: el asignador de actividad busca instalar los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes no se redactan y se eliminan de la línea de tiempo. Los contribuyentes se preprocesan utilizando una heurística centrada en la calidad para crear una agenda ordenada para disminuir el orden de calidad. Además, los métodos asociados con A y tarea (es decir, Min, Sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea y la tarea acumula la calidad solo si todos sus niños están programados, esto sesga el proceso de programación para fallar temprano (y los contribuyentes regeneradores) cuando los métodos elegidos para el y no se pueden asignar juntos. El asignador aparece iterativamente el primer método mNEW de la agenda e intenta instalarlo. Esto implica la primera verificación que se han programado todas las actividades que habilitan MNNEW, mientras se intenta instalar cualquier habilitador que no lo sea. Si alguna de las actividades del habilitador no se instala, el pase de asignación falla. Cuando tiene éxito, las restricciones permiten que se activen las actividades del habilitador con MNNEW. El STN rechaza una restricción de facilitador inviable al devolver un conflicto. En este caso, cualquier actividades de habilitador que haya programado esté desinstalada y el asignador devuelve la falla. Una vez que se garantiza la programación de los habilitadores, se busca una ranura factible en la línea de tiempo de los agentes dentro de la ventana de tiempo MNNEWS y el asignador intenta insertar MNNEW entre dos métodos actualmente programados. En el nivel STN, la inserción de MNEWS rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que encadenan a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve el éxito, de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a relacionar y los intentos de asignación de la siguiente ranura posible para la inserción de MNNEW.5. La dinámica de la ejecución que mantiene un horario de veces flexible nos permite utilizar un enfoque basado en conflictos para la reparación del programa: en lugar de reaccionar a cada evento en la ejecución que puede afectar el cronograma existente al calcular una solución actualizada, el STN puede absorber cualquier cambio de cambio.Eso no causa un conflicto. En consecuencia, se minimizan el cálculo (produciendo un nuevo horario) y los costos de comunicación (informar a otros agentes de cambios que los afectan). Un mecanismo básico necesario para modelar la ejecución en el STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo de tiempo actual e incluye un enlace entre él y el punto de tiempo calendario cero. Como cada método está programado, se establece una restricción de precedencia simple entre el punto de tiempo de tiempo actual y el método. Cuando el programador recibe una actualización de tiempo actual, el enlace entre Calendar-Zero y la hora actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema se refiere a la sincronización entre el ejecutor y el programador, como productor y consumidor del cronograma que se ejecuta en diferentes hilos dentro de un agente determinado. Esta coordinación debe ser robusta a pesar del hecho de que el sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 487, el albacea debe iniciar métodos para la ejecución en tiempo real, incluso mientras el planificador puede reevaluar el cronograma para maximizar la calidad y/o transmitir un horario revisado. Si el ejecutor, por ejemplo, se pliega un método para la ejecución basado en la hora actual, mientras que el programador está instanciando un cronograma revisado en el que ese método ya no es ejecutado a continuación, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte al introducir una ventana de congelación;El programador no puede reprogramar un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el planificador. El planificador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámica de ejecución: 1) retroalimentación como resultado de la ejecución del método: tanto los agentes como los de otros agentes, y 2) cambios en el modelo de Caems correspondiente a un conjunto de un conjunto deEvoluciones simulatordinadas del problema y el entorno. Dichos mensajes se denominan actualizaciones y son tratados por el planificador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones a su vez aquí y diferimos hasta más tarde la discusión de consultas al planificador, un modo de qué if iniciado por un agente remoto que está buscando una calidad global más alta. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los programadores es una opción;Esencialmente, un cronograma completo de actividades que el agente puede ejecutar junto con las métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en ningún horario de otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo el comportamiento de programación en cualquier momento en el que una opción local que maximice la vista local de la calidad se devuelve rápidamente, posiblemente seguido de horarios de calidad a nivel mundial que implican la coordinación entre agentes si los ciclos de programador disponibles lo permiten. Como tal, el modo de programación predeterminado para actualizaciones es buscar la opción local de la más alta calidad de acuerdo con la estrategia de búsqueda de programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión.5.1 Respondiendo a la ejecución de la actividad Como se sugirió anteriormente, un cronograma comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [EST, LST] (según lo dispuesto por la representación STN subyacente). El ejecutor es libre de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado cualquier condición de habilitación adicional. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivado de distribuciones de duración del método asociado durante la construcción del cronograma). Por supuesto, a medida que se desarrolla la ejecución, las duraciones del método real pueden desviarse de estas expectativas. En estos casos, la flexibilidad retenida en el cronograma se puede utilizar para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del cronograma. Considere el caso de un mensaje de finalización del método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el tiempo en el que tiene calidad acumulada a cualquier agente remotovinculado a este método. Sin embargo, si el método se completa con una duración más corta de lo esperado, podría estar justificada una acción de reprogramación. La publicación de la duración real en el STN no introduce potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (LST) de métodos locales o remotos que dependen de este método como un facilitador, o para métodos programados sucesivos en la línea de tiempo de los agentes. Sin embargo, puede presentar la posibilidad de explotar la holgura de programación imprevista. La representación de tiempos flexibles que ofrece el STN proporciona un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar su tiempo de inicio más temprano (EST) previamente establecido. Si de hecho, el EST del siguiente método programado puede volver a la hora actual una vez que la restricción de duración real se sustituye por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse nuevamente al ejecutor. Si alternativamente, otras restricciones de problemas evitan esta relajación del EST, entonces hay un tiempo de inactividad forzado que puede explotarse revisando el cronograma, y se invoca el planificador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no hay necesidad de reprogramar bajo programación de tiempos flexibles a menos que 1) el método termine más tarde que el LST de la actividad programada posterior, o 2) termina más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en el STN, se produce una violación de restricción. En este último caso, no se acumulan calidad y se reprograma, incluso si no hay conflictos con actividades programadas posteriores. Otras actualizaciones de estado de ejecución que el agente puede recibir incluyen: • Inicio del método: si un método enviado para la ejecución se inicia dentro de su ventana [EST, LST], la respuesta es marcarlo como ejecutando. Un método no puede comenzar antes cuando el ejecutor lo transmite, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en el STN (por ejemplo, porque la duración del método esperado ya no se puede acomodar), la restricción de duración en el STN se acorta en función de la distribución conocida hasta que se restablezca o reprogramación.• Falla del método: cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, la reprogramación se exige ya que el método puede permitir otras actividades o afectar significativamente la calidad en ausencia de reparación local. Nuevamente, el albacea procederá con la ejecución del siguiente método si llega su hora de inicio antes de que se comete el horario revisado, y el programador se adapta a esto respetando la ventana de congelación.• La hora actual avanza una actualización sobre la hora actual puede llegar solo o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace de tiempo actual en el STN (como se describió anteriormente), un resultado de conflicto, el estado de ejecución es inconsistente con el cronograma. En este caso, el programador procede como si la ejecución fuera consistente con sus expectativas, sujetas a posibles actualizaciones posteriores.488 el sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 5.2 Respondiendo a las actualizaciones del modelo, el agente también puede recibir dinámicamente cambios en el modelo de agentes subyacentes a los Cems. Las revisiones dinámicas en las distribuciones de resultados para métodos que ya están en una visión subjetiva de los agentes pueden afectar los valores evaluados de calidad y/o duración que dieron forma al cronograma actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento designados y los plazos para métodos y tareas que ya están en una visión subjetiva de los agentes pueden invalidar un cronograma existente o presentar oportunidades para aumentar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se otorgan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que involucran restricciones temporales se manejan de la misma manera que se describe para los inicios y finalizaciones del método, es decir, la reprogramación se requiere solo cuando la publicación de las limitaciones revisadas conduce a un conflicto STN. En el caso de los cambios en el modelo no temporal, la acción de reprogramación actualmente siempre se inicia.6. La coordinación entre agentes, después de haber respondido localmente a un resultado de ejecución inesperado o un cambio de modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que se ven bien localmente pueden tener un efecto global subóptimo una vez que se realizan alineaciones y, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjunto mutuamente beneficioso. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura del agente para abordar estos problemas.6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionada por el mecanismo de estado distribuido (DSM), que es responsable de comunicar los cambios realizados con el modelo o el cronograma de un agente determinado a otros agentes interesados. Más específicamente, el DSM de un agente determinado actúa para impulsar cualquier cambio realizado en los límites de tiempo, la calidad o el estado de una tarea/método local a todos los demás agentes que tienen la misma tarea/método que un nodo remoto en sus opiniones subjetivas. Un agente destinatario trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del cronograma, lo que potencialmente desencadena el programador local si se detecta la necesidad de reprogramar.6.2 Generación de opciones no locales Como se menciona en la sección anterior, los agentes primero responden a cualquier consulta o actualización dada (ya sea desde la ejecución o de otro agente) es generar una o más opciones locales. Dichas opciones representan cambios de programación local que son consistentes con todas las restricciones conocidas actualmente originadas de otros horarios de agentes y, por lo tanto, se pueden implementar sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor escopeta a los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para dicha acción coordinada por parte de dos o más agentes es responsabilidad del gerente de opciones. Ejecutando en modo de menor prioridad que el ejecutor y el planificador, el administrador de opciones inicia un proceso de generación y evaluación de opciones no local en respuesta a cualquier cambio de cronograma local realizado por el agente si las restricciones de tiempo de cálculo lo permiten. En términos generales, una opción no local identifica ciertas relajaciones (para una o más restricciones impuestas por los métodos programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado para determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados para comprometerse con este conjunto conjunto de cambios de horario. El gerente de opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el programador local en modo hipotético. Sincronización optimista: la sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se realizan supuestos optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos contribuyentes que actualmente no sean programados debido al hecho de que una o más tareas o métodos habilitadores (fuente) remotos no están programados actualmente. Para cada método local, el conjunto de habilitadores remotos se activan hipotéticamente, y el programador intenta construir un nuevo horario local bajo estos supuestos optimistas. Si tiene éxito, se genera una opción no local, que especifica el valor del nuevo cronograma local de mayor calidad, las restricciones temporales en la actividad objetivo local y el conjunto de actividades del habilitador de programación imprescindible que deben programarse por agentes remotos para quePara lograr esta calidad local. Las consultas necesarias que solicitan el impacto de calidad de la programación de estas actividades se formulan y se envían a los agentes remotos relevantes. Para ilustrar, considere nuevamente el ejemplo en la Figura 1. La calidad máxima que Agent1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual de agente 1. Dado este estado, la calidad máxima que Agent2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería 15 + 10 = 25. Utilizando la sincronización optimista, Agent2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 se programarían, y la calidad aportada por Agent2 al grupo de tareas se convertiría en 30. Agent2 envía una consulta de programación M4 al agente1. Debido a las limitaciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para obtener M4 encendido, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando Agent2 recibe esta respuesta de opción de Agent1, determina que la calidad total acumulada para el grupo de tareas sería 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 señala al Agente1 para comprometerse con esta opción no local. Relajación basada en conflictos: una segunda estrategia para generar opciones no locales, denominada relajación dirigida por conflictos, utiliza el análisis de conflictos STN para identificar y priorizar las limitaciones externas para relajarse en caso de que se encuentre un método particular que aumentaría la calidad local.para ser insportable. Recuerde que si un método no se puede insertar de manera factible en el horario, un intento de hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo continúa en tres pasos. Primero, se recopilan las limitaciones involucradas en el ciclo. En segundo lugar, en virtud de las conexiones en el STN al modelo C Taems de nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con los nodos remotos. Tercero, las restricciones en este subconjunto se retraen selectivamente al Sexto INTL. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 489 Figura 4: Se agrega una tarea de alta calidad a la estructura de tareas del agente2. Figura 5: Si M4, M5 y M7 están programados, el STN detecta un conflicto.Determine si se restaura la consistencia STN. Si tiene éxito, se genera una opción no local que indica qué restricciones remotas deben relajarse y por cuánto permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considere la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo y, por lo tanto, EST (M4) = 21. Agent2 tiene M5 y M6 en su línea de tiempo, con EST (M5) = 31 (M6 podría programarse antes o después de M5). Supongamos que Agent2 recibe una nueva tarea M7 con la fecha límite 55 (ver Figura 4). Si Agent2 pudiera programar M7, la calidad aportada por Agent2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el EST (M7) = 46, Dur (M7) = 10 y LFT (M7) = 55 (ver Figura 5). La relajación dirigida al conflicto por el Agente 2 sugiere relajar el LFT (M4) por 1 tick to 30, y esta consulta se comunica al Agente 1. De hecho, al retraer el método M1 o M2 del horario, esta relajación se puede acomodar sin pérdida de calidad para el Agente1 (debido al MIN QAF). Tras la comunicación de este hecho, el agente 2 señales para comprometerse.7. Resultados experimentales Una versión inicial del agente descrita en este documento se desarrolló en colaboración con SRI International y se sometió a la evaluación programática de los coordinadores realizados independientemente. Esta evaluación involucró más de 2000 instancias problemáticas generadas aleatoriamente por un generador de escenarios que se configuró para producir escenarios de diversos problemas de clase Descripción de la clase de agente OD OD Dynamics. Nobles.El 97.9% (390 problemas) la duración y la calidad de la tarea real varían según la distribución. Int interdependiente. Las actividades frecuentes y del 100% (360 problemas) aleatorias (especialmente facilitan) las actividades encadenadas juntas 99.5% (360 Probs) a través de secuencias de habilitan la opresión temporal TT de TT. Lanzamiento - 94.9% (360 Probaciones) Fecha límite Windows impiden tareas preferidas de alta calidad (duración más larga) de todas las programas. Los problemas de sincronización contienen un rango de 97.1% (360 probadores) diferentes tareas de suma de sincronización NTA nueva llegada de tareas.El modelo CTAEMS 99.0% (360 Probs) aumenta con nuevas tareas dinámicamente durante la ejecución. AVG general: 98.1% (2190 Probs) STD Dev: 6.96 Tabla 1: rendimiento del agente de año 1 sobre la evaluación de los coordinadores. La calidad del agente es el % de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de coordinadores agentes de programación distribuidos, como su capacidad para manejar resultados de ejecución inesperados, cadenas de NLES que involucran múltiples agentes y una programación efectiva de nuevas actividades que surgen inesperadamente enalgún punto durante la ejecución del problema. Los problemas de evaluación del año 1 se limitaron a ser lo suficientemente pequeños (3-10 agentes, 50 - 100 métodos) de modo que la comparación con un solucionador centralizado óptimo era factible. El equipo de evaluación empleó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo un agente en cada punto de decisión de ejecución, la actividad es más probable que produzca la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos se comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador de masas. Como se informó en la Tabla 1, el agente prototipo de año 1 se compara claramente favorablemente con el punto de referencia en todas las clases, que se encuentra dentro del 2% del promedio de MDP óptimo en todo el conjunto de 2190 problemas. Estos resultados son particularmente notables dado que cada programador basado en STN de agentes hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividad que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones esperadas y calidad para las actividades y una política de excluir de la consideración esas actividades con la probabilidad de falla de> 75%. El rendimiento del agente muy respetable puede ser acreditado al menos parcialmente al hecho de que la representación de tiempos flexibles empleados por el programador le proporciona un tampón importante contra la incertidumbre de la ejecución y los eventos exógenos. El agente gira en su rendimiento más bajo en las clases de experimentos TT (opresión temporal), y un examen de los registros de rastreo del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT, el agente de año 1 tiene un rendimiento inferior, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 el sexto intl. Conf.En los agentes autónomos y los sistemas de múltiples agentes (AAMAS 07) deben programarse, las tividades son tan estrictas que cualquier actividad programada que se ejecute con una duración más larga que el valor esperado, causa una falla de fecha límite. Esto constituye un caso en el que el razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de TT de bajo rendimiento implican actividades que dependen de las relaciones de facilitación para adaptarse a sus ventanas de tiempo (recuerde que la facilitación aumenta la calidad y disminuye la duración). El Limited facilita el razonamiento realizado por el programador del año 1 a veces hace que las fallas instalaran un horario inicial muy facilitado. Incluso cuando tales actividades se instalan con éxito, tienden a ser propensas a las fallas de la fecha límite, si una actividad (s) del lado de la fuente falla o excede su duración esperada, la duración más larga de la actividad objetivo puede violar su fecha límite de ventana de tiempo.8. Estado e instrucciones Nuestros esfuerzos de investigación actuales tienen como objetivo extender las capacidades del agente del año 1 y ampliar los problemas significativamente mayores. Los objetivos de evaluación programática de Year 2 requieren resolver problemas en el orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Recientemente hemos completado una reimplementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas de Year 1 coincida o superarse, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos 100 problemas de agente. Para abordar completamente diversos problemas de escala, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para la computación, comunicación y utilizando estimaciones del impacto no local de los nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos QAF-SpeciFC como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación basados en STN más avanzados, incluido el uso de desacoplamiento temporal [7] para aislar las acciones de los agentes interdependientes y la introducción de programas de contingencia sensible de probabilidad.9. Agradecimientos La arquitectura del agente de año 1 se desarrolló en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo respaldado por la Agencia de Proyectos de Investigación Advanciación del Departamento de Defensa (DARPA) bajo el contrato # FA8750-05-C0033. Los hallazgos de opiniones y conclusiones o recomendaciones expresadas en este documento son los de los autores y no reflejan necesariamente las opiniones de DARPA.10. Referencias [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Long y B. Kohout. C Taems Especificación del lenguaje v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganar eficiencia y flexibilidad en el problema temporal simple. En Proc.3er int. Taller sobre representación y razonamiento temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricción temporal. Artificial Intelligence, 49: 61-95, mayo de 1991. [4] K. Decker. Tæms: un marco para el análisis y el diseño centrado en el medio ambiente de los mecanismos de coordinación. En G. Ohare y N. Jennings, editores, Fundamentos de inteligencia artificial distribuida, Capítulo 16, páginas 429-448. Wiley Inter-Cience, 1996. [5] K. Decker y V. Lesser. Diseño de una familia de algoritmos de coordinación. En Proc.1er. En t. Conferencia sobre sistemas de múltiples agentes, San Francisco, 1995. [6] A. J. Garvey. Programación de diseño en tiempo real de diseño. Tesis doctoral, Univ.de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación de múltiples agentes. En Proc.18ª Conferencia Nacional sobre AI, 2002. [8] S. Lemai y F. Ingrand. Interelejar la planificación y ejecución temporal en dominios robóticos. En Proc.19ª Conferencia Nacional sobre AI, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: ir audazmente a donde no se ha ido ningún sistema de IA antes. Artificial Intelligence, 103 (1-2): 5-47, 1998. [10] W. Ruml, M. B. Do y M. fromhherz. Planificación en línea y programación de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger y B. Williams. Permitiendo una planificación rápida flexible a través del razonamiento temporal incremental con extracción de conflictos. En el precio. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurística basada en holgura para la programación de satisfacción de restricciones. En Proc.12ª Conferencia Nacional sobre AI, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación de tareas heurísticas dirigidas por criterios. Revista Internacional de razonamiento aproximado, 19 (1): 91-118, 1998. El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 491