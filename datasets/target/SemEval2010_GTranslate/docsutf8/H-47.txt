Un enfoque semántico para la publicidad contextual Andrei Broder Marcus Fontoura Vanja Josifovski Lance Riedel Yahoo! Research, 2821 Mission College Blvd, Santa Clara, CA 95054 {Broder, Marcusf, Vanjaj, riedell}@yahoo-inc.com Abstract Contextual Advertising o context Match (CM) se refiere a la colocación de anuncios textuales comerciales dentro del contenido de un genéricoPágina web, mientras que la publicidad de búsqueda patrocinada (SS) consiste en colocar anuncios en las páginas de resultados desde un motor de búsqueda web, con anuncios impulsados por la consulta de origen. En CM, generalmente hay una entidad intermediaria comercial de redes publicitarias a cargo de optimizar la selección de anuncios con el objetivo gemelo de aumentar los ingresos (compartido entre el editor y la red publicitaria) y mejorar la experiencia del usuario. Con estos objetivos en mente, es preferible tener anuncios relevantes para el contenido de la página, en lugar de anuncios genéricos. El mercado SS se desarrolló más rápido que el mercado CM, y la mayoría de los anuncios textuales todavía se caracterizan por frases de oferta que representan esas consultas donde los anunciantes desean que se muestren su anuncio. Por lo tanto, las primeras tecnologías para CM se han basado en soluciones anteriores para SS, simplemente extrayendo una o más frases del contenido de la página dado y mostrando anuncios correspondientes a búsquedas en estas frases, en un enfoque puramente sintáctico. Sin embargo, debido a los caprichos de la extracción de frases y la falta de contexto, este enfoque conduce a muchos anuncios irrelevantes. Para superar este problema, proponemos un sistema para la coincidencia de AD contextual basada en una combinación de características semánticas y sintácticas. Categorías y descriptores de sujetos: H.3.3 [Almacenamiento y recuperación de información]: Proceso de selección Términos generales: algoritmos, medición, rendimiento, experimentación 1. Introducción La publicidad web admite una gran franja del ecosistema de Internet de hoy. El gasto total del anunciante de Internet en EE. UU. En 2006 se estima en más de 17 mil millones de dólares con una tasa de crecimiento de casi el 20% año tras año. Una gran parte de este mercado consiste en anuncios textuales, es decir, mensajes de texto cortos generalmente marcados como enlaces patrocinados o similares. Los principales canales de publicidad utilizados para distribuir anuncios textuales son: 1. Search o publicidad de búsqueda de pago patrocinado que consiste en colocar anuncios en las páginas de resultados de un motor de búsqueda web, con anuncios impulsados por la consulta de origen. Todos los principales motores de búsqueda web actuales (Google, Yahoo!, Y Microsoft) admiten tales anuncios y actúan simultáneamente como un motor de búsqueda y una agencia de publicidad.2. La publicidad contextual o la coincidencia de contexto que se refiere a la colocación de anuncios comerciales dentro del contenido de una página web genérica. En la publicidad contextual, generalmente hay un intermediario comercial, llamado Network AD, a cargo de optimizar la selección de anuncios con el objetivo gemelo de aumentar los ingresos (compartido entre el editor y la red AD) y mejorar la experiencia del usuario. Una vez más, todos los principales motores de búsqueda web actuales (Google, Yahoo!, Y Microsoft) proporcionan dichos servicios de networking de anuncios, pero también hay muchos reproductores más pequeños. El mercado SS se desarrolló más rápido que el mercado CM, y la mayoría de los anuncios textuales todavía se caracterizan por frases de oferta que representan esas consultas donde los anunciantes desean que se muestren su anuncio.(Ver [5] para una breve historia). Sin embargo, hoy, casi todos los sitios web no transaccionales con fines de lucro (es decir, los sitios que no venden nada directamente) dependen al menos en parte de los ingresos de la coincidencia de contexto. CM admite sitios que van desde bloggers individuales y comunidades de nicho pequeños hasta grandes editores, como los principales periódicos. Sin este modelo, ¡la web sería mucho más pequeña! El modelo de precios prevalente para anuncios textuales es que los anunciantes pagan una cierta cantidad por cada clic en el anuncio (pago por clic o PPC). También se utilizan otros modelos: pago por impresión, donde los anunciantes pagan por el número de exposiciones de un anuncio y pago por acción donde el anunciante paga solo si el anuncio conduce a una venta o transacción similar. Para simplificar, solo tratamos con el modelo PPC en este documento. Dada una página, en lugar de colocar anuncios genéricos, parece preferible tener anuncios relacionados con el contenido para proporcionar una mejor experiencia del usuario y, por lo tanto, aumentar la probabilidad de clics. Esta intuición está respaldada por la analogía con la publicación convencional donde hay revistas muy exitosas (p. Vogue) donde la mayoría del contenido es publicidad tópica (moda en el caso de la bóvenes) y por estudios de usuarios que han confirmado que una mayor relevancia aumenta el número de clics en anuncios [4, 13]. Los enfoques publicados anteriores estimaron la relevancia de AD basada en la concurrencia de las mismas palabras o frases dentro de la AD y dentro de la página (ver [7, 8] y la Sección 3 para obtener más detalles). Sin embargo, los mecanismos de orientación basados únicamente en las frases que se encuentran dentro del texto de la página pueden conducir a problemas: por ejemplo, una página sobre un famoso golfista llamado John Maytag podría desencadenar un anuncio para los lavavajillas Maytag ya que Maytag es una marca popular. Otro ejemplo podría ser una página que describe el camión Chevy Tahoe (un vehículo popular en Estados Unidos) que desencadena un anuncio sobre las vacaciones del lago Tahoe. Polisemy no es el único culpable: ¡hay una historia (tal vez apócrifa) sobre una noticia espeluznante sobre un cuerpo sin cabeza que se encuentra en una maleta que desencadena un anuncio para el equipaje samsonite! En todos estos ejemplos, el desajuste surge del hecho de que los anuncios no son apropiados para el contexto. Para resolver este problema, proponemos un mecanismo de coincidencia que combine una fase semántica con la coincidencia tradicional de palabras clave, es decir, una fase sintáctica. La fase semántica clasifica la página y los anuncios en una taxonomía de temas y utiliza la proximidad de las clases de anuncios y páginas como factor en la fórmula de clasificación AD. Por lo tanto, favorecemos los anuncios que están relacionados tópicamente con la página y, por lo tanto, evitamos las dificultades del enfoque puramente sintáctico. Además, al usar una taxonomía jerárquica, permitimos la generalización gradual del espacio de búsqueda de anuncios en el caso de que no hay anuncios que coincidan con el tema preciso de la página. Por ejemplo, si la página se trata de un evento en el curling, un deporte de invierno raro, y contiene las palabras alpinas prados, el sistema aún clasificaría altamente anuncios para esquiar en prados alpinos, ya que estos anuncios pertenecen al esquí de clase que es un hermano delEl curling de clase y ambas clases comparten los deportes de invierno de los padres. En cierto sentido, las clases de taxonomía se utilizan para seleccionar el conjunto de anuncios aplicables y las palabras clave se utilizan para reducir la búsqueda de conceptos que son de granularidad demasiado pequeña para estar en la taxonomía. La taxonomía contiene nodos para temas que no cambian rápido, por ejemplo, marcas de cámaras digitales, dicen Canon. Las palabras clave capturan la especificidad a un nivel que es más dinámico y granular. En el ejemplo de la cámara digital, esto correspondería al nivel de un modelo en particular, por ejemplo, Canon SD450 cuya vida publicitaria podría ser solo unos pocos meses. La actualización de la taxonomía con nuevos nodos o incluso el nuevo vocabulario cada vez que un nuevo modelo llega al mercado es prohibitivamente costoso cuando tratamos con millones de fabricantes. Además del aumento de la tasa de clics (CTR) debido a una mayor relevancia, un beneficio significativo pero más difícil de cuantificar el beneficio de la coincidencia semántica-sintáctica es que la página resultante tiene una sensación unificada y mejora la experiencia del usuario. En el ejemplo de Chevy Tahoe anterior, el clasificador establecería que la página trata sobre automóviles/automotriz y solo se considerarán esos anuncios. Incluso si no hay anuncios para este modelo Chevy en particular, los anuncios elegidos seguirán dentro del dominio automotriz. Para implementar nuestro enfoque, necesitamos resolver un problema desafiante: clasificar tanto las páginas como los anuncios dentro de una gran taxonomía (para que la granularidad del tema sea lo suficientemente pequeña) con alta precisión (para reducir la probabilidad de incorrecto). Evaluamos varios clasificadores y taxonomías y en este documento presentamos resultados utilizando una taxonomía con cerca de 6000 nodos utilizando una variación del clasificador Rocchios [9]. Este clasificador dio los mejores resultados en la clasificación de la página y el anuncio, y en última instancia en relevancia publicitaria. El documento procede de la siguiente manera. En la siguiente sección revisamos los principios básicos de la publicidad contextual. La Sección 3 resumen el trabajo relacionado. La Sección 4 describe el clasificador de taxonomía y documento que se utilizaron para la clasificación de página y publicidad. La Sección 5 describe el método semánticointáctico. En la Sección 6 discutimos brevemente cómo buscar eficientemente el espacio de anuncios para devolver los anuncios clasificados por Top-K. La evaluación experimental se presenta en la Sección 7. Finalmente, la Sección 8 presenta los comentarios finales.2. Descripción general de la publicidad contextual La publicidad contextual es una interacción de cuatro jugadores: • El editor es el propietario de las páginas web en las que se muestra la publicidad. El editor generalmente tiene como objetivo maximizar los ingresos por publicidad al tiempo que proporciona una buena experiencia de usuario.• El anunciante proporciona el suministro de anuncios. Por lo general, la actividad de los anunciantes se organiza en torno a campañas que se definen por un conjunto de anuncios con un objetivo temporal y temático particular (por ejemplo, venta de cámaras digitales durante la temporada de vacaciones). Como en la publicidad tradicional, el objetivo de los anunciantes se puede definir ampliamente como la promoción de productos o servicios.• La red publicitaria es un mediador entre el anunciante y el editor y selecciona los anuncios que se colocan en las páginas. La red publicitaria comparte los ingresos publicitarios con el editor.• Los usuarios visitan las páginas web del editor e interactúan con los anuncios. La publicidad contextual generalmente cae en la categoría de marketing directo (en oposición a la publicidad de marca), es decir, la publicidad cuyo objetivo es una respuesta directa en la que el efecto de una campaña se mide por la reacción del usuario. Una de las ventajas de la publicidad en línea en la publicidad general y contextual en particular es que, en comparación con los medios tradicionales, es relativamente fácil medir la respuesta del usuario. Por lo general, la reacción inmediata deseada es que el usuario siga el enlace en el anuncio y visite el sitio web de los anunciantes y, como se señaló, el modelo financiero prevalente es que el anunciante paga una cierta cantidad por cada clic en el anuncio (PPC). Los ingresos se comparten entre el editor y la red. La publicidad de coincidencia de contexto ha aumentado de la publicidad de búsqueda patrocinada, que consiste en colocar anuncios en las páginas de resultados de un motor de búsqueda web, con anuncios impulsados por la consulta de origen. En la mayoría de las redes, el monto pagado por el anunciante para cada clic SS está determinado por un proceso de subasta donde los anunciantes colocan ofertas en una frase de búsqueda, y su posición en la torre de anuncios que se muestra junto con el resultado está determinado por su oferta. Por lo tanto, cada anuncio se anota con una o más frases de oferta. La frase de oferta no tiene una relación directa con la colocación de anuncios en CM. Sin embargo, es una descripción concisa de la audiencia publicitaria objetivo según lo determine el anunciante y se ha demostrado que es una característica importante para la colocación exitosa de AD CM [8]. Además de la frase de oferta, un anuncio también se caracteriza por un título generalmente que se muestra en una fuente en negrita, y un resumen o creativo, que son las pocas líneas de texto, generalmente menos de 120 caracteres, que se muestran en la página. El modelo AD-Network alinea los intereses de los editores, anunciantes y la red. En general, los clics aportan beneficios tanto al editor como a la red publicitaria al proporcionar ingresos y al anunciante al llevar el tráfico al sitio web objetivo. Los ingresos de la red, dado una página P, se pueden estimar como: r = x i = 1..k p (hacer clic | p, ai) precio (ai, i) donde k es el número de anuncios que se muestran en la página Py el precio (ai, i) es el precio de clic del anuncio actual en la posición i. El precio en este modelo depende del conjunto de anuncios presentados en la página. Se han propuesto varios modelos para determinar el precio, la mayoría de ellos basados en generalizaciones de subastas de segundos de precios. Sin embargo, por simplicidad ignoramos el modelo de precios y nos concentramos en encontrar anuncios que maximizarán el primer término del producto, es decir, buscamos arg max i p (hacer clic | p, ai) además asumimos que la probabilidad de hacer clic para unDado AD y Page están determinados por su puntaje de relevancia con respecto a la página, ignorando así el efecto posicional de la colocación de AD en la página. Suponemos que este es un factor ortogonal para el componente de relevancia y podría incorporarse fácilmente en el modelo.3. Trabajo relacionado publicidad en línea en general y publicidad contextual en particular son áreas emergentes de investigación. La literatura publicada es muy escasa. Un estudio presentado en [13] confirma la intuición de que los anuncios deben ser relevantes para el interés de los usuarios para evitar degradar la experiencia de los usuarios y aumentar la probabilidad de reacción. Un trabajo reciente de Ribeiro-Neto et.Alabama.[8] examina una serie de estrategias para igualar las páginas con anuncios basados en palabras clave extraídas. Los anuncios y las páginas se representan como vectores en un espacio vectorial. Las primeras cinco estrategias propuestas en ese trabajo coinciden con las páginas y los anuncios basados en el coseno del ángulo entre el vector AD y el vector de página. Para averiguar la parte importante del anuncio, los autores exploran el uso de diferentes secciones de anuncios (frase de oferta, título, cuerpo) como base para el Vector AD. La estrategia ganadora de los primeros cinco requiere que la frase de oferta aparezca en la página y luego clasifica todos esos anuncios por el coseno de la unión de todas las secciones de anuncios y los vectores de la página. Si bien tanto las páginas como los anuncios se asignan al mismo espacio, hay una discrepancia (desajuste de impendencia) entre el vocabulario utilizado en los anuncios y en las páginas. Además, dado que en el modelo vectorial las dimensiones están determinadas por el número de palabras únicas, la similitud de coseno simple no tendrá en cuenta los sinónimos. Para resolver este problema, Ribeiro-Neto et al expanden el vocabulario de la página con términos de otras páginas similares ponderadas en función de la similitud general de la página de origen a la página coincidente, y muestran una precisión coincidente mejorada. En un trabajo de seguimiento [7], los autores proponen un método para aprender el impacto de las características individuales utilizando la programación genética para producir una función coincidente. La función se representa como un árbol compuesto por operadores aritméticos y la función logarítmica como nodos internos, y diferentes características numéricas de la consulta y los términos de AD como Leafs. Los resultados muestran que la programación genética encuentra funciones coincidentes que mejoran significativamente la coincidencia en comparación con el mejor método (sin expansión del lado de la página) informadas en [8]. Otro enfoque de la publicidad contextual es reducirlo al problema de la publicidad de búsqueda patrocinada extrayendo frases de la página y coincidirlas con la frase de oferta de los anuncios. En [14] se describe un sistema para la extracción de frases que utilizó una variedad de características para determinar la importancia de las frases de página para fines publicitarios. El sistema está entrenado con páginas que han sido anotadas a mano con frases importantes. El algoritmo de aprendizaje tiene en cuenta las características basadas en TF-IDF, meta datos HTML y registros de consultas para detectar las frases más importantes. Durante la evaluación, cada frase de página hasta la longitud 5 se considera un resultado potencial y se evalúa contra un clasificador capacitado. En nuestro trabajo también experimentamos con un extractor de frases basado en el trabajo reportado en [12]. Si bien aumentó ligeramente la precisión, no cambió el rendimiento relativo de los algoritmos explorados.4. Clasificación de la página y AD 4.1 Elección de la taxonomía La coincidencia semántica de las páginas y los anuncios se realiza clasificando ambos en una taxonomía común. El proceso de correspondencia requiere que la taxonomía proporcione suficiente diferenciación entre los temas comerciales comunes. Por ejemplo, la clasificación de todas las páginas relacionadas con la médica en un nodo no dará como resultado una buena clasificación, ya que tanto las páginas doloridas como la gripe terminarán en el mismo nodo. Sin embargo, los anuncios adecuados para estos dos conceptos son muy diferentes. Para obtener una resolución suficiente, utilizamos una taxonomía de alrededor de 6000 nodos construidos principalmente para clasificar las consultas de intereses comerciales, en lugar de páginas o anuncios. Esta taxonomía ha sido construida comercialmente por Yahoo! Explicaremos a continuación cómo podemos usar la misma taxonomía para clasificar las páginas y anuncios también. Cada nodo en nuestra taxonomía de origen se representa como una colección de frases o consultas de oferta ejemplares que corresponden a ese concepto de nodo. Cada nodo tiene en promedio alrededor de 100 consultas. Las consultas colocadas en la taxonomía son consultas de alto volumen y consultas de alto interés para los anunciantes, como lo indican un precio inusualmente alto de costo por clic (CPC). La taxonomía ha sido poblada por editores humanos que utilizan herramientas de sugerencias de palabras clave similares a las utilizadas por las redes de anuncios para sugerir palabras clave a los anunciantes. Después de la siembra inicial con algunas consultas, utilizando las herramientas proporcionadas, un editor humano puede agregar varios cientos de consultas a un nodo dado. Sin embargo, ha sido un esfuerzo significativo desarrollar esta taxonomía de 6000 nodos y ha requerido varios años de trabajo. En [6] se ha presentado un proceso similar en espíritu para construir taxonomías empresariales a través de consultas. Sin embargo, los detalles y las herramientas son completamente diferentes. La Figura 1 proporciona algunas estadísticas sobre la taxonomía utilizada en este trabajo.4.2 Método de clasificación Como se explica, la fase semántica de la coincidencia se basa en anuncios y páginas que están tópicamente. Por lo tanto, necesitamos clasificar las páginas en la misma taxonomía utilizada para clasificar los anuncios. En esta sección, descrita los métodos que utilizamos para construir una página y un par clasificador de anuncios. La descripción detallada y la evaluación de este proceso están fuera del alcance de este documento. Dada la taxonomía de las consultas (o las frases de ofertas, utilizamos estos términos indistintamente) descrita en la sección anterior, probamos tres métodos para crear clasificadores de página y AD correspondientes. Para los dos primeros métodos, intentamos encontrar páginas y anuncios ejemplares para cada concepto de la siguiente manera: Número de categorías por nivel 0 200 400 600 800 1000 1200 1400 1600 1800 2000 1 2 3 4 5 6 7 8 9 Número de niveles de categorías Número de niños PER porNodos 0 50 100 150 200 250 300 350 400 0 2 4 6 8 10 12 14 16 18 20 22 24 29 31 33 35 52 Número de niños Consultas de Número de Nodos por nodo 0 500 1000 1500 2000 2500 3000 1 50 80 120 160 200 240 280 280320 360 400 440 480 Consultas de números (hasta 500+) Número de Nodos Figura 1: Estadísticas de taxonomía: categorías por nivel;Baroteo para nodos no hojas;y consultas por nodo generamos una capacitación de página establecida ejecutando las consultas en la taxonomía a través de un índice de búsqueda web y utilizando los 10 resultados principales después de algunos filtrados como documentos etiquetados con la etiqueta de consultas. En el lado del anuncio generamos un conjunto de capacitación para cada clase seleccionando los anuncios que tienen una frase de oferta asignada a esta clase. Usando estos conjuntos de entrenamiento, capacitamos un SVM jerárquico [2] (uno contra todos entre cada grupo de hermanos) y un clasificador de regresión de registro [11].(El segundo método difiere del primero en el tipo de filtrado secundario utilizado. Este filtrado elimina páginas de bajo contenido, páginas que se consideran inadecuadas para la publicidad, páginas que conducen a una confusión excesiva de clase, etc.) Sin embargo, obtuvimos el mejor desempeño utilizando el tercer clasificador de documentos, basado en la información en las consultas de taxonomía de origen solamente. Para cada nodo de taxonomía, concatenamos todas las consultas ejemplares en un solo metadocumento. Luego utilizamos el Meta Document como centroide para un clasificador de vecino más cercano basado en el marco Rocchios [9] con solo ejemplos positivos y sin retroalimentación de relevancia. Cada centroide se define como una suma de los valores de TF-IDF de cada término, normalizado por el número de consultas en la clase CJ = 1 | CJ |X q∈Cj q q donde cj es el centroide para la clase CJ;Q itera sobre las consultas en una clase en particular. La clasificación se basa en el coseno del ángulo entre el documento D y los metadocumentos del centroide: cmax = arg max cj ∈C cj cj · d d = arg max cj ∈C p i∈ | f |ci j · di qp i∈ | f | (ci j) 2 qp i∈ | f | (di) 2 donde f es el conjunto de características. El puntaje se normaliza mediante el documento y la longitud de la clase para producir una puntuación comparable. Los términos CI y DI representan el peso de la función I -IH en el centroide de clase y el documento respectivamente. Estos pesos se basan en la fórmula estándar de TF-IDF. Como la puntuación de la clase MAX se normaliza con respecto a la longitud del documento, los puntajes para diferentes documentos son comparables. Realizamos pruebas utilizando editores profesionales para juzgar la calidad de las tareas de clase y publicidad. Las pruebas mostraron que tanto para los anuncios como para las páginas, el clasificador Rocchio devolvió los mejores resultados, especialmente en el lado de la página. Esto es probablemente el resultado del ruido inducido al usar un motor de búsqueda para generar páginas de entrenamiento para la máquina para los clasificadores SVM y de logreza. Es un área de investigación actual sobre cómo mejorar la clasificación utilizando un conjunto de capacitación ruidoso. Según los resultados de la prueba, decidimos usar el clasificador RocChios tanto en el anuncio como en el lado de la página.5. Los sistemas de publicidad contextual de coincidencia semántica sintáctica procesan el contenido de la página, extraen características y luego busque en el espacio de anuncios para encontrar los mejores anuncios coincidentes. Dada una página P y un conjunto de anuncios a = {a1...Como} estimamos la probabilidad relativa de hacer clic P (Haga clic | P, A) con una puntuación que captura la calidad de la coincidencia entre la página y el anuncio. Para encontrar los mejores anuncios para una página, clasificamos los anuncios en A y seleccionamos los pocos principales para la pantalla. El problema se puede definir formalmente como coincidir cada página en el conjunto de todas las páginas p = {p1 ,...PPC} a uno o más anuncios en el conjunto de anuncios. Cada página se representa como un conjunto de secciones de página Pi = {pi, 1, pi, 2...Pi, M}. Las secciones de la página representan diferentes partes estructurales, como título, metadatos, cuerpo, encabezados, etc. A su vez, cada sección es una bolsa de términos desordenada (palabras clave). Una página está representada por la unión de los términos en cada sección: PI = {PWS1 1, PWS1 2...PWSI M} donde PW representa una palabra de página y el superíndice indica la sección de cada término. Un término puede ser un unigram o una frase extraída por un extractor de frases [12]. Del mismo modo, representamos cada anuncio como un conjunto de secciones a = {a1, a2 ,...Al}, cada sección es un conjunto de términos desordenado: Ai = {AWS1 1, AWS1 2...AWSJ L} donde AW es una palabra publicitaria. Los anuncios en nuestros experimentos tienen 3 secciones: título, cuerpo y frase de oferta. En este trabajo, para producir la puntuación de coincidencia, usamos solo la información textual de AD/Page, dejando la información del usuario y otros datos para el trabajo futuro. A continuación, cada página y término AD se asocian con un peso basado en los valores de TF-IDF. El valor de TF se determina en función de las secciones de anuncios individuales. Hay varias opciones para el valor de las FDI, basadas en diferentes ámbitos. En el lado del anuncio, se ha demostrado en trabajos anteriores que el conjunto de anuncios de una campaña proporciona un buen alcance para la estimación de las FDI que conducen a mejores resultados coincidentes [8]. Sin embargo, en este trabajo por simplicidad no tenemos en cuenta las campañas. Para combinar el impacto de la sección Términos y su puntaje TF-IDF, el peso del término AD/Página se define como: Tweight (KWSI) = Peso (Si) · TF IDF (KW) donde Tweight representa el peso y el peso de la pesa (SI) es el peso asignado a una página o sección de anuncios. Este peso es un parámetro fijo determinado por la experimentación. Cada anuncio y página se clasifica en la taxonomía tópica. Definimos estas dos asignaciones: impuestos (PI) = {PCI1 ,...pciu} impuesto (aj) = {acj1...ACJV} Donde PC y AC son clases de página y AD en consecuencia. Cada tarea está asociada con un peso dado por el clasificador. Los pesos se normalizan a suma a 1: x c∈T ax (xi) Cweight (c) = 1 donde xi es una página o un anuncio, y los pesos (c) es el peso de clase - confianza normalizada asignada por el clasificador. El número de clases puede variar entre diferentes páginas y anuncios. Esto corresponde al número de temas con el que se puede asociar una página/anuncio y casi siempre está en el rango 1-4. Ahora definimos el puntaje de relevancia de una AD AI y Página PI como una combinación convexa de la palabra clave (sintáctica) y puntaje de clasificación (semántica): puntaje (PI, AI) = α · Taxscore (impuestos (PI), impuestos (AI)) +(1 - α) · Palabras clave (PI, AI) El parámetro α determina el peso relativo de la puntuación de taxonomía y el puntaje de palabras clave. Para calcular la puntuación de palabras clave, usamos el modelo de espacio vectorial [1] donde las páginas y los anuncios se representan en el espacio n -dimensional, una dimensión para cada término distinto. La magnitud de cada dimensión está determinada por la fórmula tweight (). La puntuación de palabras clave se define como el coseno del ángulo entre la página y los vectores AD: KeywordScore (PI, Ai) = P i∈ | K |tweight (pwi) · tweight (awi) qp i∈ | k | (tweight (pwi)) 2 qp i∈ | k | (tweight (awi)) 2 donde k es el conjunto de todas las palabras clave. La fórmula asume la independencia entre las palabras en las páginas y los anuncios. Además, ignora el orden y la proximidad de los términos en la puntuación. Experimentamos con el impacto de las frases y la proximidad en la puntuación de palabras clave y no vimos un impacto sustancial de estos dos factores. Ahora pasamos a la definición de los impuestos. Esta función indica la coincidencia tópica entre un anuncio dado y una página. A diferencia de las palabras clave que se tratan como dimensiones independientes, aquí las clases (temas) se organizan en una jerarquía. Uno de los objetivos en el diseño de la función TaxScore es poder generalizar dentro de la taxonomía, que es aceptar anuncios relacionados con temas. La generalización puede ayudar a colocar anuncios en los casos en que no hay anuncio que coincida tanto con la categoría como las palabras clave de la página. El ejemplo en la Figura 2 ilustra esta situación. En este ejemplo, en ausencia de anuncios de esquí, una página sobre el esquí que contiene la palabra atómica podría coincidir con el anuncio de snowboard disponible para la misma marca. En general, nos gustaría que el partido sea más fuerte cuando tanto el AD como la página se clasifican en el mismo nodo Figura 2: dos rutas de generalización y más débiles cuando la distancia entre los nodos en la taxonomía se hace más grande. Hay múltiples formas de especificar la distancia entre dos nodos de taxonomía. Además del requisito anterior, esta función debe prestarse a una búsqueda eficiente del espacio AD. Dada una página, tenemos que encontrar el anuncio en unos pocos milisegundos, ya que esto afecta la presentación a un usuario que espera. Esto se discutirá más a fondo en la siguiente sección. Para capturar tanto los requisitos de generalización como de eficiencia, definimos la función TaxScore de la siguiente manera: TaxScore (PC, AC) = x PC∈P C X AC∈C Idist (LCA (PC, AC), AC) · C de peso (PC) · CWeight (AC -peso (AC) En esta función consideramos cada combinación de clase de página y clase AD. Para cada combinación, multiplicamos el producto de los pesos de clase con la función de distancia inversa entre el ancestro menos común de las dos clases (LCA) y la clase AD. La función de distancia inversa IDIST (C1, C2) toma dos nodos en la misma ruta en la taxonomía de la clase y devuelve un número en el intervalo [0, 1] dependiendo de la distancia de los dos nodos de clase. Devuelve 1 si los dos nodos son iguales y disminuye hacia 0 cuando LCA (PC, AC) o AC es la raíz de la taxonomía. La tasa de disminución determina el peso de la generalización versus los otros términos en la fórmula de puntuación. Para determinar la tasa de disminución, consideramos el impacto en la especificidad de la coincidencia cuando sustituimos una clase con uno de sus antepasados. En general, el impacto depende del tema. Por ejemplo, el pasatiempo de nodo en nuestra taxonomía tiene decenas de niños, cada uno representando un pasatiempo diferente, dos ejemplos navegando y tejiendo. Colocar un anuncio sobre tejer en una página sobre la navegación no tiene mucho sentido. Sin embargo, en el ejemplo de deportes de invierno anteriores, en ausencia de una mejor alternativa, los anuncios de esquí podrían colocarse en páginas de snowboard, ya que podrían promover los mismos lugares, proveedores de equipos, etc. Dicho análisis detallado caso por caso es prohibitivamente costoso debido al tamaño de la taxonomía. Una opción es usar las confidencias de las clases de antepasados según lo dado por el clasificador. Sin embargo, encontramos que estos números no son adecuados para este propósito, ya que la magnitud de las confidencias no necesariamente disminuye al subir el árbol. Otra opción es utilizar los métodos Explore-EXPLOIT basados en el aprendizaje automático de la retroalimentación de clics como se describe en [10]. Sin embargo, por simplicidad, en este trabajo elegimos una heurística simple para determinar el costo de generalización de un niño a un padre. En esta heurística observamos la ampliación del alcance cuando nos movemos de un niño a un padre. Estimamos la ampliación por la densidad de los AD clasificados en los nodos parentales frente al nodo secundario. La densidad se obtiene clasificando un gran conjunto de anuncios en la taxonomía utilizando el clasificador de documento descrito anteriormente. Según esto, deje que NC sea el número de documentos clasificado en el subárbol enraizado en c.Luego definimos: idist (c, p) = nc np donde c representa el nodo secundario y p es el nodo principal. Esta fracción se puede ver como una probabilidad de que un anuncio que pertenece al tema principal sea adecuado para el tema infantil.6. Al buscar el espacio de anuncios en la sección anterior, discutimos la elección de la función de puntuación para estimar la coincidencia entre un anuncio y una página. El sistema ofrece los anuncios de Top-K con la puntuación más alta para la ubicación en la página de los editores. El proceso de cálculo de puntaje y selección de anuncios se debe realizar en tiempo real y, por lo tanto, debe ser muy eficiente. Como las colecciones de anuncios están en el rango de cientos de millones de entradas, existe la necesidad de acceso indexado a los anuncios. Los índices invertidos proporcionan soluciones de latencia escalables y de baja para buscar documentos. Sin embargo, estos se han usado tradicionalmente para buscar en función de las palabras clave. Para poder buscar en los anuncios en una combinación de palabras clave y clases, hemos asignado la coincidencia de clasificación para la coincidencia de términos y adaptado la función de puntuación para que sea adecuada para una evaluación rápida sobre índices invertidos. En esta sección, consignamos la indexación de anuncios y la función de clasificación de nuestro sistema de búsqueda de anuncios prototipo para anuncios y páginas coincidentes. Utilizamos un marco de índice invertido estándar donde hay una lista de publicación para cada término distinto. Los anuncios se analizan en términos y cada término se asocia con un peso basado en la sección en la que aparece. Se suman pesos de distintos eventos de un término en un anuncio, de modo que las listas de publicación contienen una entrada por término/combinación de AD. ¿El siguiente desafío es cómo indexar los anuncios para que la información de la clase se preserve en el índice? Un método simple es crear metaterms únicos para las clases y anotar cada anuncio con un meta-término para cada clase asignada. Sin embargo, este método no permite la generalización, ya que solo se seleccionarán los anuncios que coincidan con una etiqueta exacta de la página. Por lo tanto, anotamos cada anuncio con un meta-término para cada antepasado de la clase asignada. Los pesos de los metaderes se asignan de acuerdo con el valor de la función IDIST () definida en la sección anterior. En el lado de la consulta, dadas las palabras clave y la clase de una página, componemos una consulta de solo palabra clave insertando un término de clase para cada antepasado de las clases asignadas a la página. La función de puntuación se adapta a la puntuación de dos partes para la clase MetaTerms y otra para el término de texto. Durante el cálculo de la puntuación de la clase, para cada ruta de clase usamos solo el meta-término de clase más bajo, ignorando a los demás. Por ejemplo, si un anuncio pertenece a la clase de esquí y está anotado tanto con el esquí como con sus deportes de invierno de los padres, el índice contendrá los metaderios de clase especial para el esquí y los deportes de invierno (y todos sus antepasados) con los pesos segúnEl producto de la confianza del clasificador y la función IDIST. Al combinar con una página clasificada en esquí, la consulta contendrá términos para el esquí de clase y para cada uno de sus antepasados. Sin embargo, al anotar un anuncio clasificado en esquí, usaremos el peso para el meta-trimestre de la clase de esquí. Los anuncios clasificados en el snowboard se calificarán utilizando el peso del meta-trimestre deportivo de invierno. Para hacer este cheque de manera eficiente, mantenemos una lista ordenada de todas las rutas de clase y, en el momento de la puntuación, buscamos en las rutas de abajo hacia arriba para que aparezca un meta-término en el anuncio. El primer meta-término se usa para la puntuación, el resto se ignoran. En tiempo de ejecución, evaluamos la consulta utilizando una variante del algoritmo de la varita [3]. Este es un algoritmo de documento en el tiempo [1] que utiliza un enfoque de rama y unido para obtener movimientos eficientes para los cursores asociados a las listas de publicaciones. Encuentra que el siguiente cursor se mueve en función de un límite superior del puntaje para los documentos en los que se colocan actualmente los cursores. El algoritmo mantiene un montón de los mejores candidatos actuales. Los documentos con un límite superior más pequeño que el puntaje mínimo actual entre los documentos candidatos se pueden eliminar de más consideraciones y, por lo tanto, los cursores pueden saltar sobre ellos. Para encontrar el límite superior para un documento, el algoritmo supone que todos los cursores que son antes de que presionen este documento (es decir, el documento contiene todos los términos representados por los cursores antes o en ese documento). Se ha demostrado que la varita se puede usar con cualquier función que sea monotónica con respecto al número de términos coincidentes en el documento. Nuestra función de puntuación es monotónica ya que la puntuación nunca puede disminuir cuando se encuentran más términos en el documento. En el caso especial cuando agregamos un cursor que representa a un antepasado de un término de clase ya factorizado en el puntaje, el puntaje simplemente no cambia (agregamos 0). Dadas estas propiedades, utilizamos una adaptación del algoritmo de la varita donde cambiamos el cálculo de la función de puntuación y el cálculo de la puntuación de límite superior para reflejar nuestra función de puntuación. El resto del algoritmo permanece sin cambios.7. Evaluación experimental 7.1 Datos y metodología Cuantificamos el efecto de la coincidencia sintáctica semántica utilizando un conjunto de 105 páginas. Este conjunto de páginas fue seleccionado por una muestra aleatoria de un conjunto más grande de alrededor de 20 millones de páginas con publicidad contextual. Los anuncios para cada una de estas páginas se han seleccionado de un grupo más grande de anuncios (decenas de millones) por experimentos anteriores realizados por Yahoo! Cada par de la página ha sido juzgado por tres o más jueces humanos en una escala 1 a 3: 1. Relevante, el anuncio está semánticamente directamente relacionado con el tema principal de la página. Por ejemplo, si la página se trata de la Liga Nacional de Fútbol y el anuncio se trata de boletos para los juegos de la NFL, se calificaría como 1. 2. Algo relevante, el anuncio está relacionado con el tema secundario de la página, o está relacionado con el tema principal de la página de manera general. En el ejemplo de la página de la NFL, un anuncio sobre productos de marca NFL se juzgaría como 2. 3. Irrelevante, el anuncio no está relacionado con la página. Por ejemplo, una mención del jugador de la NFL John Maytag desencadena anuncios de lavadora en una página de la NFL.Páginas 105 palabras por página 868 Juicios 2946 Judg.Acuerdo entre editor 84% ADS únicos 2680 ADS únicos por página 25.5 Página Clasificación Precisión 70% Clasificación de anuncios Precisión 86% Tabla 1: Estadísticas del conjunto de datos Para obtener una puntuación para un par de la página AG, promedimos todos los puntajes y luego redondeados al más cercano a la más cercanaentero. Luego utilizamos estos juicios para evaluar qué tan bien nuestros métodos distinguen las asignaciones de AD positivas y negativas para cada página. Las estadísticas del conjunto de datos de la página se dan en la Tabla 1. Los experimentos originales que combinaban las páginas y los anuncios están relacionado libremente con la asignación basada en la coincidencia y clasificación basada en palabras clave sintácticas, pero utilizaron diferentes taxonomías y técnicas de extracción de palabras clave. Por lo tanto, no pudimos usar la agrupación estándar como método de evaluación ya que no controlamos la forma en que se seleccionaron los pares y no pudimos establecer con precisión el conjunto de anuncios de los cuales se seleccionaron los anuncios colocados. En cambio, en nuestra evaluación para cada página consideramos solo aquellos anuncios para los cuales tenemos un juicio. Cada método diferente se aplicó a este conjunto y los anuncios fueron clasificados por la puntuación. La efectividad relativa de los algoritmos se juzgó comparando qué tan bien los métodos separaron los anuncios con juicio positivo de los ADS con juicio negativo. Presentamos precisión en varios niveles de recuperación dentro de este conjunto. Como el conjunto de anuncios por página es relativamente pequeño, la evaluación informa una precisión que es más alta de lo que sería con un conjunto mayor de anuncios negativos. Sin embargo, estos números aún establecen el rendimiento relativo de los algoritmos y podemos usarlo para evaluar el rendimiento en diferentes umbrales de puntaje. Además de la recuperación de precisión sobre los anuncios juzgados, también presentamos el coeficiente de correlación de rango de Kendalls τ para establecer cuán lejos del orden perfecto están los ordenamientos producidos por nuestros algoritmos de clasificación. Para esta prueba, clasificamos los anuncios juzgados por los puntajes asignados por los jueces y luego comparamos esta orden con la orden asignada por nuestros algoritmos. Finalmente, también examinamos la precisión en la posición 1, 3 y 5. 7.2 Resultados La Figura 3 muestra las curvas de recuperación de precisión para la coincidencia sintáctica (palabras clave solo utilizadas) frente a una coincidencia sintáctica semántica con el valor óptimo de α = 0.8 (juzgado porEl puntaje de 11 puntos [1]). En esta figura, suponemos que los pares de ADPAGE juzgados con 1 o 2 son ejemplos positivos y los 3s son ejemplos negativos. También examinamos contar solo los pares juzgados con 1 como ejemplos positivos y no encontramos un cambio significativo en el rendimiento relativo de los métodos probados. Superpuesto también son resultados utilizando frases en la coincidencia de palabras clave. Vemos que estas características adicionales no cambian el rendimiento relativo del algoritmo. Los gráficos muestran un impacto significativo de la información de la clase, especialmente en el rango medio de los valores de recuperación. En el bajo retiro, parte de la tabla se encuentran las curvas. Esto indica que cuando la coincidencia de palabras clave es realmente fuerte (es decir, cuando el anuncio está casi contenido dentro de la página) la precisión 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 Recuerda precisión alfa = .9, sin frase alfa = 0,Sin frase alfa = 0, frase alfa = .9, frase Figura 3: Conjunto de datos 2: Precisión versus recuerdo de la coincidencia sintáctica (α = 0) versus coincidencia sintáctica-semántica (α = 0.8) α Kendalls τ α = 0 0.086α = 0.25 0.155 α = 0.50 0.166 α = 0.75 0.158 α = 1 0.136 Tabla 2: Kendalls τ para diferentes valores α de la coincidencia de palabras clave sintácticas es comparable con la de la coincidencia semántica sintáctica. Sin embargo, tenga en cuenta que los dos métodos pueden producir diferentes anuncios y podrían usarse como un complemento a nivel de recuerdo. Los componentes semánticos proporcionan una mayor elevación en precisión en el rango medio de recuperación, donde se logra una mejora del 25% mediante el uso de la información de clase para la colocación de anuncios. Esto significa que cuando hay algo de coincidencia entre el anuncio y la página, la restricción a las clases correctas proporciona un mejor alcance para seleccionar los anuncios. La Tabla 2 muestra los valores de Kendalls τ para diferentes valores de α. Calculamos los valores clasificando todos los anuncios juzgados para cada página y promediando los valores en todas las páginas. Los anuncios con juicio empatado recibieron el rango de la posición media. Los resultados muestran que cuando tenemos en cuenta todos los pares de página AD, el valor óptimo de α es de alrededor de 0.5. Tenga en cuenta que la coincidencia puramente sintáctica (α = 0) es, con mucho, el método más débil. La Figura 4 muestra el efecto del parámetro α en la puntuación. Vemos que en la mayoría de los casos la precisión crece o es plana cuando aumentamos α, excepto en el bajo nivel de recuerdo, donde debido a la pequeña cantidad de puntos de datos hay un poco de fluctuación en los resultados. La Tabla 3 muestra la precisión en las posiciones 1, 3 y 5. Nuevamente, el método puramente sintáctico tiene claramente la puntuación más baja por posiciones individuales y el número total de anuncios colocados correctamente. Los números están cerca debido al pequeño número de anuncios considerados, pero todavía hay algunas tendencias notables. Para la posición 1, el α óptimo está en el rango de 0.25 a 0.75. Para las posiciones 3 y 5, el óptimo está en α = 1. Esto también indica que para aquellos anuncios que tienen una puntuación de palabras clave muy alta, la información semántica es algo menos importante. Si casi todas las palabras en un anuncio aparecen en la página, este anuncio es precisión frente a alfa para diferentes niveles de recuperación (conjunto de datos 2) 0.45 0.55 0.65 0.75 0.85 0.95 0 0.2 0.4 0.6 0.8 1 precisión alfa 80% RECURSO 60% RECORT 40% Recuerde 20% Recuerde Figura 4: Impacto de α en la precisión para diferentes niveles de recuperación α #1 #3 #5 Sum α = 0 80 70 68 218 α = 0.25 89 76 73 238 α = 0.5 89 74 73 236 α = 0.7589 78 73 240 α = 1 86 79 74 239 Tabla 3: Precisión en la posición 1, 3 y 5 Es probable que sea relevante para esta página. Sin embargo, cuando no existe una afinidad tan clara, la información de la clase se convierte en un factor dominante.8. Conclusión La publicidad contextual es el motor económico detrás de una gran cantidad de sitios no transaccionales en la web. Los estudios han demostrado que uno de los principales factores de éxito para los anuncios contextuales es su relevancia para el contenido circundante. Todas las soluciones de coincidencia contextuales comerciales existentes conocidas por nosotros evolucionaron de las soluciones de publicidad de búsqueda por las cuales una consulta de búsqueda se corresponde con la frase de oferta de los anuncios. Una extensión natural de la publicidad de búsqueda es extraer frases de la página y combinarlas con la frase de oferta de los anuncios. Sin embargo, las frases y palabras individuales pueden tener múltiples significados y/o no estar relacionados con el tema general de la página que conduce a anuncios de fallas. En este artículo propusimos una forma novedosa de hacer coincidir los anuncios con las páginas web que dependen de una coincidencia tópica (semántica) como un componente importante de la puntuación de relevancia. El partido semántico se basa en la clasificación de páginas y anuncios en una taxonomía publicitaria comercial de 6000 nodos para determinar su distancia tópica. A medida que la clasificación se basa en el contenido completo de la página, es más robusto que las frases de página individuales. La coincidencia semántica se complementa con una coincidencia sintáctica y la puntuación final es una combinación convexa de los dos subcorres con el peso relativo de cada uno determinado por un parámetro α. Evaluamos el enfoque semántico-sintáctico contra un enfoque sintáctico en un conjunto de páginas con diferentes publicidad contextual. Como se muestra en nuestra evaluación experimental, el valor óptimo del parámetro α depende del objetivo preciso de optimización (precisión en una posición particular, precisión en el recuerdo dado). Sin embargo, en todos los casos, el valor óptimo de α está entre 0.25 y 0.9 que indica un efecto significativo del componente de puntaje semántico. La efectividad de la coincidencia sintáctica depende de la calidad de las páginas utilizadas. En páginas de menor calidad, es más probable que cometamos errores de clasificación que luego afectarán negativamente la coincidencia. Demostramos que es factible construir un clasificador a gran escala que tenga suficiente precisión para esta aplicación. Actualmente estamos examinando cómo emplear algoritmos de aprendizaje automático para aprender el valor óptimo de α en función de una colección de características de las páginas de entrada.9. Referencias [1] R. Baeza-Yates y B. Ribeiro-Neto. ACM, 1999. [2] Bernhard E. Boser, Isabelle Guyon y Vladimir Vapnik. Un algoritmo de entrenamiento para clasificadores de margen óptimo. En la teoría del aprendizaje computacional, páginas 144-152, 1992. [3] A. Z. Broder, D. Carmel, M. Herscovici, A. Soffer y J. Zien. Evaluación eficiente de consultas utilizando un proceso de recuperación de dos niveles. En CIKM 03: Proc.del duodécimo intl.conf.Sobre la gestión de información y conocimiento, páginas 426-434, Nueva York, NY, 2003. Acm[4] P. Chatterjee, D. L. Hoffman y T. P. Novak. Modelado de Clickstream: Implicaciones para los esfuerzos de publicidad basados en la web. Marketing Science, 22 (4): 520-541, 2003. [5] D. Fain y J. Pedersen. Búsqueda patrocinada: una breve historia. En Proc.del segundo taller sobre subastas de búsqueda patrocinadas, 2006. Publicación web, 2006. [6] S. C. Gates, W. Teiken y K.-Shin F. Cheng. Taxonomías por los números: construcción de taxonomías de alto rendimiento. En CIKM 05: Proc.del 14 ° ACM INTL.conf.Sobre la gestión de información y conocimiento, páginas 568-577, Nueva York, NY, 2005. Acm[7] A. Lacerda, M. Cristo, M. Andre;G., W. Fan, N. Ziviani y B. Ribeiro-Neto. En Sigir 06: Proc.de la 29a intl anual. ACM Sigir Conf., Páginas 549-556, Nueva York, NY, 2006. Acm[8] B. Ribeiro-Neto, M. Cristo, P. B. Golgher y E. S. de Moura. Acoplamiento de impedancia en publicidad dirigida al contenido. En Sigir 05: Proc.de la 28ª INTL anual. ACM Sigir Conf., Páginas 496-503, Nueva York, NY, 2005. Comentarios de relevancia en la recuperación de información. En el sistema de recuperación inteligente: experimentos en el procesamiento automático de documentos, páginas 313-323. Prentice Hall, 1971. [10p.Sandeep, D. Agarwal, D. Chakrabarti y V. Josifovski. Bandits para taxonomías: un enfoque basado en modelos. En Proc.del Siam intl.conf.en Data Mining, 2007. [11] T. Santner y D. Duffy. El análisis estadístico de datos discretos. Springer-Verlag, 1989. [12] R. Stata, K. Bharat y F. Maghoul. El término base de datos Vector: acceso rápido a los términos de indexación para páginas web. Computer Networks, 33 (1-6): 247-255, 2000. [13] C. Wang, P. Zhang, R. Choi y M. D. Edita. Comprender la actitud de los consumidores hacia la publicidad. En el octavo América Conf.En el sistema de información, páginas 1143-1148, 2002. [14] W. Yih, J. Goodman y V. R. Carvalho. Encontrar palabras clave publicitarias en páginas web. En www 06: Proc.del 15 ° Intl.conf.En World Wide Web, páginas 213-222, Nueva York, NY, 2006.