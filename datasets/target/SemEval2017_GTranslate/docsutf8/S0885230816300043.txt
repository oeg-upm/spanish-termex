El conjunto final de experimentos implicó un reentrenamiento adaptativo de los parámetros GMM -HMM después del procedimiento ANAT.Este nuevo modelo solo proporcionó una mejora de 0.3%, similar a el uso de las transformaciones ACMLLR en el modelo de base GMM -HMM.Sin embargo, el entrenamiento de ACMLLR basado en Show se transforma además del modelo entrenado adaptativamente aumentó la mejora al 0.8% absoluto.Esto mostró cómo la capacitación adaptativa proporcionó una mejor flexibilidad del modelo para adaptarse a las condiciones de fondo específicas existentes en cada programa.Finalmente, se probó el enfoque de factorización utilizando transformaciones de altavoz MLLR en la parte superior del modelo ANAT y las transformaciones de ACMLLR basadas en Show.Esto solo aumentó la mejora al 0.9% absoluto (2.9% relativo), lo que refleja la dificultad de realizar una agrupación precisa de los altavoces en esta tarea y cómo esto realmente obstaculiza la adaptación del altavoz.