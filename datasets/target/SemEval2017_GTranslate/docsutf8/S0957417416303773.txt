En los últimos años y principalmente motivados por el impulso de la minería de datos, han surgido muchos métodos para la reducción de dimensionalidad.Dentro de estos, vale la pena resaltar el método principal de análisis de componentes (PCA) (Jolliffe, 2002).En un espacio vectorial n-dimensional, la versión más simple de PCA (PCA lineal) es una técnica que encuentra los vectores mutuamente organizados en los que la proyección de las muestras genera las variaciones más altas.El resultado es un conjunto de vectores ortogonales ordenados en orden descendente de varianza alcanzada.El primero de estos vectores es aquello en el que la varianza de la proyección de las muestras es máxima.En este sentido, los KPI originales constituyen la base del espacio del vector n-dimensional, mientras que los KPI sintéticos N^ representan los vectores ortogonales con la mayor varianza.Para ser riguroso, se pueden calcular hasta N KPI ortogonales sintéticos.Sin embargo, solo un pequeño conjunto de ellos, el primer n^, es suficiente para explicar la mayor parte de la varianza de los datos.