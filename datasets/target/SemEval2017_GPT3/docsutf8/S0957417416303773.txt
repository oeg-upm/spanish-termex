En los últimos años y principalmente motivado por el impulso de la minería de datos han surgido muchos métodos para la reducción de dimensionalidad. Dentro de estos, vale la pena destacar el método de Análisis de Componentes Principales (PCA) (Jolliffe, 2002). En un espacio vectorial de N dimensiones, la versión más simple de PCA (PCA lineal) es una técnica que encuentra los vectores mutuamente no correlacionados en los cuales la proyección de las muestras genera las varianzas más altas. El resultado es un conjunto de vectores ortogonales ordenados en orden descendente de varianza lograda. El primero de estos vectores es aquel en el cual la varianza de la proyección de las muestras es máxima. En este sentido, los KPIs originales constituyen la base del espacio vectorial de N dimensiones, mientras que los KPIs sintéticos de N^ representan los vectores ortogonales con la mayor varianza. Para ser rigurosos, se pueden calcular hasta N KPIs sintéticos ortogonales. Sin embargo, solo un pequeño conjunto de ellos, los primeros N^, es suficiente para representar la mayor parte de la varianza de los datos.