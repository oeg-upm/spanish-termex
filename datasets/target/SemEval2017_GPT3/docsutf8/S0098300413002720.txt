Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta.