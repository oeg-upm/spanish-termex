El Modelo de Negociación LOGIC Carles Sierra Institut d'Investigació en Intel·ligència Artificial Consejo Superior de Investigaciones Científicas, UAB 08193 Bellaterra, Cataluña, España sierra@iiia.csic.es John Debenham Facultad de Tecnologías de la Información Universidad de Tecnología, Sídney NSW, Australia debenham@it.uts.edu.au RESUMEN Los negociadores exitosos se preparan determinando su posición a lo largo de cinco dimensiones: Legitimidad, Opciones, Metas, Independencia y Compromiso (LOGIC). Introducimos un modelo de negociación basado en estas dimensiones y en dos conceptos primitivos: intimidad (grado de cercanía) y equilibrio (grado de equidad). La intimidad es un par de matrices que evalúan tanto la contribución de un agente a la relación como la contribución de su oponente, cada una desde una perspectiva de información y desde una perspectiva utilitaria a lo largo de las cinco dimensiones de la LÓGICA. El equilibrio es la diferencia entre estas matrices. Una estrategia de relaciones mantiene una intimidad objetivo para cada relación hacia la cual un agente quisiera que la relación se moviera en el futuro. La estrategia de negociación mantiene un conjunto de opciones que están alineadas con el nivel actual de intimidad, y luego las tácticas envuelven las opciones en argumentación con el objetivo de lograr un acuerdo exitoso y manipular los equilibrios sucesivos de la negociación hacia la intimidad deseada. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría 1. INTRODUCCIÓN En este artículo proponemos un nuevo modelo de negociación para tratar relaciones a largo plazo que se basan en encuentros de negociación sucesivos. El modelo se basa en resultados de estudios de negocios y psicología [1, 16, 9], y reconoce que la negociación es un proceso de intercambio de información, así como un proceso de intercambio de utilidad [15, 14]. Creemos que si los agentes quieren tener éxito en dominios de aplicación reales, deben conciliar ambas perspectivas: la informativa y la teórica del juego. Nuestro objetivo es modelar escenarios de negociación donde los agentes representen a sus principales humanos, y por lo tanto queremos que su comportamiento sea comprensible para los humanos y respete los procedimientos habituales de negociación humana, al mismo tiempo que sea consistente con, y de alguna manera extienda, los resultados teóricos de juegos e información. En este sentido, los agentes no solo buscan maximizar la utilidad, sino que también buscan construir relaciones duraderas con niveles crecientes de intimidad que determinan qué equilibrio en el intercambio de información y recursos les resulta aceptable. Estos dos conceptos, intimidad y equilibrio, son clave en el modelo, y nos permiten entender la teoría de juegos competitiva y cooperativa como dos teorías particulares de las relaciones entre agentes (es decir, en diferentes niveles de intimidad). Estas dos teorías son demasiado específicas y distintas para describir cómo una relación (comercial) podría crecer, ya que las interacciones tienen algunos aspectos de estos dos extremos en un continuo en el que, por ejemplo, los agentes revelan cantidades crecientes de información privada a medida que su intimidad aumenta. No seguimos el enfoque de Co-Opetition [4] donde la cooperación y la competencia dependen del tema en negociación, sino que creemos que la disposición a cooperar/competir afecta todos los aspectos en el proceso de negociación. Las estrategias de negociación pueden ser vistas naturalmente como procedimientos que seleccionan tácticas utilizadas para lograr un acuerdo exitoso y alcanzar un nivel de intimidad deseado. Es común en entornos humanos utilizar tácticas que compensen desequilibrios en una dimensión de una negociación con desequilibrios en otra dimensión. En este sentido, los humanos buscan un sentido general de equidad en una interacción. En la Sección 2 delineamos los aspectos del modelado de la negociación humana que cubrimos en este trabajo. Luego, en la Sección 3 introducimos el lenguaje de negociación. La sección 4 explica de manera general la arquitectura y los conceptos de intimidad y equilibrio, y cómo influyen en la negociación. La sección 5 contiene una descripción de las diferentes métricas utilizadas en el modelo de agente, incluida la intimidad. Finalmente, la Sección 6 describe cómo las estrategias y tácticas utilizan el marco lógico, la intimidad y el equilibrio. 2. NEGOCIACIÓN HUMANA Antes de que comience una negociación, los negociadores humanos preparan los intercambios dialógicos que se pueden realizar a lo largo de las cinco dimensiones LÓGICAS [7]: • Legitimidad. ¿Qué información es relevante para el proceso de negociación? ¿Cuáles son los argumentos persuasivos sobre la equidad de las opciones? 1030 978-81-904262-7-5 (RPS) c 2007 IFAAMAS • Opciones. ¿Cuáles son los acuerdos posibles que podemos aceptar? • Metas. ¿Cuáles son las cosas subyacentes que necesitamos o nos importan? ¿Cuáles son nuestros objetivos? • Independencia. ¿Qué haremos si la negociación falla? ¿Qué alternativas tenemos? • Compromiso. ¿Qué compromisos pendientes tenemos? Los diálogos de negociación, en este contexto, intercambian movimientos dialógicos, es decir, mensajes, con la intención de obtener información sobre el oponente o revelar información sobre nosotros a lo largo de estas cinco dimensiones: solicitud de información, proponer opciones, informar sobre intereses, hacer promesas, apelar a estándares... Una parte clave de cualquier proceso de negociación es construir un modelo de nuestro(s) oponente(s) a lo largo de estas dimensiones. Todas las expresiones que los agentes hacen durante una negociación revelan información sobre su modelo de LÓGICA actual, es decir, sobre su legitimidad, opciones, objetivos, independencia y compromisos. Además, varias expresiones pueden tener una interpretación utilitaria en el sentido de que un agente puede asociarles una ganancia preferencial. Por ejemplo, una oferta puede informar a nuestro oponente de negociación sobre nuestra disposición a firmar un contrato en los términos expresados en la oferta, y al mismo tiempo el oponente puede calcular cuál es su ganancia utilitaria esperada asociada. Estas dos perspectivas: basada en la información y basada en la utilidad, son centrales en el modelo propuesto en este documento. 2.1 Intimidad y equilibrio en las relaciones. Existen evidencias de estudios psicológicos que indican que los seres humanos buscan un equilibrio en sus relaciones de negociación. La visión clásica es que las personas perciben las asignaciones de recursos como distributivamente justas (es decir, bien equilibradas) si son proporcionales a los insumos o contribuciones (es decir, equitativas). Sin embargo, estudios más recientes [16, 17] muestran que los humanos siguen un conjunto más amplio de normas de justicia distributiva dependiendo de su nivel de intimidad: equidad, igualdad y necesidad. La equidad es la asignación proporcional al esfuerzo (por ejemplo, las ganancias de una empresa van a los accionistas en proporción a su inversión), la igualdad es la asignación en cantidades iguales (por ejemplo, dos amigos comen la misma cantidad de un pastel cocinado por uno de ellos), y la necesidad es la asignación proporcional a la necesidad del recurso (por ejemplo, en caso de escasez de alimentos, una madre le da toda la comida a su bebé). Por ejemplo, si nos encontramos en un entorno puramente económico (baja intimidad), podríamos solicitar equidad para la dimensión de Opciones pero podríamos aceptar igualdad en la dimensión de Objetivos. La percepción de que una relación está en equilibrio (es decir, justa) depende en gran medida de la naturaleza de las relaciones sociales entre individuos (es decir, el nivel de intimidad). En relaciones puramente económicas (por ejemplo, negocios), la equidad se percibe como más justa; en relaciones donde la acción conjunta o el fomento de relaciones sociales son el objetivo (por ejemplo, amistades), la igualdad se percibe como más justa; y en situaciones donde el desarrollo personal o el bienestar personal son el objetivo (por ejemplo, familia), las asignaciones suelen basarse en la necesidad. Creemos que la percepción del equilibrio en los diálogos (en negociaciones u otros contextos) se basa en las relaciones sociales, y que cada dimensión de una interacción entre humanos puede correlacionarse con la cercanía social o intimidad entre las partes involucradas. Según los estudios previos, cuanto mayor sea la intimidad en las cinco dimensiones de la LÓGICA, más se utiliza la norma de necesidad, y cuanto menor sea la intimidad, más se utiliza la norma de equidad. Esto podría ser parte de nuestra evolución social. Hay amplias evidencias de que cuando las sociedades humanas evolucionaron de una estructura de cazadores-recolectores a una basada en refugios, la probabilidad de supervivencia aumentó cuando la comida escaseaba. En este contexto, podemos ver claramente que, por ejemplo, las familias intercambian no solo bienes, sino también información y conocimiento basado en la necesidad, y que pocas familias considerarían sus relaciones como desequilibradas y, por lo tanto, injustas, cuando hay una fuerte asimetría en los intercambios (una madre explicando todo a sus hijos, o comprando juguetes, no espera reciprocidad). En el caso de las parejas, hay algunas pruebas [3] de que las asignaciones de bienes y cargas (es decir, utilidades positivas y negativas) se perciben como justas, o en equilibrio, basadas en la equidad para las cargas y la igualdad para los bienes. Consulte la Tabla 1 para ver algunos ejemplos de balances deseados a lo largo de las dimensiones de LÓGICA. El equilibrio percibido en un diálogo de negociación permite a los negociadores inferir información sobre su oponente, sobre su postura lógica, y comparar sus relaciones con todos los negociadores. Por ejemplo, si percibimos que cada vez que solicitamos información esta es proporcionada, y que no se devuelven preguntas significativas, o no se presentan quejas sobre no recibir información, entonces probablemente significa que nuestro oponente percibe nuestra relación social como muy cercana. Alternativamente, podemos detectar qué problemas están causando una carga a nuestro oponente observando un desequilibrio en la información o en los sentidos utilitarios sobre ese tema. 3. MODELO DE COMUNICACIÓN 3.1 Ontología Para definir un lenguaje que estructure los diálogos de los agentes, necesitamos una ontología que incluya un repertorio (mínimo) de elementos: un conjunto de conceptos (por ejemplo, cantidad, calidad, material) organizados en una jerarquía de es-un (por ejemplo, el ornitorrinco es un mamífero, el dólar australiano es una moneda), y un conjunto de relaciones sobre estos conceptos (por ejemplo, precio(cerveza, AUD)). Modelamos ontologías siguiendo un enfoque algebraico [8] de la siguiente manera: Una ontología es una tupla O = (C, R, ≤, σ) donde: 1. C es un conjunto finito de símbolos conceptuales (incluyendo tipos de datos básicos); 2. En su forma más pura, los individuos en estas sociedades recolectan alimentos y los consumen cuando y donde se encuentran. Esta es una participación equitativa pura de los recursos, la ganancia es proporcional al esfuerzo. En estas sociedades existen unidades familiares, alrededor de un refugio, que representan la estructura básica de compartir alimentos. Por lo general, la comida se acumula en el refugio para uso futuro. Entonces, la ingesta de alimentos depende más de la necesidad de los miembros. Por lo general, también se requiere un conjunto de axiomas definidos sobre los conceptos y relaciones. Omitiremos esto aquí. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Elemento 1031 Un nuevo socio comercial mi carnicero mi jefe mi socio mis hijos Legitimidad equidad equidad equidad igualdad necesidad Opciones equidad equidad equidad mixta necesidad Metas equidad necesidad equidad necesidad necesidad Independencia equidad equidad igualdad necesidad necesidad Compromiso equidad equidad equidad mixta necesidad una equidad en la carga, igualdad en lo bueno Tabla 1: Algunos ejemplos de equilibrios deseados (sentido de justicia) dependiendo de la relación, donde ≤ es la jerarquía tradicional es-un. Para simplificar los cálculos en el cálculo de distribuciones de probabilidad, asumimos que hay un número de árboles disjuntos que cubren diferentes espacios ontológicos (por ejemplo, un árbol para tipos de tela, un árbol para formas de ropa, y así sucesivamente). R contiene relaciones entre los conceptos en la jerarquía, esto es necesario para definir objetos (por ejemplo, acuerdos) que se definen como una tupla de problemas. La distancia semántica entre conceptos dentro de una ontología depende de qué tan lejos estén en la estructura definida por la relación ≤. La distancia semántica juega un papel fundamental en las estrategias para la agencia basada en la información. Cómo los contratos firmados, Commit(·), sobre objetos en una región semántica particular, y su ejecución, Done(·), afectan nuestro proceso de toma de decisiones sobre la firma de contratos futuros en regiones semánticas cercanas es crucial para modelar el sentido común que los seres humanos aplican en la gestión de relaciones comerciales. Una medida [10] basa la similitud semántica entre dos conceptos en la longitud del camino inducido por ≤ (mayor distancia en el grafo de ≤ significa menos similitud semántica), y en la profundidad del concepto subsumidor (ancestro común) en el camino más corto entre los dos conceptos (cuanto más profundo en la jerarquía, más cercano es el significado de los conceptos). La similitud semántica se define entonces como: Sim(c, c ) = e−κ1l · eκ2h − e−κ2h eκ2h + e−κ2h donde l es la longitud (es decir, el número de saltos) del camino más corto entre los conceptos, h es la profundidad del concepto más profundo que subsume ambos conceptos, y κ1 y κ2 son parámetros que escalan las contribuciones de la longitud del camino más corto y la profundidad respectivamente. 3.2 Lenguaje La forma del lenguaje que α utiliza para representar la información recibida y el contenido de sus diálogos depende de dos nociones fundamentales. Primero, cuando los agentes interactúan dentro de una institución general aceptan explícita o implícitamente las normas que limitarán su comportamiento, y aceptan las sanciones y penalizaciones establecidas cuando se violan las normas. En segundo lugar, los diálogos en los que α participa se construyen en torno a dos acciones fundamentales: (i) transmitir información y (ii) intercambiar propuestas y contratos. Un contrato δ = (a, b) entre los agentes α y β es un par donde a y b representan las acciones de las que los agentes α y β son responsables respectivamente. Los contratos firmados por agentes y la información transmitida por agentes son similares a las normas en el sentido de que obligan a los agentes a comportarse de una manera particular, ya sea para cumplir con las condiciones del contrato o para hacer que el mundo sea coherente con la información transmitida. Los contratos y la información pueden ser considerados como declaraciones normativas que restringen el comportamiento de un agente. Normas, contratos e información tienen una dimensión temporal obvia. Por lo tanto, un agente debe cumplir con una norma mientras se encuentre dentro de una institución, un contrato tiene un período de validez y una pieza de información es verdadera solo durante un intervalo de tiempo. El conjunto de normas que afectan el comportamiento de un agente define el contexto que el agente debe tener en cuenta. El lenguaje de comunicación α tiene dos primitivas fundamentales: Commit(α, β, ϕ) para representar, en ϕ, el mundo que α pretende lograr y que β tiene derecho a verificar, quejarse o reclamar compensación por cualquier desviación, y Done(μ) para representar el evento de que cierta acción μ ha tenido lugar. De esta manera, las normas, contratos y fragmentos de información se representarán como instancias de Commit(·) donde α y β pueden ser agentes individuales o instituciones. C es: μ ::= illoc(α, β, ϕ, t) | μ; μ | Dejar contexto En μ Fin ϕ ::= término | Hecho(μ) | Comprometer(α, β, ϕ) | ϕ ∧ ϕ | ϕ ∨ ϕ | ¬ϕ | ∀v.ϕv | ∃v.ϕv contexto ::= ϕ | id = ϕ | cláusula de prolog | contexto; contexto donde ϕv es una fórmula con la variable libre v, illoc es cualquier conjunto apropiado de partículas ilocucionarias, ; significa secuenciación, y contexto representa acuerdos previos, ilocuciones previas, el contexto de trabajo ontológico, que es una proyección de los árboles ontológicos que representan el foco de la conversación, o código que alinea las diferencias ontológicas entre los hablantes necesarias para interpretar una acción a. Representar una ontología como un conjunto de predicados en Prolog es sencillo. El término establecido contiene instancias de los conceptos y relaciones de la ontología. Por ejemplo, podemos representar la siguiente oferta: Si gastas un total de más de 100 euros en mi tienda durante octubre, entonces te daré un descuento del 10% en todos los productos en noviembre, como: Oferta( α, β, gastado(β, α, octubre, X) ∧ X ≥ 100€ → ∀ y. Hecho(Inform(ξ, α, pagar(β, α, y), noviembre)) → Compromiso(α, β, descuento(y,10%))) ξ es un agente institucional que informa el pago. Sin pérdida de generalidad, asumiremos que todas las acciones son dialógicas. Asumimos la convención de que C(c) significa que c es una instancia del concepto C y r(c1, . . . , cn) determina implícitamente que ci es una instancia del concepto en la i-ésima posición de la relación r. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 1: La arquitectura del agente LOGIC 4. La arquitectura de agentes de un sistema multiagente {α, β1, . . . , βn, ξ, θ1, . . . , θt}, contiene un agente α que interactúa con otros agentes de argumentación, βi, agentes proveedores de información, θj, y un agente institucional, ξ, que representa la institución donde asumimos que ocurren las interacciones [2]. El agente institucional informa de manera pronta y honesta sobre lo que realmente ocurre después de que un agente firma un contrato o realiza algún otro tipo de compromiso. En la Sección 4.1 esto nos permite medir la diferencia entre una expresión y una observación posterior. El lenguaje de comunicación C introducido en la Sección 3.2 nos permite tanto estructurar los diálogos como estructurar el procesamiento de la información recopilada por los agentes. Los agentes tienen un lenguaje interno de primer orden probabilístico L utilizado para representar un modelo del mundo, Mt. Una arquitectura genérica basada en la información se describe en detalle en [15]. La arquitectura del agente LOGIC se muestra en la Figura 1. El agente α actúa en respuesta a una necesidad que se expresa en términos de la ontología. Una necesidad puede ser exógena, como la necesidad de comerciar de manera rentable y puede ser desencadenada por otro agente que ofrece comerciar, o endógena, como α decidiendo que posee más vino del que necesita. Las necesidades activan el razonamiento proactivo como objetivo/plan, mientras que otros mensajes son manejados por el razonamiento reactivo. Cada plan se prepara para la negociación reuniendo el contenido de una maleta lógica que el agente lleva a la negociación. La estrategia de relaciones determina con qué agente negociar para una necesidad específica; utiliza un análisis de gestión de riesgos para preservar un conjunto estratégico de relaciones comerciales para cada necesidad crítica de la misión, lo cual no se detalla aquí. Para cada relación comercial, esta estrategia genera un objetivo de relación que se expresa en el marco de LOGIC como un nivel deseado de intimidad que se debe lograr a largo plazo. Cada negociación consiste en un diálogo, Ψt, entre dos agentes, con el agente α contribuyendo con el enunciado μ y la parte. Cada uno de los planes y reacciones de α contiene constructores para un modelo de mundo inicial Mt. A continuación, Mt se mantiene a partir de percepciones recibidas utilizando funciones de actualización que transforman percepciones en restricciones en Mt; para más detalles, ver [14, 15]. La evidencia empírica muestra que en la negociación humana, se logran mejores resultados al sesgar las opciones iniciales a favor del proponente. No tenemos conocimiento de ninguna investigación empírica de esta hipótesis para agentes autónomos en escenarios reales de trading. Cada diálogo, Ψt, se evalúa utilizando el marco LOGIC en términos del valor de Ψt tanto para α como para β - ver Sección 5.2. La estrategia de negociación determina el conjunto actual de opciones {δi}, y luego las tácticas, guiadas por el objetivo de la negociación, deciden cuáles, si alguna, de estas opciones presentar y las envuelven en un diálogo argumentativo - ver Sección 6. Ahora describimos dos de las distribuciones en Mt que respaldan el intercambio de ofertas. Pt (acc(α, β, χ, δ)) estima la probabilidad de que α acepte la propuesta δ para satisfacer su necesidad χ, donde δ = (a, b) es un par de compromisos, a para α y b para β. α aceptará δ si: Pt (acc(α, β, χ, δ)) > c, para un nivel de certeza c. Esta estimación se compone de puntos de vista subjetivos y objetivos de aceptabilidad. La estimación subjetiva tiene en cuenta: en qué medida la promulgación de δ satisfará la necesidad α de χ, cuánto vale δ para α y en qué medida α cree que estará en condiciones de cumplir su compromiso a [14, 15]. Sα(β, a) es una variable aleatoria que denota la estimación de α de la valoración subjetiva de β de a sobre algún espacio de evaluación finito y numérico. La estimación objetiva determina si δ es aceptable en el mercado abierto, y la variable Uα(b) denota la valoración en el mercado abierto de αs de la implementación del compromiso b, nuevamente tomada sobre algún espacio de valoración numérica finito. También consideramos las necesidades, la variable Tα(β, a) denota la estimación de α de la fuerza de la necesidad motivadora de β para la promulgación del compromiso a sobre un espacio de valoración. Entonces, para δ = (a, b): Pt (acc(α, β, χ, δ)) = Pt „ Tα(β, a) Tα(α, b) «h × „ Sα(α, b) Sα(β, a) «g × Uα(b) Uα(a) ≥ s ! (1) donde g ∈ [0, 1] es la avaricia de α, h ∈ [0, 1] es el grado de altruismo de α, y s ≈ 1 se deriva de la postura8 descrita en la Sección 6. Los parámetros g y h son independientes. Podemos imaginar una relación que comienza con g = 1 y h = 0. Entonces, a medida que los agentes comparten cantidades crecientes de información sobre sus valoraciones de mercado abiertas, g disminuye gradualmente a 0, y luego, a medida que comparten cantidades crecientes de información sobre sus necesidades, h aumenta a 1. La base para el criterio de aceptación ha evolucionado de la equidad a la igualdad, y luego a la necesidad. Pt (acc(β, α, δ)) estima la probabilidad de que β acepte δ, observando las respuestas de β. Por ejemplo, si β envía el mensaje Oferta(δ1) entonces α deriva la restricción: {Pt (acc(β, α, δ1)) = 1} en la distribución Pt (β, α, δ), y si esta es una contraoferta a una oferta anterior de α, δ0, entonces: {Pt (acc(β, α, δ0)) = 0}. En el caso especial no atípico de la negociación de múltiples problemas donde las preferencias de los agentes sobre los problemas individuales son conocidas y son complementarias entre sí, el razonamiento de entropía máxima se puede aplicar para estimar la probabilidad de que cualquier δ de múltiples problemas sea aceptable para β enumerando los posibles mundos que representan el límite de aceptabilidad de β [6]. 4.1 Actualización del modelo de mundo de Mt El modelo de mundo de α consiste en distribuciones de probabilidad que representan su incertidumbre en el estado del mundo. α está interesada 8 Si α decide inflar sus opciones iniciales, esto se logra en la Sección 6 aumentando el valor de s. Si s es 1, entonces un acuerdo puede no ser posible. Esto ilustra la conocida ineficiencia de la negociación bilateral establecida analíticamente por Myerson y Satterthwaite en 1983. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1033 en el grado en que una enunciación describe con precisión lo que se observará posteriormente. Todas las observaciones sobre el mundo son recibidas como enunciados de un agente de una institución totalmente veraz ξ. Por ejemplo, si β comunica el objetivo de que tengo hambre y la negociación posterior termina con β comprando un libro a α (por ξ informando a α que cierta cantidad de dinero ha sido acreditada en la cuenta de α), entonces α puede concluir que el objetivo que β eligió satisfacer era algo distinto al hambre. Por lo tanto, el modelo del mundo de α contiene distribuciones de probabilidad que representan sus expectativas inciertas de lo que se observará en función de las expresiones recibidas. Representamos la relación entre la emisión, ϕ, y la observación subsiguiente, ϕ, mediante Pt (ϕ |ϕ) ∈ Mt, donde ϕ y ϕ pueden ser categorías ontológicas en interés de la viabilidad computacional. Por ejemplo, si ϕ es "Entregaré un balde de pescado a ti mañana", entonces la distribución P(ϕ |ϕ) no necesariamente debe abarcar todas las posibles acciones que β podría realizar, sino que podría ser sobre categorías ontológicas que resuman las acciones posibles de β. En ausencia de enunciados entrantes, las probabilidades condicionales, Pt (ϕ |ϕ), deberían tender hacia la ignorancia representada por una distribución límite de decaimiento D(ϕ |ϕ). α puede tener conocimiento previo sobre D(ϕ |ϕ) a medida que t → ∞, de lo contrario α puede asumir que tiene entropía máxima mientras sea consistente con los datos. En general, dada una distribución, Pt (Xi), y una distribución límite de decaimiento D(Xi), Pt (Xi) decae de la siguiente manera: Pt+1 (Xi) = Δi(D(Xi), Pt (Xi)) (2) donde Δi es la función de decaimiento para el Xi que satisface la propiedad de que limt→∞ Pt (Xi) = D(Xi). Por ejemplo, Δi podría ser lineal: Pt+1 (Xi) = (1 − νi) × D(Xi) + νi × Pt (Xi), donde νi < 1 es la tasa de decaimiento para la i-ésima distribución. Tanto la función de decaimiento como la distribución límite de decaimiento podrían ser también una función del tiempo: Δt i y Dt (Xi). Supongamos que α recibe una expresión μ = illoc(α, β, ϕ, t) del agente β en el tiempo t. Supongamos que α asigna una creencia epistémica Rt (α, β, μ) a μ - esta probabilidad tiene en cuenta el nivel de precaución personal de α. Modelamos la actualización de Pt (ϕ |ϕ) en dos casos, uno para observaciones dadas ϕ, y otro para observaciones dadas φ en el vecindario semántico de ϕ. 4.2 Actualización de Pt (ϕ |ϕ) dada ϕ. Primero, si ϕk es observado, entonces α puede establecer Pt+1 (ϕk|ϕ) en algún valor d donde {ϕ1, ϕ2, . . . , ϕm} es el conjunto de todas las posibles observaciones. Estimamos la distribución posterior completa Pt+1 (ϕ |ϕ) aplicando el principio de mínima entropía relativa9 de la siguiente manera. Sea p(μ) la distribución: 9 Dada una distribución de probabilidad q, la distribución de entropía relativa mínima p = (p1, . . . , pI ) sujeta a un conjunto de J restricciones lineales g = {gj(p) = aj · p − cj = 0}, j = 1, . . . , J (que debe incluir la restricción P i pi − 1 = 0) es: p = arg minr P j rj log rj qj. Esto puede calcularse introduciendo multiplicadores de Lagrange λ: L(p, λ) = P j pj log pj qj + λ · g. Minimizando L, { ∂L ∂λj = gj(p) = 0}, j = 1, . . . , J es el conjunto de restricciones dadas g, y una solución a ∂L ∂pi = 0, i = 1, . . . , I conduce eventualmente a p. La inferencia basada en entropía es una forma de inferencia bayesiana que es conveniente cuando los datos son escasos [5] y encapsula el razonamiento de sentido común [12]. arg minx P j xj log xj Pt(ϕ |ϕ)j que satisface la restricción p(μ)k = d. Luego, dejemos que q(μ) sea la distribución: q(μ) = Rt (α, β, μ) × p(μ) + (1 − Rt (α, β, μ)) × Pt (ϕ |ϕ) y luego, dejemos que: r(μ) = ( q(μ) si q(μ) es más interesante que Pt (ϕ |ϕ) Pt (ϕ |ϕ) en caso contrario Una medida general de si q(μ) es más interesante que Pt (ϕ |ϕ) es: K(q(μ) D(ϕ |ϕ)) > K(Pt (ϕ |ϕ) D(ϕ |ϕ)), donde K(x y) = P j xj ln xj yj es la distancia de Kullback-Leibler entre dos distribuciones de probabilidad x e y [11]. Finalmente, incorporando la Ecuación 2 obtenemos el método para actualizar una distribución Pt (ϕ |ϕ) al recibir un mensaje μ: Pt+1 (ϕ |ϕ) = Δi(D(ϕ |ϕ), r(μ)) (3). Este procedimiento trata con la degradación de la integridad, y con dos probabilidades: primero, la probabilidad z en la enunciación μ, y segundo la creencia Rt (α, β, μ) que α adjunta a μ. 4.3 Actualización de Pt (φ |φ) dada ϕ El método sim: Dado como arriba μ = illoc(α, β, ϕ, t) y la observación ϕk definimos el vector t por ti = Pt (φi|φ) + (1− | Sim(ϕk, ϕ) − Sim(φi, φ) |) · Sim(ϕk, φ) con {φ1, φ2, . . . , φp} el conjunto de todas las posibles observaciones en el contexto de φ e i = 1, . . . , p. t no es una distribución de probabilidad. El factor de multiplicación Sim(ϕ , φ) limita la variación de la probabilidad a aquellas fórmulas cuyo contexto ontológico no está demasiado alejado de la observación. El posterior Pt+1 (φ |φ) se obtiene con la Ecuación 3 con r(μ) definido como la normalización de t. El método de valoración: Para un φk dado, wexp (φk) = Pm j=1 Pt (φj|φk) · w(φj) es la expectativa αs del valor de lo que se observará dado que β ha declarado que se observará φk, para alguna medida w. Ahora supongamos que, como antes, α observa ϕk después de que el agente β ha declarado ϕ. α revisa la estimación previa de la valoración esperada wexp (φk) a la luz de la observación ϕk a: (wrev (φk) | (ϕk|ϕ)) = g(wexp (φk), Sim(φk, ϕ), w(φk), w(ϕ), wi(ϕk)) para alguna función g - la idea es, por ejemplo, que si la ejecución, ϕk, del compromiso, ϕ, de suministrar queso fue devaluada, entonces la expectativa de α del valor de un compromiso, φ, de suministrar vino debería disminuir. Estimamos el posterior aplicando el principio de entropía relativa mínima como en la Ecuación 3, donde la distribución p(μ) = p(φ |φ) satisface la restricción: p X j=1 p(ϕ ,ϕ)j · wi(φj) = g(wexp (φk), Sim(φk, ϕ), w(φk), w(ϕ), wi(ϕk)) 5. Las medidas de resumen Un diálogo, Ψt, entre los agentes α y β es una secuencia de enunciados interrelacionados en un contexto. Una relación, Ψ∗t, es una secuencia de diálogos. Primero medimos la confianza que un agente tiene en otro observando, para cada enunciado, la diferencia entre lo que se dice (el enunciado) y lo que 1034 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ocurre posteriormente (la observación). Segundo evaluamos cada diálogo a medida que avanza en términos del marco lógico; esta evaluación emplea las medidas de confianza. Finalmente definimos la intimidad de una relación como una agregación del valor de sus diálogos componentes. 5.1 Confianza. Las medidas de confianza generalizan lo que comúnmente se llaman medidas de confianza, fiabilidad y reputación en un marco computacional único que abarca las categorías de LÓGICA. En la Sección 5.2 se aplican medidas de confianza para valorar el cumplimiento de promesas en la categoría de Legitimidad, que anteriormente llamábamos honor [14], para la ejecución de compromisos, que anteriormente llamábamos confianza [13], y para valorar diálogos en la categoría de Objetivos, que anteriormente llamábamos fiabilidad [14]. Observaciones ideales. Considera una distribución de observaciones que represente α de manera ideal en el sentido de que es lo mejor que α podría esperar razonablemente observar. Esta distribución será una función de αs en el contexto con β denotado por e, y es Pt I (ϕ |ϕ, e). Aquí medimos la entropía relativa entre esta distribución ideal, Pt I (ϕ |ϕ, e), y la distribución de observaciones esperadas, Pt (ϕ |ϕ). Eso es: C(α, β, ϕ) = 1 − X ϕ Pt I (ϕ |ϕ, e) log Pt I (ϕ |ϕ, e) Pt(ϕ |ϕ) (4) donde el 1 es una constante elegida arbitrariamente siendo el valor máximo que esta medida puede tener. Esta ecuación mide la confianza para una única declaración ϕ. Tiene sentido agregar estos valores sobre una clase de enunciados, digamos sobre aquellos ϕ que están en el contexto ontológico o, es decir, ϕ ≤ o: C(α, β, o) = 1 − P ϕ:ϕ≤o Pt β(ϕ) [1 − C(α, β, ϕ)] P ϕ:ϕ≤o Pt β(ϕ) donde Pt β(ϕ) es una distribución de probabilidad sobre el espacio de enunciados que el próximo enunciado β hará a α es ϕ. De manera similar, para una estimación general de la confianza de β en α: C(α, β) = 1 − X ϕ Pt β(ϕ) [1 − C(α, β, ϕ)] Observaciones preferidas. La medida anterior requiere que se especifique una distribución ideal, Pt I (ϕ |ϕ, e), para cada ϕ. Aquí medimos en qué medida la observación ϕ es preferible a la declaración original ϕ. Dado un predicado Preferir(c1, c2, e) que significa que α prefiere c1 a c2 en el entorno e. Entonces si ϕ ≤ o: C(α, β, ϕ) = X ϕ Pt (Preferir(ϕ , ϕ, o))Pt (ϕ |ϕ) y: C(α, β, o) = P ϕ:ϕ≤o Pt β(ϕ)C(α, β, ϕ) P ϕ:ϕ≤o Pt β(ϕ) Certeza en la observación. Aquí medimos la consistencia en las observaciones aceptables esperadas, o la falta de incertidumbre esperada en esas posibles observaciones que son mejores que la declaración original. Si ϕ ≤ o, entonces: Φ+(ϕ, o, κ) =˘ ϕ | Pt (Prefer(ϕ , ϕ, o)) > κ ¯ para alguna constante κ, y: C(α, β, ϕ) = 1 + 1 B∗ · X ϕ ∈Φ+(ϕ,o,κ) Pt +(ϕ |ϕ) log Pt +(ϕ |ϕ) donde Pt +(ϕ |ϕ) es la normalización de Pt (ϕ |ϕ) para ϕ ∈ Φ+(ϕ, o, κ), B∗ = ( 1 si |Φ+(ϕ, o, κ)| = 1 log |Φ+(ϕ, o, κ)| en otro caso. Como se mencionó anteriormente, agregamos esta medida para observaciones en un contexto particular o, y medimos la confianza como antes. Nota computacional. Las diversas medidas mencionadas anteriormente implican cálculos extensos. Por ejemplo, la Ecuación 4 contiene P ϕ que suma sobre todas las posibles observaciones ϕ. Obtenemos una medida más amigable computacionalmente apelando a la estructura de la ontología descrita en la Sección 3.2, y el lado derecho de la Ecuación 4 puede aproximarse a: 1 − X ϕ :Sim(ϕ ,ϕ)≥η Pt η,I (ϕ |ϕ, e) log Pt η,I (ϕ |ϕ, e) Pt η(ϕ |ϕ) donde Pt η,I (ϕ |ϕ, e) es la normalización de Pt I (ϕ |ϕ, e) para Sim(ϕ , ϕ) ≥ η, y de manera similar para Pt η(ϕ |ϕ). La magnitud de este cálculo está controlada por el parámetro η. Una restricción aún más estricta se puede obtener con: Sim(ϕ, ϕ) ≥ η y ϕ ≤ ψ para algún ψ. 5.2 Valorando diálogos de negociación Supongamos que una negociación comienza en el tiempo s, y para el tiempo t se ha intercambiado una serie de enunciados, Φt = μ1, . . . , μn entre el agente α y el agente β. Este diálogo de negociación es evaluado por α en el contexto del modelo del mundo de α en el tiempo s, Ms, y el entorno e que incluye enunciados que pueden haber sido recibidos de otros agentes en el sistema, incluidas las fuentes de información {θi}. Si Ψt = (Φt , Ms , e), entonces α estima el valor de este diálogo para sí mismo en el contexto de Ms y e como una matriz 2 × 5 Vα(Ψt ) donde: Vx(Ψt ) = „ IL x (Ψt ) IO x (Ψt ) IG x (Ψt ) II x(Ψt ) IC x (Ψt ) UL x (Ψt ) UO x (Ψt ) UG x (Ψt ) UI x(Ψt ) UC x (Ψt ) « donde las funciones I(·) y U(·) son medidas basadas en información y utilidad respectivamente, como describimos a continuación. α estima el valor de este diálogo para β como Vβ(Ψt ) asumiendo que el aparato de razonamiento de β refleja el suyo propio. En términos generales, las valoraciones basadas en la información miden la reducción de incertidumbre, o ganancia de información, que el diálogo proporciona a cada agente, se expresan en términos de disminución de entropía que siempre se puede calcular. Las valoraciones basadas en utilidad que miden la ganancia de utilidad se expresan en términos de alguna función de evaluación de utilidad adecuada U(·) que puede ser difícil de definir. Esta es una razón por la cual el enfoque utilitario no tiene una extensión natural a la gestión de la argumentación que se logra aquí mediante nuestro enfoque basado en la información. Por ejemplo, si α recibe la expresión "Hoy es martes", esto puede traducirse en una restricción sobre una única distribución, y la disminución resultante en la entropía es la ganancia de información. Adjuntar una medida utilitaria a esta afirmación puede no ser tan simple. Utilizamos el término matriz 2 × 5 de manera flexible para describir Vα en el sentido de que los elementos de la matriz son listas de medidas que serán determinadas por los requisitos de los agentes. La Tabla 2 muestra una medida de muestra para cada una de las diez categorías, en ella el diálogo comienza en el tiempo s y termina en el tiempo t. En esa Tabla, U(·) es una función de evaluación de utilidad adecuada, needs(β, χ) significa que el agente β necesita la necesidad χ, cho(β, χ, γ) significa que el agente β satisface la necesidad χ eligiendo negociar The Sixth Intl. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1035 con el agente γ, N es el conjunto de necesidades elegidas de la ontología a algún nivel adecuado de abstracción, Tt es el conjunto de ofertas sobre la mesa en el tiempo t, com(β, γ, b) significa que el agente β tiene un compromiso pendiente con el agente γ para ejecutar el compromiso b donde b está definido en la ontología a algún nivel adecuado de abstracción, B es el número de tales compromisos, y hay n + 1 agentes en el sistema. 5.3 Intimidad y Equilibrio El equilibrio en un diálogo de negociación, Ψt, se define como: Bαβ(Ψt) = Vα(Ψt) Vβ(Ψt) para un operador de diferencia elemento por elemento que respeta la estructura de V(Ψt). La intimidad entre los agentes α y β, I∗t αβ, es el patrón de las dos matrices 2 × 5 V ∗t α y V ∗t β que son calculadas por una función de actualización a medida que cada ronda de negociación termina, I∗t αβ = ` V ∗t α , V ∗t β ´. Si Ψt termina en el tiempo t: V ∗t+1 x = ν × Vx(Ψt) + (1 − ν) × V ∗t x (5) donde ν es la tasa de aprendizaje, y x = α, β. Además, V ∗t x decae continuamente por: V ∗t+1 x = τ × V ∗t x + (1 − τ) × Dx, donde x = α, β; τ es la tasa de decaimiento, y Dx es una matriz de 2 × 5 que representa la distribución límite de decaimiento para el valor del agente x de la intimidad de la relación en ausencia de cualquier interacción. Dx es la reputación del agente x. El equilibrio de la relación entre los agentes α y β es: B∗t αβ = V ∗t α V ∗t β. En particular, la intimidad determina los valores de los parámetros g y h en la Ecuación 1. Como ejemplo simple, si tanto IO α (Ψ∗t ) como IO β (Ψ∗t ) aumentan, entonces g disminuye, y a medida que los ocho componentes restantes de LÓGICA basada en la información aumentan, h aumenta. La noción de equilibrio puede aplicarse a pares de enunciados tratándolos como diálogos degenerados. En la negociación simple de múltiples problemas, la estrategia de revelación equitativa de información generaliza la estrategia de ojo por ojo en la negociación de un solo problema, y se extiende a una estrategia de argumentación de ojo por ojo al aplicar el mismo principio en el marco de LOGIC. 6. ESTRATEGIAS Y TÁCTICAS Cada negociación tiene que lograr dos objetivos. Primero puede tener la intención de lograr algún resultado contractual. En segundo lugar, se buscará contribuir al crecimiento, o declive, de la intimidad en la relación. Ahora describimos con mayor detalle el contenido de la caja de Negociación en la Figura 1. La literatura sobre negociación siempre aconseja que el comportamiento de un agente no debe ser predecible incluso en relaciones cercanas e íntimas. La variación requerida de comportamiento se describe normalmente como variando la postura de negociación que varía informalmente de persona amigable a persona dura. La postura se muestra en la Figura 1, inyecta ruido aleatorio acotado en el proceso, donde el límite se estrecha a medida que aumenta la intimidad. La postura, St αβ, es una matriz de 2 × 5 de multiplicadores elegidos al azar, cada uno ≈ 1, que perturba las acciones de α. El valor en la posición (x, y) en la matriz, donde x = I, U y y = L, O, G, I, C, se elige al azar de [1 l(I∗t αβ, x, y), l(I∗t αβ, x, y)] donde l(I∗t αβ, x, y) es el límite, e I∗t αβ es la intimidad. La estrategia de negociación se preocupa por mantener un conjunto de opciones de trabajo. Si el conjunto de opciones está vacío, entonces α abandonará la negociación. α perturba el mecanismo de aceptación (ver Sección 4) derivando s de la matriz St αβ, como el valor en la posición (I, O). De acuerdo con el comentario en la Nota al pie 7, en las primeras etapas de la negociación α puede decidir inflar sus Opciones iniciales. Esto se logra aumentando el valor de s en la Ecuación 1. La estrategia siguiente utiliza la maquinaria descrita en la Sección 4. Corrige h, g, s y c, establece las Opciones como el conjunto vacío, deja que Dt s = {δ | Pt (acc(α, β, χ, δ) > c}, luego: • repite lo siguiente tantas veces como se desee: añade δ = arg maxx{Pt (acc(β, α, x)) | x ∈ Dt s} a Opciones, elimina {y ∈ Dt s | Sim(y, δ) < k} para algún k de Dt s. Al utilizar Pt (acc(β, α, δ)), esta estrategia reacciona al historial de β de propuestas y rechazos. Las tácticas de negociación se ocupan de seleccionar algunas opciones y envolverlas en argumentación. Las interacciones previas con el agente β habrán producido un patrón de intimidad expresado en la forma de `V ∗t α, V ∗t β´. Supongamos que el objetivo de la relación es (T∗t α , T∗t β ). Siguiendo la Ecuación 5, α querrá alcanzar un objetivo de negociación, Nβ(Ψt), tal que: ν · Nβ(Ψt) + (1 − ν) · V ∗t β esté un poco del lado de T∗t β de V ∗t β: Nβ(Ψt) = ν − κ ν V ∗t β ⊕ κ ν T∗t β (6) para un κ pequeño ∈ [0, ν] que representa la tasa de desarrollo deseada por α para su relación con β. Nβ(Ψt) es una matriz de 2 × 5 que contiene variaciones en las dimensiones de LÓGICA que α le gustaría revelar a β durante Ψt (por ejemplo, Proporcionaré un poco más de información sobre las opciones de lo habitual, seré más flexible en las concesiones sobre las opciones, etc. Es razonable esperar que β avance hacia su objetivo al mismo ritmo y Nα(Ψt) se calcula reemplazando β por α en la Ecuación 6. Nα(Ψt) es lo que α espera recibir de β durante Ψt. Esto proporciona un objetivo de equilibrio de negociación de: Nα(Ψt ) Nβ(Ψt ) que puede ser utilizado como base para tácticas reactivas al esforzarse por mantener este equilibrio en las dimensiones de LÓGICA. Una táctica cautelosa podría utilizar el equilibrio para limitar la respuesta μ a cada enunciado μ de β por la restricción: Vα(μ) Vβ(μ) ≈ St αβ ⊗ (Nα(Ψt) Nβ(Ψt)), donde ⊗ es la multiplicación de matrices elemento por elemento, y St αβ es la postura. Una táctica menos neurótica podría intentar lograr el equilibrio de negociación objetivo a lo largo del diálogo completo anticipado. Si un equilibrio vinculado requiere la revelación de información negativa en una categoría LÓGICA, entonces α no contribuirá en nada a ello, y dejará esto a la descomposición natural de la reputación D como se describe arriba. 7. DISCUSIÓN En este artículo hemos introducido un enfoque novedoso para la negociación que utiliza información y medidas teóricas de juegos fundamentadas en estudios de negocios y psicología. Introduce los conceptos de intimidad y equilibrio como elementos clave para comprender qué es una estrategia y táctica de negociación. La negociación se entiende como un diálogo que afecta cinco dimensiones básicas: Legitimidad, Opciones, Objetivos, Independencia y Compromiso. Cada movimiento dialógico produce un cambio en una matriz de 2×5 que evalúa el diálogo a lo largo de cinco medidas basadas en la información y cinco medidas basadas en la utilidad. Los niveles actuales de equilibrio e intimidad y los niveles deseados, o de objetivo, son utilizados por las tácticas para determinar qué decir a continuación. Actualmente estamos explorando el uso de este modelo como una extensión de un software de eProcurement ampliamente utilizado comercializado por iSOCO, una empresa derivada del laboratorio de uno de los autores. 1036 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) IL α(Ψt ) = X ϕ∈Ψt Ct (α, β, ϕ) − Cs (α, β, ϕ) UL α (Ψt ) = X ϕ∈Ψt X ϕ Pt β(ϕ |ϕ) × Uα(ϕ ) IO α (Ψt ) = P δ∈T t Hs (acc(β, α, δ)) − P δ∈T t Ht (acc(β, α, δ)) |Tt| UO α (Ψt ) = X δ∈T t Pt (acc(β, α, δ)) × X δ Pt (δ |δ)Uα(δ ) IG α (Ψt ) = P χ∈N Hs (needs(β, χ)) − Ht (needs(β, χ)) |N| UG α (Ψt ) = X χ∈N Pt (needs(β, χ)) × Et (Uα(needs(β, χ))) II α(Ψt ) = Po i=1 P χ∈N Hs (cho(β, χ, βi)) − Ht (cho(β, χ, βi)) n × |N| UI α(Ψt ) = oX i=1 X χ∈N Ut (cho(β, χ, βi)) − Us (cho(β, χ, βi)) IC α (Ψt ) = Po i=1 P δ∈B Hs (com(β, βi, b)) − Ht (com(β, βi, b)) n × |B| UC α (Ψt ) = oX i=1 X δ∈B Ut (com(β, βi, b)) − Us (com(β, βi, b)) Tabla 2: Medidas de muestra para cada categoría en Vα(Ψt ). (De manera similar para Vβ(Ψt).) Carles Sierra es parcialmente apoyado por el proyecto europeo OpenKnowledge STREP y por el Proyecto IEA español. 8. REFERENCIAS [1] Adams, J. S. Desigualdad en el intercambio social. En Avances en psicología social experimental, L. Berkowitz, Ed., vol. 2. Nueva York: Academic Press, 1965. [2] Arcos, J. L., Esteva, M., Noriega, P., Rodríguez, J. Ingeniería ambiental para sistemas multiagentes, por A. y Sierra, C. Revista sobre Aplicaciones de la Inteligencia Artificial en Ingeniería 18 (2005). [3] Bazerman, M. H., Loewenstein, G. F. y White, S. B. Reversión de la preferencia en decisiones de asignación: juzgar una alternativa versus elegir entre alternativas. Administración Science Quarterly, 37 (1992), 220-240. [4] Brandenburger, A., y Nalebuff, B. Co-Opetition: Una mentalidad revolucionaria que combina competencia y cooperación. Doubleday, Nueva York, 1996. [5] Cheeseman, P., y Stutz, J. Inferencia Bayesiana y Métodos de Entropía Máxima en Ciencia e Ingeniería. Instituto Americano de Física, Melville, NY, EE. UU., 2004, cap. Sobre la relación entre la inferencia bayesiana y la entropía máxima, pp. 445-461. [6] Debenham, J. Negociando con información. En Actas de la Tercera Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente AAMAS-2004 (julio de 2004), N. Jennings, C. Sierra, L. Sonenberg y M. Tambe, Eds., ACM Press, Nueva York, pp. 664 - 671. [7] Fischer, R., Ury, W. y Patton, B. Llegar a Sí: Negociar acuerdos sin ceder. Penguin Books, 1995. [8] Kalfoglou, Y., y Schorlemmer, M. IF-Map: Un método de mapeo de ontologías basado en la teoría del flujo de información. En el Journal on Data Semantics I, S. Spaccapietra, S. March y K. Aberer, Eds., vol. 2800 de Lecture Notes in Computer Science. Springer-Verlag: Heidelberg, Alemania, 2003, pp. 98-127. [9] Lewicki, R. J., Saunders, D. M., y Minton, J. W. Elementos esenciales de la negociación. McGraw Hill, 2001. [10] Li, Y., Bandar, Z. 

McGraw Hill, 2001. [10] Li, Y., Bandar, Z. A., y McLean, D. Un enfoque para medir la similitud semántica entre palabras utilizando múltiples fuentes de información. IEEE Transactions on Knowledge and Data Engineering 15, 4 (julio / agosto de 2003), 871 - 882. [11] MacKay, D. Teoría de la Información, Inferencia y Algoritmos de Aprendizaje. Cambridge University Press, 2003. [12] París, J. Sentido común y entropía máxima. Synthese 117, 1 (1999), 75 - 93. [13] Sierra, C., y Debenham, J. Un modelo basado en la información para la confianza. En Actas de la Cuarta Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente AAMAS-2005 (Utrecht, Países Bajos, julio de 2005), F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. Singh y M. Wooldridge, Eds., ACM Press, Nueva York, pp. 497 - 504. [14] Sierra, C., y Debenham, J. Confianza y honor en una agencia basada en la información. En Actas de la Quinta Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente AAMAS-2006 (Hakodate, Japón, mayo de 2006), Stone, P. y Weiss, G., Eds., ACM Press, Nueva York, pp. 1225-1232. [15] Sierra, C. y Debenham, J. Agencia basada en la información. En Actas de la Vigésima Conferencia Internacional Conjunta de Inteligencia Artificial IJCAI-07 (Hyderabad, India, enero de 2007), pp. 1513-1518. [16] Sondak, H., Neale, M. A. y Pinkley, R. Las asignaciones negociadas de beneficios y cargas: el impacto de la valencia del resultado, la contribución y la relación. Comportamiento Organizacional y Procesos de Decisión Humana, 3 (diciembre de 1995), 249-260. [17] Valley, K. L., Neale, M. A. y Mannix, E. A. Amigos, amantes, colegas, desconocidos: Los efectos de las relaciones en el proceso y resultado de las negociaciones. En Investigación en Negociación en Organizaciones, R. Bies, R. Lewicki y B. Sheppard, Eds., vol. 5. JAI Press, 1995, pp. 65-94. 

JAI Press, 1995, pp. 65-94. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1037