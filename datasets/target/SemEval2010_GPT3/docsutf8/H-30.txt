Expansión de conceptos latentes utilizando campos aleatorios de Markov. Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Centro de Recuperación de Información Inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 RESUMEN La expansión de consultas, en forma de retroalimentación de pseudo relevancia o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de enfoques anteriores han ignorado problemas importantes, como el papel de las características y la importancia de modelar las dependencias entre términos. En este artículo, proponemos una técnica robusta de expansión de consultas basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión de conceptos latentes, proporciona un mecanismo para modelar las dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las simples características de ocurrencia de términos que son utilizadas implícitamente por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica frente a modelos de relevancia, una técnica de expansión de consultas de modelado de lenguaje de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de recuperación en varios conjuntos de datos de TREC. También describimos cómo nuestra técnica puede ser utilizada para generar conceptos significativos de varios términos para tareas como sugerencia/reformulación de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información Términos Generales Algoritmos, Experimentación, Teoría 1. Los usuarios de los sistemas de recuperación de información deben expresar necesidades de información complejas en términos de expresiones booleanas, una lista corta de palabras clave, una oración, una pregunta o posiblemente un relato más extenso. Se pierde mucha información durante el proceso de traducción desde la necesidad de información hasta la consulta real. Por esta razón, ha habido un fuerte interés en las técnicas de expansión de consultas. Tales técnicas se utilizan para ampliar la consulta original y producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de consultas han sido ampliamente estudiadas para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la simplista suposición de bolsa de palabras que subyace en BM25 y en el enfoque de modelado de lenguaje (unigrama) para la recuperación de información [20, 22]. El modelo MRF generaliza los modelos de unigrama, bigrama y otras diversas dependencias [14]. La mayoría de los modelos de dependencia de términos pasados no han logrado mostrar mejoras consistentes y significativas sobre las líneas de base de unigramas, con pocas excepciones [8]. El modelo MRF, sin embargo, ha demostrado ser altamente efectivo en una serie de tareas, incluyendo la recuperación ad hoc [14, 16], la búsqueda de páginas con nombres [16] y la búsqueda web en japonés [6]. Hasta ahora, el modelo ha sido utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo puede ser ampliado y utilizado para la expansión de consultas utilizando una técnica que llamamos expansión de conceptos latentes (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia de términos con la expansión de consultas. Las técnicas de expansión de consultas anteriores se basan en modelos de bolsa de palabras. Por lo tanto, al realizar la expansión de consultas utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia de términos y la expansión de consultas. A continuación, como mostraremos, el modelo MRF permite que se utilicen características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han hecho uso implícito de características de ocurrencia de términos. Al utilizar conjuntos de características más robustos, es posible producir términos de expansión mejores que discriminan de manera más efectiva entre documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona de manera fluida un mecanismo para generar conceptos de una sola y múltiples términos. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que hacen uso de conceptos generalizados, sin embargo, dichos enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está motivado tanto formalmente como es una extensión natural del modelo subyacente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2 describimos enfoques relacionados de expansión de consultas. La sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica propuesta de expansión de conceptos latentes. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el artículo y resume los principales resultados. 2. TRABAJO RELACIONADO Uno de los enfoques clásicos y más ampliamente utilizados para la expansión de consultas es el algoritmo de Rocchio [21]. El enfoque de Rocchio, que fue desarrollado dentro del modelo de espacio vectorial, reajusta el vector de consulta original moviendo los pesos hacia el conjunto de documentos relevantes o pseudo-relevantes y alejándolos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchio a un modelo de recuperación estadística, como el modelado del lenguaje para la recuperación de información. Se han desarrollado varias técnicas de expansión de consultas formalizadas para el marco de modelado de lenguaje, incluyendo el feedback basado en el modelo de Zhai y Lafferty y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan utilizar documentos pseudo-relevantes o relevantes para estimar un modelo de consulta mejor. El feedback basado en modelos encuentra el modelo que mejor describe los documentos relevantes teniendo en cuenta un modelo de fondo (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, modelos de relevancia, está más relacionada con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que el feedback basado en modelos, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, ellos modelan una noción más generalizada de relevancia, como mostraremos ahora. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, P(·|Q), que codifica la probabilidad de cada término dado la consulta como evidencia. Se calcula como: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) donde RQ es el conjunto de documentos que son relevantes o pseudo relevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se asume que P(D) es uniforme en este conjunto. Estas suposiciones suaves hacen que el cálculo del posterior bayesiano sea más práctico. Después de que el modelo es estimado, los documentos son clasificados por recortar el modelo de relevancia al elegir los k términos más probables de P(·|Q). Esta distribución recortada se interpola luego con el modelo de consulta de máxima verosimilitud original. Esto se puede considerar como la expansión de la consulta original por k términos ponderados. A lo largo del resto de este trabajo, nos referimos a esta instancia de modelos de relevancia como RM3. Ha habido relativamente poco trabajo realizado en el área de expansión de consultas en el contexto de modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandir utilizando conceptos de varios términos. El método de análisis de contexto local (LCA) de Xu y Crofts combinaba la recuperación a nivel de pasaje con la expansión de conceptos, donde los conceptos eran términos y frases simples [28]. Los conceptos de expansión fueron elegidos y ponderados utilizando una métrica basada en estadísticas de co-ocurrencia. Sin embargo, no está claro, basándose en el análisis realizado, cuánto ayudaron las frases en comparación con los términos individuales solos. Papka y Allan investigan el uso de retroalimentación de relevancia para realizar la expansión de conceptos de varios términos en el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en el LCA e incluyen estructuras de lenguaje de consulta InQuery, como #UW50(casa blanca), que corresponde al concepto en el que los términos casa y blanca ocurren, en cualquier orden, dentro de 50 términos uno del otro. Los resultados mostraron que combinar conceptos de un solo término y conceptos de varios términos con una ventana grande mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas. 3. Este apartado detalla nuestra técnica propuesta de expansión de conceptos latentes. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas. 3.1 MRFs para IR 3.1.1 Conceptos básicos Los campos aleatorios de Markov, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí estamos interesados en modelar la distribución conjunta sobre una consulta Q = q1, . . . , qn y un documento D. Se asume que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, muestrear de la distribución proporciona pares de documentos y consultas, de modo que el documento sea relevante para la consulta. Un MRF se define por un grafo G y un conjunto de funciones de potencial no negativas sobre los cliques en G. Los nodos en el grafo representan las variables aleatorias y las aristas definen la semántica de independencia de la distribución. Un MRF cumple con la propiedad de Markov, la cual establece que un nodo es independiente de todos sus nodos no vecinos dado los valores observados de sus vecinos. Dado un grafo G, un conjunto de potenciales ψi y un vector de parámetros Λ, la distribución conjunta sobre Q y D está dada por: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) donde Z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi(c; Λ) = exp[λifi(c)], donde fi(c) es una función de características de valores reales. 3.1.2 Construcción de G Dada una consulta Q, el grafo G puede ser construido de varias maneras. Sin embargo, siguiendo el trabajo previo, consideramos tres variantes simples [14]. Estas variantes son independencia total, donde cada término de consulta es independiente de los demás dado un documento, dependencia secuencial, que asume que existe una dependencia entre los términos de consulta adyacentes, y dependencia total, que no hace suposiciones de independencia. 3.1.3 Parametrización Los MRFs suelen ser parametrizados comúnmente en función de los cliques máximos de G. Sin embargo, dicha parametrización es demasiado gruesa para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con cliques a un nivel más detallado, manteniendo al mismo tiempo el número de características, y por lo tanto el número de parámetros, razonable. Por lo tanto, permitimos que los grupos compartan funciones de características y parámetros basados en conjuntos de grupos. Es decir, todos los subgrupos dentro de un conjunto de subgrupos están asociados con la misma función de característica y comparten un solo parámetro. Esto une de manera efectiva los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros mientras aún proporciona un mecanismo para el ajuste fino en el nivel de conjuntos de cliques. Proponemos siete conjuntos de cliques para utilizar en la recuperación de información. Los primeros tres conjuntos de cliques consisten en cliques que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estos grupos deberían codificar qué tan bien los términos en la configuración del grupo describen el documento. Estos conjuntos son: • TD - conjunto de cliques que contienen el nodo del documento y exactamente un término de consulta. • OD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta. • UD - conjunto de cliques que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Ten en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre los grupos dentro de cada conjunto podemos controlar cuánta influencia recibe cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada clique dentro de los conjuntos. En cambio, ahora solo debemos estimar un parámetro por conjunto. A continuación, consideramos cliques que solo contienen nodos de términos de consulta. Estas cliques, que no fueron consideradas en [14], se definen de manera análoga a las recién definidas, excepto que las cliques solo están formadas por nodos de términos de consulta y no contienen el nodo de documento. Las funciones de características sobre estos conjuntos deben capturar qué tan compatibles son entre sí los términos de consulta. Estas características de grupo pueden adoptar la forma de modelos de lenguaje que imponen la corrección de los términos. Por lo tanto, definimos los siguientes conjuntos de cliques dependientes de la consulta: • TQ - conjunto de cliques que contienen exactamente un término de la consulta. • OQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en orden secuencial dentro de la consulta. • UQ - conjunto de cliques que contienen dos o más términos de la consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la clique que solo contiene el nodo del documento. Las características sobre este nodo pueden ser utilizadas como un tipo de documento previo, codificando propiedades centradas en el documento. Este conjunto de cliques trivial es entonces: • D - conjunto de cliques que contiene solo el nodo único D. Observamos que nuestros conjuntos de cliques forman una cobertura de conjuntos sobre los cliques de G, pero no son una partición, ya que algunos cliques aparecen en múltiples conjuntos de cliques. Después de atar los parámetros en nuestros conjuntos de cliques y usar la forma de la función potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - dependiente del documento y la consulta + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - dependiente de la consulta + λDfD(D) FD(D) - dependiente del documento − log ZΛ documento + independiente de la consulta donde FDQ, FQ y FD son funciones de conveniencia definidas por los componentes dependientes del documento y la consulta, dependientes de la consulta y dependientes del documento de la distribución conjunta, respectivamente. Estos se utilizarán para simplificar y clarificar las expresiones derivadas a lo largo del resto del documento. 3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de cliques puede ser utilizada en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no exista un conjunto único y universalmente aplicable de características. Para dar una idea de la variedad de características que se pueden utilizar, ahora describimos brevemente posibles tipos de características que podrían ser utilizadas. Posibles características dependientes del término de consulta incluyen tf, idf, entidades nombradas, proximidad de términos y estilo de texto, por nombrar algunas. Se pueden utilizar muchos tipos de características dependientes del documento, como la longitud del documento, el PageRank, la legibilidad y el género, entre otros. Dado que nuestro objetivo aquí no es encontrar características óptimas, utilizamos un conjunto simple y fijo de características que han demostrado ser efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para ver la lista de características utilizadas. Estas características intentan capturar la ocurrencia de términos y la proximidad entre términos. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad. 3.1.5 Clasificación Dada una consulta Q, deseamos clasificar los documentos en orden descendente según PG,Λ(D|Q). Después de eliminar las expresiones independientes del documento del registro PG,Λ(Q, D), derivamos la siguiente función de clasificación: PG,Λ(D|Q) rango = FDQ(D, Q) + FD(D) (2), que es una simple combinación lineal ponderada de funciones de características que pueden calcularse eficientemente para grafos razonables. 3.1.6 Estimación de Parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, no es apropiado entrenarlos utilizando la función de valor de características fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, tfw,D es el número de veces que el término w ocurre en el documento D, tf#1(qi...qi+k),D denota el número de veces que la frase exacta qi . . . qi+k ocurre en el documento D, tf#uw(qi...qj ),D es el número de veces que los términos qi, . . . qj aparecen ordenados o desordenados dentro de una ventana de N términos, y |D| es la longitud del documento D. Los valores de cf y |C| se definen de manera análoga a nivel de colección. Finalmente, α y β son hiperparámetros del modelo que controlan el suavizado para las características de términos únicos y frases, respectivamente. Enfoques convencionales basados en la verosimilitud debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima verosimilitud sea la estimación que maximiza nuestra métrica de evaluación. Por esta razón, entrenamos de manera discriminativa nuestro modelo para maximizar directamente la métrica de evaluación considerada [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, hacemos uso de una estrategia simple de escalada de colina, aunque son posibles otros enfoques más sofisticados [10]. 3.2 Expansión de Conceptos Latentes En esta sección describimos cómo este modelo MRF extendido puede ser utilizado de una manera novedosa para generar conceptos de un solo término y de varios términos que están relacionados temáticamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica pueden ser utilizados para la expansión de consultas u otras tareas, como sugerir formulaciones alternativas de consultas. Suponemos que cuando un usuario formula su consulta original, tiene en mente un conjunto de conceptos, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, varios términos o alguna combinación de ambos. Por lo tanto, nuestro objetivo es recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco de trabajo al expandir primero el grafo original G para incluir el tipo de concepto que nos interesa generar. Llamamos a este gráfico expandido H. En la Figura 1, el gráfico del medio proporciona un ejemplo de cómo construir un gráfico expandido que puede generar conceptos de un solo término. De manera similar, el gráfico de la derecha ilustra un gráfico ampliado que genera dos conceptos de términos. Aunque estos dos ejemplos hacen uso de la suposición de dependencia secuencial (es decir, dependencias entre términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden utilizar cualquier estructura de independencia. Después de que H se construye, calculamos PH,Λ(E|Q), una distribución de probabilidad sobre conceptos latentes, de acuerdo a: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) donde R es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Dado que no es práctico calcular esta suma, debemos aproximarla. Observamos que PH,Λ(Q, E, D) probablemente se concentra alrededor de aquellos documentos D que están altamente clasificados según la consulta Q. Por lo tanto, aproximamos PH,Λ(E|Q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) donde RQ es un conjunto de documentos relevantes o pseudo-relevantes para la consulta Q y todos los conjuntos de cliques se construyen utilizando H. Como vemos, la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación original de la consulta para el documento (ver Ecuación 2), la puntuación del concepto E para el documento y la puntuación independiente del documento de E. Por lo tanto, esta ecuación puede interpretarse como la medida de qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para lograr la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD(Q, D) y FQD(E, D), lo que nos permite ponderar de manera diferente las características de ventana ordenadas y no ordenadas para la consulta original y el concepto de expansión candidato. 3.2.1 Expansión de consulta Para utilizar este marco para la expansión de consultas, primero elegimos un grafo de expansión H que codifique la estructura de concepto latente en la que estamos interesados en expandir la consulta. Luego seleccionamos los k conceptos latentes con la mayor probabilidad dada por la Ecuación 3. Se construye un nuevo grafo G al aumentar el grafo original G con los k conceptos de expansión E1, . . . , Ek. Finalmente, los documentos se clasifican según PG ,Λ(D|Q, E1, . . . , Ek) utilizando la Ecuación 2. 3.2.2 Comparación con los Modelos de Relevancia. Al inspeccionar las Ecuaciones 1 y 3 se revela la estrecha conexión que existe entre LCE y los modelos de relevancia. Ambos modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede ser visto como una generalización del modelado del lenguaje, también LCE puede ser visto como una generalización de los modelos de relevancia. Existen diferencias importantes entre los modelos de lenguaje MRFs/LCE y los modelos de lenguaje unigram/relevancia. Consulte la Figura 1 para ver las representaciones gráficas de ambos modelos. Los modelos de lenguaje unigrama y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución encasilla el modelo en la representación de bolsa de palabras y el uso implícito de características de ocurrencia de términos. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambas suposiciones, al modelar tanto las dependencias entre los términos de consulta como permitir el uso explícito de características arbitrarias. Ir más allá de la simplista suposición de la bolsa de palabras de esta manera resulta en un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de recuperación. 4. RESULTADOS EXPERIMENTALES Para comprender mejor las fortalezas y debilidades de nuestra técnica, la evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos de TREC considerados. Las colecciones WSJ, AP y ROBUST son más pequeñas y consisten enteramente de artículos de agencias de noticias, mientras que WT10g y GOV2 son colecciones web grandes. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de entrenamiento y otro de prueba, donde el conjunto de entrenamiento se utiliza únicamente para la estimación de parámetros y el conjunto de prueba se utiliza con fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del Lemur Toolkit [18, 23]. Todas las colecciones fueron detenidas utilizando una lista estándar de 418 términos comunes y truncadas utilizando un truncador de Porter. En todos los casos, solo se utiliza la parte del título de los temas de TREC para construir las consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14]. 4.1 Resultados de recuperación ad-hoc Ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de retroalimentación de relevancia pseudo. Comparamos el modelado de lenguaje unigrama (con suavizado de Dirichlet), el modelo MRF (sin expansión), los modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diferentes conjuntos de datos. Para el modelo de lenguaje unigrama, se entrenó el parámetro de suavizado. Para el modelo MRF, entrenamos los parámetros del modelo (es decir, y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de pseudoNombre Descripción # Docs Temas de Entrenamiento Temas de Prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 ROBUST Robust 2004 datos 528,155 301-450 601-700 WT10g Colección Web de TREC 1,692,096 451-500 501-550 GOV2 Rastreo 2004 del dominio .gov 25,205,179 701-750 751-800 Tabla 2: Resumen de las colecciones y temas de TREC. documentos de retroalimentación relevantes utilizados y el número de términos de expansión. 4.1.1 Expansión con Conceptos de Términos Únicos Comenzamos evaluando qué tan bien funciona nuestro modelo al expandir utilizando solo términos individuales. Antes de describir y analizar los resultados, declaramos explícitamente cómo se calculan las probabilidades de términos de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiendo con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades de términos de expansión se calculan de la siguiente manera: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) donde b ∈ Q denota el conjunto de bigramas en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λTD = λT,D = 1 y todos los demás parámetros en 0, obtenemos la fórmula exacta que se utiliza para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE añade dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y no ordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva similar a tf.idf al término de expansión candidato w. El factor idf, que no está presente en los modelos de relevancia, juega un papel importante en la selección del término de expansión. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figura 2: Histogramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión de conceptos latentes (LCE) con respecto al modelo de probabilidad de consulta (QL) para los conjuntos de datos AP, ROBUST y WT10G. Los resultados, evaluados utilizando la precisión promedio media, se muestran en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y LCE siempre superan significativamente al modelo de lenguaje unigrama. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son del 6.9% para AP, 12.9% para WSJ, 6.5% para ROBUST, 16.7% para WT10G y 7.3% para GOV2. Además, LCE muestra pequeñas mejoras, pero no significativas, respecto al modelado de relevancia para métricas como precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en dichas métricas sobre el modelo de lenguaje unigrama. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10g. Esto reitera la importancia de las características no unigrama, basadas en la proximidad para la búsqueda web basada en contenido observada previamente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que los modelos de relevancia, sorprendentemente hay poco sobreajuste. En cambio, el modelo muestra buenas propiedades de generalización. 4.1.2 Expansión con Conceptos de Múltiples Términos También investigamos la expansión utilizando conceptos de una y dos palabras. Para cada consulta, expandimos utilizando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de términos individuales. Descubrimos que los dos conceptos de palabras elegidos a menudo consistían en dos términos altamente correlacionados que también son elegidos como conceptos de términos individuales. Por ejemplo, se eligió el concepto de dos términos mercado de valores, mientras que también se eligieron los conceptos de un solo término acciones y mercado. Por lo tanto, muchos conceptos de dos palabras es poco probable que aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben ser elegidos de acuerdo con ciertos criterios que también tengan en cuenta la novedad, la diversidad o las correlaciones de términos. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden dar resultados diferentes en última instancia, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no arrojan resultados concluyentes en cuanto a la expansión utilizando conceptos de varios términos. En cambio, los resultados plantean preguntas abiertas interesantes y direcciones para futuras exploraciones. Tabla 3: Promedio de precisión media en el conjunto de pruebas para modelado de lenguaje (LM), campo aleatorio de Markov (MRF), modelos de relevancia (RM3) y expansión de conceptos latentes (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (p < 0.05) sobre LM, MRF y RM3, respectivamente. 4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión de conceptos latentes pueden mejorar significativamente la efectividad de recuperación sobre el modelo de probabilidad de consulta base. En esta sección analizamos la robustez de estos dos métodos. Aquí definimos la robustez como el número de consultas cuya efectividad se ve mejorada/afectada (y en qué medida) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo perjudicará mínimamente a unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión de conceptos latentes para los conjuntos de datos AP, ROBUST y WT10G. El análisis de los dos conjuntos de datos no mostrados es similar. Los histogramas proporcionan, para varios rangos de disminuciones/aumentos relativos en la precisión media promedio, el número de consultas que se vieron perjudicadas/mejoradas con respecto a la línea base de probabilidad de consulta. Como muestran los resultados, LCE muestra una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y perjudican 11, mientras que LCE mejora 35 y perjudica 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos ROBUST, los modelos de relevancia mejoran 67 consultas y perjudican 32, y LCE mejora 77 y perjudica 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y perjudican 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por el LCE frente a los modelos de relevancia es significativamente mayor tanto para los conjuntos de datos ROBUST como WT10G. Además, cuando LCE afecta al rendimiento, es menos probable que afecte tanto como el modelado de relevancia, lo cual es una propiedad deseable. En general, LCE mejora la efectividad para el 65%-80% de las consultas, dependiendo del conjunto de datos. Cuando se utiliza en combinación con un sistema de predicción de rendimiento de consulta altamente preciso, puede ser posible expandir selectivamente las consultas y minimizar la pérdida asociada con el rendimiento sub-baseline. 4.3 Generación de Conceptos de Múltiples Términos Aunque encontramos que la expansión utilizando conceptos de múltiples términos no logró producir mejoras concluyentes en la efectividad, hay otras tareas potenciales para las cuales estos conceptos pueden ser útiles, como sugerencia/reformulación de consultas, resumen y extracción de conceptos. Por ejemplo, para una tarea de sugerencia de consultas, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones alternativas de la consulta. Aunque evaluar nuestro modelo en estas tareas está fuera del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos de una, dos y tres palabras más probables generados utilizando LCE para la consulta logros del telescopio Hubble utilizando los 25 documentos mejor clasificados de la colección ROBUST. Es bien sabido que generar conceptos de múltiples términos utilizando un modelo basado en unigramas produce resultados insatisfactorios, ya que no considera las dependencias entre los términos. Esto no es el caso al generar conceptos de múltiples términos usando nuestro modelo. En cambio, la mayoría de los conceptos generados son bien formados y significativos. Hay varios casos donde los conceptos son menos coherentes, como espejo espejo espejo. En este caso, la probabilidad de que aparezca el término "espejo" en un documento pseudo-relevante supera a las características de modelado de lenguaje (por ejemplo, fOQ), lo que provoca que este concepto no coherente tenga una alta probabilidad. Tales ejemplos son minoría, sin embargo. No solo los conceptos generados son bien formados y significativos, sino que también son relevantes al tema de la consulta original. Como podemos ver, todos los conceptos generados están relacionados con el tema y de alguna manera están relacionados con el telescopio Hubble. Es interesante ver que el concepto de fallo del telescopio Hubble es uno de los tres conceptos de términos más probables, dado que es algo contradictorio con la consulta original. A pesar de esta contradicción, es probable que los documentos que discuten las fallas del telescopio también describan los éxitos, por lo tanto, es probable que este sea un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos generados por LCE son de una naturaleza diferente a los que se generarían utilizando un modelo de relevancia de bigrama. Por ejemplo, un modelo de bigrama sería poco probable que genere el concepto telescopio espacio NASA, ya que ninguno de los bigramas que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en una serie de características diferentes sobre varios tipos de cliques, es más general y robusto que un modelo de bigrama. Aunque solo proporcionamos los conceptos generados para una sola consulta, señalamos que el mismo análisis y conclusiones se generalizan a través de otros conjuntos de datos, con conceptos coherentes y relacionados temáticamente generados de manera consistente utilizando LCE. 4.4 Discusión Nuestra técnica de expansión de conceptos latentes captura dos tipos de dependencia semiortogonales. En la recuperación de información, ha existido un interés a largo plazo en comprender el papel de la dependencia de términos. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia abarca frases, proximidad de términos y co-ocurrencia de términos [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, sinónimos y en cierta medida el truncamiento [3]. Estas técnicas han sido exploradas tanto en el lado de la consulta como en el lado del documento. En el lado de la consulta, esto se suele hacer utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se hace como expansión de documentos o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frase y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura dependencias semánticas del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda al usar el modelo MRF no se pierde después de la expansión de consultas. Si los mismos tipos de dependencias fueran capturados tanto por dependencias sintácticas como semánticas, se esperaría que LCE funcionara aproximadamente igual de bien que los modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias, observamos un efecto aditivo en lugar de un efecto absorbente. Una área interesante de trabajo futuro es determinar si modelar las dependencias semánticas del lado del documento puede aportar algo al modelo. Resultados previos que han combinado dependencias semánticas del lado de la consulta y del documento han mostrado resultados mixtos [13, 27]. 5. CONCLUSIONES En este artículo propusimos una técnica robusta de expansión de consultas llamada expansión de conceptos latentes. La técnica se demostró ser una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso en el sentido de que realiza una expansión de un solo término o de varios términos dentro de un marco que permite el modelado de dependencias entre términos y el uso de características arbitrarias, mientras que trabajos anteriores se basaban en la suposición de la bolsa de palabras y características de ocurrencia de términos. Mostramos que la técnica puede ser utilizada para producir conceptos de expansión de varios términos de alta calidad, bien formados y relevantes desde el punto de vista temático. Los conceptos generados pueden ser utilizados en un módulo de sugerencia de consultas alternativas. También demostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en la precisión promedio media en comparación con los modelos de relevancia en una selección de conjuntos de datos de TREC. También se demostró que el modelo MRF por sí solo, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reafirma observaciones previas de que modelar dependencias a través del uso de características de proximidad dentro del MRF tiene un mayor impacto en colecciones más grandes y ruidosas que en colecciones más pequeñas y bien comportadas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes, y mostramos cómo LCE captura tanto las dependencias sintácticas como semánticas del lado de la consulta. El trabajo futuro se centrará en incorporar dependencias del lado del documento también. Agradecimientos Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente, en parte por la subvención NSF #CNS-0454018, en parte por ARDA y la subvención NSF #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son responsabilidad del autor o los autores y no necesariamente reflejan las del patrocinador.  REFERENCIAS [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en TREC 2004: Novedad y DIFICULTAD. En Actas en línea de la Conferencia de Recuperación de Información de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de la subcadena más corta. ACM Trans. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consultas utilizando modelos de caminata aleatoria. En Proc. 14th Intl. Conf. sobre Gestión de Información y Conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Revista de la Sociedad Americana de Ciencia de la Información, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc. 14º Anu. Internacional. Conferencia ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de consultas NTCIR-5 utilizando modelos de dependencia de términos. En Actas del Quinto Taller de Reunión NTCIR sobre Evaluación de Tecnologías de Acceso a la Información, páginas 494-501, 2005. [7] J. Fagan. Indexación automática de frases para la recuperación de documentos: Un examen de métodos sintácticos y no sintácticos. En el Proc. décimo anual. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para recuperación de información. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 170-177, 2004. [9] D. Harper y C. J. van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de co-ocurrencia. Revista de Documentación, 34(3):189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc. de la Conf. Internacional de Aprendizaje Automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de lenguaje basados en relevancia. En Proc. 24º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clústeres utilizando modelos de lenguaje. En Proc. 27º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Proc. 28vo Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para la recuperación de información. Recuperación de información, por aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en la pista de terabyte en 2005. En Actas en línea de la Conferencia de Recuperación de Texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante escalada de colina con una comparación con un enfoque de entropía máxima. Informe técnico, MITRE, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas de lémures. En Proc. de la Conferencia de Recuperación de Texto, 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en trec-3. En Actas en línea de la Tercera Conferencia de Recuperación de Texto, páginas 109-126, 1995. [21] J. J. Rocchio. Retroalimentación de relevancia en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de lenguaje general para la recuperación de información. En Proc. octava conferencia internacional sobre Gestión de la Información y el Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: Un motor de búsqueda basado en modelos de lenguaje para consultas complejas. En Actas de la Conferencia Internacional sobre Análisis de Inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de lenguaje con expansión de documentos. En Proc. de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. Guestrin y D. Koller. Redes de Markov de margen máximo. En Proc. de Avances en Sistemas de Información Neural (NIPS 2003), 2003. [26] C. J. van Rijsbergen. Una base teórica para el uso de datos de coocurrencia en la recuperación de información. Revista de Documentación, 33(2):106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc. 29º Anu. Internacional. ACM SIGIR Conf. sobre Investigación y Desarrollo en Recuperación de Información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Syst., 18(1):79-112, 2000. [29] C. Zhai y J. Lafferty. Retroalimentación basada en modelos en el enfoque de modelado del lenguaje para la recuperación de información. En Proc. 10th Intl. Conferencia sobre Gestión de la Información y el Conocimiento, páginas 403-410, 2001.