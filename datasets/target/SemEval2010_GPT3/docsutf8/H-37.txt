Los SVM en línea relajados para el filtrado de spam. D. Sculley Universidad de Tufts Departamento de Ciencias de la Computación 161 College Ave., Medford, MA, EE. UU. dsculleycs.tufts.edu Gabriel M. Wachman Universidad de Tufts Departamento de Ciencias de la Computación 161 College Ave., Medford, MA, EE. UU. gwachm01cs.tufts.edu RESUMEN El spam es un problema clave en la comunicación electrónica, incluidos los sistemas de correo electrónico a gran escala y el creciente número de blogs. El filtrado basado en contenido es un método confiable para combatir esta amenaza en sus diversas formas, pero algunos investigadores académicos y profesionales de la industria no están de acuerdo en la mejor manera de filtrar el correo no deseado. Los primeros han abogado por el uso de Máquinas de Vectores de Soporte (SVM) para el filtrado basado en contenido, ya que esta metodología de aprendizaje automático proporciona un rendimiento de vanguardia para la clasificación de texto. Sin embargo, aún no se han demostrado ganancias de rendimiento similares para el filtrado de spam en línea. Además, los profesionales citan el alto costo de las SVM como razón para preferir métodos bayesianos más rápidos (aunque menos estadísticamente robustos). En este artículo, ofrecemos una solución a esta controversia. Primero, demostramos que las SVM en línea realmente ofrecen un rendimiento de clasificación de vanguardia en la filtración de spam en línea en grandes conjuntos de datos de referencia. Segundo, demostramos que un rendimiento casi equivalente puede lograrse mediante un SVM en línea relajado (ROSVM) con un costo computacional considerablemente reducido. Nuestros resultados son verificados experimentalmente en tareas de detección de correo no deseado, spam en blogs y splogs. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información - spam Términos Generales Medición, Experimentación, Algoritmos 1. INTRODUCCIÓN La comunicación electrónica está cada vez más plagada por contenido no deseado o perjudicial conocido como spam. La forma más conocida de spam es el correo no deseado, que sigue siendo un problema importante para los grandes sistemas de correo electrónico. Otras formas de spam también están volviéndose problemáticas, incluido el spam en blogs, en el cual los spammers publican comentarios no deseados en blogs [21], y los splogs, que son blogs falsos construidos para permitir el spam de enlaces con la esperanza de aumentar la importancia medida de una página web determinada a los ojos de los motores de búsqueda automatizados [17]. Hay una variedad de métodos para identificar estas muchas formas de correo no deseado, incluyendo la compilación de listas negras de remitentes conocidos de spam y la realización de análisis de enlaces. El enfoque del análisis de contenido ha demostrado una promesa particular y generalidad para combatir el correo no deseado. En el análisis de contenido, el texto del mensaje real (a menudo incluyendo hiperenlaces y metatexto, como HTML y encabezados) se analiza utilizando técnicas de aprendizaje automático para la clasificación de texto con el fin de determinar si el contenido dado es spam. El análisis de contenido se ha aplicado ampliamente en la detección de correo no deseado [11], y también se ha utilizado para identificar spam en blogs [21] y splogs [17]. En este documento, no exploramos el problema relacionado del spam de enlaces, que actualmente se combate mejor mediante análisis de enlaces [13]. 1.1 Una controversia anti-spam La comunidad anti-spam ha estado dividida en la elección del mejor método de aprendizaje automático para la detección de spam basada en contenido. Los investigadores académicos han tendido a favorecer el uso de Máquinas de Vectores de Soporte (SVMs), un método de aprendizaje automático estadísticamente robusto que produce un rendimiento de vanguardia en la clasificación de texto general. Sin embargo, las SVMs suelen requerir un tiempo de entrenamiento que es cuadrático en el número de ejemplos de entrenamiento, y son imprácticas para sistemas de correo electrónico a gran escala. Los profesionales que necesitan filtrado de spam basado en contenido suelen optar por utilizar el método de clasificación de texto Naive Bayes, que es más rápido (aunque menos estadísticamente robusto) [11, 12, 20]. Este método bayesiano requiere solo tiempo de entrenamiento lineal y se implementa fácilmente en un entorno en línea con actualizaciones incrementales. Esto permite que un sistema desplegado se adapte fácilmente a un entorno cambiante con el tiempo. Otros métodos rápidos para el filtrado de spam incluyen modelos de compresión [1] y regresión logística [10]. Todavía no se ha demostrado empíricamente que las SVM mejoren el rendimiento sobre estos métodos en un entorno de detección de spam en línea [4]. 1.2 Contribuciones En este artículo, abordamos la controversia anti-spam y ofrecemos una posible solución. Primero demostramos que las SVM en línea realmente ofrecen detección de spam de última generación a través de pruebas empíricas en varios conjuntos de datos de referencia grandes de correo no deseado por correo electrónico. Luego analizamos el efecto del parámetro de compensación en la función objetivo de la SVM, lo que demuestra que la metodología costosa de SVM puede, de hecho, ser excesiva para la detección de spam. Reducimos el costo computacional del aprendizaje de SVM al relajar este requisito sobre el margen máximo en entornos en línea, y creamos un SVM en línea relajado, ROSVM, apropiado para el filtrado de spam basado en contenido de alto rendimiento en entornos a gran escala. La controversia entre académicos y profesionales en los centros de filtrado de spam se centra en el uso de SVMs. Los primeros defienden su uso, pero aún no han demostrado un rendimiento sólido con SVM en la filtración de spam en línea. De hecho, los resultados de [4] muestran que, cuando se utilizan con parámetros predeterminados, las SVM realmente tienen un rendimiento peor que otros métodos. En esta sección, revisamos el funcionamiento básico de las SVM y describimos un algoritmo simple de SVM en línea. Luego demostramos que las SVM en línea logran, de hecho, un rendimiento de vanguardia en la filtración de correo no deseado, comentarios de blog no deseados y splogs, siempre y cuando el parámetro de compensación C se establezca en un valor alto. Sin embargo, el costo de las SVM en línea resulta ser prohibitivo para aplicaciones a gran escala. Estos hallazgos motivan nuestra propuesta de SVM en línea relajados en la siguiente sección. 2.1 Antecedentes: SVMs Las SVMs son una metodología robusta de aprendizaje automático que ha demostrado ofrecer un rendimiento de vanguardia en la clasificación de texto [14], al encontrar un hiperplano que separa dos clases de datos en el espacio de datos mientras maximiza el margen entre ellos. Utilizamos la siguiente notación para describir las SVM, la cual se basa en [23]. Un conjunto de datos X contiene n vectores de ejemplos etiquetados {(x1, y1) . . . (xn, yn)}, donde cada xi es un vector que contiene características que describen el ejemplo i, y cada yi es la etiqueta de clase para ese ejemplo. En la detección de spam, las clases spam y ham (es decir, no spam) se les asignan las etiquetas de clase numéricas +1 y −1, respectivamente. Los SVM lineales que empleamos en este artículo utilizan un vector de hipótesis w y un término de sesgo b para clasificar un nuevo ejemplo x, generando una etiqueta de clase predicha f(x): f(x) = signo(< w, x > + b). Los SVM encuentran la hipótesis w, que define el hiperplano separador, minimizando la siguiente función objetivo sobre todos los n ejemplos de entrenamiento: τ(w, ξ) = 1/2 ||w||2 + C Σ i=1^n ξi bajo las restricciones de que ∀i = {1..n} : yi(< w, xi > + b) ≥ 1 − ξi, ξi ≥ 0. En esta función objetivo, cada variable de holgura ξi muestra la cantidad de error que el clasificador comete en un ejemplo dado xi. Minimizar la suma de las variables de holgura corresponde a minimizar la función de pérdida en los datos de entrenamiento, mientras que minimizar el término 1 2 ||w||2 corresponde a maximizar el margen entre las dos clases [23]. Estos dos objetivos de optimización suelen estar en conflicto; el parámetro de compensación C determina cuánta importancia dar a cada una de estas tareas. Las SVM lineales aprovechan la dispersión de datos para clasificar una nueva instancia en tiempo O(s), donde s es el número de características no nulas. Este es el mismo tiempo de clasificación que otros conjuntos de datos lineales Dado: conjunto de datos X = (x1, y1), . . . , (xn, yn), C, m: Inicializar w := 0, b := 0, seenData := { } Para Cada xi ∈ X hacer: Clasificar xi usando f(xi) = signo(< w, xi > +b) SI yif(xi) < 1 Encontrar w , b usando SMO en seenData, usando w, b como hipótesis inicial. Añadir xi a seenData hecho Figura 1: Pseudo código para SVM en línea. clasificadores, y como clasificación Bayesiana ingenua. Entrenar SVMs, sin embargo, típicamente toma tiempo O(n2), para n ejemplos de entrenamiento. Recientemente se propuso una variante para SVM lineales que se entrena en tiempo O(ns) [15], pero debido a que este método tiene una constante alta, no lo exploramos aquí. 2.2 SVMs en línea En muchas aplicaciones tradicionales de aprendizaje automático, los SVM se aplican en modo por lotes. Es decir, un SVM se entrena con un conjunto completo de datos de entrenamiento y luego se prueba con un conjunto separado de datos de prueba. La filtración de spam se suele probar e implementar en un entorno en línea, que avanza de forma incremental. Aquí, el aprendiz clasifica un nuevo ejemplo, se le dice si su predicción es correcta, actualiza su hipótesis en consecuencia y luego espera un nuevo ejemplo. El aprendizaje en línea permite que un sistema desplegado se adapte a sí mismo en un entorno cambiante. Volver a entrenar un SVM desde cero en el conjunto completo de datos previamente vistos para cada nuevo ejemplo es prohibitivo en costos. Sin embargo, utilizar una hipótesis antigua como punto de partida para el reentrenamiento reduce este costo considerablemente. Se propuso un método de aprendizaje SVM incremental y decremental en [2]. Debido a que solo nos preocupamos por el aprendizaje incremental, aplicamos un algoritmo más simple para convertir un aprendiz de SVM por lotes en un SVM en línea (ver Figura 1 para el seudocódigo), que es similar al enfoque de [16]. Cada vez que el SVM en línea se encuentra con un ejemplo que fue clasificado incorrectamente, se vuelve a entrenar utilizando la hipótesis antigua como punto de partida. Ten en cuenta que debido a las condiciones de Karush-Kuhn-Tucker (KKT), no es necesario volver a entrenar con ejemplos bien clasificados que se encuentran fuera de los márgenes [23]. Utilizamos el algoritmo SMO de Platts [22] como un solucionador SVM central, ya que es un método iterativo que es adecuado para converger rápidamente a partir de una buena hipótesis inicial. Dado que trabajos anteriores (y nuestras propias pruebas iniciales) indican que los valores de características binarias ofrecen los mejores resultados para la filtración de spam [20, 9], optimizamos nuestra implementación del Online SMO para aprovechar productos internos rápidos con vectores binarios. 1 2.3 Mapeo de características Contenido de Spam La extracción de características de aprendizaje automático de texto se puede realizar de diversas formas, especialmente cuando ese texto puede incluir hipercontenido y metacontenido como HTML e información de encabezado. Sin embargo, investigaciones previas han demostrado que métodos simples de clasificación de texto, como vectores de bolsa de palabras y n-gramas de caracteres superpuestos, pueden lograr resultados sólidos [9]. Formalmente, un vector de bolsa de palabras es un vector x con una dimensión única para cada posible 1. Nuestro código fuente está disponible de forma gratuita en www.cs.tufts.edu/∼dsculley/onlineSMO. 1 0.999 0.995 0.99 0.985 0.98 0.1 1 10 100 1000 ÁreaROC C 2-gramas 3-gramas 4-gramas palabras Figura 2: Ajuste del parámetro de compensación C. Se realizaron pruebas con Online SMO, utilizando vectores de características binarias, en el conjunto de datos de spamassassin de 6034 ejemplos. Grafique los puntos de C versus el Área bajo la curva ROC. Palabra, definida como una subcadena contigua de caracteres que no son espacios en blanco. Un vector n-grama es un vector x con una dimensión única para cada subcadena posible de un total de n caracteres. Ten en cuenta que los n-gramas pueden incluir espacios en blanco y ser superpuestos. Utilizamos la puntuación de características binarias, que se ha demostrado ser la más efectiva para una variedad de métodos de detección de spam [20, 9]. Normalizamos los vectores con la norma euclidiana. Además, con los datos de correo electrónico, reducimos el impacto de mensajes largos (por ejemplo, con archivos adjuntos) considerando solo los primeros 3,000 caracteres de cada cadena. Para los comentarios de blogs y splogs, consideramos todo el texto, incluidos los metadatos como las etiquetas HTML, tal como se presenta. No se utilizó ninguna otra selección de características o conocimiento de dominio. 2.4 Ajuste del parámetro de compensación, C El parámetro de compensación SVM C debe ajustarse para equilibrar los objetivos (potencialmente conflictivos) de maximizar el margen y minimizar el error de entrenamiento. El trabajo inicial sobre detección de spam basada en SVM [9] mostró que valores altos de C ofrecen el mejor rendimiento con características binarias. El trabajo posterior no siempre ha seguido esta pauta: se utilizó un valor predeterminado (bajo) de C en la detección de splogs [17], y también en el correo no deseado [4]. Siguiendo la práctica estándar de aprendizaje automático, ajustamos C en datos de ajuste separados que no se utilizaron posteriormente para pruebas. Utilizamos el conjunto de datos de spam de correo electrónico spamassassin disponible públicamente, y creamos una tarea de aprendizaje en línea intercalando aleatoriamente los 6034 mensajes etiquetados para crear un único conjunto ordenado. Para ajustar, realizamos una búsqueda de parámetros gruesa para C utilizando potencias de diez desde .0001 hasta 10000. Utilizamos la SVM en línea descrita anteriormente, y probamos tanto vectores binarios de bolsa de palabras como vectores de n-gramas con n = {2, 3, 4}. Utilizamos los primeros 3000 caracteres de cada mensaje, que incluían información del encabezado, cuerpo del correo electrónico y posiblemente adjuntos. Siguiendo la recomendación de [6], utilizamos el Área bajo la curva ROC como nuestra medida de evaluación. Los resultados (ver Figura 2) concuerdan con [9]: hay un plateau de alto rendimiento alcanzado con todos los valores de C ≥ 10, y el rendimiento decae bruscamente con C < 1. Para el resto de nuestros experimentos con SVMs en este artículo, establecimos C = 100. Volveremos a la observación de que valores muy altos de C no degradan el rendimiento como apoyo a la intuición de que las SVM relajadas deberían funcionar bien en el spam. Tabla 1: Resultados para la filtración de correo no deseado por correo electrónico con SVM en línea en conjuntos de datos de referencia. La puntuación reportada es (1-ROCA)%, donde 0 es óptimo. trec05p-1 trec06p OnSVM: palabras 0.015 (.011-.022) 0.034 (.025-.046) trigramas 0.011 (.009-.015) 0.025 (.017-.035) tetragramas 0.008 (.007-.011) 0.023 (.017-.032) SpamProbe 0.059 (.049-.071) 0.092 (.078-.110) BogoFilter 0.048 (.038-.062) 0.077 (.056-.105) Ganadores de TREC 0.019 (.015-.023) 0.054 (.034-.085) 53-Ensemble 0.007 (.005-.008) 0.020 (.007-.050) Tabla 2: Resultados para la Detección de Spam en Comentarios de Blogs utilizando SVMs y Validación Cruzada de Dejar Uno Fuera. Informamos las mismas medidas de rendimiento que en el trabajo anterior para una comparación significativa. precisión exactitud recuperación SVM C = 100: palabras 0.931 0.946 0.954 trigramas 0.951 0.963 0.965 tetragramas 0.949 0.967 0.956 Método anterior mejor 0.83 0.874 0.874 2.5 Correo no deseado por correo electrónico y SVM en línea Con C ajustado en un conjunto de ajuste separado, luego probamos el rendimiento de SVM en línea en la detección de spam. Utilizamos dos grandes conjuntos de datos de referencia de correo no deseado como nuestros corpus de prueba. Estos conjuntos de datos son el conjunto de datos público TREC 2005 trec05p-1 de 92,189 mensajes, y los conjuntos de datos públicos TREC 2006, trec06p, que contienen 37,822 mensajes en inglés. (No informamos nuestros resultados sólidos en el corpus trec06c de mensajes en chino, ya que se han planteado dudas sobre la validez de este conjunto de pruebas). Utilizamos el orden canónico proporcionado con cada uno de estos conjuntos de datos para una comparación justa. Los resultados de estos experimentos, con vectores de bolsa de palabras y vectores n-grama, aparecen en la Tabla 1. Para comparar nuestros resultados con las puntuaciones anteriores en estos conjuntos de datos, utilizamos la misma medida (1-ROCA)% descrita en [6], que es uno menos el área bajo la curva ROC, expresada como un porcentaje. Esta medida muestra el porcentaje de probabilidad de error cometido por un clasificador al afirmar que un mensaje es más probable que sea spam que otro. Estos resultados muestran que las SVM en línea ofrecen un rendimiento de vanguardia en el correo no deseado. El único sistema conocido que supera a los SVM en línea en el conjunto de datos trec05p-1 es un clasificador de conjunto reciente que combina los resultados de 53 filtros de spam únicos. Según nuestro conocimiento, el SVM en línea ha superado a cualquier otro filtro individual en estos conjuntos de datos, incluidos aquellos que utilizan métodos bayesianos [5, 3], modelos de compresión [5, 3], regresión logística [10] y variantes de perceptrón [3], los ganadores de la competencia TREC [5, 3] y los filtros de spam de correo electrónico de código abierto BogoFilter v1.1.5 y SpamProbe v1.4d. 2.6 Spam en Comentarios de Blog y SVMs El spam en comentarios de blog es similar al spam en correo electrónico en muchos aspectos, y se han propuesto métodos basados en contenido para detectar estos comentarios de spam [21]. Sin embargo, aún no existen conjuntos de datos de referencia grandes de comentarios de blog spam etiquetados. Por lo tanto, realizamos experimentos en el único conjunto de datos disponible públicamente que conocemos, el cual fue utilizado en el blog basado en contenido Tabla 3: Resultados para la detección de Splog vs. Blog utilizando SVMs y Validación Cruzada de Dejar Uno Fuera. Informamos las mismas medidas de evaluación que en el trabajo anterior para una comparación significativa. características precisión recall F1 SVM C = 100: palabras 0.921 0.870 0.895 trigramas 0.904 0.866 0.885 tetragramas 0.928 0.876 0.901 SVM previo con: palabras 0.887 0.864 0.875 tetragramas 0.867 0.844 0.855 palabras+urls 0.893 0.869 0.881 experimentos de detección de spam en comentarios por [21]. Debido al tamaño reducido del conjunto de datos, y porque investigadores anteriores no llevaron a cabo sus experimentos en un entorno en línea, probamos el rendimiento de las SVM lineales utilizando validación cruzada de dejar uno fuera, con SVM-Light, una implementación estándar de SVM de código abierto [14]. Utilizamos la configuración de parámetros C = 100, con los mismos mapeos del espacio de características mencionados anteriormente. Informamos sobre la precisión, la exactitud y la recuperación para comparar estos con los resultados proporcionados en el mismo conjunto de datos por [21]. Estos resultados (ver Tabla 2) muestran que las SVMs ofrecen un rendimiento superior en este conjunto de datos en comparación con la metodología anterior. 2.7 Splogs y SVMs Al igual que con el spam de comentarios de blog, todavía no existe un corpus de referencia grande y públicamente disponible de datos de prueba etiquetados para la detección de splogs. Sin embargo, los autores de [17] nos proporcionaron amablemente el conjunto de datos etiquetados de 1,389 blogs y splogs que utilizaron para probar la detección de splogs basada en contenido utilizando SVMs. La única diferencia entre nuestra metodología y la de [17] es que ellos utilizaron parámetros predeterminados para C, los cuales SVM-Light establece en 1 avg||x||2. (Para vectores normalizados, este valor predeterminado establece C = 1). También probaron varios mapeos de características informadas por el dominio, como asignar características especiales a las etiquetas de URL. Para nuestros experimentos, utilizamos los mismos mapeos de características mencionados anteriormente, y probamos el efecto de establecer C = 100. Al igual que en la metodología de [17], realizamos validación cruzada de dejar uno fuera para una comparación equitativa en estos datos. Los resultados (ver Tabla 3) muestran que un valor alto de C produce un rendimiento superior para los mismos mapeos de espacio de características, e incluso permite que el simple mapeo de 4-gramas supere al mejor mapeo anterior que incorporaba conocimiento de dominio utilizando palabras y URLs. 2.8 Costo Computacional Los resultados presentados en esta sección demuestran que linfeatures trec06p trec05p-1 palabras 12196s 66478s 3-gramas 44605s 128924s 4-gramas 87519s 242160s tamaño del corpus 32822 92189 Tabla 4: Tiempo de ejecución para SVMs en línea con detección de spam por correo electrónico, en segundos de CPU. Estos tiempos no incluyen el tiempo dedicado a mapear cadenas a vectores de características. El número de ejemplos en cada conjunto de datos se indica en la última fila como tamaño del corpus. Figura 3: Visualizando el efecto de C. El hiperplano A maximiza el margen mientras acepta una pequeña cantidad de error de entrenamiento. Esto corresponde a establecer C en un valor bajo. El hiperplano B acepta un margen más pequeño para reducir el error de entrenamiento. Esto corresponde a establecer C en un valor alto. El filtrado de spam basado en contenido parece funcionar mejor con valores altos de C. Las SVM lineales ofrecen un rendimiento de vanguardia en el filtrado de spam basado en contenido. Sin embargo, este rendimiento tiene un costo. Aunque los conjuntos de datos de spam de comentarios de blogs y splogs son demasiado pequeños para que el tiempo de entrenamiento cuadrático de las SVM parezca problemático, los conjuntos de datos de correos electrónicos son lo suficientemente grandes como para ilustrar los problemas del costo de entrenamiento cuadrático. La Tabla 4 muestra el tiempo de cálculo versus el tamaño del conjunto de datos para cada una de las tareas de aprendizaje en línea (en el mismo sistema). El costo de entrenamiento de las SVM es prohibitivo para la detección de spam basada en contenido a gran escala, o para un gran proveedor de blogs. En la siguiente sección, reducimos este costo relajando los requisitos costosos de las SVM. 3. Uno de los principales beneficios de las SVM en línea relajadas (ROSVM) es que encuentran un hiperplano de decisión que maximiza el margen entre las clases en el espacio de datos. Maximizar el margen es costoso, típicamente requiriendo un tiempo de entrenamiento cuadrático en el número de ejemplos de entrenamiento. Sin embargo, como vimos en la sección anterior, la tarea de detección de spam basada en contenido se logra mejor con SVMs con un valor alto de C. Establecer C con un valor alto para este dominio implica que minimizar la pérdida de entrenamiento es más importante que maximizar el margen (ver Figura 3). Por lo tanto, si bien las SVM crean filtros de spam de alto rendimiento, aplicarlos en la práctica es excesivo. La característica de maximización de margen completo que proporcionan es innecesaria, y relajar este requisito puede reducir el costo computacional. Proponemos tres formas de relajar las SVM en línea: • Reducir el tamaño del problema de optimización optimizando solo sobre los últimos p ejemplos. • Reducir el número de actualizaciones de entrenamiento entrenando solo en errores reales. • Reducir el número de iteraciones en la SVM iterativa Dado: conjunto de datos X = (x1, y1), . . . , (xn, yn), C, m, p: Inicializar w := 0, b := 0, seenData := { } Para Cada xi ∈ X hacer: Clasificar xi usando f(xi) = signo(< w, xi > +b) Si yif(xi) < m Encontrar w , b con SMO en seenData, usando w, b como hipótesis inicial. Establecer (w, b) := (w,b) Si tamaño(seenData) > p eliminar el ejemplo más antiguo de seenData Agregar xi a seenData hecho Figura 4: Pseudo-código para SVM en línea relajada. permitiendo una solución aproximada al problema de optimización. Como describimos en el resto de esta subsección, todos estos métodos intercambian la robustez estadística por un menor costo computacional. Los resultados experimentales reportados en la siguiente sección muestran que igualan o se acercan al rendimiento de los SVM en línea completos en la detección de spam basada en contenido. 3.1 Reducción del Tamaño del Problema En los SVM en línea completos, volvemos a optimizar sobre el conjunto completo de datos vistos en cada actualización, lo cual se vuelve costoso a medida que crece el número de puntos de datos vistos. Podemos limitar este gasto considerando solo los p ejemplos más recientes para la optimización (ver Figura 4 para el seudocódigo). Ten en cuenta que esto no es equivalente a entrenar un nuevo clasificador SVM desde cero en los p ejemplos más recientes, ya que cada problema de optimización sucesivo se inicia con la hipótesis previa w [8]. Esta hipótesis puede contener valores para características que no se encuentran en ningún lugar de los p ejemplos más recientes, y estos no serán modificados. Esto permite que la hipótesis recuerde características raras (pero informativas) que se aprendieron más allá de p ejemplos en el pasado. Formalmente, el problema de optimización ahora está definido de manera más clara en su forma dual [23]. En este caso, la SVM de margen suave original se calcula maximizando en el ejemplo n: W (α) = nX i=1 αi − 1 2 nX i,j=1 αiαjyiyj < xi, xj >, sujeto a las restricciones anteriores [23]: ∀i ∈ {1, . . . , n} : 0 ≤ αi ≤ C y nX i=1 αiyi = 0. A esto, añadimos la restricción adicional del búfer de retroceso ∀j ∈ {1, . . . , (n − p)} : αj = cj donde cj es una constante, fijada como el último valor encontrado para αj mientras j > (n − p). Por lo tanto, el margen encontrado por una optimización no está garantizado de ser aquel que maximiza el margen para el conjunto global de datos de ejemplos {x1, . . . , xn)}, sino más bien aquel que satisface un requisito relajado de maximizar el margen sobre los ejemplos { x(n−p+1), . . . , xn}, sujeto a las restricciones fijas en el hiperplano que fueron encontradas en optimizaciones previas sobre ejemplos {x1, . . . , x(n−p)}. (Para completitud, cuando p ≥ n, define (n − p) = 1.) Este conjunto de restricciones reduce el número de variables libres en el problema de optimización, disminuyendo el costo computacional. 3.2 Reducción del número de actualizaciones Como se mencionó anteriormente, las condiciones KKT muestran que un ejemplo bien clasificado no cambiará la hipótesis; por lo tanto, no es necesario volver a entrenar cuando nos encontramos con dicho ejemplo. Bajo las condiciones KKT, un ejemplo xi se considera bien clasificado cuando yif(xi) > 1. Si volvemos a entrenar con cada ejemplo que no esté bien clasificado, nuestro hiperplano estará garantizado de ser óptimo en cada paso. El número de actualizaciones de re-entrenamiento puede reducirse al relajar la definición de bien clasificado. Un ejemplo xi se considera ahora bien clasificado cuando yif(xi) > M, para algún 0 ≤ M ≤ 1. Aquí, cada actualización sigue produciendo un hiperplano óptimo. El aprendiz puede encontrarse con un ejemplo que se encuentre dentro de los márgenes, pero más lejos de los márgenes que M. Tal ejemplo significa que la hipótesis ya no es óptima globalmente para el conjunto de datos, pero se considera lo suficientemente buena para seguir utilizándola sin necesidad de un reentrenamiento inmediato. Este procedimiento de actualización es similar al utilizado por variantes del algoritmo Perceptrón [18]. En el caso extremo, podemos establecer M = 0, lo que crea un SVM en línea impulsado por errores. En la sección experimental, mostramos que esta versión de SVM en línea, que se actualiza solo en errores reales, no degrada significativamente el rendimiento en la detección de spam basada en contenido, pero sí reduce significativamente el costo. 3.3 Reducción de Iteraciones Como un solucionador iterativo, SMO realiza pases repetidos sobre el conjunto de datos para optimizar la función objetivo. SMO tiene un bucle principal, que puede alternar entre recorrer todo el conjunto de datos o el conjunto activo más pequeño de los vectores de soporte actuales [22]. Las iteraciones sucesivas de este bucle acercan el hiperplano a un valor óptimo. Sin embargo, es posible que estas iteraciones proporcionen menos beneficios de los que justifica su costo. Es decir, una aproximación cercana puede ser suficiente. Introducimos un parámetro T para controlar el número máximo de iteraciones que permitimos. Como veremos en la sección experimental, este parámetro se puede establecer tan bajo como 1 con poco impacto en la calidad de los resultados, lo que proporciona ahorros computacionales. 4. En la Sección 2, argumentamos que el buen rendimiento en la detección de spam basada en contenido con SVMs con un valor alto de C muestra que el criterio de margen máximo es excesivo, incurriendo en un costo computacional innecesario. En la Sección 3, propusimos ROSVM para abordar este problema, ya que ambos métodos renuncian a garantías sobre el hiperplano de margen máximo a cambio de un costo computacional reducido. En esta sección, probamos estos métodos en los mismos conjuntos de datos de referencia para ver si se puede lograr un rendimiento de vanguardia con estos métodos menos costosos. Descubrimos que ROSVM es capaz de lograr estos altos niveles de rendimiento con un costo considerablemente reducido. Nuestros principales pruebas de detección de spam basado en contenido se realizan en grandes conjuntos de datos de correo electrónico de referencia. Luego aplicamos estos métodos en los conjuntos de datos más pequeños de spam de comentarios de blogs y blogs, con un rendimiento similar. 4.1 Pruebas ROSVM En la Sección 3, propusimos tres enfoques para reducir el costo computacional de Online SMO: reduciendo el prob0.005 0.01 0.025 0.05 0.1 10 100 1000 10000 100000 (1-ROCA)% Tamaño del búfer trec05p-1 trec06p 0 50000 100000 150000 200000 250000 10 100 1000 10000 100000 CPUSec. Tamaño del búfer trec05p-1 trec06p Figura 5: Pruebas de tamaño reducido, reduciendo el tamaño del lema, el número de iteraciones de optimización y el número de actualizaciones de entrenamiento. Cada uno de estos enfoques relaja el criterio de margen máximo en el conjunto global de datos previamente vistos. Aquí probamos el efecto que cada uno de estos métodos tiene tanto en la efectividad como en la eficiencia. En cada uno de estos tests, utilizamos los grandes conjuntos de datos de correos electrónicos de referencia, trec05p-1 y trec06p. 4.1.1 Prueba de Tamaño Reducido Para nuestra primera prueba de ROSVM, experimentamos con el efecto de reducir el tamaño del problema de optimización considerando solo los p ejemplos más recientes, como se describe en la sección anterior. Para este test, utilizamos los mismos mapeos de 4-gramas que en los experimentos de referencia en la Sección 2, con el mismo valor de C = 100. Probamos una variedad de valores p en una búsqueda en una rejilla gruesa. La Figura 5 informa sobre el efecto del tamaño del búfer p en relación con la medida de rendimiento (1-ROCA)% (arriba) y el número de segundos de CPU requeridos (abajo). Los resultados muestran que los valores de p < 100 sí resultan en un rendimiento degradado, aunque se evalúan muy rápidamente. Sin embargo, los valores de p de 500 a 10,000 funcionan casi tan bien como el Online SMO original (representado aquí como p = 100,000), a un costo computacional considerablemente reducido. Estos resultados son importantes para lograr un rendimiento de vanguardia en la detección de spam basada en contenido a gran escala de manera práctica con SVM en línea. Normalmente, el tiempo de entrenamiento crecería de forma cuadrática con el número de ejemplos vistos. Sin embargo, fijar un valor de p garantiza que el tiempo de entrenamiento sea independiente del tamaño del conjunto de datos. Además, un búfer de retroceso permite que el filtro se ajuste a la deriva de concepto. 0.005 0.01 0.025 0.05 0.1 10521 (1-ROCA)% Máx. Iteraciones. trec06p trec05p-1 50000 100000 150000 200000 250000 10521 Segundos de CPU. En la segunda prueba de ROSVM, experimentamos con reducir el número de iteraciones. Nuestros tests iniciales mostraron que el número máximo de iteraciones utilizado por Online SMO rara vez era mucho mayor que 10 en la detección de spam basada en contenido; por lo tanto, probamos valores de T = {1, 2, 5, ∞}. Otros parámetros fueron idénticos a las pruebas originales de SVM en línea. Los resultados de esta prueba fueron sorprendentemente estables (ver Figura 6). Reducir el número máximo de iteraciones de SMO por actualización no tuvo prácticamente ningún impacto en el rendimiento de clasificación, pero sí resultó en un aumento moderado en la velocidad. Esto sugiere que cualquier iteración adicional se dedica a intentar encontrar mejoras en un hiperplano que ya está muy cerca de ser óptimo. Estos resultados muestran que para la detección de spam basada en contenido, podemos reducir el costo computacional permitiendo solo una iteración de SMO (es decir, T = 1) con un rendimiento efectivamente equivalente. 4.1.3 Pruebas de Actualizaciones Reducidas Para nuestro tercer experimento de ROSVM, evaluamos el impacto de ajustar el parámetro M para reducir el número total de actualizaciones. Como se mencionó anteriormente, cuando M = 1, el hiperplano es óptimo a nivel global en cada paso. Reducir M permite que un hiperplano ligeramente inconsistente persista hasta que se encuentre con un ejemplo para el cual es demasiado inconsistente. Probamos valores de M de 0 a 1, en incrementos de 0.1. (Tenga en cuenta que usamos p = 10000 para disminuir el costo de evaluar estas pruebas). Los resultados de estos tests aparecen en la Figura 7, y muestran que hay una ligera degradación en el rendimiento con valores reducidos de M, y que esta degradación en el rendimiento va acompañada de un aumento en la eficiencia. Valores de 0.005 0.01 0.025 0.05 0.1 0 0.2 0.4 0.6 0.8 1 (1-ROCA)% M trec05p-1 trec06p 5000 10000 15000 20000 25000 30000 35000 40000 0 0.2 0.4 0.6 0.8 1 CPUSec. Figura 7: Pruebas de Actualizaciones Reducidas. M > 0.7 ofrece un rendimiento efectivamente equivalente a M = 1, y aún así reduce costos. 4.2 SVMs en línea y ROSVM Ahora comparamos ROSVM con SVMs en línea en las tareas de detección de spam en correos electrónicos, comentarios de blogs y splogs. Estos experimentos muestran un rendimiento comparable en estas tareas, a costos radicalmente diferentes. En la sección anterior, se probó el efecto de los diferentes métodos de relajación por separado. Aquí, probamos estos métodos juntos para crear una implementación completa de ROSVM. Elegimos los valores p = 10000, T = 1, M = 0.8 para las tareas de detección de correo no deseado por correo electrónico. Ten en cuenta que estos valores de parámetros fueron seleccionados para permitir que ROSVM logre resultados de rendimiento comparables con SVM en línea, con el fin de probar la diferencia total en el costo computacional. Los conjuntos de datos de splog y blog eran mucho más pequeños, por lo que establecimos p = 100 para estas tareas para permitir comparaciones significativas entre los problemas de optimización de tamaño reducido y tamaño completo. Debido a que estos valores no fueron ajustados manualmente, tanto el rendimiento de generalización como los resultados de tiempo de ejecución son significativos en estos experimentos. 4.2.1 Configuración Experimental Comparamos SVM en línea y ROSVM en la detección de spam en correos electrónicos, comentarios de blogs y splogs. Para el correo no deseado por correo electrónico, utilizamos los dos grandes corpus de referencia, trec05p-1 y trec06p, en el estándar de pedido en línea. Ordenamos aleatoriamente tanto el corpus de spam de comentarios de blogs como el corpus de splogs para crear tareas de aprendizaje en línea. Ten en cuenta que este es un escenario diferente al de la tarea de validación cruzada de dejar uno fuera presentada en estos corpus en la Sección 2; los resultados no son directamente comparables. Sin embargo, esta tabla muestra el diseño experimental de los datos de referencia de correo no deseado por correo electrónico. Estos resultados comparan SVM en línea y ROSVM en la detección de spam por correo electrónico, utilizando un espacio de características binarias de 4-gramos. El puntaje reportado es (1-ROCA)%, donde 0 es óptimo. trec05p-1 trec05p-1 trec06p trec06p (1-ROC)% CPUs (1-ROC)% CPUs OnSVM 0.0084 242,160 0.0232 87,519 ROSVM 0.0090 24,720 0.0240 18,541 Tabla 6: Spam de Comentarios de Blog. Estos resultados comparan SVM en línea y ROSVM en la detección de spam en comentarios de blog utilizando un espacio de características binarias de 4-gramos. I'm sorry, but the sentence "Acc." is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? I'm sorry, but the sentence "Prec." is not a complete sentence. Could you please provide more context or the full sentence you would like me to translate to Spanish? La comparación entre nuestros dos métodos en línea en estas tareas de detección de spam basadas en contenido sí permite una comparación significativa. Ejecutamos cada método en cada tarea y reportamos los resultados en las Tablas 5, 6 y 7. Se debe tener en cuenta que el tiempo de CPU reportado para cada método fue generado en el mismo sistema informático. Este tiempo refleja únicamente el tiempo necesario para completar el aprendizaje en línea sobre datos tokenizados. No informamos el tiempo tomado para tokenizar los datos en 4-gramos binarios, ya que es la misma constante aditiva para todos los métodos en cada tarea. En todos los casos, ROSVM fue significativamente menos costoso computacionalmente. 4.3 Discusión Los resultados de comparación mostrados en las Tablas 5, 6 y 7 son sorprendentes de dos maneras. Primero, muestran que el rendimiento de las SVM en línea puede ser igualado e incluso superado por métodos de margen relajado. En segundo lugar, muestran una disparidad dramática en el costo computacional. ROSVM es una orden de magnitud más eficiente que el SVM en línea normal, y proporciona resultados comparables. Además, el búfer de retroceso fijo garantiza que el costo de cada actualización no dependa del tamaño del conjunto de datos ya visto, a diferencia de las SVM en línea. Ten en cuenta que los conjuntos de datos de blogs y splogs son relativamente pequeños, y los resultados en estos conjuntos de datos deben considerarse preliminares. En general, estos resultados muestran que no es necesario pagar el alto costo de las SVM para lograr este nivel de rendimiento en la detección de spam basada en contenido. Las ROSVM ofrecen una alternativa mucho más económica con poco o ningún deterioro en el rendimiento. 5. CONCLUSIONES En el pasado, los investigadores académicos y los profesionales de la industria han estado en desacuerdo sobre el mejor método para la detección de spam basada en contenido en línea en la web. Hemos presentado una resolución a este debate. Los SVM en línea, de hecho, son rentables. Estos resultados comparan SVM en línea y ROSVM en la detección de splogs utilizando un espacio de características binarias de 4-gramos. I'm sorry, but the sentence "Acc." is not a complete sentence. Can you please provide more context or a full sentence for me to translate to Spanish? I'm sorry, but the sentence "Prec." is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? Los procesadores F1 de SVM obtienen un rendimiento de vanguardia en esta tarea con el ajuste adecuado del parámetro de compensación C, pero con un costo que crece cuadráticamente con el tamaño del conjunto de datos. Los altos valores de C requeridos para obtener el mejor rendimiento con SVMs muestran que la maximización del margen de los SVMs en línea es excesiva para esta tarea. Por lo tanto, hemos propuesto una alternativa menos costosa, ROSVM, que relaja este requisito de margen máximo y produce resultados casi equivalentes. Estos métodos son lo suficientemente eficientes para el filtrado a gran escala del spam basado en contenido en sus diversas formas. Es natural preguntarse por qué la tarea de detección de spam basada en contenido obtiene un rendimiento sólido con ROSVM. Después de todo, no todos los datos permiten la relajación de los requisitos de SVM. Conjeturamos que el correo no deseado, el spam de comentarios en blogs y los splogs comparten la característica de que un subconjunto de características son particularmente indicativas de si el contenido es spam o no spam. Estas características indicativas pueden estar escasamente representadas en el conjunto de datos, debido a métodos de spam como la obfuscación de palabras, en la que palabras comunes de spam son intencionalmente mal escritas en un intento de reducir la efectividad de la detección de spam basada en palabras. Maximizar el margen puede hacer que estas características escasamente representadas sean ignoradas, lo que resulta en una reducción general del rendimiento. Parece que los datos de spam son altamente separables, lo que permite que ROSVM tenga éxito con valores altos de C y poco esfuerzo dedicado a maximizar el margen. El trabajo futuro determinará qué tan aplicables son las SVM relajadas al problema general de la clasificación de texto. Finalmente, cabe destacar que el éxito de los métodos de SVM relajados para la detección de spam basada en contenido es un resultado que depende de la naturaleza de los datos de spam, los cuales potencialmente están sujetos a cambios. Aunque actualmente es cierto que el jamón y el correo no deseado son linealmente separables en un espacio de características apropiado, esta suposición puede estar sujeta a ataques. Aunque nuestros métodos actuales parecen ser robustos contra ataques primitivos en esta línea, como el ataque de la buena palabra [24], debemos explorar la viabilidad de ataques más sofisticados. 6. REFERENCIAS [1] A. Bratko y B. Filipic. Filtrado de spam utilizando modelos de compresión. Informe técnico IJS-DP-9227, Departamento de Sistemas Inteligentes, Instituto Jozef Stefan, Liubliana, Eslovenia, 2005. [2] G. Cauwenberghs y T. Poggio. Aprendizaje de máquina de vector de soporte incremental y decremental. En NIPS, páginas 409-415, 2000. [3] G. V. Cormack. Resumen de la pista de spam de TREC 2006. Para aparecer en: Actas de la Decimoquinta Conferencia de Recuperación de Información de Texto (TREC 2006), 2006. [4] G. V. Cormack y A. Bratko. Comparación de filtros de spam en lotes y en línea. En Actas de la Tercera Conferencia sobre Correo Electrónico y Anti-Spam (CEAS), 2006. [5] G. V. Cormack y T. R. Lynam. Resumen de la pista de spam de TREC 2005. En las Actas de la Decimocuarta Conferencia de Recuperación de Información (TREC 2005), 2005. [6] G. V. Cormack y T. R. Lynam. Evaluación en línea supervisada de filtro de spam. Informe técnico, Escuela de Ciencias de la Computación David R. Cheriton, Universidad de Waterloo, Canadá, febrero de 2006. [7] N. Cristianini y J. Shawe-Taylor. Una introducción a las máquinas de vectores de soporte. Cambridge University Press, 2000. [8] D. DeCoste y K. Wagstaff. Siembra alfa para máquinas de vectores de soporte. En KDD 00: Actas de la sexta conferencia internacional de la ACM SIGKDD sobre descubrimiento de conocimiento y minería de datos, páginas 345-349, 2000. [9] H. Drucker, V. Vapnik y D. Wu. Máquinas de vectores de soporte para la categorización de spam. IEEE Transactions on Neural Networks, 10(5):1048-1054, 1999. [10] J. Goodman y W. Yin. Entrenamiento en línea de filtro de spam discriminatorio. En Actas de la Tercera Conferencia sobre Correo Electrónico y Anti-Spam (CEAS), 2006. [11] P. Graham. Un plan para el spam. 2002. [12] P. Graham. Mejor filtrado bayesiano. 2003. [13] Z. Gyongi y H. Garcia-Molina. Spam: Ya no es solo para buzones de correo electrónico. Computadora, 38(10):28-34, 2005. [14] T. Joachims. Categorización de texto con máquinas de vectores de soporte: Aprendizaje con muchas características relevantes. En ECML 98: Actas de la 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, 1998. [15] T. Joachims. Entrenando SVM lineales en tiempo lineal. En KDD 06: Actas de la 12ª conferencia internacional de la ACM SIGKDD sobre descubrimiento de conocimiento y minería de datos, páginas 217-226, 2006. [16] J. Kivinen, A. Smola y R. Williamson. Aprendizaje en línea con núcleos. En Avances en Sistemas de Procesamiento de Información Neural 14, páginas 785-793. MIT Press, 2002. [17] P. Kolari, T. Finin, y A. Joshi. SVMs para la blogósfera: Identificación de blogs y detección de splogs. Simposio de Primavera de la AAAI sobre Enfoques Computacionales para Analizar Blogs, 2006. [18] W. Krauth y M. M´ezard. Algoritmos de aprendizaje con estabilidad óptima en redes neuronales. Revista de Física A, 20(11):745-752, 1987. [19] T. Lynam, G. Cormack y D. Cheriton. Fusión de filtro de spam en línea. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 123-130, 2006. [20] V. Metsis, I. Androutsopoulos y G. Paliouras. Filtrado de spam con el método de Naive Bayes: ¿cuál Naive Bayes? Tercera Conferencia sobre Correo Electrónico y Anti-Spam (CEAS), 2006. [21] G. Mishne, D. Carmel y R. Lempel. Bloqueando el spam en blogs con desacuerdo de modelos de lenguaje. Actas del 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web (AIRWeb), mayo de 2005. [22] J. Platt. Optimización secuencial mínima: Un algoritmo rápido para entrenar máquinas de vectores de soporte. En B. Scholkopf, C. Burges y A. Smola, editores, Avances en Métodos de Núcleo - Aprendizaje de Vectores de Soporte. MIT Press, 1998. [23] B. Scholkopf y A. Smola. Aprendizaje con Kernels: Máquinas de Vectores de Soporte, Regularización, Optimización y Más Allá. MIT Press, 2001. [24] G. L. Wittel y S. F. Wu. Sobre el ataque a los filtros de spam estadísticos. CEAS: Primera Conferencia sobre Correo Electrónico y Anti-Spam, 2004.