Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \( i \in I \), \( \max_{b \in A_i} u_i(b, a_{-i}) - u_i(a) \leq \varepsilon \), donde \( \varepsilon = \int_{Y_i} \int_{Z} \int_{R} \int_{Y} \int_{b \in A_i \backslash a_i} \Pr(u_i(b, a_{-i}) \leq u + \varepsilon) f_{u_i(a)}(u) du \), donde \( f_{u_i(a)}(u) \) es la función de densidad de probabilidad de \( N(\overline{u_i(a)}, \sigma_i(a)) \). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. 

LEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.
Estadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.
Editorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo).