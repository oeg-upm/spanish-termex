Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but "Ck" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. 

Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. 

McGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159

Springer, 2000. 159