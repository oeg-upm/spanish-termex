AdaRank: Un algoritmo de aumento para la recuperación de información Jun Xu Microsoft Research Asia No. En este documento abordamos el tema del aprendizaje para clasificar en la recuperación de documentos. En la tarea, se crea automáticamente un modelo con algunos datos de entrenamiento y luego se utiliza para clasificar documentos. La bondad de un modelo suele evaluarse con medidas de rendimiento como MAP (Precisión Promedio Media) y NDCG (Ganancia Acumulada Descontada Normalizada). Idealmente, un algoritmo de aprendizaje entrenaría un modelo de clasificación que pudiera optimizar directamente las medidas de rendimiento con respecto a los datos de entrenamiento. Sin embargo, los métodos existentes solo pueden entrenar modelos de clasificación minimizando funciones de pérdida vagamente relacionadas con las medidas de rendimiento. Por ejemplo, Ranking SVM y RankBoost entrenan modelos de ranking minimizando los errores de clasificación en pares de instancias. Para abordar el problema, proponemos un algoritmo de aprendizaje novedoso dentro del marco de boosting, que puede minimizar una función de pérdida definida directamente en las medidas de rendimiento. Nuestro algoritmo, conocido como AdaRank, construye repetidamente clasificadores débiles sobre la base de datos de entrenamiento reponderada y finalmente combina linealmente los clasificadores débiles para hacer predicciones de clasificación. Demostramos que el proceso de entrenamiento de AdaRank es exactamente el de mejorar la medida de rendimiento utilizada. Los resultados experimentales en cuatro conjuntos de datos de referencia muestran que AdaRank supera significativamente a los métodos base de BM25, Ranking SVM y RankBoost. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación Términos Generales Algoritmos, Experimentación, Teoría 1. INTRODUCCIÓN Recientemente, el aprendizaje para clasificar ha ganado cada vez más atención en los campos de recuperación de información y aprendizaje automático. Cuando se aplica a la recuperación de documentos, aprender a clasificar se convierte en una tarea de la siguiente manera. En el entrenamiento, se construye un modelo de clasificación con datos que consisten en consultas, sus documentos recuperados correspondientes y niveles de relevancia proporcionados por humanos. En el ranking, dado una nueva consulta, los documentos recuperados correspondientes son ordenados utilizando el modelo de ranking entrenado. En la recuperación de documentos, generalmente los resultados de clasificación se evalúan en términos de medidas de rendimiento como MAP (Precisión Promedio Media) [1] y NDCG (Ganancia Acumulativa Descontada Normalizada) [15]. Idealmente, la función de clasificación se crea de manera que se maximice la precisión de la clasificación en términos de una de las medidas con respecto a los datos de entrenamiento. Se han desarrollado y aplicado varios métodos para aprender a clasificar en la recuperación de documentos. Por ejemplo, Herbrich et al. [13] proponen un algoritmo de aprendizaje para clasificación basado en Máquinas de Vectores de Soporte, llamado Ranking SVM. Freund et al. [8] siguen un enfoque similar y realizan el aprendizaje utilizando boosting, conocido como RankBoost. Todos los métodos existentes utilizados para la recuperación de documentos [2, 3, 8, 13, 16, 20] están diseñados para optimizar funciones de pérdida vagamente relacionadas con las medidas de rendimiento de IR, no funciones de pérdida directamente basadas en las medidas. Por ejemplo, Ranking SVM y RankBoost entrenan modelos de ranking minimizando los errores de clasificación en pares de instancias. En este artículo, nuestro objetivo es desarrollar un nuevo algoritmo de aprendizaje que pueda optimizar directamente cualquier medida de rendimiento utilizada en la recuperación de documentos. Inspirados en el trabajo de AdaBoost para clasificación [9], proponemos desarrollar un algoritmo de boosting para recuperación de información, denominado AdaRank. AdaRank utiliza una combinación lineal de clasificadores débiles como su modelo. En el aprendizaje, se repite el proceso de volver a ponderar la muestra de entrenamiento, crear un clasificador débil y calcular un peso para el clasificador. Mostramos que el algoritmo AdaRank puede optimizar de forma iterativa una función de pérdida exponencial basada en cualquiera de las medidas de rendimiento de IR. Se proporciona un límite inferior del rendimiento en los datos de entrenamiento, lo que indica que la precisión de clasificación en términos de la medida de rendimiento puede mejorar continuamente durante el proceso de entrenamiento. AdaRank ofrece varias ventajas: facilidad en la implementación, solidez teórica, eficiencia en el entrenamiento y alta precisión en la clasificación. Los resultados experimentales indican que AdaRank puede superar a los métodos base de BM25, Ranking SVM y RankBoost, en cuatro conjuntos de datos de referencia que incluyen OHSUMED, WSJ, AP y .Gov. Ajustar modelos de clasificación utilizando ciertos datos de entrenamiento y una medida de rendimiento es una práctica común en RI [1]. A medida que el número de características en el modelo de clasificación aumenta y la cantidad de datos de entrenamiento crece, el ajuste se vuelve más difícil. Desde el punto de vista de IR, AdaRank puede ser visto como un método de aprendizaje automático para ajuste de modelos de clasificación. Recientemente, la optimización directa de medidas de rendimiento en el aprendizaje se ha convertido en un tema de investigación candente. Se han propuesto varios métodos para la clasificación [17] y el ranking [5, 19]. AdaRank se puede ver como un método de aprendizaje automático para la optimización directa de medidas de rendimiento, basado en un enfoque diferente. El resto del documento está organizado de la siguiente manera. Después de un resumen del trabajo relacionado en la Sección 2, describimos en detalle el algoritmo propuesto AdaRank en la Sección 3. Los resultados experimentales y las discusiones se presentan en la Sección 4. La sección 5 concluye este artículo y presenta el trabajo futuro. TRABAJO RELACIONADO 2.1 Recuperación de Información El problema clave para la recuperación de documentos es la clasificación, específicamente, cómo crear el modelo de clasificación (función) que pueda ordenar los documentos en función de su relevancia para la consulta dada. Es una práctica común en IR ajustar los parámetros de un modelo de clasificación utilizando algunos datos etiquetados y una medida de rendimiento [1]. Por ejemplo, los métodos de vanguardia de BM25 [24] y LMIR (Modelos de Lenguaje para la Recuperación de Información) [18, 22] tienen todos parámetros para ajustar. A medida que los modelos de clasificación se vuelven más sofisticados (se utilizan más características) y más datos etiquetados están disponibles, ajustar o entrenar los modelos de clasificación resulta ser un problema desafiante. Recientemente, se han aplicado métodos de aprendizaje para clasificar en la construcción de modelos de clasificación y se han obtenido algunos resultados prometedores. Por ejemplo, Joachims [16] aplica Ranking SVM a la recuperación de documentos. Él utiliza datos de clics para deducir datos de entrenamiento para la creación del modelo. Cao et al. [4] adaptan el Ranking SVM para la recuperación de documentos modificando la función de Pérdida Bisagra para cumplir mejor con los requisitos de RI. Específicamente, introducen una función de pérdida de bisagra que penaliza fuertemente los errores en la parte superior de las listas de clasificación y los errores de las consultas con menos documentos recuperados. Burges et al. [3] emplean la Entropía Relativa como función de pérdida y el Descenso de Gradiente como algoritmo para entrenar un modelo de Red Neuronal para clasificación en la recuperación de documentos. El método se conoce como RankNet. 2.2 Aprendizaje automático Hay tres temas en el aprendizaje automático que están relacionados con nuestro trabajo actual. Están aprendiendo a clasificar, potenciar y optimizar directamente las medidas de rendimiento. Aprender a clasificar es crear automáticamente una función de clasificación que asigna puntuaciones a las instancias y luego clasificar las instancias utilizando esas puntuaciones. Se han propuesto varios enfoques para abordar el problema. Un enfoque principal para aprender a clasificar es transformarlo en una clasificación binaria en pares de instancias. Este enfoque de pares se ajusta bien a la recuperación de información y, por lo tanto, se utiliza ampliamente en IR. Los métodos típicos del enfoque incluyen Ranking SVM [13], RankBoost [8] y RankNet [3]. Para otros enfoques de aprendizaje para clasificar, consulte [2, 11, 31]. En el enfoque de clasificación por pares, la tarea de aprendizaje se formaliza como un problema de clasificar pares de instancias en dos categorías (correctamente clasificados e incorrectamente clasificados). De hecho, se sabe que reducir los errores de clasificación en pares de instancias es equivalente a maximizar un límite inferior de MAP [16]. En ese sentido, los métodos existentes de Ranking SVM, RankBoost y RankNet solo pueden minimizar funciones de pérdida que están vagamente relacionadas con las medidas de rendimiento de IR. El boosting es una técnica general para mejorar las precisiones de los algoritmos de aprendizaje automático. La idea básica del boosting es construir repetidamente aprendices débiles reponderando los datos de entrenamiento y formar un conjunto de aprendices débiles de tal manera que el rendimiento total del conjunto sea mejorado. Freund y Schapire han propuesto el primer algoritmo de boosting conocido llamado AdaBoost (Adaptive Boosting) [9], el cual está diseñado para clasificación binaria (predicción 0-1). Más tarde, Schapire y Singer han introducido una versión generalizada de AdaBoost en la que los aprendices débiles pueden proporcionar puntuaciones de confianza en sus predicciones en lugar de tomar decisiones 0-1 [26]. Se han realizado extensiones para abordar los problemas de clasificación multi-clase [10, 26], regresión [7] y ranking [8]. De hecho, AdaBoost es un algoritmo que ingeniosamente construye un modelo lineal minimizando la función de pérdida exponencial con respecto a los datos de entrenamiento [26]. Nuestro trabajo en este artículo puede ser visto como un método de impulso desarrollado para la clasificación, especialmente para la clasificación en IR. Recientemente, varios autores han propuesto llevar a cabo la optimización directa de medidas de rendimiento multivariadas en el aprendizaje. Por ejemplo, Joachims [17] presenta un método SVM para optimizar directamente medidas de rendimiento multivariadas no lineales como la medida F1 para clasificación. Cossock & Zhang [5] encuentran una forma de optimizar aproximadamente la medida de rendimiento de clasificación DCG [15]. Metzler et al. [19] también proponen un método para maximizar directamente métricas basadas en rangos para la clasificación en base al aprendizaje de variedades. AdaRank es otro algoritmo que intenta optimizar directamente medidas de rendimiento multivariadas, pero se basa en un enfoque diferente. AdaRank es único en que emplea una función de pérdida exponencial basada en medidas de rendimiento de IR y una técnica de aumento. NUESTRO MÉTODO: ADARANK 3.1 Marco General Primero describimos el marco general del aprendizaje para clasificar la relevancia de documentos en la recuperación de información. En la recuperación (prueba), dado un query, el sistema devuelve una lista de clasificación de documentos en orden descendente de los puntajes de relevancia. Las puntuaciones de relevancia se calculan con una función de clasificación (modelo). En el aprendizaje (entrenamiento), se proporciona un número de consultas y sus documentos recuperados correspondientes. Además, también se proporcionan los niveles de relevancia de los documentos con respecto a las consultas. Los niveles de relevancia se representan como rangos (es decir, categorías en un orden total). El objetivo del aprendizaje es construir una función de clasificación que logre los mejores resultados en la clasificación de los datos de entrenamiento en términos de minimización de una función de pérdida. Idealmente, la función de pérdida se define en base a la medida de rendimiento utilizada en las pruebas. Supongamos que Y = {r1, r2, · · · , r } es un conjunto de rangos, donde · · · denota el número de rangos. Existe un orden total entre los rangos r r −1 · · · r1, donde · denota una relación de preferencia. En el entrenamiento, se proporciona un conjunto de consultas Q = {q1, q2, · · · , qm}. Cada consulta qi está asociada con una lista de documentos recuperados di = {di1, di2, · · · , di,n(qi)} y una lista de etiquetas yi = {yi1, yi2, · · · , yi,n(qi)}, donde n(qi) denota los tamaños de las listas di y yi, dij denota el j-ésimo documento en di, y yij ∈ Y denota la clasificación del documento di j. Se crea un vector de características xij = Ψ(qi, di j) ∈ X a partir de cada par consulta-documento (qi, di j), i = 1, 2, · · · , m; j = 1, 2, · · · , n(qi). Por lo tanto, el conjunto de entrenamiento puede ser representado como S = {(qi, di, yi)}m i=1. El objetivo del aprendizaje es crear una función de clasificación f: X → Y, de modo que para cada consulta los elementos en su lista de documentos correspondiente puedan ser asignados puntajes de relevancia utilizando la función y luego ser clasificados según los puntajes. Específicamente, creamos una permutación de enteros π(qi, di, f) para la consulta qi, la lista correspondiente de documentos di y la función de clasificación f. Si di = {di1, di2, · · · , di,n(qi)} está identificado por la lista de enteros {1, 2, · · · , n(qi)}, entonces la permutación π(qi, di, f) se define como una biyección de {1, 2, · · · , n(qi)} en sí misma. Usamos π(j) para denotar la posición del elemento j (es decir, di j). El proceso de aprendizaje resulta ser el de minimizar la función de pérdida que representa la discrepancia entre la permutación π(qi, di, f) y la lista de rangos yi, para todas las consultas. Tabla 1: Notaciones y explicaciones. Explicaciones de las notaciones qi ∈ Q con la consulta di = {di1, di2, · · · , di,n(qi)} Lista de documentos para qi yi j ∈ {r1, r2, · · · , r } Rango de di j con respecto a qi yi = {yi1, yi2, · · · , yi,n(qi)} Lista de rangos para qi S = {(qi, di, yi)}m i=1 Conjunto de entrenamiento xij = Ψ(qi, dij) ∈ X Vector de características para (qi, di j) f(xij) ∈ Modelo de ranking π(qi, di, f) Permutación para qi, di y f ht(xi j) ∈ t-ésimo weak ranker E(π(qi, di, f), yi) ∈ [−1, +1] Función de medida de rendimiento En el artículo, definimos el modelo de rango como una combinación lineal de weak rankers: f(x) = T t=1 αtht(x), donde ht(x) es un weak ranker, αt es su peso y T es el número de weak rankers. En la recuperación de información, se utilizan medidas de rendimiento basadas en consultas para evaluar la eficacia de una función de clasificación. Por medida basada en consultas, nos referimos a una medida definida sobre una lista de clasificación de documentos con respecto a una consulta. Estas medidas incluyen MAP, NDCG, MRR (Mean Reciprocal Rank), WTA (Winners Take ALL) y Precisión@n [1, 15]. Utilizamos una función general E(π(qi, di, f), yi) ∈ [−1, +1] para representar las medidas de rendimiento. El primer argumento de E es la permutación π creada utilizando la función de clasificación f en di. El segundo argumento es la lista de rangos yi proporcionada por los humanos. E mide la concordancia entre π y yi. La Tabla 1 proporciona un resumen de las notaciones descritas anteriormente. A continuación, como ejemplos de medidas de rendimiento, presentamos las definiciones de MAP y NDCG. Dada una consulta qi, la lista correspondiente de rangos yi, y una permutación πi en di, la precisión promedio para qi se define como: AvgPi = n(qi) j=1 Pi( j) · yij n(qi) j=1 yij , (1) donde yij toma los valores 1 y 0, representando relevante o irrelevante y Pi( j) se define como la precisión en la posición de dij: Pi( j) = k:πi(k)≤πi(j) yik πi(j) , (2) donde πi( j) denota la posición de di j. Dada una consulta qi, la lista de rangos yi y una permutación πi en di, NDCG en la posición m para qi se define como: Ni = ni · j:πi(j)≤m 2yi j − 1 log(1 + πi( j)) , (3) donde yij toma rangos como valores y ni es una constante de normalización. ni se elige de manera que una clasificación perfecta π∗ i tenga una puntuación NDCG en la posición m de 1. 3.2 Algoritmo Inspirado en el algoritmo AdaBoost para clasificación, hemos ideado un algoritmo novedoso que puede optimizar una función de pérdida basada en medidas de rendimiento de IR. El algoritmo se conoce como AdaRank y se muestra en la Figura 1. AdaRank toma un conjunto de entrenamiento S = {(qi, di, yi)}m i=1 como entrada y toma la función de medida de rendimiento E y el número de iteraciones T como parámetros. AdaRank realiza T rondas y en cada ronda crea un clasificador débil ht (t = 1, · · · , T). Finalmente, genera un modelo de clasificación f combinando linealmente los clasificadores débiles. En cada ronda, AdaRank mantiene una distribución de pesos sobre las consultas en los datos de entrenamiento. Denotamos la distribución de pesos Entrada: S = {(qi, di, yi)}m i=1, y parámetros E y T. Inicializar P1(i) = 1/m. Para t = 1, · · · , T • Crear un clasificador débil ht con distribución ponderada Pt en los datos de entrenamiento S. • Elegir αt αt = 1 2 · ln m i=1 Pt(i){1 + E(π(qi, di, ht), yi)} m i=1 Pt(i){1 − E(π(qi, di, ht), yi)} . • Crear ft ft(x) = t k=1 αkhk(x). • Actualizar Pt+1 Pt+1(i) = exp{−E(π(qi, di, ft), yi)} m j=1 exp{−E(π(qj, dj, ft), yj)} . Para el modelo de clasificación de salida: f(x) = fT (x). Figura 1: El algoritmo AdaRank en la ronda t como Pt y el peso en la i-ésima consulta de entrenamiento qi en la ronda t como Pt(i). Inicialmente, AdaRank asigna pesos iguales a las consultas. En cada ronda, aumenta los pesos de aquellas consultas que no están bien clasificadas por ft, el modelo creado hasta el momento. Como resultado, el aprendizaje en la siguiente ronda se centrará en la creación de un clasificador débil que pueda trabajar en la clasificación de esas consultas difíciles. En cada ronda, se construye un clasificador débil ht basado en los datos de entrenamiento con una distribución de pesos Pt. La bondad de un clasificador débil se mide por la medida de rendimiento E ponderada por Pt: m i=1 Pt(i)E(π(qi, di, ht), yi). Varios métodos para la construcción de clasificadores débiles pueden ser considerados. Por ejemplo, se puede crear un clasificador débil utilizando un subconjunto de consultas (junto con su lista de documentos y etiquetas) muestreado de acuerdo con la distribución Pt. En este artículo, utilizamos características individuales como clasificadores débiles, como se explicará en la Sección 3.6. Una vez que se construye un clasificador débil ht, AdaRank elige un peso αt > 0 para el clasificador débil. Intuitivamente, αt mide la importancia de ht. Un modelo de clasificación ft se crea en cada ronda combinando linealmente los clasificadores débiles construidos hasta el momento h1, · · · , ht con pesos α1, · · · , αt. Luego, ft se utiliza para actualizar la distribución Pt+1. 3.3 Análisis Teórico Los algoritmos de aprendizaje existentes para clasificación intentan minimizar una función de pérdida basada en pares de instancias (pares de documentos). Por el contrario, AdaRank intenta optimizar una función de pérdida basada en consultas. Además, la función de pérdida en AdaRank se define en base a medidas generales de rendimiento en IR. Las medidas pueden ser MAP, NDCG, WTA, MRR, u otras medidas cuyo rango esté dentro de [−1, +1]. A continuación explicamos por qué esto es así. Idealmente queremos maximizar la precisión de clasificación en términos de una medida de rendimiento en los datos de entrenamiento: max f∈F m i=1 E(π(qi, di, f), yi), (4) donde F es el conjunto de posibles funciones de clasificación. Esto es equivalente a minimizar la pérdida en los datos de entrenamiento min f∈F m i=1 (1 − E(π(qi, di, f), yi)). Es difícil optimizar directamente la pérdida, ya que E es una función no continua y, por lo tanto, puede ser difícil de manejar. En cambio, intentamos minimizar una cota superior de la pérdida en (5) min f∈F m i=1 exp{−E(π(qi, di, f), yi)}, (6) porque e−x ≥ 1 − x se cumple para cualquier x ∈ . Consideramos el uso de una combinación lineal de clasificadores débiles como nuestro modelo de clasificación: f(x) = Σ t=1 αtht(x). La minimización en (6) resulta ser min ht∈H,αt∈ + L(ht, αt) = m i=1 exp{−E(π(qi, di, ft−1 + αtht), yi)}, donde H es el conjunto de posibles clasificadores débiles, αt es un peso positivo, y ( ft−1 + αtht)(x) = ft−1(x) + αtht(x). Varias formas de calcular los coeficientes αt y los clasificadores débiles ht pueden ser consideradas. Siguiendo la idea de AdaBoost, en AdaRank tomamos el enfoque de modelado aditivo en etapas hacia adelante [12] y obtenemos el algoritmo en la Figura 1. Se puede demostrar que existe un límite inferior en la precisión de clasificación para AdaRank en los datos de entrenamiento, como se presenta en el Teorema 1. Teorema 1. El siguiente límite se cumple en la precisión de clasificación del algoritmo AdaRank en los datos de entrenamiento: 1 m m i=1 E(π(qi, di, fT ), yi) ≥ 1 − T t=1 e−δt min 1 − ϕ(t)2, donde ϕ(t) = m i=1 Pt(i)E(π(qi, di, ht), yi), δt min = mini=1,··· ,m δt i, y δt i = E(π(qi, di, ft−1 + αtht), yi) − E(π(qi, di, ft−1), yi) −αtE(π(qi, di, ht), yi), para todo i = 1, 2, · · · , m y t = 1, 2, · · · , T. Una prueba del teorema se puede encontrar en el apéndice. El teorema implica que la precisión de clasificación en términos de la medida de rendimiento puede mejorarse continuamente, siempre y cuando se cumpla e−δt min 1 − ϕ(t)2 < 1. 3.4 Ventajas AdaRank es un método simple pero poderoso. Más importante aún, es un método que puede ser justificado desde el punto de vista teórico, como se discutió anteriormente. Además, AdaRank tiene varias ventajas adicionales en comparación con los métodos existentes de aprendizaje para clasificar, como Ranking SVM, RankBoost y RankNet. Primero, AdaRank puede incorporar cualquier medida de rendimiento, siempre que la medida esté basada en consultas y esté en el rango de [−1, +1]. Ten en cuenta que las principales medidas de IR cumplen con este requisito. En contraste, los métodos existentes solo minimizan funciones de pérdida que están débilmente relacionadas con las medidas de IR [16]. Segundo, el proceso de aprendizaje de AdaRank es más eficiente que el de los algoritmos de aprendizaje existentes. La complejidad temporal de AdaRank es del orden O((k+T)·m·n log n), donde k denota el número de características, T el número de rondas, m el número de consultas en los datos de entrenamiento, y n es el número máximo de documentos para las consultas en los datos de entrenamiento. La complejidad temporal de RankBoost, por ejemplo, es del orden O(T · m · n2) [8]. En tercer lugar, AdaRank emplea un marco más razonable para realizar la tarea de clasificación que los métodos existentes. Específicamente en AdaRank, las instancias corresponden a consultas, mientras que en los métodos existentes las instancias corresponden a pares de documentos. Como resultado, AdaRank no tiene las siguientes deficiencias que afectan a los métodos existentes. (a) Los métodos existentes tienen que hacer una suposición fuerte de que los pares de documentos de la misma consulta están distribuidos de forma independiente. En realidad, esto claramente no es el caso y este problema no existe para AdaRank. (b) Clasificar los documentos más relevantes en la parte superior de las listas de documentos es crucial para la recuperación de documentos. Los métodos existentes no pueden centrarse en el entrenamiento en las partes superiores, como se indica en [4]. Se han propuesto varios métodos para rectificar el problema (por ejemplo, [4]), sin embargo, no parecen resolver fundamentalmente el problema. Por el contrario, AdaRank puede enfocarse naturalmente en entrenar en la parte superior de las listas de documentos, ya que las medidas de rendimiento utilizadas favorecen las clasificaciones en las que los documentos relevantes se encuentran en la parte superior. En los métodos existentes, el número de pares de documentos varía de una consulta a otra, lo que resulta en la creación de modelos sesgados hacia consultas con más pares de documentos, como se señala en [4]. AdaRank no tiene esta desventaja, ya que trata las consultas en lugar de los pares de documentos como unidades básicas en el aprendizaje. 3.5 Diferencias con AdaBoost AdaRank es un algoritmo de aumento. En ese sentido, es similar a AdaBoost, pero también tiene varias diferencias llamativas con AdaBoost. Primero, los tipos de instancias son diferentes. AdaRank utiliza consultas y sus listas de documentos correspondientes como instancias. Las etiquetas en los datos de entrenamiento son listas de rangos (niveles de relevancia). AdaBoost utiliza vectores de características como instancias. Las etiquetas en los datos de entrenamiento son simplemente +1 y −1. Segundo, las medidas de rendimiento son diferentes. En AdaRank, la medida de rendimiento es una medida genérica, definida en la lista de documentos y la lista de clasificación de una consulta. En AdaBoost, la medida de rendimiento correspondiente es una medida específica para la clasificación binaria, también conocida como margen [25]. Tercero, las formas de actualizar los pesos también son diferentes. En AdaBoost, la distribución de pesos en las instancias de entrenamiento se calcula según la distribución actual y el rendimiento del aprendiz débil actual. En AdaRank, en cambio, se calcula según el rendimiento del modelo de clasificación creado hasta el momento, como se muestra en la Figura 1. Ten en cuenta que AdaBoost también puede adoptar el método de actualización de pesos utilizado en AdaRank. Para AdaBoost son equivalentes (cf., [12] página 305). Sin embargo, esto no es cierto para AdaRank. 3.6 Construcción de un Clasificador Débil Consideramos una implementación eficiente para la construcción de un clasificador débil, la cual también se utiliza en nuestros experimentos. En la implementación, como clasificador débil elegimos la característica que tiene el rendimiento ponderado óptimo entre todas las características: max k m i=1 Pt(i)E(π(qi, di, xk), yi). Creando clasificadores débiles de esta manera, el proceso de aprendizaje resulta en la selección repetida de características y la combinación lineal de las características seleccionadas. Ten en cuenta que las características que no son seleccionadas en la fase de entrenamiento tendrán un peso de cero. 4. RESULTADOS EXPERIMENTALES Realizamos experimentos para probar el rendimiento de AdaRank utilizando cuatro conjuntos de datos de referencia: OHSUMED, WSJ, AP y .Gov. Tabla 2: Características utilizadas en los experimentos en los conjuntos de datos OHSUMED, WSJ y AP. C(w, d) representa la frecuencia de la palabra w en el documento d; C representa la colección completa; n denota el número de términos en la consulta; | · | denota la función de tamaño; e id f(·) denota la frecuencia inversa del documento. 1 wi∈q d ln(c(wi, d) + 1) 2 wi∈q d ln( |C| c(wi,C) + 1) 3 wi∈q d ln(id f(wi)) 4 wi∈q d ln(c(wi,d) |d| + 1) 5 wi∈q d ln(c(wi,d) |d| · id f(wi) + 1) 6 wi∈q d ln(c(wi,d)·|C| |d|·c(wi,C) + 1) 7 ln(puntuación de BM25) 0.2 0.3 0.4 0.5 0.6 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RarnkBoost AdaRank.MAP AdaRank.NDCG Figura 2: Precisión de clasificación en los datos de OHSUMED. 4.1 Configuración del experimento SVM de clasificación [13, 16] y RankBoost [8] fueron seleccionados como baselines en los experimentos, porque son los métodos de aprendizaje de clasificación más avanzados. Además, se utilizó BM25 [24] como referencia, representando el método de RI de última generación (de hecho, utilizamos la herramienta Lemur1). Para AdaRank, el parámetro T se determinó automáticamente durante cada experimento. Específicamente, cuando no hay mejora en la precisión de clasificación en términos de la medida de rendimiento, la iteración se detiene (y se determina T). Se utilizaron las medidas E, MAP y NDCG@5. Los resultados para AdaRank utilizando MAP y NDCG@5 como medidas en el entrenamiento se representan como AdaRank.MAP y AdaRank.NDCG, respectivamente. 4.2 Experimento con Datos de OHSUMED En este experimento, hicimos uso del conjunto de datos de OHSUMED [14] para probar el rendimiento de AdaRank. El conjunto de datos OHSUMED consta de 348,566 documentos y 106 consultas. Hay un total de 16,140 pares de consulta-documento sobre los cuales se realizan juicios de relevancia. Las valoraciones de relevancia son ya sea d (definitivamente relevante), p (posiblemente relevante) o n (no relevante). Los datos han sido utilizados en muchos experimentos en IR, por ejemplo [4, 29]. Como características, adoptamos aquellas utilizadas en la recuperación de documentos [4]. La tabla 2 muestra las características. Por ejemplo, tf (frecuencia del término), idf (frecuencia inversa del documento), dl (longitud del documento) y combinaciones de ellos se definen como características. El puntaje BM25 en sí mismo también es una característica. Se eliminaron las palabras vacías y se realizó el stemming en los datos. Dividimos aleatoriamente las consultas en cuatro subconjuntos iguales y realizamos experimentos de validación cruzada de 4 pliegues. Ajustamos los parámetros para BM25 durante uno de los ensayos y los aplicamos a los otros ensayos. Los resultados reportados en la Figura 2 son aquellos promediados a lo largo de cuatro ensayos. En el cálculo de MAP, definimos la clasificación d como relevante y 1 http://www.lemurproject.com Tabla 3: Estadísticas sobre los conjuntos de datos de WSJ y AP. Conjunto de datos # consultas # documentos recuperados # documentos por consulta AP 116 24,727 213.16 WSJ 126 40,230 319.29 0.40 0.45 0.50 0.55 0.60 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figura 3: Precisión de ranking en el conjunto de datos WSJ. Los otros dos rangos se consideran irrelevantes. A partir de la Figura 2, vemos que tanto AdaRank.MAP como AdaRank.NDCG superan a BM25, Ranking SVM y RankBoost en cuanto a todas las medidas. Realizamos pruebas significativas (prueba t) sobre las mejoras de AdaRank.MAP sobre BM25, Ranking SVM y RankBoost en términos de MAP. Los resultados indican que todas las mejoras son estadísticamente significativas (valor p < 0.05). También realizamos una prueba t sobre las mejoras de AdaRank.NDCG en comparación con BM25, Ranking SVM y RankBoost en términos de NDCG@5. Las mejoras también son estadísticamente significativas. 4.3 Experimento con datos de WSJ y AP En este experimento, hicimos uso de los conjuntos de datos de WSJ y AP de la pista de recuperación ad-hoc de TREC, para probar el rendimiento de AdaRank. WSJ contiene 74,520 artículos del Wall Street Journal de 1990 a 1992, y AP contiene 158,240 artículos de Associated Press en 1988 y 1990. Se seleccionan 200 consultas de los temas de TREC (No.101 a No.300). Cada consulta tiene asociado un número de documentos que están etiquetados como relevantes o irrelevantes (para la consulta). Siguiendo la práctica en [28], las consultas que tenían menos de 10 documentos relevantes fueron descartadas. La Tabla 3 muestra las estadísticas de los dos conjuntos de datos. De la misma manera que en la sección 4.2, adoptamos las características enumeradas en la Tabla 2 para la clasificación. También realizamos experimentos de validación cruzada de 4 pliegues. Los resultados reportados en la Figura 3 y 4 son aquellos promediados sobre cuatro pruebas en los conjuntos de datos de WSJ y AP, respectivamente. A partir de las Figuras 3 y 4, podemos ver que AdaRank.MAP y AdaRank.NDCG superan a BM25, Ranking SVM y RankBoost en cuanto a todas las medidas tanto en WSJ como en AP. Realizamos pruebas t en las mejoras de AdaRank.MAP y AdaRank.NDCG sobre BM25, Ranking SVM y RankBoost en WSJ y AP. Los resultados indican que todas las mejoras en términos de MAP son estadísticamente significativas (valor p < 0.05). Sin embargo, solo algunas de las mejoras en términos de NDCG@5 son estadísticamente significativas, aunque en general las mejoras en las puntuaciones de NDCG son bastante altas (1-2 puntos). 4.4 Experimento con datos .Gov En este experimento, utilizamos aún más los datos .Gov de TREC para probar el rendimiento de AdaRank en la tarea de recuperación web. El corpus es un rastreo del dominio .gov a principios de 2002, y ha sido utilizado en la TREC Web Track desde 2002. Hay un total de 0.40 0.45 0.50 0.55 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figura 4: Precisión de clasificación en el conjunto de datos AP. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 MAP NDCG@1 NDCG@3 NDCG@5 NDCG@10 BM25 Ranking SVM RankBoost AdaRank.MAP AdaRank.NDCG Figura 5: Precisión de clasificación en el conjunto de datos .Gov. Tabla 4: Características utilizadas en los experimentos en el conjunto de datos .Gov. 1 BM25 [24] 2 MSRA1000 [27] 3 PageRank [21] 4 HostRank [30] 5 Propagación de Relevancia [23] (10 características) de 1,053,110 páginas web con 11,164,829 hipervínculos en los datos. Se utilizaron las 50 consultas en la tarea de destilación de temas en la pista web de TREC 2003. Las verdades fundamentales para las consultas son proporcionadas por el comité TREC con juicios binarios: relevante o irrelevante. El número de páginas relevantes varía de una consulta a otra (de 1 a 86). Extrajimos 14 características de cada par de consulta-documento. La tabla 4 proporciona una lista de las características. Son los resultados de algunos algoritmos (sistemas) conocidos. Estas características son diferentes de las que se encuentran en la Tabla 2, porque la tarea es distinta. Nuevamente, realizamos experimentos de validación cruzada de 4 pliegues. Los resultados promediados de cuatro pruebas se informan en la Figura 5. De los resultados, podemos ver que AdaRank.MAP y AdaRank.NDCG superan a todos los baselines en cuanto a todas las medidas. Realizamos pruebas t sobre las mejoras de AdaRank.MAP y AdaRank.NDCG sobre BM25, Ranking SVM y RankBoost. Algunas de las mejoras no son estadísticamente significativas. Esto se debe a que solo tenemos 50 consultas utilizadas en los experimentos, y el número de consultas es demasiado pequeño. 4.5 Discusiones Investigamos las razones por las que AdaRank supera a los métodos de referencia, utilizando los resultados del conjunto de datos OHSUMED como ejemplos. Primero, examinamos la razón por la que AdaRank tiene un mejor rendimiento que Ranking SVM y RankBoost. Específicamente comparamos las tasas de error entre diferentes pares de clasificación realizados por Ranking SVM, RankBoost, AdaRank.MAP y AdaRank.NDCG en los datos de prueba. Los resultados promediados de cuatro pruebas en la validación cruzada de 4 pliegues se muestran en la Figura 6. Utilizamos d-n para representar los pares entre definitivamente relevante y no relevante, d-p los pares entre definitivamente relevante y parcialmente relevante, y p-n los pares entre parcialmente relevante y no relevante. A partir de la Figura 6, podemos ver que AdaRank.MAP y AdaRank.NDCG cometen menos errores para d-n y d-p, que están relacionados con los primeros puestos de las clasificaciones y son importantes. Esto se debe a que AdaRank.MAP y AdaRank.NDCG pueden enfocarse naturalmente en el entrenamiento en los primeros lugares optimizando MAP y NDCG@5, respectivamente. También realizamos estadísticas sobre el número de pares de documentos por consulta en los datos de entrenamiento (para la prueba 1). Las consultas se agrupan en diferentes grupos según el número de pares de documentos asociados a ellas. La Figura 7 muestra la distribución de los grupos de consulta. En la figura, por ejemplo, 0-1k es el grupo de consultas cuyo número de pares de documentos está entre 0 y 999. Podemos ver que los números de pares de documentos realmente varían de una consulta a otra. A continuación evaluamos las precisiones de AdaRank.MAP y RankBoost en términos de MAP para cada uno de los grupos de consultas. Los resultados se informan en la Figura 8. Encontramos que el MAP promedio de AdaRank.MAP sobre los grupos es dos puntos más alto que RankBoost. Además, es interesante ver que AdaRank.MAP tiene un rendimiento particularmente mejor que RankBoost para consultas con un pequeño número de pares de documentos (por ejemplo, 0-1k, 1k-2k y 2k-3k). Los resultados indican que AdaRank.MAP puede evitar de manera efectiva la creación de un modelo sesgado hacia consultas con más pares de documentos. Para AdaRank.NDCG, se pueden observar resultados similares. 0.2 0.3 0.4 0.5 MAP grupo de consultas RankBoost AdaRank.MAP Figura 8: Diferencias en MAP para diferentes grupos de consultas. 0.30 0.31 0.32 0.33 0.34 prueba 1 prueba 2 prueba 3 prueba 4 MAP AdaRank.MAP AdaRank.NDCG Figura 9: MAP en el conjunto de entrenamiento cuando el modelo se entrena con MAP o NDCG@5. Llevamos a cabo un experimento adicional para ver si AdaRank tiene la capacidad de mejorar la precisión de clasificación en términos de una medida utilizando dicha medida en el entrenamiento. Específicamente, entrenamos modelos de clasificación utilizando AdaRank.MAP y AdaRank.NDCG y evaluamos sus precisión en el conjunto de datos de entrenamiento en términos de MAP y NDCG@5. El experimento se llevó a cabo para cada prueba. La Figura 9 y la Figura 10 muestran los resultados en términos de MAP y NDCG@5, respectivamente. Podemos ver que, AdaRank.MAP entrenado con MAP tiene un mejor rendimiento en términos de MAP, mientras que AdaRank.NDCG entrenado con NDCG@5 tiene un mejor rendimiento en términos de NDCG@5. Los resultados indican que AdaRank puede mejorar efectivamente el rendimiento de clasificación en términos de una medida al utilizar la medida en el entrenamiento. Finalmente, intentamos verificar la corrección del Teorema 1. Es decir, la precisión del ranking en términos de la medida de rendimiento puede mejorarse continuamente, siempre y cuando se cumpla que e−δt min 1 − ϕ(t)2 < 1. Como ejemplo, la Figura 11 muestra la curva de aprendizaje de AdaRank.MAP en términos de MAP durante la fase de entrenamiento en una prueba de la validación cruzada. Desde la figura, podemos ver que la precisión de clasificación de AdaRank.MAP mejora constantemente a medida que avanza el entrenamiento, hasta que alcanza su punto máximo. El resultado concuerda bien con el Teorema 1.5. CONCLUSIÓN Y TRABAJO FUTURO En este artículo hemos propuesto un algoritmo novedoso para aprender modelos de clasificación en la recuperación de documentos, denominado AdaRank. A diferencia de los métodos existentes, AdaRank optimiza una función de pérdida que está directamente definida en las medidas de rendimiento. Emplea una técnica de aumento en el aprendizaje del modelo de clasificación. AdaRank ofrece varias ventajas: facilidad de implementación, solidez teórica, eficiencia en el entrenamiento y alta precisión en la clasificación. Los resultados experimentales basados en cuatro conjuntos de datos de referencia muestran que AdaRank puede superar significativamente a los métodos base de BM25, Ranking SVM y RankBoost. 0.49 0.50 0.51 0.52 0.53 prueba 1 prueba 2 prueba 3 prueba 4 NDCG@5 AdaRank.MAP AdaRank.NDCG Figura 10: NDCG@5 en el conjunto de entrenamiento cuando el modelo se entrena con MAP o NDCG@5. 0.29 0.30 0.31 0.32 0 50 100 150 200 250 300 350 MAP número de rondas Figura 11: Curva de aprendizaje de AdaRank. El trabajo futuro incluye un análisis teórico sobre el error de generalización y otras propiedades del algoritmo AdaRank, y evaluaciones empíricas adicionales del algoritmo, incluyendo comparaciones con otros algoritmos que pueden optimizar directamente medidas de rendimiento. AGRADECIMIENTOS Agradecemos a Harry Shum, Wei-Ying Ma, Tie-Yan Liu, Gu Xu, Bin Gao, Robert Schapire y Andrew Arnold por sus valiosos comentarios y sugerencias para este artículo. 7. REFERENCIAS [1] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. Addison Wesley, mayo de 1999. [2] C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Avances en Sistemas de Procesamiento de Información Neural 18, páginas 395-402. MIT Press, Cambridge, MA, 2006. [3] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. 

MIT Press, Cambridge, MA, 2006. [3] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En ICML 22, páginas 89-96, 2005. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En SIGIR 29, páginas 186-193, 2006. [5] D. Cossock y T. Zhang. Clasificación de subconjuntos utilizando regresión. En COLT, páginas 605-619, 2006. [6] N. Craswell, D. Hawking, R. Wilkinson y M. Wu. Resumen de la pista web TREC 2003. En TREC, páginas 78-92, 2003. [7] N. Duffy y D. Helmbold. Métodos de aumento para regresión. I'm sorry, but "Mach" is not a complete sentence. Could you please provide more context or clarify the sentence you would like me to translate to Spanish? Aprender., 47(2-3):153-200, 2002. [8] Y. Freund, R. D. Iyer, R. E. Schapire y Y. Cantante. Un algoritmo de refuerzo eficiente para combinar preferencias. Revista de Investigación en Aprendizaje Automático, 4:933-969, 2003. [9] Y. Freund y R. E. Schapire. Una generalización de la teoría de decisiones del aprendizaje en línea y una aplicación al boosting. J. Comput. This is not a complete sentence. Please provide more context or a complete sentence to be translated. Cienc., 55(1):119-139, 1997. [10] J. Friedman, T. Hastie y R. Tibshirani. Regresión logística aditiva: Una perspectiva estadística del boosting. Los Anales de Estadística, 28(2):337-374, 2000. [11] G. Fung, R. Rosales y B. Krishnapuram. Aprendizaje de clasificaciones mediante separación de envolvente convexa. En Advances in Neural Information Processing Systems 18, páginas 395-402. MIT Press, Cambridge, MA, 2006. [12] T. Hastie, R. Tibshirani, y J. H. Friedman. Los Elementos del Aprendizaje Estadístico. Springer, agosto de 2001. [13] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de gran margen para regresión ordinal. MIT Press, Cambridge, MA, 2000. [14] W. Hersh, C. Buckley, T. J. Leone, y D. Hickam. Ohsumed: una evaluación interactiva de recuperación y una nueva colección de pruebas grande para la investigación. En SIGIR, páginas 192-201, 1994. [15] K. Jarvelin y J. Kekalainen. Métodos de evaluación IR para recuperar documentos altamente relevantes. En SIGIR 23, páginas 41-48, 2000. [16] T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En SIGKDD 8, páginas 133-142, 2002. [17] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En ICML 22, páginas 377-384, 2005. [18] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En SIGIR 24, páginas 111-119, 2001. [19] D. A. Metzler, W. B. Croft y A. McCallum. Maximización directa de métricas basadas en rangos para la recuperación de información. Informe técnico, CIIR, 2005. [20] R. Nallapati. Modelos discriminativos para la recuperación de información. En SIGIR 27, páginas 64-71, 2004. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de pagerank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. M. Ponte y W. B. Croft. Un enfoque de modelado del lenguaje para la recuperación de información. En SIGIR 21, páginas 275-281, 1998. [23] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen, y W.-Y. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 28, páginas 408-415, 2005. [24] S. E. Robertson y D. A. Casco. El informe final de la pista de filtrado TREC-9. En TREC, páginas 25-40, 2000. [25] R. E. Schapire, Y. Freund, P. Barlett y W. S. Lee. Aumentando el margen: Una nueva explicación para la efectividad de los métodos de votación. En ICML 14, páginas 322-330, 1997. [26] R. E. Schapire y Y. Cantante. Algoritmos de mejora mejorados utilizando predicciones con calificación de confianza. I'm sorry, but "Mach" is not a complete sentence. Could you please provide more context or clarify the sentence you would like me to translate to Spanish? Aprender., 37(3):297-336, 1999. [27] R. Song, J. Wen, S. Shi, G. Xin, T. yan Liu, T. Qin, X. Zheng, J. Zhang, G. Xue, y W.-Y. This is not a complete sentence. Please provide the full sentence you would like me to translate to Spanish. Microsoft Research Asia participó en la pista web y la pista de terabyte de TREC 2004. En TREC, 2004. [28] A. Trotman. Aprendizaje para clasificar. I'm sorry, but I need a complete sentence to provide an accurate translation. Retr., 8(3):359-381, 2005. [29] J. Xu, Y. Cao, H. Li, and Y. Huang.
Traducción: Retr., 8(3):359-381, 2005. [29] J. Xu, Y. Cao, H. Li y Y. Huang. Aprendizaje sensible al costo de SVM para clasificación. En ECML, páginas 833-840, 2006. [30] G.-R. Xue, Q. Yang, H.-J. Zeng, Y. Yu y Z. Chen. Explotando la estructura jerárquica para el análisis de enlaces. En SIGIR 28, páginas 186-193, 2005. [31] H. Yu. Muestreo selectivo de SVM para clasificación con aplicación a la recuperación de datos. En SIGKDD 11, páginas 354-363, 2005. APÉNDICE Aquí presentamos la prueba del Teorema 1. PRUEBA. Establezca ZT = m i=1 exp {−E(π(qi, di, fT ), yi)} y φ(t) = 1 2 (1 + ϕ(t)). Según la definición de αt, sabemos que eαt = φ(t) 1−φ(t). ZT = m i=1 exp {−E(π(qi, di, fT−1 + αT hT ), yi)} = m i=1 exp −E(π(qi, di, fT−1), yi) − αT E(π(qi, di, hT ), yi) − δT i ≤ m i=1 exp {−E(π(qi, di, fT−1), yi)} exp {−αT E(π(qi, di, hT ), yi)} e−δT min = e−δT min ZT−1 m i=1 exp {−E(π(qi, di, fT−1), yi)} ZT−1 exp{−αT E(π(qi, di, hT ), yi)} = e−δT min ZT−1 m i=1 PT (i) exp{−αT E(π(qi, di, hT ), yi)}.

ZT = m i=1 exp {−E(π(qi, di, fT−1 + αT hT ), yi)} = m i=1 exp −E(π(qi, di, fT−1), yi) − αT E(π(qi, di, hT ), yi) − δT i ≤ m i=1 exp {−E(π(qi, di, fT−1), yi)} exp {−αT E(π(qi, di, hT ), yi)} e−δT min = e−δT min ZT−1 m i=1 exp {−E(π(qi, di, fT−1), yi)} ZT−1 exp{−αT E(π(qi, di, hT ), yi)} = e−δT min ZT−1 m i=1 PT (i) exp{−αT E(π(qi, di, hT ), yi)}. Además, si E(π(qi, di, hT), yi) ∈ [−1, +1] entonces, ZT ≤ e−δT minZT−1 m i=1 PT(i) 1+E(π(qi, di, hT), yi) 2 e−αT + 1−E(π(qi, di, hT), yi) 2 eαT = e−δT min ZT−1  φ(T) 1 − φ(T) φ(T) + (1 − φ(T)) φ(T) 1 − φ(T)   = ZT−1e−δT min 4φ(T)(1 − φ(T)) ≤ ZT−2 T t=T−1 e−δt min 4φ(t)(1 − φ(t)) ≤ Z1 T t=2 e−δt min 4φ(t)(1 − φ(t)) = m m i=1 1 m exp{−E(π(qi, di, α1h1), yi)} T t=2 e−δt min 4φ(t)(1 − φ(t)) = m m i=1 1 m exp{−α1E(π(qi, di, h1), yi) − δ1 i } T t=2 e−δt min 4φ(t)(1 − φ(t)) ≤ me−δ1 min m i=1 1 m exp{−α1E(π(qi, di, h1), yi)} T t=2 e−δt min 4φ(t)(1 − φ(t)) ≤ m e−δ1 min 4φ(1)(1 − φ(1)) T t=2 e−δt min 4φ(t)(1 − φ(t)) = m T t=1 e−δt min 1 − ϕ(t)2. ∴ 1 m m i=1 E(π(qi, di, fT), yi) ≥ 1 m m i=1 {1 − exp(−E(π(qi, di, fT), yi))} ≥ 1 − T t=1 e−δt min 1 − ϕ(t)2.