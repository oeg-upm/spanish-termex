Implementación de un Mecanismo de Ajuste Dinámico con Selección Eficiente de Réplicas en Entornos de Cuadrícula de Datos Chao-Tung Yang I-Hsien Yang Chun-Hsiang Chen Shih-Yu Wang Laboratorio de Computación de Alto Rendimiento Departamento de Ciencias de la Computación e Ingeniería de la Información Universidad de Tunghai Ciudad de Taichung, 40704, Taiwán R.O.C. La arquitectura de co-asignación se desarrolló para permitir la descarga paralela de conjuntos de datos desde múltiples servidores. Varias estrategias de coasignación han sido acopladas y utilizadas para explotar las diferencias de velocidad entre varios enlaces cliente-servidor y para abordar las fluctuaciones dinámicas de velocidad dividiendo los archivos en múltiples bloques de tamaños iguales. Sin embargo, un obstáculo importante, el tiempo de inactividad de los servidores más rápidos que tienen que esperar al servidor más lento para entregar el bloque final, hace importante reducir las diferencias en el tiempo de finalización entre los servidores réplica. En este artículo, proponemos un esquema de coalocación dinámica, denominado esquema de Coalocación Co-Ajustada Recursiva, para mejorar el rendimiento de la transferencia de datos en Rejillas de Datos. Nuestro enfoque reduce el tiempo de inactividad esperando al servidor más lento y disminuye el tiempo de finalización de la transferencia de datos. También ofrecemos un esquema efectivo para reducir el costo de volver a ensamblar bloques de datos. Categorías y Descriptores de Asignaturas C.2.4 [Sistemas Distribuidos]: Aplicaciones distribuidas. H.3.5 [Servicios de Información en Línea]: Compartir datos, servicios basados en la web. Gestión, Rendimiento, Diseño, Experimentación. 1. INTRODUCCIÓN Las redes de datos agregan recursos distribuidos para resolver problemas de gestión de conjuntos de datos de gran tamaño. La mayoría de las aplicaciones de Data Grid se ejecutan simultáneamente y acceden a grandes cantidades de archivos de datos en el entorno de la Grid. Ciertas aplicaciones científicas intensivas en datos, como la física de altas energías, las aplicaciones de bioinformática y los observatorios astrofísicos virtuales, implican enormes cantidades de datos que requieren sistemas de gestión de archivos de datos para replicar archivos y gestionar transferencias de datos y acceso distribuido a los datos. La infraestructura de la cuadrícula de datos integra dispositivos de almacenamiento de datos y servicios de gestión de datos en el entorno de la cuadrícula, que consiste en recursos informáticos y de almacenamiento dispersos, quizás ubicados en diferentes países/regiones pero accesibles para los usuarios [12]. La replicación de contenido popular en servidores distribuidos es ampliamente utilizada en la práctica [14, 17, 19]. Recientemente, comunidades científicas de intercambio de datos a gran escala, como las descritas en [1, 5], utilizaron esta tecnología para replicar sus grandes conjuntos de datos en varios sitios. Descargar grandes conjuntos de datos desde varias ubicaciones de réplica puede resultar en tasas de rendimiento variadas, ya que los sitios de réplica pueden tener arquitecturas, cargas de sistema y conectividad de red diferentes. La calidad del ancho de banda es el factor más importante que afecta las transferencias entre clientes y servidores, ya que las velocidades de descarga están limitadas por la congestión del tráfico de ancho de banda en los enlaces que conectan los servidores con los clientes. Una forma de mejorar la velocidad de descarga es determinar las mejores ubicaciones de réplicas utilizando técnicas de selección de réplicas [19]. Este método selecciona los mejores servidores para proporcionar tasas de transferencia óptimas, ya que la calidad del ancho de banda puede variar de forma impredecible debido a la naturaleza compartida de internet. Otra forma es utilizar la tecnología de co-asignación [17] para descargar datos. La coasignación de transferencias de datos permite a los clientes descargar datos desde múltiples ubicaciones al establecer múltiples conexiones en paralelo. Esto puede mejorar el rendimiento en comparación con los casos de un solo servidor y aliviar el problema de congestión en internet [17]. Varios estrategias de coasignación fueron proporcionadas en trabajos anteriores [17]. Permanece una desventaja en el tiempo de inactividad ya que los servidores más rápidos deben esperar a que el servidor más lento entregue su último bloque. Por lo tanto, es importante reducir las diferencias en el tiempo de finalización entre los servidores réplica. En este artículo, proponemos un esquema de coasignación dinámica basado en la arquitectura de transferencia de datos de coasignación en la red llamado esquema de coasignación RecursiveAdjustment que reduce el tiempo de inactividad esperando al servidor más lento y mejora el rendimiento de la transferencia de datos [24]. Los resultados experimentales muestran que nuestro enfoque es superior a los métodos anteriores y logró el mejor rendimiento general. También discutimos el costo de combinación y proporcionamos un esquema efectivo para reducirlo. El resto de este documento está organizado de la siguiente manera. La revisión de antecedentes relacionados y estudios se presentan en la Sección 2 y la arquitectura de co-asignación y trabajos relacionados se introducen en la Sección 3. En la Sección 4, proponemos un servicio eficiente de selección de réplicas. Nuestros enfoques de investigación se describen en la Sección 5, y los resultados experimentales y una evaluación del rendimiento de nuestro esquema se presentan en la Sección 6. La sección 7 concluye este documento de investigación. ANTECEDENTES 2.1 Rejilla de Datos Las Rejillas de Datos permiten el intercambio, selección y conexión de una amplia variedad de recursos computacionales y de almacenamiento distribuidos geográficamente para resolver aplicaciones científicas intensivas en datos a gran escala (por ejemplo, física de altas energías, aplicaciones de bioinformática y observatorio virtual astrofísico). El término Data Grid tradicionalmente representa la red de recursos de almacenamiento distribuido, desde sistemas de archivo hasta cachés y bases de datos, que están vinculados utilizando un espacio de nombres lógico para crear identificadores globales y persistentes y proporcionar mecanismos de acceso uniformes. Las Rejillas de Datos [1, 2, 16] federan una gran cantidad de recursos de almacenamiento. Grandes colecciones de datos medidos o calculados están surgiendo como recursos importantes en muchas aplicaciones intensivas en datos. 2.1.1 Gestión de Réplicas La gestión de réplicas implica la creación o eliminación de réplicas en un sitio de cuadrícula de datos [19]. En otras palabras, el rol de un administrador de réplicas es crear o eliminar réplicas, dentro de sistemas de almacenamiento especificados. La mayoría de las veces, estas réplicas son copias exactas de los archivos originales, creadas solo para aprovechar ciertos beneficios de rendimiento. Un administrador de réplicas generalmente mantiene un catálogo de réplicas que contiene las direcciones de los sitios de réplica y las instancias de archivos. El servicio de gestión de réplicas es responsable de administrar la replicación de copias completas y parciales de conjuntos de datos, definidos como colecciones de archivos. El servicio de gestión de réplicas es solo un componente en un entorno de Data Grid que brinda soporte para aplicaciones de alto rendimiento y alta intensidad de datos. Una réplica o ubicación es un subconjunto de una colección que se almacena en un sistema de almacenamiento físico particular. Puede haber múltiples subconjuntos posiblemente superpuestos de una colección almacenados en múltiples sistemas de almacenamiento en una Rejilla de Datos. Estos sistemas de almacenamiento en red pueden utilizar una variedad de tecnologías de almacenamiento subyacentes y protocolos de movimiento de datos, que son independientes de la gestión de réplicas. 2.1.2 Catálogo de Réplicas Como se mencionó anteriormente, el propósito del catálogo de réplicas es proporcionar mapeos entre nombres lógicos de archivos o colecciones y una o más copias de los objetos en sistemas de almacenamiento físico. El catálogo de réplicas incluye entradas opcionales que describen archivos lógicos individuales. Los archivos lógicos son entidades con nombres globalmente únicos que pueden tener una o más instancias físicas. El catálogo puede contener opcionalmente una entrada de archivo lógico en el catálogo de réplicas para cada archivo lógico en una colección. Una cuadrícula de datos puede contener múltiples catálogos de réplicas. Por ejemplo, una comunidad de investigadores interesados en un tema de investigación particular podría mantener un catálogo de réplicas para una colección de conjuntos de datos de interés mutuo. Es posible crear jerarquías de catálogos de réplicas para imponer una estructura similar a la de un directorio en colecciones lógicas relacionadas. Además, el administrador de réplicas puede realizar control de acceso en catálogos completos, así como en archivos lógicos individuales. 2.1.3 Selección de Réplicas El propósito de la selección de réplicas [16] es seleccionar una réplica entre los sitios que constituyen una Data Grid [19]. Los criterios de selección dependen de las características de la aplicación. Al utilizar este mecanismo, los usuarios de la Data Grid pueden gestionar fácilmente réplicas de conjuntos de datos en sus sitios, con un mejor rendimiento. Se ha dedicado mucho esfuerzo previo al problema de selección de réplicas. El proceso común de selección de réplicas consta de tres pasos: preparación de datos, preprocesamiento y predicción. Entonces, las aplicaciones pueden seleccionar una réplica según sus atributos específicos. La selección de réplicas es importante para aplicaciones intensivas en datos, y puede proporcionar transparencia de ubicación. Cuando un usuario solicita acceso a un conjunto de datos, el sistema determina una forma apropiada de entregar la réplica al usuario. 2.2 Globus Toolkit y GridFTP El Proyecto Globus [9, 11, 16] proporciona herramientas de software colectivamente llamadas El Kit de Herramientas Globus que facilita la construcción de Grids computacionales y aplicaciones basadas en Grid. Muchas organizaciones utilizan la Herramienta Globus para construir Grillas computacionales que apoyen sus aplicaciones. La composición del Globus Toolkit se puede visualizar como tres pilares: Gestión de Recursos, Servicios de Información y Gestión de Datos. Cada pilar representa un componente principal del Globus Toolkit y hace uso de una base común de seguridad. GRAM implementa un protocolo de gestión de recursos, MDS implementa un protocolo de servicios de información y GridFTP implementa un protocolo de transferencia de datos. Todos utilizan el protocolo de seguridad GSI en la capa de conexión [10, 11, 16, 13]. La alianza Globus propuso un protocolo común de transferencia y acceso de datos llamado GridFTP que proporciona un movimiento seguro y eficiente de datos en entornos de Grid. Este protocolo, que extiende el protocolo estándar FTP, proporciona un superconjunto de las características ofrecidas por los diversos sistemas de almacenamiento en red actualmente en uso. Para resolver los problemas que surgen, la comunidad de Data Grid intenta desarrollar un mecanismo seguro y eficiente de transporte de datos y servicios de gestión de réplicas. GridFTP es un protocolo de transporte de datos confiable, seguro y eficiente que se desarrolló como parte del proyecto Globus. Hay otra tecnología clave del proyecto Globus, llamada catálogo de réplicas [16], que se utiliza para registrar y gestionar copias completas y parciales de conjuntos de datos. El catálogo de réplicas contiene la información de mapeo de un archivo lógico o colección a uno o más archivos físicos. 2.3 Servicio Meteorológico de Red El Servicio Meteorológico de Red (NWS) [22] es un sistema de monitoreo generalizado y distribuido para producir pronósticos de rendimiento a corto plazo basados en mediciones de rendimiento históricas. El objetivo del sistema es caracterizar y predecir dinámicamente el rendimiento entregable a nivel de aplicación a partir de un conjunto de recursos de red y computacionales. Una instalación típica implica un nws_nameserver, uno o más nws_memory (que pueden residir en máquinas diferentes) y un nws_sensor ejecutándose en cada máquina con los recursos que se van a monitorear. El sistema incluye sensores para el rendimiento TCP/IP de extremo a extremo (ancho de banda y latencia), porcentaje de CPU disponible y memoria no paginada disponible. 798 2.4 Utilidades Sysstat Las utilidades Sysstat [15] son un conjunto de herramientas de monitoreo de rendimiento para el sistema operativo Linux. El paquete Sysstat incorpora los comandos sar, mpstat e iostat. El comando sar recopila y reporta información de actividad del sistema, la cual también puede ser guardada en un archivo de actividad del sistema para inspección futura. El comando iostat informa estadísticas de la CPU y estadísticas de E/S para dispositivos tty y discos. Las estadísticas reportadas por SAR se refieren a tasas de transferencia de E/S, actividad de paginación, actividades relacionadas con procesos, interrupciones, actividad de red, utilización de memoria y espacio de intercambio, utilización de CPU, actividades del kernel y estadísticas de TTY, entre otros. Las máquinas Uniprocessor (UP) y Symmetric multiprocessor (SMP) son totalmente compatibles. 3. La arquitectura de co-asignación propuesta en [17] consta de tres componentes principales: un servicio de información, un intermediario/co-asignador y sistemas de almacenamiento locales. La Figura 1 muestra la co-asignación de transferencias de datos de la red, que es una extensión de la plantilla básica para la gestión de recursos [7] proporcionada por Globus Toolkit. Las aplicaciones especifican las características de los datos deseados y envían la descripción de los atributos a un intermediario. El corredor consulta los recursos disponibles y obtiene las ubicaciones de réplicas de los servicios de información [6] y los servicios de gestión de réplicas [19], y luego obtiene una lista de ubicaciones físicas para los archivos deseados. Figura 1. La arquitectura de coasignación de cuadrícula de datos [17] pasa las ubicaciones candidatas de réplicas a un servicio de selección de réplicas [19], que fue presentado en un trabajo previo [23]. Este servicio de selección de réplicas proporciona estimaciones del rendimiento de transferencia de candidatos basadas en un modelo de costos y elige las cantidades apropiadas para solicitar a las ubicaciones más adecuadas. El agente de coasignación luego descarga los datos en paralelo desde los servidores seleccionados. En estas investigaciones, se utilizó GridFTP [1, 11, 16] para habilitar transferencias de datos en paralelo. GridFTP es un protocolo de transferencia de datos de alto rendimiento, seguro y confiable, optimizado para redes de área amplia de alta velocidad de banda ancha. Entre sus muchas características se encuentran la seguridad, los flujos paralelos, las transferencias de archivos parciales, las transferencias de terceros y los canales de datos reutilizables. Su capacidad de transferencia parcial de archivos permite recuperar archivos de servidores de datos especificando los desplazamientos de inicio y fin de las secciones de archivos. Las rejillas de datos consisten en recursos informáticos y de almacenamiento dispersos ubicados en diferentes países/regiones pero accesibles para los usuarios [8]. En este estudio utilizamos el middleware de cuadrícula Globus Toolkit [16] como infraestructura de la cuadrícula de datos. El Globus Toolkit proporciona soluciones para consideraciones como seguridad, gestión de recursos, gestión de datos y servicios de información. Uno de sus componentes principales es MDS [6, 11, 16, 25], el cual está diseñado para proporcionar un mecanismo estándar para descubrir y publicar información sobre el estado y la configuración de recursos. Proporciona una interfaz uniforme y flexible para los datos recopilados por proveedores de información de nivel inferior en dos modos: estáticos (por ejemplo, sistemas operativos, tipos de CPU y arquitecturas de sistemas) y datos dinámicos (por ejemplo, disponibilidad de disco, disponibilidad de memoria y carga). Y utiliza GridFTP [1, 11, 16], un protocolo de transporte de datos confiable, seguro y eficiente para proporcionar una gestión eficiente y transferencia de terabytes o petabytes de datos en un entorno de recursos distribuidos de amplia área. A medida que los conjuntos de datos se replican dentro de entornos de Grid para fiabilidad y rendimiento, los clientes requieren la capacidad de descubrir réplicas de datos existentes, y crear y registrar nuevas réplicas. Un Servicio de Localización de Réplicas (RLS) proporciona un mecanismo para descubrir y registrar réplicas existentes. Se han desarrollado varios métricas de predicción para ayudar en la selección de réplicas. Por ejemplo, Vazhkudai y Schopf [18, 20, 21] utilizaron historiales de transferencia de datos pasados para estimar las velocidades actuales de transferencia de datos. En nuestro trabajo previo [23, 24], propusimos un modelo de costo de selección de réplicas y un servicio de selección de réplicas para llevar a cabo la selección de réplicas. En [17], el autor propone una arquitectura de coasignación para coasignar transferencias de datos de Grid a través de múltiples conexiones, aprovechando la función de copia parcial de GridFTP. También proporciona Balanceo de Carga por Fuerza Bruta, Basado en Historial y Dinámico para asignar bloques de datos. Coasignación por Fuerza Bruta: La coasignación por Fuerza Bruta funciona dividiendo el tamaño del archivo de manera equitativa entre los flujos disponibles. No aborda las diferencias de ancho de banda entre los distintos enlaces cliente-servidor. Coasignación basada en historial: El esquema de coasignación basado en historial mantiene los tamaños de bloque por flujo proporcionales a las tasas de transferencia predichas. Balanceo de carga conservador: Uno de sus métodos de coasignación dinámica es el Balanceo de Carga Conservador. La estrategia de coasignación dinámica de equilibrio de carga conservadora divide los conjuntos de datos solicitados en k bloques disjuntos de tamaño igual. Los servidores disponibles se asignan bloques individuales para entregar en paralelo. Cuando un servidor termina de entregar un bloque, se solicita otro, y así sucesivamente, hasta que se descarga el archivo completo. Las cargas en los flujos coasignados se ajustan automáticamente porque los servidores más rápidos entregarán más rápidamente proporcionando porciones más grandes del archivo. Equilibrio de carga agresivo: Otra estrategia dinámica de colocación conjunta, presentada en [17], es el Equilibrio de carga agresivo. La estrategia de co-asignación dinámica de equilibrio de carga agresiva presentada en [17] añade funciones que modifican las entregas de tamaño de bloque al: (1) aumentar progresivamente las cantidades de datos solicitadas a servidores más rápidos, y (2) reducir las cantidades de datos solicitadas a servidores más lentos o dejar de solicitar datos de ellos por completo. Las estrategias de coasignación descritas anteriormente no solucionan la limitación de que los servidores más rápidos tengan que esperar a que el servidor más lento entregue su último bloque. En la mayoría de los casos, esto desperdicia mucho tiempo y disminuye el rendimiento general. Por lo tanto, proponemos un enfoque eficiente llamado Recursivo-Ajuste Co-Asignación y basado en una arquitectura de co-asignación. Mejora la co-asignación dinámica y reduce el tiempo de espera, mejorando así el rendimiento general de la transferencia. Un SERVICIO DE SELECCIÓN DE RÉPLICAS EFICIENTE Construimos un servicio de selección de réplicas para permitir a los clientes seleccionar los servidores de réplicas mejores en entornos de Data Grid. Consulte a continuación para obtener una descripción detallada. 4.1 Escenario de Selección de Réplicas Nuestro modelo propuesto de selección de réplicas se ilustra en [23], que muestra cómo un cliente identifica la mejor ubicación para una transferencia de réplica deseada. El cliente primero inicia sesión en un sitio local y ejecuta la aplicación de la plataforma Data Grid, la cual verifica si los archivos están disponibles en el sitio local. Si están presentes en el sitio local, la aplicación accede a ellos inmediatamente; de lo contrario, pasa los nombres de archivo lógicos al servidor del catálogo de réplicas, que devuelve una lista de ubicaciones físicas para todas las copias registradas. La aplicación envía esta lista de ubicaciones de réplicas a un servidor de selección de réplicas, que identifica las ubicaciones de destino del sistema de almacenamiento para todas las operaciones de transferencia de datos candidatas. El servidor de selección de réplicas envía las posibles ubicaciones de destino al servidor de información, el cual proporciona mediciones de rendimiento y predicciones de los tres factores del sistema descritos a continuación. El servidor de selección de réplicas elige mejores ubicaciones de réplicas según estas estimaciones y devuelve la información de ubicación a la aplicación de transferencia, la cual recibe la réplica a través de GridFTP. Cuando la aplicación finaliza, devuelve los resultados al usuario. 4.2 Factores del sistema Determinar la mejor base de datos entre muchas con las mismas réplicas es un problema significativo. En nuestro modelo, consideramos tres factores del sistema que afectan la selección de réplicas: Ancho de banda de red: Este es uno de los factores más significativos de Data Grid ya que los archivos de datos en entornos de Data Grid suelen ser muy grandes. En otras palabras, los tiempos de transferencia de archivos de datos dependen estrechamente de las situaciones de ancho de banda de la red. Debido a que el ancho de banda de la red es un factor dinámico inestable, debemos medirlo con frecuencia y predecirlo de la manera más precisa posible. El Servicio Meteorológico de Red (NWS) es una herramienta poderosa para este propósito. Carga de la CPU: Las plataformas de cuadrícula consisten en números de sistemas heterogéneos, construidos con diferentes arquitecturas de sistema, por ejemplo, plataformas de clúster, supercomputadoras, PC. La carga de la CPU es un factor del sistema dinámico, y una carga pesada en la CPU del sistema afectará sin duda el proceso de descarga de archivos de datos desde el sitio. La medición se realiza mediante el Toolkit Globus / MDS. Estado de E/S: Los nodos de la cuadrícula de datos consisten en diferentes sistemas de almacenamiento heterogéneos. Los archivos de datos en las redes de datos son enormes. Si el estado de E/S de un sitio del que deseamos descargar archivos está muy ocupado, afectará directamente el rendimiento de la transferencia de datos. Medimos los estados de E/S utilizando las utilidades sysstat [15]. Nuestro Modelo de Costo de Selección de Réplicas La función objetivo de un modelo de costos para el almacenamiento de datos distribuidos y replicados es la puntuación de información del servicio de información. Enumeramos algunos factores influyentes para nuestro modelo de costos en la sección anterior. Sin embargo, debemos expresar estos factores en notación matemática para un análisis más detallado. Suponemos que el nodo i es el sitio local en el que el usuario o la aplicación inicia sesión, y el nodo j posee la réplica que el usuario o la aplicación desea. Los siete parámetros del sistema que considera nuestro modelo de costos de selección de réplicas son: Scorei-j: el valor de puntuación representa qué tan eficientemente un usuario o aplicación en el nodo i puede adquirir una réplica del nodo j BW jiP: porcentaje de ancho de banda disponible del nodo i al nodo j; ancho de banda actual dividido por el ancho de banda teórico más alto BBW: peso del ancho de banda de red definido por el administrador de Data Grid CPU jP: porcentaje de estados de inactividad de la CPU del nodo j WCPU: peso de carga de la CPU definido por el administrador de Data Grid OI jP /: porcentaje de estados de inactividad de E/S del nodo j WI/O: peso del estado de E/S definido por el administrador de Data Grid Definimos la siguiente fórmula general utilizando estos factores del sistema. Los tres factores influyentes en esta fórmula: WBW, WCPU y WI/O describen los pesos de la CPU, E/S y ancho de banda de red, los cuales pueden ser determinados por los administradores de la organización de Data Grid según los diversos atributos de los sistemas de almacenamiento en los nodos de Data Grid, ya que algunos equipos de almacenamiento no afectan la carga de la CPU. Después de varias mediciones experimentales, determinamos que el ancho de banda de la red es el factor más significativo que influye directamente en los tiempos de transferencia de datos. Cuando realizamos transferencias de datos utilizando el protocolo GridFTP, descubrimos que los estados de la CPU y E/S afectan ligeramente el rendimiento de la transferencia de datos. Sus valores respectivos en nuestro entorno de Data Grid son 80%, 10% y 10%. 4.4 Análisis de Costo de Co-Asignación Cuando los clientes descargan conjuntos de datos utilizando la tecnología de co-asignación de GridFTP, se incurre en tres costos de tiempo: el tiempo requerido para la autenticación del cliente en el servidor de GridFTP, el tiempo real de transmisión de datos y el tiempo de reensamblaje de bloques de datos. Tiempo de autenticación: Antes de una transferencia, el cliente debe cargar un proxy de Globus y autenticarse en el servidor GridFTP con las credenciales de usuario especificadas. El cliente luego establece un canal de control, configura los parámetros de transferencia y solicita la creación de un canal de datos. Cuando se ha establecido el canal, los datos comienzan a fluir. Tiempo de transmisión: El tiempo de transmisión se mide desde el momento en que el cliente comienza a transferir hasta el momento en que se completan todos los trabajos de transmisión, e incluye el tiempo requerido para restablecer los canales de datos entre las solicitudes de transferencia. Las vías de datos solo necesitan abrirse una vez y pueden manejar muchas transferencias antes de cerrarse. Esto permite que las mismas vías de datos se utilicen para múltiples transferencias de archivos. Sin embargo, los canales de datos deben reiniciarse explícitamente entre las solicitudes de transferencia. Esto es menos costoso en tiempo. Tiempo de combinación: la arquitectura de coasignación explota la característica de copia parcial de la herramienta de movimiento de datos GridFTP para permitir transferencias de datos a través de múltiples conexiones. Con la transferencia parcial de archivos, se pueden recuperar secciones de archivos de servidores de datos especificando solo los desplazamientos de inicio y fin de la sección. Cuando se entregan estas secciones de archivo, es posible que necesiten ser reensambladas; la operación de reensamblaje conlleva un costo adicional de tiempo. 5. ESTRATEGIA DE COASIGNACIÓN DINÁMICA La coasignación dinámica, descrita anteriormente, es el enfoque más eficiente para reducir la influencia de las variaciones de red entre clientes y servidores. Sin embargo, el tiempo de inactividad de los servidores más rápidos esperando a que el servidor más lento entregue el último bloque sigue siendo un factor importante que afecta la eficiencia general, el cual el Balanceo de Carga Conservador y el Balanceo de Carga Agresivo [17] no pueden evitar de manera efectiva. El enfoque propuesto en el presente documento, un mecanismo de asignación dinámica llamado Coasignación Recursiva-Ajustable, puede superar esto y, por lo tanto, mejorar el rendimiento de transferencia de datos. 5.1 Coasignación Recursiva-Ajustable La Coasignación Recursiva-Ajustable funciona ajustando continuamente la carga de trabajo de cada servidor de réplicas para que corresponda a su ancho de banda en tiempo real durante las transferencias de archivos. El objetivo es hacer que el tiempo de finalización esperado de todos los servidores sea el mismo. Como muestra la Figura 2, cuando se selecciona primero una sección de archivo apropiada, se divide en tamaños de bloque adecuados según los anchos de banda del servidor respectivos. El coasignador luego asigna los bloques a los servidores para la transferencia. En este momento, se espera que el tiempo de finalización de la transferencia sea consistente en E(T1). Sin embargo, dado que los anchos de banda del servidor pueden fluctuar durante las entregas de segmentos, el tiempo real de finalización puede ser diferente (línea sólida, en la Figura 2). Una vez que el servidor más rápido termina su trabajo en el tiempo T1, la siguiente sección se asigna nuevamente a los servidores. Esto permite que cada servidor termine su carga de trabajo asignada para el tiempo esperado en E(T2). Estos ajustes se repiten hasta que se complete la transferencia de todo el archivo. Servidor 1 Servidor 2 Servidor 3 Ronda 1 Ronda 2 E(T1) E(T2)T1 Archivo A Sección 1 Sección 2 ... ... ... Figura 2. El proceso de ajuste del proceso de coasignación recursiva se ilustra en la Figura 3. Cuando un usuario solicita el archivo A, el servicio de selección de réplicas responde con el subconjunto de todos los servidores disponibles definidos por la matriz de rendimiento máximo. El servicio de co-asignación recibe esta lista de servidores réplica seleccionados. Suponiendo que se seleccionan n servidores réplica, Si denota el servidor i tal que 1 i n. Luego se establece una conexión para la descarga de archivos con cada servidor. El proceso de Co-Asignación de Ajuste Recursivo es el siguiente. Una nueva sección de un archivo a asignar es primero definida. El tamaño de la sección, SEj, es: SEj = TamañoArchivoNoAsignado , (0 < < 1) (2) donde SEj denota la sección j tal que 1 ≤ j ≤ k, asumiendo que asignamos k veces para el proceso de descarga. Y así, hay k secciones, mientras que Tj denota el tiempo asignado a la sección j. UnassignedFileSize es la porción del archivo A que aún no se ha distribuido para su descarga; inicialmente, UnassignedFileSize es igual al tamaño total del archivo A. es la tasa que determina cuánto de la sección queda por asignar. Figura 3. El proceso de Co-Asignación de Ajuste Recursivo. En el siguiente paso, SEj se divide en varios bloques y se asigna a n servidores. Cada servidor tiene una tasa de transferencia en tiempo real al cliente de Bi, la cual es medida por el Servicio Meteorológico de Red (NWS) [18]. El tamaño de bloque por flujo desde SEj para cada servidor i en el tiempo Tj es: i n i ii n i iji zeUnFinishSiBBzeUnFinishSiSES -)( 11 (3) donde UnFinishSizei denota el tamaño de bloques de transferencia no finalizados asignados en rondas anteriores en el servidor i. UnFinishSizei es igual a cero en la primera ronda. Idealmente, dependiendo del ancho de banda en tiempo real en el momento Tj, se espera que cada flujo termine su carga de trabajo en el futuro. Esto cumple con nuestro requisito de minimizar el tiempo que los servidores más rápidos deben esperar a que el servidor más lento termine. Si, en algunos casos, las variaciones en la red degradan considerablemente las tasas de transferencia, UnFinishSizei puede exceder n i ii n i ij BBzeUnFinishSiSE 11 *)(, que es el tamaño total del bloque que se espera transferir después de Tj. En tales casos, el coasignador elimina los servidores de antemano y asigna SEj a otros servidores. Después de la asignación, todos los canales continúan transfiriendo bloques de datos. Cuando un canal más rápido termina sus bloques de datos asignados, el coasignador comienza a asignar nuevamente una sección no asignada del archivo A. El proceso de asignar bloques de datos 801 para ajustar el tiempo de finalización del flujo esperado continúa hasta que se haya asignado todo el archivo. 5.2 Determinar cuándo detener el ajuste continuo Nuestro enfoque obtiene nuevas secciones de archivos completos dividiendo rangos de archivos no asignados en cada ronda de asignación. Estas porciones no asignadas de los rangos de archivo se vuelven más pequeñas después de cada asignación. Dado que el ajuste es continuo, funcionaría como un bucle infinito si no estuviera limitado por una condición de parada. Sin embargo, ¿cuándo es apropiado detener el ajuste continuo? Proporcionamos dos criterios de monitoreo, LeastSize y ExpectFinishedTime, para permitir a los usuarios definir umbrales de parada. Cuando se alcanza un umbral, el servidor de coasignación deja de dividir el resto del archivo y asigna ese resto como la sección final. El criterio LeastSize especifica el archivo más pequeño que queremos procesar, y cuando la porción no asignada de UnassignedFileSize cae por debajo de la especificación de LeastSize, la división se detiene. El criterio ExpectFinishedTime especifica el tiempo restante que se espera que dure la transferencia. Cuando el tiempo de transferencia esperado de la porción no asignada de un archivo cae por debajo del tiempo especificado por ExpectFinishedTime, la división del archivo se detiene. El valor esperado del tiempo de descanso se determina por: 1 n i iBFileSizeUnAssigned (4) Estos dos criterios determinan el tamaño final de la sección asignada. Valores de umbral más altos inducirán menos divisiones y generarán costos de co-asignación más bajos, que incluyen el establecimiento de conexiones, negociación, reensamblaje, etc. Sin embargo, aunque el tiempo total de ajuste de la coalocación puede ser menor, las variaciones de ancho de banda también pueden ejercer más influencia. Por el contrario, valores de umbral más bajos inducirán ajustes más frecuentes en la carga de trabajo del servidor dinámico y, en el caso de mayores fluctuaciones en la red, resultarán en menos diferencias en el tiempo de finalización de la transferencia del servidor. Sin embargo, valores más bajos también aumentarán los tiempos de coasignación, y por lo tanto, aumentarán los costos de coasignación. Por lo tanto, el entorno de internet, los tamaños de archivo transferidos y los costos de coasignación deben considerarse todos al determinar los umbrales óptimos. 5.3 Reducción de la Sobrecarga de Reensamblaje El proceso de reensamblar bloques después de transferencias de datos utilizando tecnología de coasignación resulta en una sobrecarga adicional y disminuye el rendimiento general. El sobrecosto de reensamblaje está relacionado con el tamaño total del bloque, y podría reducirse mediante la actualización de las capacidades del hardware o el uso de algoritmos de software mejores. Proponemos un mecanismo de reensamblaje alternativo eficiente para reducir la sobrecarga de combinación añadida una vez que se han completado todas las transmisiones de bloques. Se diferencia del método convencional en el que el software comienza el ensamblaje después de que todos los bloques hayan sido entregados, comenzando a ensamblar bloques una vez que finalizan las primeras entregas. Por supuesto, esto hace necesario mantener el orden original de división. Estrategias de coasignación como el Balanceo de Carga Conservador y la Coasignación de Ajuste Recursivo producen bloques adicionales durante las transferencias de archivos y pueden beneficiarse al habilitar el reensamblaje durante las transferencias de datos. Si algunos bloques se ensamblan de antemano, el costo de tiempo para ensamblar los bloques restantes después de que todas las transferencias finalicen puede reducirse. 6. RESULTADOS EXPERIMENTALES Y ANÁLISIS En esta sección, discutimos el rendimiento de nuestra estrategia de Co-Asignación Recursiva de Ajuste. Evaluamos cuatro esquemas de coalocación: (1) Fuerza Bruta (Brute), (2) Basado en Historial (History), (3) Balance de Carga Conservador (Conservative) y (4) Coalocación Co-Ajustada Recursiva (Recursive). Analizamos el rendimiento de cada esquema comparando su tiempo de finalización de transferencia y el tiempo total de inactividad que los servidores más rápidos pasaron esperando a que el servidor más lento terminara de entregar el último bloque. También analizamos el rendimiento general en los diferentes casos. Realizamos experimentos de transferencia de datos de gran área utilizando nuestra herramienta cliente GUI de GridFTP. Ejecutamos nuestra herramienta de cliente de co-asignación en nuestra plataforma de pruebas en la Universidad de Tunghai (THU), en la ciudad de Taichung, Taiwán, y obtuvimos archivos de cuatro servidores réplica seleccionados: uno en la Universidad de Providence (PU), uno en la Escuela Secundaria Li-Zen (LZ), uno en la Escuela de Tecnología Hsiuping (HIT) y uno en la Escuela Secundaria Da-Li (DL). Todas estas instituciones están en Taiwán, y cada una está al menos a 10 km de la THU. La Figura 4 muestra nuestro banco de pruebas de la cuadrícula de datos. Nuestros servidores tienen instalado Globus 3.0.2 o una versión superior. Escuela Secundaria THU Li-Zen (LZ) HITCeleron 900 MHz 256 MB RAM 60 GB HD AMD Athlon(tm) XP 2400+ 1024 MB RAM 120 GB HD Pentium 4 2.8 GHz 512 MB RAM 80 GB HD Escuela Secundaria Da-Li (DL) Athlon MP 2000 MHz *2 1 GB RAM 60 GB HD Pentium 4 1.8 GHZ 128 MB RAM 40 GB HD Pentium 4 2.5 GHZ 512 MB RAM 80 GB HD Figura 4. En nuestro banco de pruebas de Data Grid, en los siguientes experimentos, establecimos = 0.5, el umbral de LeastSize en 10MB, y experimentamos con tamaños de archivo de 10 MB, 50 MB, 100 MB, 500 MB, 1000 MB, 2000 MB y 4000 MB. Para la comparación, medimos el rendimiento del Balanceo de Carga Conservador en cada tamaño utilizando los mismos números de bloques. La Figura 5 muestra una captura de pantalla de nuestra herramienta cliente GridFTP. Esta herramienta de cliente está desarrollada utilizando Java CoG. Permite un desarrollo de aplicaciones más fácil y rápido al fomentar la reutilización colaborativa de código y evitar la duplicación de esfuerzos entre entornos de resolución de problemas, portales científicos, middleware de Grid y pilotos colaborativos. La Tabla 1 muestra las tasas de transmisión promedio entre THU y cada servidor réplica. Estos números fueron obtenidos al transferir archivos de 500MB, 1000MB y 2000MB desde un único servidor réplica utilizando nuestra herramienta cliente GridFTP, y cada número es un promedio de varias ejecuciones. Tabla 1. Tasa de transmisión de extremo a extremo de GridFTP desde THU a varios servidores. Tasa de transmisión promedio del servidor: HIT 61.5 Mbps, LZ 59.5 Mbps, DL 32.1 Mbps, PU 26.7 Mbps. Figura 5. Nuestra herramienta cliente GridFTP analizó el efecto de servidores más rápidos esperando al servidor más lento para entregar el último bloque en cada esquema. La Figura 6(a) muestra el tiempo total de inactividad para diferentes tamaños de archivo. Tenga en cuenta que nuestro esquema de Co-Asignación Recursiva logró mejoras significativas en el rendimiento en comparación con otros esquemas para cada tamaño de archivo. Estos resultados demuestran que nuestro enfoque reduce eficientemente las diferencias en los tiempos de finalización de los servidores. Los resultados experimentales mostrados en la Figura 6(b) indican que nuestro esquema de comenzar la reensamblaje de bloques tan pronto como los primeros bloques han sido entregados completamente reduce el tiempo de combinación, ayudando así a estrategias de co-asignación como el Balance de Carga Conservador y la Co-Asignación de Ajuste Recursivo que producen más bloques durante las transferencias de datos. La Figura 7 muestra los resultados experimentales del tiempo total de finalización en una vista detallada de la estructura de costos. Los servidores estaban en PU, DL y HIT, con el cliente en THU. Las tres primeras barras para cada tamaño de archivo representan el tiempo para descargar el archivo completo desde un único servidor, mientras que las otras barras muestran descargas coasignadas utilizando los tres servidores. Nuestro esquema de coasignación terminó el trabajo más rápido que las otras estrategias de coasignación. Por lo tanto, podemos inferir que las principales ventajas que ofrece nuestra tecnología son tiempos de transmisión y combinación más bajos que otras estrategias de co-asignación. 0 20 40 60 80 100 120 140 160 180 200 100 500 1000 1500 2000 Tamaño del archivo (MB) Tiempo de espera (seg) Brute3 History3 Conservative3 Recursive3 0 10 20 30 40 50 60 70 80 90 100 500 1000 1500 2000 Tamaño del archivo (MB) Tiempo de combinación (seg) Brute3 History3 Conservative3 Recursive3 Figura 6. (a) Tiempos de inactividad para varios métodos; los servidores están en PU, DL y HIT. (b) Tiempos de combinación para varios métodos; los servidores están en PU, DL y HIT. En el siguiente experimento, utilizamos la estrategia de Coasignación Recursiva-Ajustable con varios conjuntos de servidores réplica y medimos el rendimiento general, donde el rendimiento general es: Rendimiento Total = Tamaño del archivo / Tiempo Total de Finalización (5). La Tabla 2 enumera todos los experimentos que realizamos y los conjuntos de servidores réplica utilizados. Los resultados en la Figura 8(a) muestran que el uso de tecnologías de coallocation no produjo ninguna mejora para tamaños de archivo más pequeños como 10MB. También muestran que en la mayoría de los casos, el rendimiento general aumentó a medida que aumentaba el número de flujos coasignados. Observamos que para nuestro banco de pruebas y nuestra tecnología de coasignación, el rendimiento general alcanzó su valor más alto en el caso REC3_2. Sin embargo, en el caso REC4, cuando agregamos un flujo al conjunto de servidores réplica, el rendimiento no aumentó. Por el contrario, disminuyó. Podemos inferir que la eficiencia de coasignación alcanzó la saturación en el caso REC3_2, y que flujos adicionales causaron sobrecarga adicional y redujeron el rendimiento general. Esto significa que más flujos de descarga no necesariamente resultan en un rendimiento más alto. Debemos elegir un número adecuado de flujos para lograr un rendimiento óptimo. Mostramos la vista detallada de la estructura de costos para el caso de REC3_2 y el caso de REC4 en la Figura 8(b). El costo detallado consiste en el tiempo de autenticación, tiempo de transferencia y tiempo de combinación. 0 100 200 300 400 500 600 PU1 DL1 HIT1 BRU3 HIS3 CON3 REC3 PU1 DL1 HIT1 BRU3 HIS3 CON3 REC3 PU1 DL1 HIT1 BRU3 HIS3 CON3 REC3 PU1 DL1 HIT1 BRU3 HIS3 CON3 REC3 500 1000 1500 2000 Tamaño del archivo (MB) Tiempo de finalización (seg) Tiempo de autenticación Tiempo de transmisión Tiempo de combinación Figura 7. Tiempos de finalización para varios métodos; los servidores están en PU, DL y HIT. Tabla 2. Los conjuntos de servidores réplica para todos los casos son: Case Servers PU1 PU DL1 DL REC2 PU, DL REC3_1 PU, DL, LZ REC3_2 PU, DL, HIT REC4 PU, DL, HIT, LZ 0 10 20 30 40 50 60 70 10 50 100 500 1000 1500 2000 Tamaño del archivo (MB) Rendimiento general (Mbits) PU1 DL1 REC2 REC3_1 REC3_2 REC4 0 10 20 30 40 50 60 70 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 10 50 100 500 1000 1500 2000 Tamaño del archivo (MB) Rendimiento general (Mbits) Tiempo de autenticación Tiempo de transmisión Tiempo de combinación Figura 8. (a) Rendimientos generales para varios conjuntos de servidores. (b) Vista detallada de la estructura de costos para el caso de REC3_2 y el caso de REC4. 7. CONCLUSIONES La arquitectura de coasignación proporciona un agente coordinado para asignar bloques de datos. Un trabajo previo mostró que el esquema de co-asignación dinámica conduce a mejoras en el rendimiento. Sin embargo, no puede manejar el tiempo de inactividad de los servidores más rápidos, que deben esperar a que el servidor más lento entregue su bloque final. Propusimos el esquema de Co-Asignación Recursiva-Ajustable para mejorar el rendimiento de transferencia de datos utilizando la arquitectura de co-asignación en [17]. En este enfoque, las cargas de trabajo de los servidores de réplica seleccionados se ajustan continuamente durante las transferencias de datos, y proporcionamos una función que permite a los usuarios definir un umbral final de bloque 803, de acuerdo con su entorno de cuadrícula de datos. Los resultados experimentales muestran la efectividad de nuestra técnica propuesta en mejorar el tiempo de transferencia y reducir el tiempo total de inactividad esperando al servidor más lento. También discutimos el costo de recombinación y proporcionamos un esquema efectivo para reducirlo. 8. REFERENCIAS [1] B. Allcock, J. Bester, J. Bresnahan, A. Chervenak, I. Foster, C. Kesselman, S. Meder, V. Nefedova, D. Quesnel y S. Tuecke, Gestión y Transferencia de Datos en Entornos de Redes Computacionales de Alto Rendimiento, Computación Paralela, 28(5):749-771, mayo de 2002. [2] B. Allcock, J. Bester, J. Bresnahan, A. Chervenak, I. Foster, C. Kesselman, S. Meder, V. Nefedova, D. Quesnel y S. Tuecke, Transporte de Datos Seguro y Eficiente y Gestión de Réplicas para la Computación de Alto Rendimiento con Datos Intensivos, Actas del Decimoctavo Simposio IEEE sobre Sistemas y Tecnologías de Almacenamiento Masivo, pp. 13-28, 2001. [3] B. Allcock, S. Tuecke, I. Foster, A. Chervenak y C. Kesselman. Protocolos y Servicios para la Ciencia de Datos Intensivos Distribuidos. Actas de ACAT2000, pp. 161-163, 2000. [4] A. Chervenak, E. Deelman, I. Foster, L. Guy, W. Hoschek, A. Iamnitchi, C. Kesselman, P. Kunszt y M. Ripeanu, Giggle: Un marco para la construcción de servicios de ubicación de réplicas escalables, Actas de SC 2002, Baltimore, MD, 2002. [5] A. Chervenak, I. Foster, C. Kesselman, C. Salisbury y S. Tuecke, La Data Grid: Hacia una arquitectura para la gestión distribuida y análisis de grandes conjuntos de datos científicos, Revista de Aplicaciones de Redes y Computadoras, 23:187-200, 2001. [6] K. Czajkowski, S. Fitzgerald, I. Foster y C. Kesselman, Servicios de Información de Grid para Compartir Recursos Distribuidos, Actas del Décimo Simposio Internacional de Computación Distribuida de Alto Rendimiento de IEEE (HPDC-1001), 181-194, agosto de 2001. [7] K. Czajkowski, I. Foster y C. Kesselman. Coasignación de recursos en rejillas computacionales, Actas del Octavo Simposio Internacional de Computación Distribuida de Alto Rendimiento de IEEE (HPDC-899), agosto de 1999. [8] F. Donno, L. Gaido, A. Ghiselli, F. Prelz y M. Sgaravatto, Prototipo 1 de DataGrid, Conferencia de Redes de TERENA, http://www.terena.nl/conferences/tnc2002/Papers/p5a2ghiselli.pdf, junio de 2002, [9] I. Foster, C. Kesselman y S. Tuecke. La Anatomía de la Red: Permitiendo Organizaciones Virtuales Escalables. Int. Revista de Aplicaciones de Supercomputadoras y Computación de Alto Rendimiento, 15(3), pp. 200-222, 2001. [10] I. Foster y C. Kesselman, Globus: Un conjunto de herramientas de infraestructura de metacomputación, Intl J. Supercomputer Applications, 11(2), pp. 115-128, 1997. [11] Global Grid Forum, http://www.ggf.org/ [12] W. Hoschek, J. Jaen-Martinez, A. Samar, H. Stockinger y K. Stockinger, Gestión de datos en un Proyecto Internacional de Grid de Datos, Proc. del Primer Taller Internacional de Grid Computing IEEE/ACM - Grid 2000, Bangalore, India, diciembre de 2000. [13] IBM Red Books, Introducción a la Computación en Grid con Globus, IBM Press, www.redbooks.ibm.com/redbooks/pdfs/sg246895.pdf [14] H. Stockinger, A. Samar, B. Allcock, I. Foster, K. Holtman y B. Tierney, Replicación de archivos y objetos en rejillas de datos, Journal of Cluster Computing, 5(3):305-314, 2002. [15] Página de inicio de utilidades SYSSTAT, http://perso.wanadoo.fr/sebastien.godard/ [16] La Alianza Globus, http://www.globus.org/ [17] S. Vazhkudai, Facilitando la coasignación de transferencias de datos en rejillas, Proc. del Cuarto Taller Internacional sobre Computación en Rejilla, pp. 41-51, noviembre de 2003. [18] S. Vazhkudai y J. Schopf, Uso de técnicas de regresión para predecir grandes transferencias de datos, International Journal of High Performance Computing Applications (IJHPCA), 17:249-268, agosto de 2003. [19] S. Vazhkudai, S. Tuecke e I. Foster, Selección de réplicas en la malla de datos de Globus, Actas del 1er Simposio Internacional sobre Computación en Clúster y la Malla (CCGRID 2001), pp. 106-113, mayo de 2001. [20] S. Vazhkudai, J. Schopf, Predicción de transferencias de datos esporádicas en la malla, Actas del 11º Simposio Internacional de Computación Distribuida de Alto Rendimiento de IEEE (HPDC-11 02), pp. 188-196, julio de 2002. [21] S. Vazhkudai, J. Schopf e I. Foster, Prediciendo el rendimiento de transferencias de datos de amplia área, Actas del 16º Simposio Internacional de Procesamiento Paralelo y Distribuido (IPDPS 2002), pp. 34-43, abril de 2002, pp. 34-43. [22] R. Wolski, N. Spring y J. Hayes, El Servicio de Pronóstico del Tiempo de Red: Un Servicio de Pronóstico de Rendimiento de Recursos Distribuidos para Metacomputación, Sistemas Informáticos de Generación Futura, 15(5-6):757-768, 1999. [23] Chao-Tung Yang, Chun-Hsiang Chen, Kuan-Ching Li y Ching-Hsien Hsu, Análisis de rendimiento de la aplicación de tecnología de selección de réplicas para entornos de Grid de Datos, PaCT 2005, Notas de Conferencias en Ciencias de la Computación, vol. 3603, pp. 278-287, Springer-Verlag, septiembre de 2005. [24] Chao-Tung Yang, I-Hsien Yang, Kuan-Ching Li y ChingHsien Hsu, Un Esquema de Co-Asignación Recursiva en Entornos de Grid de Datos, ICA3PP 2005 Algoritmo y Arquitectura para Procesamiento Paralelo, Notas de Conferencias en Ciencias de la Computación, vol. 3719, pp. 40-49, Springer-Verlag, octubre de 2005. [25] X. Zhang, J. Freschl y J. Schopf, Un Estudio de Rendimiento de Servicios de Monitoreo e Información para Sistemas Distribuidos, Actas del 12º Simposio Internacional de Computación Distribuida de Alto Rendimiento de IEEE (HPDC-12 03), pp. 270-282, agosto de 2003.