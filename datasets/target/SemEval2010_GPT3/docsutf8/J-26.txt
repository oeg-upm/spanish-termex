Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica "Y", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \ i = S \ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \ i) = g(R) · Δh i (T \ i), y para cualquier i ∈ R, Δf i (S \ i) = h(T) · Δg i (R \ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \i) + g(R) · P i∈R ci Δ g i (R\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo "Read Once AND-of-OR" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28