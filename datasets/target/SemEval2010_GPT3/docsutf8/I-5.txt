Hacia la asignación de recursos basada en agentes autoorganizados en un entorno de múltiples servidores. Tino Schlegel1, Ryszard Kowalczyk2. Universidad de Tecnología Swinburne, Facultad de Tecnologías de la Información y la Comunicación, Hawthorn, 3122 Victoria, Australia {tschlegel1, rkowalczyk2}@ict.swin.edu.au. RESUMEN Las aplicaciones distribuidas requieren técnicas distribuidas para una asignación eficiente de recursos. Estas técnicas deben tener en cuenta la heterogeneidad y la posible falta de fiabilidad de los recursos y consumidores de recursos en entornos distribuidos. En este artículo proponemos un algoritmo distribuido que resuelve el problema de asignación de recursos en sistemas multiagentes distribuidos. Nuestra solución se basa en la autoorganización de agentes, la cual no requiere ningún facilitador o capa de gestión. La asignación de recursos en el sistema es un efecto puramente emergente. Presentamos los resultados del mecanismo de asignación de recursos propuesto en el entorno simulado de servidores múltiples estáticos y dinámicos. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial Distribuida]: Coherencia y coordinación Términos Generales Algoritmos 1. INTRODUCCIÓN Con la creciente popularidad de tecnologías de computación distribuida como Grid [12] y servicios web [20], Internet se está convirtiendo en una plataforma informática poderosa donde diferentes pares de software (por ejemplo, agentes) pueden utilizar recursos informáticos existentes para realizar tareas. En este sentido, cada agente es un consumidor de recursos que adquiere una cierta cantidad de recursos para la ejecución de sus tareas. Es difícil para un mecanismo central de asignación de recursos recopilar y gestionar la información sobre todos los recursos compartidos y consumidores de recursos para realizar de manera efectiva la asignación de recursos. Por lo tanto, se requieren soluciones distribuidas del problema de asignación de recursos. Los investigadores han reconocido estos requisitos [10] y han propuesto técnicas para la asignación de recursos distribuidos. Un tipo prometedor de enfoques distribuidos se basa en modelos de mercado económico [4], inspirados en los principios de los mercados de valores reales. Aunque esos enfoques estén distribuidos, generalmente requieren un facilitador para la fijación de precios, la búsqueda de recursos y la asignación de trabajos a los recursos [5, 9]. Otro problema principalmente sin resolver de esos enfoques es el ajuste fino del precio y el tiempo, las restricciones presupuestarias para permitir una asignación eficiente de recursos en sistemas grandes y dinámicos [22]. En este documento proponemos una solución distribuida del problema de asignación de recursos basada en la autoorganización de los consumidores de recursos en un sistema con recursos limitados. En nuestro enfoque, los agentes asignan dinámicamente tareas a servidores que proporcionan una cantidad limitada de recursos. En nuestro enfoque, los agentes seleccionan de forma autónoma la plataforma de ejecución para la tarea en lugar de pedir a un intermediario de recursos que realice la asignación. Todo el control necesario para nuestro algoritmo está distribuido entre los agentes en el sistema. Optimizan continuamente el proceso de asignación de recursos a lo largo de su vida para adaptarse a los cambios en la disponibilidad de recursos compartidos, aprendiendo de decisiones de asignación pasadas. La única información disponible para todos los agentes son la carga de recursos y la información sobre el éxito de la asignación de recursos de asignaciones pasadas. La información adicional sobre la carga de recursos de los servidores no se difunde. El concepto básico de nuestra solución está inspirado en el razonamiento inductivo y la racionalidad limitada introducida por W. Brian Arthur [2]. El mecanismo propuesto no requiere una autoridad central de control, una capa de gestión de recursos o introducir comunicación adicional entre agentes para decidir qué tarea se asigna en qué servidor. Demostramos que este mecanismo funciona bien en sistemas dinámicos con un gran número de tareas y puede adaptarse fácilmente a diferentes tamaños de sistemas. Además, el rendimiento general del sistema no se ve afectado en caso de que los agentes o servidores fallen o no estén disponibles. El enfoque propuesto proporciona una forma sencilla de implementar la asignación de recursos distribuidos y tiene en cuenta las tendencias del sistema multiagente hacia la autonomía, la heterogeneidad y la falta de fiabilidad de los recursos y agentes. Esta técnica propuesta puede ser fácilmente complementada por técnicas para encolar o rechazar solicitudes de asignación de recursos de agentes [11]. Tales capacidades de auto-gestión de agentes de software permiten una asignación de recursos confiable incluso en un entorno con proveedores de recursos poco confiables. Esto se puede lograr mediante las interacciones mutuas entre agentes aplicando técnicas de la teoría de sistemas complejos. La autoorganización de todos los agentes conduce a una autoorganización de los recursos del sistema 74 978-81-904262-7-5 (RPS) c 2007 IFAAMAS y es una propiedad emergente del sistema [21]. El resto del documento está estructurado de la siguiente manera: La siguiente sección proporciona una visión general del trabajo relacionado ya realizado en el área de equilibrio de carga, asignación de recursos o programación. La sección 3 describe el modelo de un entorno multiagente que se utilizó para realizar simulaciones con el fin de evaluar el rendimiento. Las secciones 4 y 5 describen el algoritmo de asignación de recursos distribuidos y presentan varios resultados experimentales. Un resumen, una conclusión y una perspectiva del trabajo futuro finalizan este documento. El trabajo relacionado La asignación de recursos es un problema importante en el área de la informática. En los últimos años, diferentes grupos de investigación han propuesto soluciones basadas en diferentes suposiciones y restricciones [7, 3, 15, 10]. En términos generales, la asignación de recursos es un mecanismo o política para la gestión eficiente y efectiva del acceso a un recurso limitado o conjunto de recursos por parte de sus consumidores. En el caso más simple, los consumidores de recursos solicitan a un intermediario central o despachador los recursos disponibles donde el consumidor de recursos será asignado. El corredor generalmente tiene pleno conocimiento de todos los recursos del sistema. Todas las solicitudes entrantes son dirigidas al corredor, quien es el único tomador de decisiones. En esos enfoques, el consumidor de recursos no puede influir en el proceso de decisión de asignación. El equilibrio de carga [3] es un caso especial del problema de asignación de recursos que utiliza un intermediario que intenta ser justo con todos los recursos al equilibrar la carga del sistema de manera equitativa entre todos los proveedores de recursos. Este mecanismo funciona mejor en un sistema homogéneo. Una técnica distribuida simple para la gestión de recursos es la planificación de capacidad mediante la negativa o encolamiento de agentes entrantes para evitar la sobrecarga de recursos [11]. Desde la perspectiva del propietario de recursos, esta técnica es importante para prevenir la sobrecarga en el recurso, pero no es suficiente para una asignación efectiva de recursos. Esta técnica solo puede proporcionar un buen complemento para los mecanismos de asignación de recursos distribuidos. La mayoría de las técnicas actuales para la asignación de recursos en herramientas de computación en malla como Globus [12] o Condor-G [13] coordinan la asignación de recursos con un subastador, árbitro, despachador, programador o gestor. Esos coordinadores suelen necesitar tener conocimiento global sobre el estado de todos los recursos del sistema. Un ejemplo de un algoritmo de asignación de recursos dinámicos es el proyecto Cactus [1] para la asignación de trabajos computacionales muy costosos. El valor de las soluciones distribuidas para el problema de asignación de recursos ha sido reconocido por la investigación [10]. Inspirados en los principios de los mercados de valores, se han desarrollado modelos de mercado económico para negociar recursos con el fin de regular la oferta y la demanda en la red. Estos enfoques utilizan diferentes estrategias de precios como modelos de precios publicados, diferentes métodos de subasta o un modelo de mercado de productos básicos. Los usuarios intentan comprar recursos baratos necesarios para ejecutar el trabajo, mientras que los proveedores intentan obtener la mayor ganancia posible y operar los recursos disponibles a plena capacidad. Se presenta una colección de diferentes técnicas de asignación de recursos distribuidos basadas en modelos de mercado en Clearwater [10]. Buyya et al. desarrollaron un marco de asignación de recursos basado en la regulación de la oferta y la demanda [4] para Nimrod-G [6] con el enfoque principal en los plazos de entrega de trabajos y las restricciones presupuestarias. El Modelo de Asignación de Recursos basado en Agentes (ARAM) para redes está diseñado para programar trabajos computacionalmente costosos utilizando agentes. La desventaja de este modelo es el extenso uso de intercambio de mensajes entre agentes para monitoreo periódico e intercambio de información dentro de la estructura jerárquica. Las subtareas de un trabajo migran a través de la red hasta que encuentran un recurso que cumpla con las restricciones de precio. El itinerario de migración de trabajos está determinado por los recursos que los conectan en diferentes topologías [17]. El mecanismo propuesto en este documento elimina la necesidad de intercambio periódico de información sobre las cargas de recursos y no requiere una topología de conexión entre los recursos. Se ha realizado un considerable trabajo sobre técnicas de asignación descentralizada de recursos utilizando teoría de juegos publicado en los últimos años. La mayoría de ellos están formulados como juegos repetitivos en un entorno idealista y simplificado. Por ejemplo, Arthur introdujo el problema del bar El Farol, que no permite una solución perfecta, lógica y racional. Es un problema de decisión mal definido que asume y modela el razonamiento inductivo. Probablemente sea uno de los ejemplos más estudiados de sistemas adaptativos complejos derivados de la forma en que los humanos deciden problemas mal definidos. Una variación del problema de El Farol es el llamado juego de la minoría [8]. En este juego de decisión repetitivo, un número impar de agentes debe elegir entre dos recursos basándose en información de éxito pasado, tratando de asignarse al recurso con la minoría. Galstyan et al. [14] estudiaron una variación con más de dos recursos, cambiando las capacidades de los recursos y la información de los agentes vecinos. Demostraron que los agentes pueden adaptarse de manera efectiva a las capacidades cambiantes en este entorno utilizando un conjunto de simples tablas de búsqueda (estrategias) por agente. Otra técnica distribuida que se emplea para resolver el problema de asignación de recursos se basa en el aprendizaje por refuerzo [18]. Similar a nuestro enfoque, un conjunto de agentes compiten por un número limitado de recursos basados únicamente en experiencias individuales previas. En este documento, el objetivo del sistema es maximizar el rendimiento del sistema garantizando la equidad de los recursos, medida como el tiempo promedio de procesamiento por unidad de trabajo. Se presenta un enfoque de asignación de recursos para redes de sensores basado en técnicas de autoorganización y aprendizaje por refuerzo en [16], con un enfoque principal en la optimización del consumo de energía de los nodos de la red. Propusimos un enfoque de equilibrio de carga autoorganizado para un único servidor con el objetivo de optimizar los costos de comunicación de agentes móviles. Un agente móvil rechazará una migración a un servidor de agente remoto si espera que el servidor de destino ya esté sobrecargado por otros agentes o tareas del servidor. Los agentes toman sus decisiones por sí mismos basándose en pronósticos de la utilización del servidor. En este documento se presenta una solución para un entorno de múltiples servidores sin tener en cuenta los costos de comunicación o migración. 3. DESCRIPCIÓN DEL MODELO Modelamos un sistema multiagente distribuido como una red de servidores L = {l1, . . . , lm}, agentes A = {a1, . . . , an} y tareas T = {T1, ..., Tm}. Cada agente tiene un número de tareas Ti que deben ser ejecutadas durante su vida útil. Una tarea Ti requiere U(Ti, t) recursos para su ejecución en el tiempo t, independientemente de su servidor de ejecución. Los recursos para la ejecución de tareas son proporcionados por cada servidor li. La ubicación de la ejecución de las tareas en general está especificada por el mapa L: T × t → L. Un agente debe conocer la existencia de recursos del servidor para asignar tareas en esos recursos. Escribimos LS (ai) The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 75 Recursos del Sistema Anfitrión l4 Anfitrión l3 Anfitrión l2 2a 3a 4a a Anfitrión l1 1a 6a5 T1 T2 T3 T4 T5 T6 Figura 1: Una ilustración de nuestro modelo de múltiples servidores con recursos exclusivos y compartidos para la ejecución del agente. para abordar el conjunto de recursos conocidos por el agente ai. Los recursos en el sistema pueden ser utilizados por todos los agentes para la ejecución de tareas. La cantidad de recursos proporcionados C(li, t) de cada servidor puede variar con el tiempo. La utilización de recursos de un servidor en el tiempo t se calcula utilizando la ecuación 1, sumando el consumo de recursos U(Tj, t) de cada tarea Tj que se ejecuta en el recurso en el tiempo t. Todas las unidades de recursos utilizadas en nuestro modelo representan métricas reales como memoria o ciclos de procesador. Además del caso en que la cantidad total de recursos del sistema es suficiente para ejecutar todas las tareas, también nos interesa el caso en que no se proporcionan suficientes recursos del sistema para cumplir con todas las solicitudes de asignación. Es decir, la capacidad total de recursos compartidos es menor que la cantidad de recursos solicitados por los agentes. En este caso, algunos agentes deben esperar con su solicitud de asignación hasta que se esperen recursos libres. El modelo de sistema multiagente utilizado para nuestras simulaciones está ilustrado en la Figura 1.4. ASIGNACIÓN DE RECURSOS AUTOORGANIZADA El algoritmo de asignación de recursos descrito en esta sección está integrado en cada agente. La única información necesaria para tomar una decisión de asignación de recursos para una tarea es la utilización del servidor de las asignaciones de tareas completadas en esos servidores. No hay una difusión adicional de información sobre la utilización de recursos del servidor o información sobre recursos libres. Nuestra solución demuestra que los agentes pueden autoorganizarse en un entorno dinámico sin necesidad de información de monitoreo activo que genere una gran sobrecarga de tráfico en la red. Además, no tenemos ninguna autoridad central de control. Todo comportamiento que conduce a la asignación de recursos es creado por la competencia efectiva de los agentes por recursos compartidos y es un efecto puramente emergente. Los agentes en nuestro sistema multiagente compiten por recursos o un conjunto de recursos para ejecutar tareas. La acción colectiva de estos agentes cambia el entorno y, con el paso del tiempo, tienen que adaptarse a estos cambios para competir de manera más efectiva en el entorno recién creado. Nuestro enfoque se basa en diferentes creencias de los agentes, representadas por predictores y diferente información sobre su entorno. Los agentes prefieren una asignación de tareas en un servidor con recursos disponibles. Sin embargo, no hay forma de estar seguro de la cantidad de recursos del servidor disponibles de antemano. Todos los agentes tienen las mismas preferencias y un agente asignará una tarea en un servidor si espera tener suficientes recursos libres para su ejecución. No hay comunicación entre agentes. Las acciones tomadas por los agentes influyen en las acciones de otros agentes de forma indirecta. El mecanismo aplicado está inspirado en el razonamiento inductivo y los principios de racionalidad limitada [2]. Se deriva de la forma humana de resolver problemas mal definidos. Los humanos tienden a tener en cuenta muchas hipótesis y actuar en base a la más plausible. Por lo tanto, cada agente lleva un registro del rendimiento de una colección privada de sus predictores y selecciona aquel que actualmente sea más prometedor para la toma de decisiones. 4.1 Algoritmo de asignación de recursos Esta sección describe el mecanismo de decisión para nuestra asignación de recursos autoorganizada. Todo el control necesario está integrado en los propios agentes. No hay una autoridad superior de control, capa de gestión para apoyo en la toma de decisiones o distribución de información. Todos los agentes tienen un conjunto de predictores para cada recurso con el fin de pronosticar la futura utilización de estos servidores para la asignación potencial de tareas. Para hacerlo, los agentes utilizan información histórica de asignaciones de tareas pasadas en esos recursos. Basándose en la utilización de recursos pronosticada, el agente tomará su decisión de asignación de recursos. Después de que la tarea haya finalizado su ejecución y devuelto los resultados al agente, se evalúan las actuaciones del predictor y se actualiza la información histórica. El Algoritmo 1 muestra el algoritmo de asignación de recursos para cada agente. El agente primero predice la carga de recursos de los próximos pasos para cada servidor con información histórica (línea 3-7). Si la carga de recursos predicha más el consumo de recursos de las tareas está por debajo de la última capacidad de servidor conocida, este servidor se agrega a la lista de candidatos para la asignación. El agente luego evalúa si se esperan recursos compartidos gratuitos para la asignación de tareas. En el caso de que no se esperen recursos gratuitos (línea 9), el agente explorará los recursos asignando la tarea a un servidor seleccionado al azar de entre todos los servidores no predecibles para recopilar información sobre la carga de recursos. Este es el caso estándar al comienzo del ciclo de vida del agente, ya que no hay información disponible sobre el entorno. La predicción de la carga de recursos en sí misma utiliza un conjunto de r predictores P(a, l) := {pi|1 ≤ i ≤ r} por servidor. Uno de los predictores pA ∈ P de cada conjunto se llama predictor activo, el cual pronostica la carga de recursos de los próximos pasos. Cada predictor es una función P: H → ℵ+ ∪ {0} del espacio de datos históricos H a un número entero no negativo, que es el valor pronosticado. Por ejemplo, un predictor podría pronosticar una carga de recursos igual a la cantidad promedio de recursos ocupados durante la última ejecución en este recurso. Un historial H de información de carga de recursos es una lista de hasta m elementos de historial hi = (xi, yi), que incluyen la fecha de observación xi y el valor observado yi. El elemento más reciente del historial es h0. Nuestro algoritmo utiliza un conjunto de predictores en lugar de solo uno, para evitar que todos los agentes tomen la misma decisión basada en el valor predicho, lo que invalidaría sus creencias. Imagina que solo un recurso compartido es conocido por un número de agentes que utilizan un predictor para pronosticar el 76 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Carga de Recursos Tiempo (a) Predictor6 Predictor7 Predictor 8 Predictor9 Predictor10 Predictor2 Predictor 4 Predictor 3 Predictor5 Predictor1 (b) Figura 2: (a) Información de carga de recursos recopilada de asignaciones de tareas anteriores que se utiliza para predicciones futuras. (b) Distribución de probabilidad de los predictores para seleccionar el nuevo predictor activo. mismo valor que la última utilización conocida de recursos del servidor. Todos los agentes que asignaron una tarea en un servidor que estaba ligeramente sobrecargado rechazarían otra asignación en este servidor, ya que esperan que el servidor vuelva a estar sobrecargado según las predicciones. Como resultado, el servidor tendría una gran cantidad de recursos libres. Un conjunto de diferentes predictores que predicen diferentes valores evita esta situación de invalidar las creencias de los agentes [19]. Un ejemplo de información de carga de recursos recopilada de las últimas 5 visitas de un agente a un recurso compartido se puede ver en la Figura 2(a). Muestra que el recurso fue visitado con frecuencia, lo que significa que había recursos gratuitos disponibles para la ejecución y no era necesario explorar otros servidores. Esto puede cambiar en el futuro ya que la carga de recursos ha aumentado significativamente recientemente. En el caso en que el conjunto de servidores que se predice que tienen recursos disponibles no esté vacío (línea 13), el agente selecciona uno de ellos para su asignación. Hemos implementado dos algoritmos alternativos para la selección de un servidor para la asignación de tareas. Algoritmo 1 Algoritmo de asignación de recursos de un agente 1 L ← ∅ //servidor con recursos libres 2 u ← U(T, t + 1) //consumo de recursos de la tarea 3 para todo P(a, l)|l ∈ LS (a) hacer 4 U(l) ← predicción de carga de recursos (P(a, l), t + 1) 5 si U(l) + u ≤ C(l) entonces 6 L ← L ∪ {P(a, l)} 7 fin si 8 fin para 9 si L = ∅ entonces 10 //todos los recursos compartidos impredecibles 11 E ← LS /{l ∈ LS (a)|P(a, l) ∈ L} 12 allocationServer ← un elemento aleatorio de E 13 else 14 allocationServer ← selección de servidor (L) 15 fin si 16 devolver allocationServer El Algoritmo 2 muestra el primer método, que es una selección no determinista según la previsibilidad de la utilización de recursos del servidor. Una distribución de probabilidad se calcula a partir de los niveles de confianza de las predicciones de recursos. El nivel de confianza depende de tres factores: la precisión del predictor activo, la cantidad de información histórica sobre el servidor y la edad promedio de la información histórica (ver Ecuación 3). El servidor con el nivel de confianza más alto tiene la mayor probabilidad de ser seleccionado como el servidor activo. G(P) = w1 · tamaño(H) m + w2 · Edad(H) máx Edad(H) + w3 · g(p) máx (g(p)) (3) donde: wi − pesos tamaño(H) − número de datos en el historial m − número máximo de valores históricos Edad(H) − edad promedio de los datos históricos g(p) − ver ecuación 4 Algoritmo 2 selecciónServidor(L) - mejor servidor predecible 1 para todos los P(a, l) ∈ L hacer 2 calcular G(P) 3 fin para 4 transformar todos los G(P) en una distribución de probabilidad 5 devolver l ∈ LS seleccionado de acuerdo con la distribución de probabilidad Algoritmo 3 selecciónServidor(L) - más recursos libres 1 para todos los P(a, l) ∈ L hacer 2 c(l) ← C(l) − Ul 3 fin para 4 devolver l ∈ LS |c(l) es máximo El segundo método de selección alternativo de un servidor del conjunto de servidores predichos con recursos libres es determinista y se muestra en el algoritmo 3. Se elige el servidor con la mayor cantidad esperada de recursos gratuitos del conjunto L de servidores con recursos gratuitos esperados. En el caso en que todos los agentes predigan que hay más recursos disponibles en un servidor en particular, todos los agentes asignarán la tarea a este servidor, lo que invalidaría las creencias de los agentes. Sin embargo, nuestros experimentos muestran que la información de historial individual y la selección no determinista del predictor activo generalmente evitan esta situación. En caso de que el algoritmo de asignación de recursos no devuelva ningún servidor (Alg. 1, línea 16), no se recomienda asignar un recurso. El agente no asignará la tarea a un recurso. Este caso ocurre solo si es posible predecir la carga de recursos para todos los servidores pero no se esperan recursos libres. Después de que la ejecución del agente haya finalizado, se realiza el proceso de evaluación descrito en el algoritmo 4. Este proceso se divide en tres casos. Primero, la tarea no fue asignada a un recurso. En este caso, el agente no puede decidir si la decisión de no asignar la tarea fue correcta o no. El agente luego elimina los datos históricos antiguos. Esto es necesario para una adaptación exitosa en el futuro. Si el agente no eliminara la información histórica antigua, la predicción siempre pronosticaría que no hay recursos disponibles gratuitos. El agente nunca asignaría una tarea a uno de los recursos en el futuro. La información histórica antigua se elimina del historial de recursos de los agentes utilizando una tasa de descomposición. La tasa de decaimiento es una función de distribución acumulativa que calcula la probabilidad de que un elemento histórico sea eliminado después de haber alcanzado un cierto The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 77 Edad de los datos históricos Tasa de decaimiento 0 1 más antiguo Figura 3: Tasa de decaimiento de la edad de la información histórica. La implementación actual utiliza una función de densidad de probabilidad constante en un dominio configurable. La Figura 3 muestra un ejemplo de una función de distribución acumulativa para la tasa de decaimiento. Dependiendo del entorno, la función de densidad de probabilidad debe ser modificada. Si el número de servidores potenciales por agente es alto, la información histórica debe mantenerse por más tiempo para evitar la exploración de recursos no explorados. Además, un entorno dinámico requiere información más actualizada para realizar predicciones más fiables. El segundo caso en el proceso de evaluación (Alg. 4, línea 5) describe las acciones tomadas después de que un servidor fue visitado por primera vez. El agente crea un nuevo conjunto de predictores para este servidor y registra la información histórica. Todos los predictores para este conjunto son elegidos al azar de un conjunto predefinido. g(p) = l i=0 ri (4) donde: ri = ⎧ ⎨ ⎩ 1 si la decisión i-ésima es correcta 0 si el resultado i-ésimo es desconocido −1 si la decisión i-ésima es incorrecta El caso general (Alg. 4, línea 8) es la evaluación después de que el agente asignó la tarea a un recurso. El agente evalúa todos los predictores del conjunto de predictores para este recurso al predecir la carga del recurso con todos los predictores basados en los datos históricos antiguos. Los predictores que hicieron una predicción correcta, lo que significa que la asignación de recursos fue correcta, recibirán una calificación positiva. Este es el caso en el que el recurso no estaba sobrecargado y se predijeron recursos libres para la ejecución, o el recurso estaba sobrecargado y este predictor habría evitado la asignación. Todos los predictores que predijeron valores que llevarían a decisiones incorrectas recibirán calificaciones negativas. En todos los demás casos, que incluye cuando no era posible hacer una predicción, se otorga una calificación neutral a los pronosticadores. Basándose en estas calificaciones de rendimiento, los niveles de confianza se calculan utilizando la ecuación 4. La confianza para todos los predictores que no pueden predecir con la información histórica actual sobre el servidor se establece en cero para evitar la selección de estos como el nuevo predictor activo. Estos valores se transforman en una distribución de probabilidad. Según esta distribución de probabilidad, el nuevo predictor activo se elige e implementa mediante una selección de ruleta. La Figura 2(b) ilustra las probabilidades de un conjunto de 10 predictores, las cuales han sido calculadas a partir de los niveles de confianza de los predictores. Aunque el predictor 9 tiene la probabilidad de selección más alta, no fue elegido por el proceso de selección de la ruleta como el predictor activo. Esta selección no determinista de predictores evita la invalidación de las creencias de los agentes en caso de que los agentes tengan el mismo conjunto de predictores. La precisión de la predicción, que es el error de la predicción en comparación con el valor observado, no se tiene en cuenta. Supongamos que el predictor activo predice ligeramente por encima de la capacidad de recursos, lo que no conduce a una asignación de recursos. De hecho, habría suficientes recursos disponibles para la ejecución. Una predicción menos precisa que está muy por debajo de la capacidad llevaría a la decisión correcta y, por lo tanto, es preferible. La última acción del algoritmo de evaluación (Alg. 4, línea 22) actualiza el historial con la información más reciente de carga de recursos del servidor. Los datos de la historia más antigua se sobrescriben si ya se han registrado m valores de historia para el servidor. Algoritmo 4 Evaluación de Decisiones 1 si l ∈ LE entonces 2 para todos los P(a, l)|l ∈ LS (a) hacer 3 evaporar datos históricos antiguos 4 fin para 5 sino si P(a, l) = nulo entonces 6 crear (P(a, l)) 7 actualizar H(l) 8 sino 9 para todos los p ∈ P(a, l) hacer 10 pred ← predicción de carga de recursos(p) 11 si (U(l) ≤ C(l) Y pred + U(a, t) ≤ C(l)) O (U(l) > C(l) Y pred + U(a, t) > C(l)) entonces 12 agregar calificación positiva(p) 13 sino si U(l) ≤ C(l) Y pred + U(a, t) > C(l) O U(l) ≤ C(l) Y pred + U(a, t) > C(l) entonces 14 agregar calificación negativa(p) 15 sino 16 agregar calificación neutral(p) 17 fin si 18 fin para 19 calcular todos los g(p); g(p) ← 0, si p no está funcionando 20 transformar todos los g(p) en una distribución de probabilidad 21 pA ← p ∈ P(a, l) es seleccionado de acuerdo a esta distribución de probabilidad 22 actualizar H(l) 23 fin si 4.2 Observaciones y Limitaciones del Enfoque Nuestro mecanismo de predicción utiliza varios tipos de predictores simples en lugar de uno sofisticado. Este método asegura que los agentes puedan competir de manera más efectiva en un entorno cambiante. Diferentes tipos de predictores son adecuados para diferentes situaciones y entornos. Por lo tanto, todos los predictores se evalúan después de cada decisión y se selecciona el predictor activo. Este carácter no determinista del nuevo predictor activo respalda que las creencias de los agentes no serán invalidadas, lo cual ocurre en el caso de que todos los predictores estén tomando la misma decisión. Especialmente si solo hay un recurso compartido disponible y todos los agentes tienen la opción de ir a este recurso compartido o no [19]. Nuestro enfoque de autoorganización es robusto frente a fallos de recursos o agentes en el sistema. Si se unen o se van, el sistema puede autoorganizarse rápidamente y adaptarse a las nuevas condiciones. No hay cuellos de botella clásicos ni un único punto de falla como en los mecanismos centralizados. Las limitaciones son la dependencia de la información de utilización de recursos históricos de otros servidores. Un pronóstico de la utilización de recursos de un servidor remoto solo es posible si un agente tiene una cantidad de información histórica sobre un recurso compartido. Si el número de servidores por agente es muy grande, no hay una manera eficiente de recopilar información histórica sobre los servidores remotos. Este problema ocurre si la cantidad de recursos compartidos proporcionados es de 78. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es limitada y no es suficiente para todos los consumidores de recursos. En este caso, un agente intentaría aleatoriamente todos los servidores conocidos hasta encontrar uno con recursos disponibles o no haya ninguno. En el peor de los casos, para cuando se prueben todos los servidores, la información histórica de los servidores ya estará desactualizada. EVALUACIÓN EXPERIMENTAL La primera parte de esta sección ofrece un breve resumen de la configuración de nuestro entorno de simulación. En el resto de la sección, se presentan y discuten los resultados de los experimentos. Todos los experimentos se llevan a cabo en un banco de pruebas especial que simula y modela un sistema multiagente. Hemos implementado este banco de pruebas en el lenguaje de programación Java, independiente de cualquier conjunto de herramientas de agente específico. Permite una variedad de experimentos en entornos estables y dinámicos con un número configurable de agentes, tareas y servidores. Se utiliza un modelo basado en eventos para activar todas las actividades en el sistema. Para todas las simulaciones, limitamos el número de datos históricos para cada servidor a 10, el número de calificaciones de rendimiento por predictor a 10 y asignamos 10 predictores a cada conjunto de predictores para cada agente. Todos los predictores son elegidos al azar de un conjunto predefinido arbitrario de 32 predictores del siguiente tipo. Los predictores difieren en diferentes ciclos o tamaños de ventana. - Predictor de n-ciclos: p(n) = yn utiliza el valor de la historia en la posición n-ésima desde el final. - Predictor de n-media: p(n) = 1 n · n i=1 yi utiliza el valor medio de los n últimos valores de la historia. - Predictor de regresión lineal de n: p(n, t) = a·t+b utiliza el valor de regresión lineal de los últimos n valores de la historia, donde a, b se calculan utilizando regresión lineal con ajuste de mínimos cuadrados considerando los últimos n datos de la historia. - Predictor de distribución de n: utiliza un valor aleatorio de la distribución de frecuencia de los n últimos valores de la historia. - Predictor de espejo de n: p(n) = 2 · H − yn utiliza la imagen de espejo alrededor de la media de todos los valores de la historia del n-ésimo valor de la historia. La eficiencia de nuestra propuesta de asignación de recursos autoorganizada se evalúa mediante el desarrollo de carga de recursos de cada servidor durante la simulación, así como el desarrollo acumulado de carga de recursos totales sobre todos los recursos compartidos. Las cargas de recursos para cada servidor se calculan utilizando la ecuación 1 como la suma del consumo de recursos de todos los agentes actualmente ejecutados en este servidor. La carga total de recursos del sistema se calcula como la suma de la carga de recursos de todos los recursos. El algoritmo de asignación de recursos autoorganizado tiene elementos aleatorios. Por lo tanto, los resultados presentados muestran valores medios y desviación estándar calculados sobre 100 experimentos repetidos. 5.1 Configuración Experimental Los siguientes parámetros tienen un impacto en el proceso de asignación de recursos. Damos una visión general de los parámetros y una breve descripción. - Agentes: El número de agentes involucrados en la asignación de recursos. Este número varía en los experimentos entre 650 y 750 dependiendo de la cantidad total de recursos del sistema disponibles. - Consumo de recursos: Cada tarea consume recursos del servidor para su ejecución. El consumo de recursos se asigna aleatoriamente a cada tarea antes de su asignación de un intervalo. El consumo de recursos se especifica en unidades de recursos que corresponden a métricas del mundo real como la memoria o los ciclos del procesador. - Servidor de inicio de agentes: Todos los agentes se encuentran en un servidor de inicio de agentes. Los recursos de esos servidores no son considerados en nuestra simulación y no afectan el rendimiento de la asignación de recursos. - Recursos del servidor: Los experimentos utilizan servidores con diferentes cantidades de recursos compartidos disponibles. El primer experimento se lleva a cabo en un entorno de servidor estático que proporciona la misma cantidad de recursos compartidos, mientras que el otro experimento varía los recursos de servidor disponibles durante la simulación. La cantidad total de recursos permanece constante en ambos experimentos. - Tiempo de ejecución: El tiempo de ejecución de una tarea para la ejecución, independiente de la plataforma de ejecución. Por esta vez, la tarea consume la cantidad asignada de recursos del servidor. Este parámetro se asigna aleatoriamente antes de la ejecución. - Tiempo de creación de la tarea: El tiempo antes de que se cree la siguiente tarea después de la finalización exitosa o fallida. Este parámetro influye en la antigüedad de la información histórica sobre los recursos y tiene una gran influencia en la duración de la fase inicial de adaptación. Este parámetro se asigna aleatoriamente después de que se haya completado la tarea. 5.2 Resultados Experimentales Esta sección muestra los resultados de experimentos seleccionados que demuestran el rendimiento de nuestro mecanismo propuesto de asignación de recursos. El primer experimento muestra el rendimiento en un entorno estable donde un número de agentes asignan tareas a servidores que proporcionan una cantidad constante de recursos. El segundo experimento se llevó a cabo en un entorno de servidor dinámico con un número constante de agentes. El primer experimento muestra nuestro modelo en un entorno estable de 3 servidores que proporcionan un total de 7000 unidades de recursos. La capacidad de recursos de cada servidor permanece constante durante el experimento. Utilizamos 650 agentes con los parámetros del tiempo de ejecución entre 1 y 15 unidades de tiempo y un tiempo de creación de tarea en el intervalo [0 − 30] unidades de tiempo. El consumo de recursos de las tareas se asigna aleatoriamente en el intervalo de [1 - 45] unidades de recurso. La Figura 4 muestra los resultados de 100 repeticiones de este experimento. La Figura 4(a) muestra que la cantidad total de recursos proporcionados es mayor que la demanda de recursos en promedio. Al comienzo del experimento, todos los agentes asignan sus tareas aleatoriamente en uno de los servidores disponibles y exploran las capacidades y utilizaciones de recursos disponibles durante aproximadamente 150 unidades de tiempo. Esta fase inicial de exploración muestra que la carga promedio de recursos de cada servidor tiene un nivel similar. Esto provoca una situación de sobrecarga en el servidor 1 debido a su baja capacidad de recursos compartidos, y una gran cantidad de recursos libres en el servidor 2. Los agentes que asignaron tareas al servidor 1 detectan la situación de sobrecarga y exploran de forma aleatoria otros servidores disponibles. Encuentran recursos gratuitos en el servidor 2. Después del período de aprendizaje, los agentes se han autoorganizado en este entorno estable y han encontrado una solución estable para la asignación de The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 79 0 250 500 750 1,000 1,250 1,500 Tiempo 0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 Carga de Recursos (a) Carga total de recursos versus capacidad total de recursos compartidos 0 250 500 750 1,000 1,250 1,500 Tiempo 0 500 1,000 1,500 2,000 2,500 Carga de Recursos (b) Carga de recursos servidor 0 0 250 500 750 1,000 1,250 1,500 Tiempo 0 500 1,000 1,500 2,000 2,500 Carga de Recursos (c) Carga de recursos servidor 1 0 250 500 750 1,000 1,250 1,500 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 Carga de Recursos (d) Carga de recursos servidor 2 Figura 4: Resultados del experimento 1 en un entorno estático de 3 servidores promediados sobre 100 repeticiones. todas las tareas. La desviación estándar de las cargas de recursos es pequeña para cada servidor, lo que indica que nuestro enfoque distribuido encuentra soluciones estables en casi cada ejecución. Este experimento utilizó el algoritmo 2 para la selección del servidor activo. También realizamos el mismo experimento con el mecanismo de selección de recursos más libre para seleccionar el servidor activo. La asignación de recursos para cada servidor es similar. La cantidad absoluta de recursos gratuitos por servidor es casi la misma. El Experimento 2 se llevó a cabo en un entorno dinámico de 3 servidores con un total de 750 agentes. La cantidad de recursos del servidor 0 y del servidor 1 cambia periódicamente, mientras que la cantidad total de recursos disponibles permanece constante. El servidor 0 tiene una capacidad inicial de 1000 unidades, mientras que el servidor 1 comienza con una capacidad de 4000 unidades. El cambio en la capacidad comienza después de 150 unidades de tiempo, que es aproximadamente al final de la fase de aprendizaje. La figura 5 (b, c, d) muestra el comportamiento de nuestra asignación de recursos autoorganizada en este entorno. Todos los agentes utilizan el mecanismo de selección de recursos más libres determinístico para seleccionar el servidor activo. Se puede observar en la Fig. 5(b) y 5(c) que el número de recursos asignados al servidor 0 y al servidor 1 cambia periódicamente con la cantidad de recursos proporcionados. Esto demuestra que los agentes pueden percibir los recursos disponibles en este entorno dinámico y son capaces de adaptarse a esos cambios. El desarrollo de la carga de recursos del servidor 2 (ver Fig. 5(d)) muestra un cambio periódico porque algunos agentes intentan asignar tareas a este servidor en caso de que su servidor previamente preferido reduzca la cantidad de recursos compartidos. La carga total de recursos de todos los recursos compartidos es constante a lo largo de los experimentos, lo que indica que todos los agentes asignan sus tareas a uno de los recursos compartidos. Fig. 4(a)). 6.
Fig. 4(a)). 6. CONCLUSIONES Y TRABAJO FUTURO En este artículo se presentó una técnica de asignación de recursos distribuida autoorganizativa para sistemas multiagente. Permitimos a los agentes seleccionar la plataforma de ejecución para sus tareas ellos mismos antes de cada ejecución en tiempo de ejecución. En nuestro enfoque, los agentes compiten por una asignación en uno de los 0 500 1,000 1,500 2,000 Tiempo 0 2,500 5,000 7,500 Carga de Recursos (a) Carga total de recursos versus capacidad total de recursos compartidos 0 500 1,000 1,500 2,000 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 Carga de Recursos (b) Carga de recursos servidor 1 0 500 1,000 1,500 2,000 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 Carga de Recursos (c) Carga de recursos servidor 2 0 500 1,000 1,500 2,000 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 Carga de Recursos (d) Carga de recursos servidor 3 Figura 5: Resultados del experimento 2 en un entorno de servidor dinámico promediado en 100 repeticiones. recurso compartido disponible. Los agentes perciben su entorno de servidor y adaptan sus acciones para competir de manera más eficiente en el nuevo entorno creado. Este proceso es adaptativo y tiene un fuerte retroalimentación, ya que las decisiones de asignación influencian indirectamente las decisiones de otros agentes. La asignación de recursos es un efecto puramente emergente. Nuestro mecanismo demuestra que la asignación de recursos puede ser realizada mediante la competencia efectiva de agentes individuales y autónomos. Ni necesitan coordinación o información de una autoridad superior ni se requiere una comunicación directa adicional entre agentes. Este mecanismo fue inspirado por el razonamiento inductivo y los principios de racionalidad limitada, lo que permite a los agentes adaptar sus estrategias para competir de manera efectiva en un entorno dinámico. En caso de que un servidor no esté disponible, los agentes pueden adaptarse rápidamente a esta nueva situación explorando nuevos recursos o permaneciendo en el servidor local si no es posible una asignación. Especialmente en entornos dinámicos y escalables como los sistemas de rejilla, se requiere un mecanismo robusto y distribuido para la asignación de recursos. Nuestro enfoque de asignación de recursos autoorganizados fue evaluado con una serie de experimentos de simulación en un entorno dinámico de agentes y recursos del servidor. Los resultados presentados para este nuevo enfoque de optimización de migración estratégica son muy prometedores y justifican una mayor investigación en un entorno real de sistema multiagente. Es una política distribuida, escalable y fácil de entender para la regulación de la oferta y la demanda de recursos. Todo el control se implementa en los agentes. Un mecanismo de decisión simple basado en diferentes creencias del agente crea un comportamiento emergente que conduce a una asignación efectiva de recursos. Este enfoque puede ser fácilmente ampliado o respaldado por mecanismos de equilibrio/cola de recursos proporcionados por los recursos. Nuestro enfoque se adapta a los cambios en el entorno pero no es evolutivo. No hay descubrimiento de nuevas estrategias por parte de los agentes. El conjunto de predictores permanece igual a lo largo de toda la vida. De hecho, creemos que esto podría mejorar aún más el comportamiento de los sistemas a lo largo de un período prolongado y podría ser el 80 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) investigará en el futuro. La evolución sería muy lenta y selectiva y no influiría en el comportamiento del sistema en un período a corto plazo que está cubierto por nuestros resultados experimentales. En un futuro cercano investigaremos si es posible una adaptación automática de la tasa de decaimiento de la información histórica en nuestro algoritmo y si puede mejorar el rendimiento de la asignación de recursos. La tasa de descomposición está actualmente predefinida y debe ser alterada manualmente dependiendo del entorno. Un gran número de recursos compartidos requiere información histórica más antigua para evitar una exploración de recursos demasiado frecuente. Por el contrario, un entorno dinámico con capacidades variables requiere información más actualizada para realizar predicciones más fiables. Somos conscientes de la larga fase de aprendizaje en entornos con un gran número de recursos compartidos conocidos por cada agente. En caso de que los agentes soliciten más recursos de los que los servidores compartidos proporcionan, todos los agentes explorarán aleatoriamente todos los servidores conocidos. Este proceso de adquirir información de carga de recursos sobre todos los servidores puede llevar mucho tiempo en el caso de que no se proporcionen recursos compartidos suficientes para todas las tareas. En el peor de los casos, para cuando se explore todos los servidores, la información histórica de algunos servidores podría estar desactualizada y la exploración comenzará de nuevo. En esta situación, es difícil para un agente recopilar eficientemente información histórica sobre todos los servidores remotos. Este tema necesita más investigación en el futuro. REFERENCIAS [1] G. Allen, W. Benger, T. Dramlitsch, T. Goodale, H.-C. Hege, G. Lanfermann, A. Merzky, T. Radke, E. Seidel y J. Shalf. Herramientas de Cactus para Aplicaciones de Red. En Cluster Computing, volumen 4, páginas 179-188, Hingham, MA, EE. UU., 2001. Kluwer Academic Publishers. [2] W. B. Arthur.
Editorial Kluwer Academic. [2] W. B. Arthur. Razonamiento inductivo y racionalidad limitada. American Economic Review (Papers and Proceedings), 84(2):406-411, mayo de 1994. [3] T. Bourke. Balanceo de carga del servidor. OReilly Media, 1ª edición, agosto de 2001. [4] R. Buyya. Gestión y programación de recursos distribuidos basada en economía para la computación en malla. Tesis doctoral, Universidad de Monash, Melbourne, Australia, mayo de 2002. [5] R. Buyya, D. Abramson, J. Giddy y H. Stockinger. Modelos económicos para la gestión de recursos y programación en la computación en malla. Número especial sobre Entornos de Computación en Red de la Revista Concurrency and Computation, 13-15(14):1507-1542, 2002. [6] R. Buyya, S. Chapin y D. DiNucci. Modelos arquitectónicos para la gestión de recursos en la red. En Actas del Primer Taller Internacional sobre Computación en Red, páginas 18-35. Springer LNCS, 2000. [7] T. L. Casavant y J. G. Kuhl. Una taxonomía de programación en sistemas informáticos distribuidos de propósito general. IEEE Transactions on Software Engineering, 14(2):141-154, febrero de 1988. [8] D. Challet y Y. Zhang. Aparición de la cooperación y la organización en un juego evolutivo. Physica A, 407(246), 1997. [9] K.-P. Chow y Y.-K. Kwok. En equilibrio de carga para computación multiagente distribuida. En IEEE Transactions on Parallel and Distributed Systems, volumen 13, páginas 787-801. IEEE, agosto de 2002. [10] S. H. Clearwater. Control basado en el mercado. Un paradigma para la asignación distribuida de recursos. World Scientific, Singapur, 1996. [11] C. Fl¨us. Planificación de capacidad de sistemas de agentes móviles para el diseño eficiente de aplicaciones de intranet. Tesis doctoral, Universidad de Duisburg-Essen (Alemania), febrero de 2005. [12] I. Foster y C. Kesselman. Globus: Un conjunto de herramientas de infraestructura de metacomputación. Revista Internacional de Aplicaciones de Supercomputación, 11(2):115-129, 1997. [13] J. Frey, T. Tannenbaum, I. Foster, M. Livny y S. Tuecke. Condor-G: Un agente de gestión de computación para redes de múltiples instituciones. Computación en clúster, 5(3):237-246, 2002. [14] A. Galstyan, S. Kolar y K. Lerman. Juegos de asignación de recursos con capacidades de recursos cambiantes. En Actas de la segunda conferencia internacional conjunta sobre agentes autónomos y sistemas multiagente, páginas 145 - 152, Melbourne, Australia, 2003. ACM Press, Nueva York, NY, EE. UU. [15] C. Georgousopoulos y O. F. Rana. Combinando enfoques basados en el estado y en el modelo para el equilibrio de carga de agentes móviles. En SAC 03: Actas del simposio de computación aplicada de ACM de 2003, páginas 878-885, Nueva York, NY, EE. UU., 2003. ACM Press. [16] G. Mainland, D. C. Parkes y M. Welsh. Asignación descentralizada y adaptativa de recursos para redes de sensores. En Actas del 2º Simposio USENIX sobre Diseño e Implementación de Sistemas de Red (NSDI 05), mayo de 2005. [17] S. Manvi, M. Birje y B. Prasad. Un modelo de asignación de recursos basado en agentes para rejillas computacionales. Sistemas Multiagente y de Red - Una Revista Internacional, 1(1):17-27, 2005. [18] A. Schaerf, Y. Shoham y M. Tennenholtz. Equilibrio de carga adaptativo: Un estudio en el aprendizaje multiagente. En Journal of Artificial Intelligence Research, volumen 2, páginas 475-500, 1995. [19] T. Schlegel, P. Braun y R. Kowalczyk. Hacia Agentes Móviles Autónomos con Comportamiento de Migración Emergente. En Actas de la Quinta Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 2006), Hakodate (Japón), páginas 585-592. ACM Press, mayo de 2006. [20] W3C. Actividad de servicios web, 2002. http://www.w3.org/2002/ws - última visita 23.10.2006. [21] M. M. Waldrop. Complejidad: La ciencia emergente en el límite entre el orden y el caos. Simon & Schuster, 1ª edición, 1992. [22] R. Wolsk, J. S. Plank, J. Brevik y T. Bryan. Analizando estrategias de asignación de recursos basadas en el mercado para la red computacional. En la Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, volumen 15, páginas 258-281. Sage Science Press, 2001. 

Editorial Sage Science, 2001. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 81