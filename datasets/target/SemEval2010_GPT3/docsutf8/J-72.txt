Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término "exactamente" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. 

MIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. 

Springer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.
ACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188