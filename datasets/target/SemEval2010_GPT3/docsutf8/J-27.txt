Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42