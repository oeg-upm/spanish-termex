BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de "Estoy vivo" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado.