Gestión Distribuida de Horarios Flexibles Stephen F. Smith, Anthony Gallagher, Terry Zimmerman, Laura Barbulescu, Zachary Rubinstein Instituto de Robótica, Universidad Carnegie Mellon 5000 Forbes Avenue, Pittsburgh PA 15024 {sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu RESUMEN Consideramos el problema de gestionar horarios en un entorno incierto y distribuido. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo es maximizar la calidad conjunta obtenida de las actividades ejecutadas por todos los agentes, dado que, durante la ejecución, eventos inesperados obligarán a realizar cambios en algunas actividades prescritas y reducirán la utilidad de ejecutar otras. Describimos una arquitectura de agente para resolver este problema que acopla dos mecanismos básicos: (1) una representación flexible del tiempo de la agenda de los agentes (utilizando una Red Temporal Simple) y (2) un procedimiento de reprogramación incremental. El primero se protege contra la incertidumbre temporal al permitir que la ejecución proceda a partir de un conjunto de soluciones factibles, y el segundo actúa para revisar el horario de los agentes cuando la ejecución se ve obligada a salir de este conjunto de soluciones o cuando los eventos de ejecución reducen el valor esperado de este conjunto de soluciones factibles. La coordinación básica con otros agentes se logra simplemente comunicando los cambios de horario a aquellos agentes con actividades interdependientes. Entonces, según lo permita el tiempo, se utiliza la infraestructura central de resolución de problemas locales para impulsar un proceso de generación de opciones y consultas entre agentes, con el objetivo de identificar oportunidades para mejorar la solución a través de un cambio conjunto. Utilizando un simulador para modelar el entorno, comparamos el rendimiento de nuestro sistema multiagente con el de un solucionador MDP centralizado esperado óptimo (pero no escalable). Categorías y Descriptores de Asignaturas I.2.11 [Metodologías de Computación]: Inteligencia ArtificialInteligencia Artificial Distribuida Términos Generales Algoritmos, Diseño 1. INTRODUCCIÓN Las limitaciones prácticas de muchos entornos de aplicación requieren la gestión distribuida de planes y horarios en ejecución. Factores como la separación geográfica de los agentes ejecutores, limitaciones en el ancho de banda de comunicación, restricciones relacionadas con la cadena de mando y el alto ritmo de la dinámica de ejecución pueden impedir que un solo agente obtenga una visión global completa del problema, y por lo tanto, requieren decisiones colaborativas pero localizadas en la planificación y programación. En este documento, consideramos el problema de gestionar y ejecutar horarios en un entorno incierto y distribuido según lo definido por el programa Coordinadores de DARPA. Suponemos un equipo de agentes colaborativos, cada uno responsable de ejecutar una parte de un horario global preestablecido, pero ninguno posee una visión global del problema o la solución. El objetivo del equipo es maximizar la calidad total de todas las actividades ejecutadas por todos los agentes, dado que eventos inesperados obligarán a cambios en las actividades programadas previamente y alterarán la utilidad de ejecutar otras a medida que se desarrolla la ejecución. Para proporcionar una base para la coordinación distribuida, cada agente es consciente de las dependencias entre sus actividades programadas y las de otros agentes. A cada agente también se le proporciona un conjunto precalculado de opciones locales de contingencia (alternativas). Central en nuestro enfoque para resolver este problema multiagente es un marco de programación incremental flexible en el tiempo. En una representación de horarios flexibles de un agente, los intervalos de ejecución asociados con las actividades programadas no están fijos, sino que se les permite flotar dentro de las restricciones de tiempo y secuenciación de actividades impuestas. Esta representación permite el uso explícito de holgura como cobertura contra formas simples de incertidumbre ejecutiva (por ejemplo, duraciones de actividades), y su implementación subyacente como un modelo de Red Temporal Simple (STN) proporciona mecanismos eficientes de actualización y aplicación de consistencia. Se ha demostrado las ventajas de los marcos de tiempo flexibles en varios contextos de planificación y programación centralizada (por ejemplo, [12, 8, 9, 10, 11]). Sin embargo, su uso en entornos de resolución de problemas distribuidos ha sido bastante escaso ([7] es una excepción), y enfoques previos para la programación multiagente (por ejemplo, [6, 13, 5]) generalmente han operado con representaciones de horarios de agentes fijos en el tiempo. Definimos una arquitectura de agente centrada en la gestión incremental de un horario flexible de tiempos. La representación basada en STN subyacente se utiliza (1) para aflojar el acoplamiento entre los hilos del ejecutor y del planificador, (2) para retener una capacidad básica de absorber retrasos (o aceleraciones) inesperados en la ejecución, y (3) para proporcionar un criterio básico para detectar la necesidad de cambio de planificación. El cambio local es logrado por un programador incremental, diseñado para maximizar la calidad mientras intenta minimizar el cambio de horario. A esta infraestructura de gestión de horarios, añadimos dos mecanismos para la coordinación de múltiples agentes. La coordinación básica con otros agentes se logra mediante la simple comunicación de cambios en el horario local a otros agentes con actividades interdependientes. Superpuesto a esto se encuentra un proceso de generación y evaluación de opciones no locales (similar en algunos aspectos a [5]), dirigido a la identificación de oportunidades para mejorar globalmente a través de cambios conjuntos en los horarios de múltiples agentes. Este último proceso utiliza el análisis de conflictos detectados en la STN como base para generar opciones. El resto del documento está organizado de la siguiente manera. Comenzamos por resumir brevemente el problema general de programación distribuida de interés en nuestro trabajo. A continuación, presentamos la arquitectura del agente que hemos desarrollado para resolver este problema y esbozamos su funcionamiento. En las siguientes secciones, describimos los componentes de la arquitectura con más detalle, considerando a su vez cuestiones relacionadas con la ejecución de los horarios de los agentes, la revisión incremental de los horarios de los agentes y la coordinación de los cambios de horario entre múltiples agentes. Luego presentamos algunos resultados experimentales para indicar el rendimiento actual del sistema. Finalmente concluimos con una breve discusión de los planes de investigación actuales. 2. EL PROBLEMA DE LOS COORDINADORES Como se indicó anteriormente, el problema de gestión de horarios distribuidos que abordamos en este documento es el propuesto por el programa de Coordinadores de DARPA. El problema de los Coordinadores se preocupa generalmente por la ejecución colaborativa de una misión conjunta por un equipo de agentes en un entorno altamente dinámico. Una misión se formula como una red de tareas, las cuales son distribuidas entre los agentes por el simulador MASS de manera que ningún agente tenga una visión completa y objetiva de todo el problema. En cambio, cada agente recibe solo una vista subjetiva que contiene la porción de la red de tareas que se relaciona con las tareas terrestres de las que es responsable y cualquier tarea remota que tenga interdependencias con estas tareas locales. Un horario inicial precalculado también se distribuye a los agentes, y el horario de cada agente indica qué tareas locales deben ejecutarse y cuándo. Cada tarea tiene un valor de calidad asociado que se acumula si se ejecuta con éxito dentro de sus restricciones, y el objetivo general es maximizar la calidad obtenida durante la ejecución. Figura 2: Vista subjetiva para el Agente 2. A medida que avanza la ejecución, los agentes deben reaccionar a resultados inesperados (por ejemplo, retrasos en las tareas, fallos) y cambios en la misión (por ejemplo, nuevas tareas, cambios en los plazos) generados por el simulador, reconocer cuándo las tareas programadas ya no son factibles o deseables, y coordinarse entre sí para tomar acciones correctivas de reprogramación que maximicen la calidad y mantengan el avance de la ejecución de la misión en general. Los problemas se especifican formalmente utilizando una versión del lenguaje TAEMS (Análisis de Tareas, Modelado del Entorno y Simulación) [4] llamada C TAEMS [1]. Dentro de C TAEMS, las tareas se representan jerárquicamente, como se muestra en el ejemplo en la Figura 1. En el nivel más alto y abstracto, la raíz del árbol es una tarea especial llamada grupo de tareas. En niveles sucesivos, las tareas constituyen actividades agregadas, las cuales pueden descomponerse en conjuntos de subtareas y/o actividades primitivas, denominadas métodos. Los métodos aparecen a nivel de hoja de las estructuras de tareas de C TAEMS y son aquellos que son directamente ejecutables en el mundo. Cada método declarado m solo puede ser ejecutado por un agente especificado (denotado por ag : AgenteN en la Figura 1) y cada agente puede estar ejecutando como máximo un método en cualquier momento dado (es decir, los agentes son recursos de capacidad unitaria). Las duraciones y la calidad de los métodos suelen especificarse como distribuciones de probabilidad discretas, por lo que solo se conocen con certeza una vez que se han ejecutado. También es posible que un método falle inesperadamente durante la ejecución, en cuyo caso la calidad informada es cero. Para cada tarea, se define una función de acumulación de calidad qaf, que especifica cuándo y cómo una tarea acumula calidad a medida que se ejecutan sus subtareas (métodos). Por ejemplo, una tarea con un qaf mínimo acumulará la calidad de su hijo con la calidad más baja si todos sus hijos ejecutan y acumulan calidad positiva. Las tareas con la suma o el máximo de qafs adquieren calidad tan pronto como un niño las ejecute con calidad positiva; como sugieren sus nombres de qaf, sus valores respectivos serán en última instancia la calidad total o máxima de todos los niños que las ejecutaron. Una tarea de suma sincronizada acumulará calidad solo para aquellos niños que comiencen la ejecución simultáneamente con el primer niño que ejecuta, mientras que una tarea de exactamente uno acumulará calidad solo si precisamente uno de sus niños ejecuta. Las interdependencias entre tareas/métodos en el problema se modelan a través de efectos no locales (ENL). Se pueden especificar dos tipos de NLEs: duro y suave. Para simplificar, las Figuras 1 y 2 muestran solo valores fijos para la calidad del método y la duración. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 485 precondiciones causales: por ejemplo, el habilita nle en la Figura 1 estipula que el método objetivo M5 no puede ser ejecutado hasta que el método fuente M4 acumule calidad. Las restricciones blandas, que incluyen facilitadores e impedimentos, no son obligatorias; sin embargo, cuando entran en juego, amplifican (o disminuyen) la calidad y duración de la tarea objetivo. Cualquier tarea o método dado también puede estar limitado por un tiempo de inicio más temprano y una fecha límite, especificando la ventana en la que puede ser ejecutado de manera factible. También es posible que a herede estas limitaciones de tareas ancestrales en niveles superiores de la estructura de tareas, y su ventana efectiva de ejecución será definida por la restricción más estricta de estas. La Figura 1 muestra la vista objetiva completa de un problema simple de 2 agentes. La Figura 2 muestra la vista subjetiva disponible para el agente 2 para el mismo problema. En lo que sigue, a veces utilizaremos el término actividad para referirnos genéricamente tanto a los nodos de tarea como a los de método. 3. RESUMEN DEL ENFOQUE Nuestro marco de solución combina dos principios básicos para hacer frente al problema de gestionar horarios de múltiples agentes en un entorno de ejecución incierto y bajo presión de tiempo. Primero está el uso de una representación de restricciones de solución basada en STN flexible, que permite que la ejecución sea guiada por un conjunto de horarios en lugar de una solución puntual única. Esto proporciona una cobertura básica contra la incertidumbre temporal y puede ser utilizado para modular la necesidad de revisión de la solución. El segundo principio es responder primero localmente a eventos excepcionales, y luego, según el tiempo lo permita, explorar opciones no locales (es decir, opciones que implican cambios por 2 o más agentes) para mejorar la solución global. Esto proporciona un medio para mantener el ritmo de la ejecución y para vincular la cantidad de esfuerzo invertido en la mejora de soluciones multiagente más globales al tiempo disponible. El tiempo de resolución de problemas, tanto locales como no locales, se minimiza aún más mediante el uso de un procedimiento central de programación incremental. Figura 3: Arquitectura del Agente. Nuestro marco de solución se concreta en la arquitectura del agente representada en la Figura 3. En su forma más básica, un agente consta de cuatro componentes principales: un Ejecutor, un Planificador, un Administrador de Estado Distribuido (DSM) y un Administrador de Opciones, todos los cuales comparten un modelo común del estado actual del problema y la solución que acopla una representación a nivel de dominio de la estructura de tareas subjetivas de c taems a una STN subyacente. En cualquier momento durante la operación, el horario actualmente instalado dicta el momento y la secuencia de las actividades a nivel de dominio que serán iniciadas por el agente. El Ejecutor, ejecutándose en su propio hilo, monitorea continuamente las condiciones habilitantes de varias actividades pendientes, y activa la siguiente actividad pendiente tan pronto como se satisfacen todas sus restricciones causales y temporales. Cuando se reciben los resultados de la ejecución del entorno (MASS) y/o cambios en las restricciones externas asumidas son recibidos de otros agentes, el modelo del estado actual de los agentes se actualiza. En los casos en que esta actualización genere inconsistencias en el STN o se reconozca que el horario local actual podría mejorarse, se invoca al Planificador, que se ejecuta en un hilo separado, para revisar la solución actual e instalar un nuevo horario. Cuando las restricciones de horario locales cambian ya sea en respuesta a una actualización del estado actual o a través de la manipulación por parte del Planificador, se invoca al DSM para comunicar estos cambios a los agentes interesados (es decir, aquellos agentes que comparten dependencias y tienen vistas subjetivas superpuestas). Después de responder localmente a una actualización de estado dada y comunicar las consecuencias, el agente utilizará cualquier tiempo de computación restante para explorar posibilidades de mejora a través de un cambio conjunto. El Administrador de Opciones utiliza el Programador (en este caso en modo hipotético) para generar una o más opciones no locales, es decir, identificar cambios en el horario de uno o más agentes para permitir que el agente local mejore la calidad de su horario. Estas opciones se formulan y se comunican como consultas a los agentes remotos correspondientes, quienes a su vez evalúan hipotéticamente el impacto de los cambios propuestos desde su perspectiva local. En aquellos casos en los que se verifica una mejora global, se comprometen cambios conjuntos. En las siguientes secciones consideramos con más detalle la mecánica de estos componentes. 4. EL PROGRAMADOR Como se indicó anteriormente, nuestro programador de agentes opera de forma incremental. Los marcos de programación incremental son ideales para dominios que requieren un acoplamiento estrecho entre el programador y la ejecución: en lugar de recalcular un nuevo horario en respuesta a cada cambio, responden rápidamente a los eventos de ejecución localizando los cambios y realizando ajustes en el horario actual para acomodar el evento. Existe un sesgo inherente hacia la estabilidad del horario que brinda un mejor respaldo para la continuidad en la ejecución. Esta última propiedad también es ventajosa en entornos de múltiples agentes, ya que la estabilidad de la solución tiende a minimizar la ondulación en los horarios de diferentes agentes. La combinación de la programación incremental con la programación de tiempos flexibles añade una ventaja adicional en un entorno de ejecución incierto y multiagente. Como se mencionó anteriormente, Slack se puede utilizar como cobertura contra los tiempos de ejecución inciertos de los métodos. También proporciona una base para suavizar el impacto de las interdependencias entre agentes. En esta sección, resumimos el planificador central que hemos desarrollado para resolver el problema de los Coordinadores. En las secciones siguientes discutimos su uso en la gestión de la ejecución y la coordinación con otros agentes. 4.1 Representación de la Solución STN Para mantener el rango de valores admisibles para los tiempos de inicio y finalización de varios métodos en la programación de agentes dada. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), todas las restricciones de problemas y programación que afectan estos tiempos están codificadas en una Red Temporal Simple (STN) subyacente. Un STN representa restricciones temporales como un grafo G < N, E >, donde los nodos en N representan el conjunto de puntos temporales de interés, y las aristas en E son distancias entre pares de puntos temporales en N. Un punto temporal especial, llamado cero calendario, ancla la red y tiene el valor 0. Las restricciones en las actividades (por ejemplo, tiempo de liberación, tiempo de vencimiento, duración) y las relaciones entre actividades (por ejemplo, relación padre-hijo, habilita) se representan uniformemente como restricciones temporales (es decir, aristas) entre los puntos relevantes de inicio y finalización del tiempo. El horario de un agente se designa como un orden total de métodos seleccionados al establecer restricciones de precedencia entre los puntos finales e iniciales de cada par ordenado. A medida que se insertan nuevos métodos en un cronograma o las actualizaciones de estado externo requieren ajustes a las restricciones existentes (por ejemplo, la sustitución de una restricción de duración real, el ajuste de un plazo), la red propaga restricciones y mantiene límites inferiores y superiores en todos los puntos temporales de la red. Esto se logra de manera eficiente mediante el uso de un algoritmo estándar de camino más corto entre todos los pares; en nuestra implementación, aprovechamos un procedimiento incremental basado en [2]. A medida que se actualizan los límites, se realiza una verificación de consistencia para la presencia de ciclos negativos, y la ausencia de dicho ciclo garantiza la viabilidad temporal continua de la red (y, por lo tanto, del cronograma). De lo contrario, se ha detectado un conflicto y es necesario realizar cierta cantidad de retracción de restricciones para restaurar la viabilidad. 4.2 Mantener horarios de alta calidad El programador consta de dos componentes básicos: un propagador de calidad y un asignador de actividades que trabajan en un bucle estrechamente integrado. El propagador de calidad analiza la jerarquía de actividades y recopila un conjunto de métodos que (si se programan) maximizarían la calidad del problema local de los agentes. Los métodos se recopilan sin tener en cuenta la contención de recursos; en esencia, el propagador de calidad resuelve de manera óptima un problema relajado en el que los agentes son capaces de realizar un número infinito de actividades al mismo tiempo. El asignador selecciona métodos de esta lista e intenta instalarlos en el horario de los agentes. La falta de hacerlo vuelve a invocar al propagador de calidad con la actividad problemática excluida. El Propagador de Calidad - El propagador de calidad realiza las siguientes acciones en la estructura de tareas de C TAEMS: • Calcula la calidad de todas las actividades en la estructura de tareas: La calidad esperada qual(m) de un método m se calcula a partir de la distribución de probabilidad de los resultados de ejecución. La calidad qual(t) de una tarea t se calcula aplicando su qaf a la calidad evaluada de sus hijos. • Genera una lista de contribuyentes para cada tarea: métodos que, si se programan, maximizarán la calidad obtenida por la tarea. • Genera una lista de activadores para cada tarea: métodos que, si se programan, son suficientes para calificar la tarea como programada. Los métodos en la lista de activadores se eligen para minimizar las demandas en la línea de tiempo de los agentes sin tener en cuenta la calidad. La primera vez que se invoca el propagador de calidad, se calculan las cualidades de todas las tareas y métodos y se determinan las listas iniciales de contribuyentes y activadores. Las llamadas subsiguientes al propagador ocurren cuando el asignador instala métodos en la línea de tiempo de los agentes: si el asignador falla en instalar un método, el propagador vuelve a calcular una nueva lista de contribuyentes y activadores. El Asignador de Actividades - El asignador de actividades busca instalar a los contribuyentes del grupo de tareas identificados por el propagador de calidad en la línea de tiempo de los agentes. Cualquier método actualmente programado que no aparezca en la lista de contribuyentes se desprograma primero y se elimina del cronograma. Los contribuyentes son luego preprocesados utilizando una heurística centrada en la calidad para crear una agenda ordenada en orden decreciente de calidad. Además, los métodos asociados con la tarea a (es decir, min, sumand) se agrupan consecutivamente dentro de la agenda. Dado que una tarea "and" acumula calidad solo si todos sus hijos están programados, esto sesga el proceso de programación hacia el fracaso temprano (y la regeneración de contribuyentes) cuando los métodos elegidos para el "and" no pueden asignarse juntos. El asignador saca de manera iterativa el primer método mnew de la agenda e intenta instalarlo. Esto implica primero verificar que todas las actividades que permiten el nuevo hayan sido programadas, mientras se intenta instalar cualquier habilitador que no lo esté. Si alguna de las actividades habilitadoras no se instala correctamente, la asignación falla. Cuando tiene éxito, las restricciones que vinculan las actividades habilitadoras con mnew se activan. El STN rechaza una restricción de habilitador inviable devolviendo un conflicto. En este evento, cualquier actividad habilitadora programada se desinstala y el asignador devuelve un fallo. Una vez que se garantiza la programación de los habilitadores, se busca un intervalo factible en la línea de tiempo de los agentes dentro de la ventana de tiempo de mnews y el asignador intenta insertar mnew entre dos métodos actualmente programados. A nivel del STN, la inserción de mnews rompe la restricción de secuenciación entre los dos métodos de línea de tiempo existentes e intenta insertar dos nuevas restricciones de secuenciación que enlazan mnew a estos métodos. Si estas inserciones tienen éxito, la rutina devuelve éxito; de lo contrario, los dos métodos de línea de tiempo existentes se vuelven a enlazar y se intenta asignar el siguiente espacio posible para la nueva inserción. 5. La dinámica de la ejecución. Mantener un horario flexible nos permite utilizar un enfoque basado en conflictos para reparar el horario: en lugar de reaccionar ante cada evento en la ejecución que pueda afectar el horario existente al calcular una solución actualizada, la STN puede absorber cualquier cambio que no genere un conflicto. En consecuencia, se minimizan los costos de computación (produciendo un nuevo horario) y de comunicación (informando a otros agentes de los cambios que les afectan). Un mecanismo básico necesario para modelar la ejecución en la STN es un modelo dinámico para el tiempo actual. Empleamos un modelo propuesto por [7] que establece un punto de tiempo actual y que incluye un enlace entre este y el punto de tiempo cero del calendario. A medida que se programa cada método, se establece una restricción de precedencia simple entre el punto de tiempo actual y el método. Cuando el planificador recibe una actualización del tiempo actual, el enlace entre el calendario-cero y el tiempo-actual se modifica para reflejar este nuevo tiempo, y la restricción se propaga a todos los métodos programados. Un segundo problema concierne a la sincronización entre el ejecutor y el planificador, como productor y consumidor del horario que se ejecuta en diferentes hilos dentro de un agente dado. Esta coordinación debe ser robusta a pesar de que el Sexto Congreso Internacional. La conferencia conjunta sobre agentes autónomos y sistemas multiagente (AAMAS 07) 487 necesita que el ejecutor comience los métodos para la ejecución en tiempo real, incluso mientras el planificador pueda estar reevaluando el horario para maximizar la calidad y/o transmitiendo un horario revisado. Si el ejecutor, por ejemplo, programa un método para la ejecución basado en el tiempo actual mientras el planificador está instanciando un horario revisado en el que ese método ya no es el siguiente a ser ejecutado, puede surgir un estado inconsistente dentro de la arquitectura del agente. Esto se aborda en parte mediante la introducción de una ventana de congelación; un período de tiempo corto (y ajustable) especificado más allá del tiempo actual dentro del cual cualquier actividad programada como elegible para comenzar en el horario actual no puede ser reprogramada por el programador. El programador se activa en respuesta a varios mensajes ambientales. Hay dos tipos de clases de mensajes ambientales que discutimos aquí como dinámicas de ejecución: 1) retroalimentación como resultado de la ejecución del método, tanto del propio agente como de otros agentes, y 2) cambios en el modelo C TAEMS correspondientes a un conjunto de evoluciones dirigidas por el simulador del problema y el entorno. Tales mensajes se denominan actualizaciones y son tratados por el programador como directivas para modificar permanentemente los parámetros en su modelo. Discutimos estos tipos de actualizaciones aquí y posponemos hasta más tarde la discusión de las consultas al programador, un modo de "qué pasaría si" iniciado por un agente remoto que busca una mayor calidad global. Ya sea que se invoque a través de una actualización o una consulta, la respuesta de los planificadores es una opción; esencialmente un horario completo de actividades que el agente puede ejecutar junto con métricas de calidad asociadas. Definimos una opción local como un horario válido para las actividades de un agente, que no requiere cambios en el horario de ningún otro agente. El diseño general para manejar la dinámica de ejecución tiene como objetivo programar en cualquier momento un comportamiento en el que se devuelva rápidamente una opción local que maximice la vista local de calidad, posiblemente seguida de horarios de mayor calidad a nivel global que impliquen coordinación entre agentes si los ciclos del planificador disponibles lo permiten. Por lo tanto, el modo de programación predeterminado para las actualizaciones es buscar la opción local de mayor calidad según la estrategia de búsqueda de los programadores, instanciar la opción como su horario actual y notificar al ejecutor de la revisión. 5.1 Respuesta a la ejecución de actividades Como se sugirió anteriormente, un horario comprometido consiste en una secuencia de métodos, cada uno con una ventana de tiempo de inicio designada [est, lst] (según lo proporcionado por la representación subyacente de STN). El ejecutor tiene la libertad de ejecutar un método en cualquier momento dentro de su ventana de tiempo de inicio, una vez que se hayan confirmado las condiciones adicionales habilitantes. Estas ventanas de tiempo de inicio programadas se establecen utilizando la duración esperada de cada método programado (derivada de las distribuciones de duración de los métodos asociados durante la construcción del horario). Por supuesto, a medida que se lleva a cabo la ejecución, las duraciones reales de los métodos pueden desviarse de estas expectativas. En estos casos, la flexibilidad mantenida en el horario puede ser utilizada para absorber parte de esta imprevisibilidad y modular la invocación de un proceso de revisión del horario. Considera el caso de un mensaje de finalización de método, uno de los mensajes ambientales que podrían comunicarse al planificador como una actualización del estado de ejecución. Si el tiempo de finalización coincide con la duración esperada (es decir, se completa exactamente como se esperaba), entonces la respuesta de los programadores es simplemente marcarlo como completado y el agente puede proceder a comunicar el momento en el que ha acumulado calidad a cualquier agente remoto vinculado a este método. Sin embargo, si el método se completa en un tiempo menor al esperado, podría ser necesario tomar medidas de reprogramación. La publicación de la duración real en el STN no introduce ningún potencial de conflicto en este caso, ya sea con los últimos tiempos de inicio (lsts) de los métodos locales o remotos que dependen de este método como facilitador, o con los métodos programados sucesivamente en la línea de tiempo de los agentes. Sin embargo, puede presentar una posibilidad para explotar el margen de programación no previsto. La representación de tiempos flexibles proporcionada por el STN ofrece un medio rápido para evaluar si el siguiente método en la línea de tiempo puede comenzar la ejecución inmediata en lugar de esperar a su hora de inicio más temprana previamente establecida (est). Si de hecho el est del próximo método programado puede regresar al tiempo actual una vez que se sustituye la restricción de duración real por la restricción de duración esperada, entonces el horario puede dejarse intacto y simplemente comunicarse de vuelta al ejecutor. Si, alternativamente, otras restricciones del problema impiden esta relajación del EST, entonces hay tiempo de inactividad forzado que puede ser aprovechado al revisar el horario, y se invoca al programador (siempre respetando el período de congelación). Si el método se completa más tarde de lo esperado, entonces no es necesario reprogramar bajo un horario de tiempos flexibles a menos que 1) el método termine más tarde que el último de la actividad programada posterior, o 2) termine más tarde que su fecha límite. Por lo tanto, solo invocamos al planificador si, al publicar el final tardío en la STN, se produce una violación de la restricción. En el último caso no se acumula ninguna calidad y se requiere reprogramar incluso si no hay conflictos con las actividades programadas posteriormente. Otros estados de ejecución que el agente puede recibir incluyen: • inicio del método - Si un método enviado para su ejecución comienza dentro de su ventana [est, lst], la respuesta es marcarlo como ejecutándose. Un método no puede comenzar antes de ser transmitido por el ejecutor, pero es posible que comience más tarde de lo solicitado. Si la hora de inicio publicada causa una inconsistencia en la STN (por ejemplo, porque la duración esperada del método ya no se puede acomodar), la restricción de duración en la STN se acorta en función de la distribución conocida hasta que se restablezca la consistencia o se requiera reprogramación. • fallo del método - Cualquier método en ejecución puede fallar inesperadamente, sin obtener calidad para el agente. En este punto, reprogramar está ordenado ya que el método puede permitir otras actividades o impactar significativamente la calidad en ausencia de reparación local. Nuevamente, el ejecutor procederá con la ejecución del siguiente método si su hora de inicio llega antes de que se confirme el horario revisado, y el planificador lo acomoda respetando la ventana de congelación. • el tiempo actual avanza. Una actualización sobre el tiempo actual puede llegar ya sea sola o como parte de cualquiera de las actualizaciones discutidas anteriormente. Si, al actualizar el enlace currenttime en el STN (como se describe arriba), se produce un conflicto, el estado de ejecución es inconsistente con el horario. En este caso, el programador continúa como si la ejecución fuera consistente con sus expectativas, sujeto a posibles actualizaciones posteriores. 488 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 5.2 Respondiendo a Actualizaciones del Modelo El agente también puede recibir dinámicamente cambios en el modelo C TAEMS subyacente de los agentes. Las revisiones dinámicas en las distribuciones de resultados para los métodos que ya están en la vista subjetiva de un agente pueden afectar la calidad evaluada y/o los valores de duración que dieron forma al horario actual. Del mismo modo, las revisiones dinámicas en los tiempos de lanzamiento y plazos designados para métodos y tareas que ya están en la vista subjetiva de un agente pueden invalidar un horario existente o presentar oportunidades para mejorar la calidad. También es posible durante la ejecución recibir actualizaciones en las que se proporcionan nuevos métodos y posiblemente estructuras de tareas completas al agente para su inclusión en su visión subjetiva. Los cambios en el modelo que implican restricciones temporales se manejan de manera muy similar a como se describe para el inicio y finalización de métodos, es decir, la reprogramación solo es necesaria cuando la publicación de las restricciones revisadas conduce a un conflicto en la STN. En el caso de cambios en el modelo no temporales, la acción de reprogramación se inicia siempre actualmente. 6. COORDINACIÓN INTER-AGENTE Después de haber respondido localmente a un resultado de ejecución inesperado o un cambio en el modelo, es necesario comunicar las consecuencias a los agentes con actividades interdependientes para que puedan alinear sus decisiones en consecuencia. Las respuestas que parecen ser buenas localmente pueden tener un efecto global subóptimo una vez que se realicen alineaciones, por lo tanto, los agentes deben tener la capacidad de buscar cambios de horario conjuntos mutuamente beneficiosos. En esta sección resumimos los mecanismos de coordinación proporcionados en la arquitectura de agentes para abordar estos problemas. 6.1 Comunicación de restricciones no locales Un medio básico de coordinación con otros agentes es proporcionado por el Mecanismo de Estado Distribuido (DSM), que es responsable de comunicar los cambios realizados en el modelo o programación de un agente dado a otros agentes interesados. Más específicamente, el DSM de un agente dado actúa para propagar cualquier cambio realizado en los límites de tiempo, calidad o estado de una tarea/método local a todos los demás agentes que tienen esa misma tarea/método como un nodo remoto en sus visiones subjetivas. Un agente receptor trata cualquier cambio comunicado como formas adicionales de actualizaciones, en este caso una actualización que modifica las restricciones actuales asociadas con tareas o métodos no locales (pero interdependientes). Estos cambios se manejan de manera idéntica a las actualizaciones que reflejan los resultados de la ejecución del horario, potencialmente activando el planificador local si se detecta la necesidad de reprogramación. 6.2 Generación de Opciones No Locales Como se mencionó en la sección anterior, la primera respuesta de los agentes a cualquier consulta o actualización (ya sea de la ejecución o de otro agente) es generar una o más opciones locales. Tales opciones representan cambios locales en el horario que son consistentes con todas las restricciones actualmente conocidas que provienen de los horarios de otros agentes, y por lo tanto pueden ser implementadas sin interacción con otros agentes. En muchos casos, sin embargo, un cambio de mayor alcance en los horarios de dos o más agentes puede producir una respuesta de mayor calidad. La exploración de oportunidades para tal acción coordinada por dos o más agentes es responsabilidad del Gerente de Opciones. Ejecutándose en un modo de prioridad inferior al del Executor y Scheduler, el Options Manager inicia un proceso de generación y evaluación de opciones no locales en respuesta a cualquier cambio de horario local realizado por el agente si las restricciones de tiempo de computación lo permiten. En general, una opción no local identifica ciertas relajaciones (a uno o más restricciones impuestas por métodos que son programados por uno o más agentes remotos) que permiten la generación de un horario local de mayor calidad. Cuando se encuentra, un agente coordinador utiliza una opción no local para formular consultas a cualquier otro agente involucrado con el fin de determinar el impacto de tales relajaciones de restricciones en sus horarios locales. Si el cambio de calidad combinado informado de un conjunto de una o más consultas relevantes es una ganancia neta, entonces el agente emisor señala a los otros agentes involucrados que se comprometan con este conjunto conjunto de cambios de horario. El Administrador de Opciones actualmente emplea dos estrategias de búsqueda básicas para generar opciones no locales, cada una explotando el planificador local en modo hipotético. Sincronización optimista: La sincronización optimista es una estrategia de generación de opciones no local donde la búsqueda se utiliza para explorar el impacto en la calidad si se hacen suposiciones optimistas sobre los habilitadores remotos actualmente no programados. Más específicamente, la estrategia busca métodos de contribuyentes que podrían ser, actualmente, no programados debido a que una o más tareas o métodos de habilitación remota (fuente) no están actualmente programados. Para cada método local de este tipo, se activan hipotéticamente los habilitadores remotos, y el planificador intenta construir un nuevo horario local bajo estas suposiciones optimistas. Si se tiene éxito, se genera una opción no local que especifica el valor del nuevo horario local de mayor calidad, las restricciones temporales en la actividad objetivo local, y el conjunto de actividades habilitadoras que deben ser programadas por agentes remotos para lograr esta calidad local. Las consultas necesarias que solicitan el impacto en la calidad de programar estas actividades son formuladas y enviadas a los agentes remotos relevantes. Para ilustrar, considera nuevamente el ejemplo en la Figura 1. La máxima calidad que el Agente1 puede contribuir al grupo de tareas es 15 (programando M1, M2 y M3). Suponga que este es el horario actual del Agente1. Dado este estado, la máxima calidad que el Agente2 puede contribuir al grupo de tareas es 10, y la calidad total del grupo de tareas sería entonces 15 + 10 = 25. Usando sincronización optimista, el Agente2 generará una opción no local que indica que si M5 se habilita, tanto M5 como M6 serían programados, y la calidad contribuida por el Agente2 al grupo de tareas sería de 30. El Agente2 envía una consulta M4 de programación obligatoria al Agente1. Debido a las restricciones de la ventana de tiempo, el Agente1 debe eliminar M3 de su horario para incluir M4, lo que resulta en un nuevo horario de menor calidad de 5. Sin embargo, cuando el Agente2 recibe esta respuesta de opción del Agente1, determina que la calidad total acumulada para el grupo de tareas sería de 5 + 30 = 35, una ganancia neta de 10. Por lo tanto, el Agente 2 le indica al Agente 1 que se comprometa con esta opción no local. Relajación impulsada por conflictos: una segunda estrategia para generar opciones no locales, denominada Relajación Dirigida por Conflictos, utiliza el análisis de conflictos de STN para identificar y priorizar las restricciones externas a relajar en caso de que se encuentre que un método en particular que aumentaría la calidad local no sea planificable. Recuerda que si un método no puede ser insertado de manera factible en el horario, intentar hacerlo generará un ciclo negativo. Dado este ciclo, el mecanismo avanza en tres pasos. Primero, se recopilan las restricciones involucradas en el ciclo. Segundo, en virtud de las conexiones en la STN con el modelo C TAEMS a nivel de dominio, este conjunto se filtra para identificar el subconjunto asociado con nodos remotos. Tercero, las restricciones en este subconjunto se retiran selectivamente a The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 4: Se añade una tarea de alta calidad a la estructura de tareas del Agente2. Figura 5: Si M4, M5 y M7 están programados, se detecta un conflicto por la STN. Determine si se restaura la consistencia de la STN. Si se tiene éxito, se genera una opción no local que indica qué restricción(es) remota(s) deben relajarse y en qué medida para permitir la instalación del nuevo horario local de mayor calidad. Para ilustrar esta estrategia, considera la Figura 5 donde el Agente1 tiene M1, M2 y M4 en su línea de tiempo, por lo tanto est(M4) = 21. El Agente 2 tiene M5 y M6 en su línea de tiempo, con est(M5) = 31 (M6 podría ser programado antes o después de M5). Supongamos que el Agente2 recibe una nueva tarea M7 con fecha límite 55 (ver Figura 4). Si el Agente2 pudiera programar M7, la calidad contribuida por el Agente2 al grupo de tareas sería de 70. Sin embargo, un intento de programar M7 junto con M5 y M6 conduce a un conflicto, ya que el est(M7) = 46, dur(M7) = 10 y lft(M7) = 55 (ver Figura 5). La relajación dirigida por conflictos por parte del Agente 2 sugiere relajar el lft(M4) en 1 tick a 30, y esta consulta se comunica al Agente 1. De hecho, al retirar cualquiera de los métodos M1 o M2 del horario, esta relajación puede ser acomodada sin pérdida de calidad para el Agente1 (debido al qaf mínimo). Tras la comunicación de este hecho, el Agente 2 señala para proceder. 7. RESULTADOS EXPERIMENTALES Una versión inicial del agente descrito en este documento fue desarrollada en colaboración con SRI International y sometida a la evaluación programática independiente realizada por Coordinators. Esta evaluación involucró más de 2000 instancias de problemas generadas aleatoriamente por un generador de escenarios que fue configurado para producir escenarios de diferentes Clases de Problemas, Descripción de Clases de Agentes, Calidad de Clases de Agentes y Solo Dinámicas OD. Sin NLEs. El 97.9% (390 problemas) La duración y calidad reales de la tarea varían según la distribución. INTER Interdependiente. Actividades de CADENAS frecuentes y 100% aleatorias (360 problemas) (especialmente facilitadas) encadenadas juntas 99.5% (360 problemas) a través de secuencias de NLEs habilitadores (1-4 cadenas/problema) TT Ajuste Temporal. La liberación - 94.9% (360 problemas) Las ventanas de plazo impiden que todas las tareas de alta calidad preferidas (de mayor duración) sean programadas. Los problemas de sincronización contienen un rango del 97.1% (360 problemas) de diferentes tareas de suma de sincronización NTA Nueva llegada de tareas. El modelo cTaems 99.0% (360 problemas) se ve aumentado con nuevas tareas dinámicamente durante la ejecución. Promedio general: 98.1% (2190 problemas) Desv. estándar: 6.96 Tabla 1: Rendimiento del agente del año 1 en la evaluación de Coordinadores. La calidad del agente es el porcentaje de duraciones óptimas dentro de seis clases de experimentos. Estas clases, resumidas en la Tabla 1, fueron diseñadas para evaluar aspectos clave de un conjunto de Agentes de programación distribuida Coordinadores, como su capacidad para manejar resultados de ejecución inesperados, cadenas de nles que involucran múltiples agentes y la programación efectiva de nuevas actividades que surgen inesperadamente en algún momento durante la ejecución del problema. Los problemas de evaluación del año 1 estaban limitados a ser lo suficientemente pequeños (3-10 agentes, 50-100 métodos) para que la comparación con un solucionador centralizado óptimo fuera factible. El equipo de evaluación utilizó un solucionador basado en MDP capaz de desenrollar todo el espacio de búsqueda para estos problemas, eligiendo para un agente en cada punto de decisión de ejecución la actividad más probable de producir la máxima calidad global. Esto estableció un punto de referencia desafiante para que los sistemas de agentes distribuidos lo comparen. La configuración de hardware utilizada por los evaluadores instanció y ejecutó un agente por máquina, dedicando una máquina separada al simulador MASS. Como se informa en la Tabla 1, el agente prototipo del año 1 se compara claramente de manera favorable con el punto de referencia en todas las clases, acercándose al óptimo de MDP en un promedio del 2% sobre el conjunto completo de 2190 problemas. Estos resultados son particularmente notables dado que el planificador basado en STN de cada agente hace muy poco razonamiento sobre la probabilidad de éxito de las secuencias de actividades que selecciona para ejecutar. Solo se adoptaron tácticas simples para abordar explícitamente dicha incertidumbre, como el uso de duraciones y calidad esperadas para las actividades y una política de excluir de consideración aquellas actividades con una probabilidad de falla superior al 75%. El rendimiento del agente, muy respetable, se puede atribuir al menos parcialmente al hecho de que la representación de tiempos flexibles utilizada por el programador le proporciona un importante margen de maniobra contra la incertidumbre de la ejecución y los eventos exógenos. El agente muestra su peor rendimiento en las clases del experimento TT (Temporal Tightness), y un examen de los registros de trazas del agente revela posibles razones. En aproximadamente la mitad de los problemas de TT en los que el agente del año 1 no cumple, las ventanas de tiempo especificadas dentro de las cuales un agente ac490 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) tiene actividades tan ajustadas en su programación que cualquier actividad programada que se ejecute con una duración mayor a la esperada, provoca un incumplimiento de la fecha límite. Esto constituye un caso en el que un razonamiento más sofisticado sobre la probabilidad de éxito beneficiaría a este agente. La otra mitad de los problemas de bajo rendimiento de TT implican actividades que dependen de relaciones de facilitación para encajar en sus ventanas de tiempo (recordemos que la facilitación aumenta la calidad y disminuye la duración). Las limitaciones en el razonamiento realizado por el planificador del año 1 a veces causan fallas al instalar un horario inicial altamente facilitado. Incluso cuando dichas actividades se instalan con éxito, tienden a ser propensas a incumplimientos de plazos. Si una actividad del lado de la fuente falla o excede su duración esperada, la duración más larga resultante de la actividad objetivo puede violar su plazo límite de tiempo. 8. ESTADO Y DIRECCIONES Nuestros esfuerzos de investigación actuales tienen como objetivo ampliar las capacidades del agente del Año 1 y escalar a problemas significativamente más grandes. Los objetivos de evaluación programática del segundo año requieren resolver problemas del orden de 100 agentes y 10,000 métodos. Esta escala impone demandas computacionales mucho más altas en todos los componentes de los agentes. Hemos completado recientemente una nueva implementación del agente prototipo diseñado para abordar algunos problemas de rendimiento reconocidos. Además de verificar que el rendimiento en los problemas del Año 1 se iguala o supera, recientemente hemos realizado algunas pruebas exitosas con el agente en unos pocos problemas de 100 agentes. Para abordar completamente varios problemas de ampliación, estamos investigando una serie de mecanismos de coordinación más avanzados. Para proporcionar una perspectiva más global a las decisiones de programación local, estamos introduciendo mecanismos para calcular, comunicar y utilizar estimaciones del impacto no local de nodos remotos. Para abordar mejor el problema de establecer puntos de sincronización entre agentes, ampliamos el uso de propietarios de tareas y protocolos específicos de QAF como un medio para dirigir la actividad de coordinación. Finalmente, planeamos explorar el uso de mecanismos de coordinación impulsados por STN más avanzados, incluyendo el uso de desacoplamiento temporal [7] para aislar las acciones de agentes interdependientes y la introducción de horarios de contingencia sensibles a la probabilidad. 9. AGRADECIMIENTOS La arquitectura del agente del Año 1 fue desarrollada en colaboración con Andrew Agno, Roger Mailler y Regis Vincent de SRI International. Este documento se basa en el trabajo apoyado por la Agencia de Proyectos de Investigación Avanzada del Departamento de Defensa (DARPA) bajo el Contrato # FA8750-05-C0033. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este documento son responsabilidad de los autores y no reflejan necesariamente las opiniones de DARPA. 10. REFERENCIAS [1] M. Boddy, B. Horling, J. Phelps, R. Goldman, R. Vincent, A. Largo, y B. Kohout. Especificación del lenguaje C taems v. 1.06, octubre de 2005. [2] A. Cesta y A. Oddi. Ganando eficiencia y flexibilidad en el problema temporal simple. En Proc. 3rd Int. Taller sobre Representación y Razonamiento Temporal, Key West FL, mayo de 1996. [3] R. Dechter, I. Meiri y J. Pearl. Redes de restricciones temporales. Inteligencia Artificial, 49:61-95, mayo de 1991. [4] K. Decker. TÆMS: Un marco para el análisis y diseño centrado en el entorno de mecanismos de coordinación. En G. OHare y N. Jennings, editores, Fundamentos de la Inteligencia Artificial Distribuida, capítulo 16, páginas 429-448. Wiley Inter-Science, 1996. [5] K. Decker y V. Lesser. Diseñando una familia de algoritmos de coordinación. En Proc. 1ro. Int. Conferencia sobre Sistemas Multiagente, San Francisco, 1995. [6] A. J. Garvey. Planificación en tiempo real de diseño a tiempo. Tesis doctoral, Univ. de Massachusetts, febrero de 1996. [7] L. Hunsberger. Algoritmos para un problema de desacoplamiento temporal en la planificación multiagente. En Proc. 18ª Conferencia Nacional de IA, 2002. [8] S. Lemai y F. Ingrand. Entrelazando la planificación temporal y la ejecución en dominios de robótica. En Proc. 19ª Conferencia Nacional de Inteligencia Artificial, 2004. [9] N. Muscettola, P. P. Nayak, B. Pell y B. C. Williams. Agente remoto: Ir audazmente a donde ningún sistema de IA ha llegado antes. Inteligencia Artificial, 103(1-2):5-47, 1998. [10] W. Ruml, M. B. Do, y M. Fromherz. Planificación y programación en línea de fabricación de alta velocidad. En Proc. ICAPS-05, Monterey, 2005. [11] I. Shu, R. Effinger, y B. Williams. Permitiendo una planificación rápida y flexible a través de un razonamiento temporal incremental con extracción de conflictos. En proceso. ICAPS-05, Monterey, 2005. [12] S. Smith y C. Cheng. Heurísticas basadas en Slack para la programación de satisfacción de restricciones. En Proc. 12ª Conferencia Nacional de IA, Wash DC, julio de 1993. [13] T. Wagner, A. Garvey y V. Lesser. Programación heurística dirigida por criterios. Revista Internacional de Razonamiento Aproximado, 19(1):91-118, 1998. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 491