Un método de Vectores de Soporte para optimizar la Precisión Promedio Yisong Yue Universidad de Cornell Ithaca, NY, EE. UU. yyue@cs.cornell.edu Thomas Finley Universidad de Cornell Ithaca, NY, EE. UU. tomf@cs.cornell.edu Filip Radlinski Universidad de Cornell Ithaca, NY, EE. UU. filip@cs.cornell.edu Thorsten Joachims Universidad de Cornell Ithaca, NY, EE. UU. tj@cs.cornell.edu RESUMEN El aprendizaje automático se utiliza comúnmente para mejorar los sistemas de recuperación clasificados. Debido a dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión media promedio (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes que optimizan el MAP no encuentran una solución óptima global o son computacionalmente costosos. Por el contrario, presentamos un algoritmo de aprendizaje SVM general que encuentra de manera eficiente una solución óptima global para una relajación directa de MAP. Evaluamos nuestro enfoque utilizando los corpus de la pista web TREC 9 y TREC 10 (WT10g), comparando con SVM optimizados para precisión y área bajo la curva ROC. En la mayoría de los casos mostramos nuestro método para producir mejoras estadísticamente significativas en las puntuaciones de MAP. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de Recuperación Términos Generales Algoritmo, Teoría, Experimentación 1. INTRODUCCIÓN Los sistemas de recuperación de información de última generación comúnmente utilizan técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no están optimizados para la medida de evaluación más utilizada, es decir, la Precisión Promedio Media (MAP). En cambio, los algoritmos actuales tienden a seguir uno de dos enfoques generales. El primer enfoque es aprender un modelo que estime la probabilidad de que un documento sea relevante dado una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento de MAP puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un MAP alto solo requiere encontrar un buen ordenamiento de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, probablemente necesitando más datos de entrenamiento para lograr el mismo rendimiento de MAP. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], área bajo la curva ROC [1, 5, 10, 11, 13, 21] o modificaciones del área bajo la curva ROC [4], y NDCG [2, 3]. Aprender un modelo para optimizar tales medidas podría resultar en un rendimiento de MAP subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento de MAP, se sabe que ni lograr una precisión óptima ni un área bajo la curva ROC pueden garantizar un rendimiento de MAP óptimo[7]. En este artículo, presentamos un enfoque general para aprender funciones de clasificación que maximizan el rendimiento de MAP. Específicamente, presentamos un algoritmo SVM que optimiza globalmente una relajación de pérdida de bisagra de MAP. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento de MAP al evitar pasos intermedios adicionales y heurísticas. El nuevo algoritmo también hace que sea conceptualmente tan fácil optimizar las SVM para MAP como anteriormente solo era posible para precisión y ROCArea. A diferencia del trabajo reciente que optimiza directamente el rendimiento de MAP realizado por Metzler & Croft [16] y Caruana et al. [6], nuestra técnica es eficiente computacionalmente al encontrar una solución óptima a nivel global. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar miles de características. Ahora describimos el algoritmo en detalle y proporcionamos la prueba de corrección. A continuación, proporcionamos un análisis del tiempo de ejecución. Concluimos con los resultados empíricos de experimentos en el corpus de la pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo y está disponible para uso público. EL PROBLEMA DEL APRENDIZAJE Siguiendo la configuración estándar del aprendizaje automático, nuestro objetivo es aprender una función h: X → Y entre un espacio de entrada X (todas las consultas posibles) y un espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h(x), consideraremos una función de pérdida ∆ : Y × Y → . ∆(y, ˆy) cuantifica la penalización por hacer la predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas específicas de rendimiento, las cuales explotaremos en http://svmrank.yisongyue.com para optimizar el MAP. Nos restringimos al escenario de aprendizaje supervisado, donde pares de entrada/salida (x, y) están disponibles para el entrenamiento y se asume que provienen de alguna distribución fija P(x, y). El objetivo es encontrar una función h tal que el riesgo (es decir, la pérdida esperada), R∆ P (h) = Z X×Y ∆(y, h(x))dP(x, y), se minimice. Por supuesto, P(x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, S = {(xi, yi) ∈ X × Y : i = 1, . . . , n}, el rendimiento de h en S puede medirse mediante el riesgo empírico, R∆ S (h) = 1 n ∑ i=1 n ∆(yi, h(xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y Y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos C = {d1, . . . ,d|C|}. Podemos definir la pérdida de precisión promedio como ∆map(y, ˆy) = 1 − MAP(rank(y), rank(ˆy)), donde rank(y) es un vector de los valores de rango de cada documento en C. Por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 teniendo un rango más alto que d2, rank(y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de clasificación, donde los documentos relevantes tienen un valor de clasificación 1 y los documentos no relevantes tienen un valor de clasificación 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin empates). Sea p = rango(y) y ˆp = rango(ˆy). La puntuación de precisión promedio se define como MAP(p, ˆp) = 1 rel X j:pj =1 Prec@j, donde rel = |{i : pi = 1}| es el número de documentos relevantes, y Prec@j es el porcentaje de documentos relevantes en los primeros j documentos en la clasificación predicha ˆy. MAP es la media de las puntuaciones de precisión promedio de un grupo de consultas. La mayoría de los algoritmos de aprendizaje se optimizan para precisión o ROCArea. Si bien optimizar estas medidas podría lograr un buen rendimiento de MAP, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de MAP. ROCArea asigna una penalización igual a cada desordenamiento de un par relevante/no relevante. Por el contrario, MAP asigna mayores penalizaciones a los errores de ordenamiento más arriba en la clasificación predicha. Usando nuestra notación, el Área bajo la Curva ROC (ROCArea) se puede definir como ROC(p, ˆp) = 1 rel · (|C| − rel) X i:pi=1 X j:pj =0 1[ˆpi>ˆpj ], donde p es el ranking verdadero (débil), ˆp es el ranking predicho, y 1[b] es la función indicadora condicionada a b. Doc ID 1 2 3 4 5 6 7 8 p 1 0 0 0 0 1 1 0 rank(h1(x)) 8 7 6 5 4 3 2 1 rank(h2(x)) 1 2 3 4 5 6 7 8 Tabla 1: Ejemplo y Modelos Supongamos que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, h1 y h2, como se muestra en la Tabla 1. Estas dos hipótesis predicen un ranking para la consulta x sobre un corpus de ocho documentos. Tabla 2: Rendimiento de los Modelos de Juguete La Tabla 2 muestra las puntuaciones de MAP y ROCArea de h1 y h2. Aquí, un método de aprendizaje que optimiza para el Área bajo la curva ROC elegiría h2 ya que esto resulta en un puntaje de Área bajo la curva ROC más alto, pero esto produce un puntaje de MAP subóptimo. 2.2 MAP vs Precisión Usando un ejemplo muy similar, ahora demostramos cómo optimizar para la precisión podría resultar en un puntaje de MAP subóptimo. Los modelos que se optimizan para la precisión no están directamente preocupados por la clasificación. En cambio, aprenden un umbral tal que los documentos que obtienen una puntuación superior al umbral pueden ser clasificados como relevantes y los documentos que obtienen una puntuación inferior como no relevantes. Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una única consulta x. Hipótesis MAP Mejor Precisión h1(q) 0.70 0.64 h2(q) 0.64 0.73 Tabla 4: Rendimiento de los Modelos de Juguete La Tabla 4 muestra los puntajes de MAP y mejor precisión de h1(q) y h2(q). La mejor precisión se refiere a la precisión más alta alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con h1(q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que resulta en una precisión de 0.64. De manera similar, con h2(q), un umbral entre los documentos 5 y 6 da 3 errores (los documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que resulta en una precisión de 0.73. Un método de aprendizaje que optimiza la precisión elegiría h2 ya que esto resulta en un puntaje de precisión más alto, pero esto produce un puntaje de MAP subóptimo. 3. OPTIMIZANDO LA PRECISIÓN PROMEDIO Nos basamos en el enfoque utilizado por [13] para optimizar el Área bajo la Curva ROC. A diferencia de ROCArea, sin embargo, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, el cual describimos en esta sección. Recuerda que la clasificación verdadera es una clasificación débil con dos valores de clasificación (relevante y no relevante). Que Cx y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta x, respectivamente. Nos enfocamos en funciones que están parametrizadas por un vector de peso w, y por lo tanto deseamos encontrar w para minimizar el riesgo empírico, R∆ S (w) ≡ R∆ S (h(·; w)). Nuestro enfoque es aprender una función discriminante F: X × Y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h(x; w) = argmax y∈Y F(x, y; w). (1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas Ψ(x, y) ∈ RN, es decir, F(x, y; w) = wT Ψ(x, y). (2) La función de características combinadas que utilizamos es Ψ(x, y) = 1 |Cx| · |C¯x| X i:di∈Cx X j:dj ∈C¯x [yij (φ(x, di) − φ(x, dj))], donde φ: X × C → N es una función de mapeo de características de un par consulta/documento a un punto en un espacio dimensional N. Representamos las clasificaciones como una matriz de ordenamientos por pares, Y ⊂ {−1, 0, +1}|C|×|C| . Para cualquier y ∈ Y, yij = +1 si di está clasificado por delante de dj, y yij = −1 si dj está clasificado por delante de di, y yij = 0 si di y dj tienen el mismo rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, que cumplen con la antisimetría y la transitividad). De manera intuitiva, Ψ es una suma de las diferencias vectoriales de todos los pares de documentos relevantes/no relevantes. Dado que asumimos que las clasificaciones predichas son clasificaciones completas, yij es o bien +1 o −1 (nunca 0). Dado un vector de pesos aprendido w, predecir un ranking (es decir, resolver la ecuación (1)) dado una consulta x se reduce a elegir cada yij para maximizar wT Ψ(x, y). Como también se discute en [13], esto se logra ordenando los documentos por wT φ(x, d) en orden descendente. Discutiremos más adelante las elecciones de φ que utilizamos para nuestros experimentos. 3.1 SVM Estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se entrena en la diferencia de pares de documentos relevantes/no relevantes. Muchos enfoques basados en SVM optimizan sobre estas diferencias en pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para el MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales como la pérdida MAP directamente en problemas de optimización global como el entrenamiento de SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Utilizamos la formulación del SVM estructural, presentada en el Problema de Optimización 1, para aprender un w ∈ RN. Problema de optimización 1. (SVM estructural) min w,ξ≥0 1 2 w 2 + C n nX i=1 ξi (3) s.t. ∀i, ∀y ∈ Y \ yi : wT Ψ(xi, yi) ≥ wT Ψ(xi, y) + ∆(yi, y) − ξi (4) La función objetivo a minimizar (3) es un compromiso entre la complejidad del modelo, w 2 , y una relajación de pérdida de MAP mediante la pérdida de bisagra, P ξi. Como es habitual en el entrenamiento de SVM, C es igual a 2. Por ejemplo, una dimensión podría ser el número de veces que las palabras de la consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia. 1: Entrada: (x1, y1), . . . , (xn, yn), C, 2: Wi ← ∅ para todo i = 1, . . . , n 3: repetir 4: para i = 1, . . . , n hacer 5: H(y; w) ≡ ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi) 6: calcular ˆy = argmaxy∈Y H(y; w) 7: calcular ξi = max{0, maxy∈Wi H(y; w)} 8: si H(ˆy; w) > ξi + entonces 9: Wi ← Wi ∪ {ˆy} 10: w ← optimizar (3) sobre W = S i Wi 11: fin si 12: fin para 13: hasta que ningún Wi haya cambiado durante la iteración parámetro que controla este equilibrio y puede ajustarse para lograr un buen rendimiento en diferentes tareas de entrenamiento. Para cada (xi, yi) en el conjunto de entrenamiento, se añade un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Ten en cuenta que wT Ψ(x, y) es exactamente nuestra función discriminante F(x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige el ranking que maximiza el discriminante (1). Si el valor del discriminante para una clasificación incorrecta y es mayor que para la clasificación verdadera yi (por ejemplo, F(xi, y; w) > F(xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos ∆(yi, y) para que se cumpla esa restricción. Por lo tanto, la suma de los márgenes, P ξi, acota superiormente la pérdida MAP. Esto se establece formalmente en la Proposición 1. Proposición 1. Sea ξ∗ (w) la solución óptima de las variables de holgura para OP 1 para un vector de peso dado w. Entonces 1 n Pn i=1 ξi es una cota superior del riesgo empírico R∆ S (w). (ver [19] para la prueba) La Proposición 1 muestra que OP 1 aprende una función de clasificación que optimiza una cota superior del error de MAP en el conjunto de entrenamiento. Desafortunadamente hay un problema: se requiere una restricción para cada posible resultado incorrecto y, y el número de resultados incorrectos posibles es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones y encuentra de forma iterativa, para cada ejemplo (xi, yi), la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos ˆy en el conjunto de trabajo Wi de restricciones activas, por ejemplo i, y volvemos a resolver (3) usando el W actualizado. Se puede demostrar que el bucle externo del Algoritmo 1 está garantizado a detenerse dentro de un número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯R = maxi maxy Ψ(xi, yi) − Ψ(xi, y), ¯∆ = maxi maxy ∆(yi, y), y para cualquier > 0, el Algoritmo 1 termina después de agregar a lo sumo max  2n ¯∆ , 8C ¯∆ ¯R2 2 ff restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H(y; w), donde H(y; w) = ∆(yi, y) + wT Ψ(xi, y) − wT Ψ(xi, yi), o equivalentemente, argmax y∈Y ∆(yi, y) + wT Ψ(xi, y), ya que wT Ψ(xi, yi) es constante con respecto a y. Aunque está estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆(yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y H(y, w)), el procedimiento de generación de restricciones no es viable. 3.2 Encontrar la restricción más violada utilizando OP 1 y optimizando la pérdida de ROCArea (∆roc), el problema de encontrar la restricción más violada, o resolver argmaxy∈Y H(y, w) (en adelante argmax H), se aborda en [13]. Resolver argmax H para ∆map es más difícil. Esto se debe principalmente a que ROCArea se descompone de manera ordenada en una suma de puntuaciones calculadas de forma independiente en cada ordenamiento relativo de un par de documentos relevantes/no relevantes. MAP, por otro lado, no se descompone de la misma manera que ROCArea. La principal contribución algorítmica de este artículo es un método eficiente para resolver argmax H para ∆map. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos da y db son ambos relevantes, entonces intercambiar las posiciones de da y db en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre sí y de los documentos no relevantes entre sí. Sin embargo, esta reorganización afectará la puntuación del discriminante, wT Ψ(x, y). Esto nos lleva a la Observación 1. Observación 1. Considera clasificaciones que estén limitadas por fijar la relevancia en cada posición de la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que cumpla con el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes están ordenados por wT φ(x, d) en orden descendente, y los documentos no relevantes también están ordenados de la misma manera por wT φ(x, d), entonces la intercalación de las dos listas ordenadas que cumpla con las restricciones maximizará H para ese conjunto de clasificaciones restringidas. La Observación 1 implica que en la clasificación que maximiza H, los documentos relevantes se ordenarán por wT φ(x, d), y los documentos no relevantes también se ordenarán de la misma manera. Al ordenar primero los documentos relevantes y no relevantes, el problema se simplifica a encontrar la intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, asumimos que los documentos relevantes y no relevantes están ordenados por wT φ(x, d) en orden descendente. Para mayor comodidad, también nos referimos a los documentos relevantes como {dx 1 , . . . dx |Cx|} = Cx, y a los documentos no relevantes como {d¯x 1 , . . . d¯x |C¯x|} = C¯x. Definimos δj(i1, i2), con i1 < i2, como el cambio en H desde cuando el documento relevante de mayor rango clasificado después de d¯x j es dx i1 hasta que es dx i2. Para i2 = i1 + 1, tenemos δj(i, i + 1) = 1 |Cx| „ j j + i − j − 1 j + i − 1 « − 2 · (sx i − s¯x j ), (5), donde si = wT φ(x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante i tiene j documentos no relevantes clasificados antes de él, en lugar de j-1. El segundo término es el cambio en la puntuación del discriminante, wT Ψ(x, y), cuando yij cambia de +1 a −1. . . , dx i , d¯x j , dx i+1, . . . . . . , d¯x j , dx i , dx i+1, . . . Figura 1: Ejemplo para δj(i, i + 1). La Figura 1 proporciona un ejemplo conceptual para δj(i, i + 1). La clasificación inferior difiere de la superior solo cuando d¯x j sube un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente δj(i, i + 1). Para cualquier i1 < i2, podemos definir δj(i1, i2) como δj(i1, i2) = i2−1 X k=i1 δj(k, k + 1), (6) o equivalentemente, δj(i1, i2) = i2−1 X k=i1 » 1 |Cx| „ j j + k − j − 1 j + k − 1 « − 2 · (sx k − s¯x j ) . Deja que o1, . . . , o|C¯x| codifiquen las posiciones de los documentos no relevantes, donde dx oj es el documento relevante de mayor rango clasificado después del j-ésimo documento no relevante. Debido a la Observación 1, esta codificación identifica de forma única un ranking completo. Podemos recuperar la clasificación como yij = 8 >>>< >>>: 0 si i = j sign(si − sj) si di, dj relevancia igual signo(oj − i − 0.5) si di = dx i , dj = d¯x j signo(j − oi + 0.5) si di = d¯x i , dj = dx j. (7) Ahora podemos reformular H en una nueva función objetivo, H (o1, . . . , o|C¯x||w) = H(¯y|w) + |C¯x | X k=1 δk(ok, |Cx | + 1), donde ¯y es la verdadera clasificación (débil). Conceptualmente, H comienza con una clasificación perfecta ¯y y agrega el cambio en H cuando cada documento no relevante sucesivo sube en la clasificación. Luego podemos reformular el problema argmax H como argmax H = argmax o1,...,o|C¯x| |C¯x | X k=1 δk(ok, |Cx | + 1) (8) sujeto a o1 ≤ . . . ≤ o|C¯x|. (9) El Algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el Algoritmo 2 comienza con un ranking perfecto. Entonces, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando ese documento hacia arriba en la clasificación para maximizar localmente H, manteniendo las posiciones de los otros documentos no relevantes constantes. 3.2.1 Prueba de Corrección El Algoritmo 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante de forma independiente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, d¯x j, Algoritmo 2 Encontrar la Restricción Más Violada (argmax H) para el Algoritmo 1 con ∆map 1: Entrada: w, Cx, C¯x 2: ordenar Cx y C¯x en orden descendente de wT φ(x, d) 3: sx i ← wT φ(x, dx i), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i), i = 1, . . . , |C¯x | 5: para j = 1, . . . , |C¯x | hacer 6: optj ← argmaxk δj(k, |Cx| + 1) 7: fin para 8: codificar ˆy de acuerdo con (7) 9: devolver ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restricciones de (9). Para que la solución sea factible, el documento no relevante j-ésimo debe ser clasificado después de los primeros j-1 documentos no relevantes, satisfaciendo así opt1 ≤ opt2 ≤ . . . ≤ opt|C¯x|. Si la solución es factible, entonces claramente resuelve (8). Por lo tanto, basta con demostrar que el Algoritmo 2 cumple con (10). Primero demostramos que δj(·, ·) es monótonamente decreciente en j. Lema 1. Para cualquier 1 ≤ i1 < i2 ≤ |Cx | + 1 y 1 ≤ j < |C¯x |, debe ser el caso que δj+1(i1, i2) ≤ δj(i1, i2). Prueba. Recuerde que tanto δj(i1, i2) como δj+1(i1, i2) son sumas de términos i2 − i1. Mostraremos que cada término en la suma de δj+1(i1, i2) no es mayor que el término correspondiente en δj(i1, i2), o δj+1(k, k + 1) ≤ δj(k, k + 1) para k = i1, . . . , i2 − 1. Cada término en δj(k, k +1) y δj+1(k, k +1) puede ser descompuesto aún más en dos partes (ver (5)). Mostraremos que cada parte de δj+1(k, k + 1) no es mayor que la parte correspondiente en δj(k, k + 1). En otras palabras, demostraremos que tanto j + 1 j + k + 1 − j j + k ≤ j j + k − j − 1 j + k − 1 (11) como −2 · (sx k − s¯x j+1) ≤ −2 · (sx k − s¯x j ) (12) son verdaderos para los valores mencionados de j y k. Es fácil ver que (11) es verdadero observando que para cualquier par de enteros positivos 1 ≤ a < b, a + 1 b + 1 − a b ≤ a b − a − 1 b − 1, y eligiendo a = j y b = j + k. La segunda desigualdad (12) se cumple porque el Algoritmo 2 primero ordena d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Así vemos que cada término en δj+1 no es mayor que el término correspondiente en δj, lo cual completa la prueba. El resultado del Lema 1 conduce directamente a nuestro resultado principal de corrección: Teorema 2. En el Algoritmo 2, los valores calculados de optj satisfacen (10), lo que implica que la solución devuelta por el Algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Demostraremos que optj ≤ optj+1 se cumple para cualquier 1 ≤ j < |C¯x|, implicando así (10). Dado que el Algoritmo 2 calcula optj como optj = argmax k δj(k, |Cx | + 1), (13), entonces por definición de δj (6), para cualquier 1 ≤ i < optj, δj(i, optj) = δj(i, |Cx | + 1) − δj(optj, |Cx | + 1) < 0. Usando el Lema 1, sabemos que δj+1(i, optj) ≤ δj(i, optj) < 0, lo que implica que para cualquier 1 ≤ i < optj, δj+1(i, |Cx | + 1) − δj+1(optj, |Cx | + 1) < 0. Supongamos por contradicción que optj+1 < optj. Entonces δj+1(optj+1, |Cx | + 1) < δj+1(optj, |Cx | + 1), lo cual contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, lo cual completa la prueba. 3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es la clasificación por wT φ(x, d), lo cual requiere un tiempo de O(n log n), donde n = |Cx | + |C¯x |. La segunda parte calcula cada optj, lo cual requiere un tiempo de O(|Cx| · |C¯x|). Aunque en el peor de los casos esto es O(n2), el número de documentos relevantes, |Cx|, suele ser muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución para la segunda parte es simplemente O(n). Para la mayoría de los conjuntos de datos del mundo real, el Algoritmo 2 está dominado por la ordenación y tiene una complejidad O(n log n). El Algoritmo 1 está garantizado de detenerse en un número polinómico de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos que funcionaron bien fueron entrenados en un tiempo razonable (generalmente menos de una hora). Una vez que el entrenamiento esté completo, hacer predicciones sobre la consulta x usando la hipótesis resultante h(x|w) solo requiere ordenar por wT φ(x, d). Desarrollamos nuestro software utilizando una interfaz de Python a SVMstruct, ya que el lenguaje Python simplificó en gran medida el proceso de codificación. Para mejorar el rendimiento, es recomendable utilizar la implementación estándar en C de SVMstruct. CONFIGURACIÓN DEL EXPERIMENTO El objetivo principal de nuestros experimentos es evaluar si la optimización directa de MAP conduce a un rendimiento de MAP mejorado en comparación con los métodos convencionales de SVM que optimizan una pérdida sustituta como la precisión o el área bajo la curva ROC. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de la TREC Web Track, uno de TREC 9 y otro de TREC 10 (temas 451-500 y 501-550), ambos de los cuales utilizaron el corpus WT10g. Para cada consulta, TREC proporciona las evaluaciones de relevancia de los documentos. Generamos nuestras características utilizando las puntuaciones de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico al significado de las características, elegimos utilizar funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Por lo tanto, nuestros experimentos de estadísticas de conjuntos de datos básicos esencialmente prueban la capacidad de nuestros métodos para volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el MAP. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante, funciones base), así como con los métodos SVM propuestos anteriormente. Comparar con las mejores funciones base pone a prueba la capacidad de nuestros métodos para aprender una combinación útil. Comparar con métodos SVM anteriores nos permite probar si optimizar directamente para el MAP (en lugar de precisión o área bajo la curva ROC) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle. 4.1 Elección de Funciones de Recuperación Elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer conjunto, generamos tres índices sobre el corpus WT10g utilizando Indri5. El primer índice fue generado utilizando la configuración predeterminada, el segundo utilizó Porter-stemming, y el último utilizó Porter-stemming y las palabras vacías predeterminadas de Indris. Para TREC 9 y TREC 10, utilizamos la parte de descripción de cada consulta y puntuamos los documentos utilizando cinco de los métodos de recuperación integrados en Indri, que son Similitud Coseno, TFIDF, Okapi, Modelo de Lenguaje con Prior de Dirichlet y Modelo de Lenguaje con Prior de Jelinek-Mercer. Todos los parámetros se mantuvieron en sus valores predeterminados. Calculamos las puntuaciones de estos cinco métodos de recuperación sobre los tres índices, dando un total de 15 funciones base. Para cada consulta, consideramos las puntuaciones de los documentos encontrados en la unión de los mejores 1000 documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntuaciones de las presentaciones de la pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y no breves de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 envíos de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales. b ca wT φ(x,d) f(d|x) Figura 2: Ejemplo de Agrupación de Características 4.2 Generación de Características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instancia concreta de φ. Para cada documento d puntuado por un conjunto de funciones de recuperación F en la consulta x, generamos las características como un vector φ(x, d) = 1[f(d|x)>k] : ∀f ∈ F, ∀k ∈ Kf, donde f(d|x) denota la puntuación que la función de recuperación f asigna al documento d para la consulta x, y cada Kf es un conjunto de valores reales. Desde un nivel alto, estamos expresando la puntuación de cada función de recuperación utilizando |Kf | + 1 contenedores. Dado que estamos utilizando núcleos lineales, se puede pensar en el problema de aprendizaje como encontrar una buena combinación de piezas constantes de los puntajes de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una única característica F = {f}. Aquí, Kf = {a, b, c}, y el vector de pesos es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wT φ(x, d) = 8 >>< >>: 0 si f(d|x) < a wa si a ≤ f(d|x) < b wa + wb si b ≤ f(d|x) < c wa + wb + wc si c ≤ f(d|x) . Esto se expresa cualitativamente en la Figura 2, donde wa y wb son positivos, y wc es negativo. Realizamos nuestros experimentos principales utilizando cuatro opciones de F: el conjunto de las funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para Kf que estuvieran razonablemente espaciados y capturaran la región sensible de f. Utilizando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Esto fue simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo. EXPERIMENTOS Para cada conjunto de datos en la Tabla 5, realizamos 50 pruebas. Para cada prueba, entrenamos con 10 consultas seleccionadas al azar, y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que tuvo mejor rendimiento en el conjunto de validación fue seleccionado y probado en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en los conjuntos de entrenamiento, validación y prueba la misma cantidad de veces. Utilizando esta configuración, realizamos los mismos experimentos mientras usábamos nuestro método (mapa SVM∆), un SVM optimizando para ROCArea (SVM∆ roc) [13], y un SVM de clasificación convencional (SVMacc) [20]. Todos los métodos de SVM utilizaron un kernel lineal. Informamos sobre el rendimiento promedio de todos los modelos en las 50 pruebas. 5.1 Comparación con Funciones Base Al analizar nuestros resultados, la primera pregunta a responder es, ¿puede SVM∆ map aprender un modelo que supere al mejor modelo base TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.290 - 0.287Mejor Func. 0.280 28/22 0.283 29/21 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con Envíos TREC TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288Mejor Func. 0.280 27/23 0.283 31/19 2do Mejor 0.269 30/20 0.251 36/14 ** 3er Mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con Funciones de Envíos TREC (sin el mejor) La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columnas contiene el rendimiento del MAP macro-promediado de SVM∆ map o una función base. Las columnas W/L muestran el número de consultas donde SVM∆ map logró un puntaje MAP más alto. Se realizaron pruebas de significancia utilizando la prueba de rango con signo de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí encontramos que SVM∆ mapea significativamente mejor que las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena con las presentaciones de TREC. Si bien logra una puntuación de MAP más alta que las mejores funciones base, la diferencia de rendimiento entre SVM∆ y las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación cuidadosamente diseñadas para lograr un alto MAP, es posible que las presentaciones con mejor rendimiento utilicen técnicas que engloben las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no sería capaz de aprender una hipótesis que pueda superar significativamente la mejor presentación. Por lo tanto, realizamos los mismos experimentos utilizando un conjunto de datos modificado en el que se eliminaron las características calculadas utilizando la mejor presentación. La tabla 8 muestra los resultados (ten en cuenta que aún estamos comparando con la mejor presentación, aunque no la estamos utilizando para el entrenamiento). Observa que si bien el rendimiento del SVM∆ map se degradó ligeramente, aún era comparable con el de la mejor presentación. 5.2 Comparación con Métodos SVM Anteriores La siguiente pregunta a responder es, ¿produce el SVM∆ map puntajes MAP más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados de SVM∆ map, SVM∆ roc y SVMacc cuando se entrenan con las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrena con las presentaciones de TREC sin la mejor presentación. Para empezar, nuestros resultados indican que SVMacc no fue competitivo con SVM∆ map y SVM∆ roc, y a veces tuvo un rendimiento notablemente inferior. Por lo tanto, probamos varios enfoques para mejorar el rendimiento de SVMacc. 5.2.1 Métodos alternativos de SVMacc Un problema que puede causar que SVMacc tenga un rendimiento deficiente es el desequilibrio severo entre documentos relevantes y no relevantes. La gran mayoría de los documentos no son relevantes. SVMacc2 aborda este problema asignando una penalización mayor a los errores de falsos negativos. Para cada conjunto de datos, la proporción de las penalizaciones por falsos negativos a falsos positivos es igual a la proporción entre el número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMacc2 sigue teniendo un rendimiento significativamente peor que SVM∆ map. Otro posible problema es que SVMacc intenta encontrar solo un umbral discriminatorio b que sea invariable a la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje intentando encontrar un buen valor de b (cuando no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMacc3, convierte las puntuaciones de la función de recuperación en percentiles. Por ejemplo, para el documento d, la consulta q y la función de recuperación f, si la puntuación f(d|q) se encuentra en el 90% superior de las puntuaciones f(·|q) para la consulta q, entonces la puntuación convertida es f(d|q) = 0.9. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Las tablas 9, 10 y 11 muestran que el rendimiento de SVMacc3 tampoco fue competitivo con SVM∆ map. El segundo método, SVMacc4, normaliza las puntuaciones dadas por f para cada consulta. Por ejemplo, suponga para la consulta q que f produce puntuaciones en el rango de 0.2 a 0.7. Entonces, para el documento d, si f(d|q) = 0.6, la puntuación convertida sería f(d|q) = (0.6 − 0.2)/(0.7 − 0.2) = 0.8. Cada Kf contiene 50 valores equidistantes entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMacc4 no fue competitivo con SVM∆ map 5.2.2 MAP vs ROCArea. SVM∆ roc tuvo un rendimiento mucho mejor que SVMacc en nuestros experimentos. Cuando se entrenó con las funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ roc fue ligeramente, aunque no significativamente, peor que el rendimiento de SVM∆ map. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente al roc SVM∆ cuando se entrenó con las presentaciones de TREC. La tabla 11 muestra el rendimiento de los modelos cuando se entrenan con las presentaciones de TREC y se elimina la mejor presentación. El rendimiento de la mayoría de los modelos se degradó ligeramente, con SVM∆ map aún teniendo el mejor rendimiento. TREC 9 TREC 10 Modelo MAP G/P MAP G/P SVM∆ map 0.284 - 0.288 SVM∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMacc 0.215 49/1 ** 0.211 50/0 ** SVMacc2 0.267 35/15 ** 0.258 44/6 ** SVMacc3 0.133 50/0 ** 0.174 46/4 ** SVMacc4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en TREC Subm. (sin Mejor) 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque basado en principios y evita heurísticas difíciles de controlar. Formulamos el problema de optimización y presentamos un algoritmo que encuentra la solución de manera demostrable en tiempo polinómico. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos convencionales de SVM. Nuestro nuevo método hace que sea conceptualmente tan fácil optimizar SVMs para MAP como anteriormente solo era posible para Precisión y Área bajo la curva ROC. El costo computacional para el entrenamiento es muy razonable en la práctica. Dado que otros métodos suelen requerir ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas importantes de IR, como la Ganancia Acumulada Normalizada Descontada [2, 3, 4, 12] y la Reciprocidad Media de Rango. 7. AGRADECIMIENTOS Este trabajo fue financiado bajo el Premio NSF IIS-0412894, el Premio NSF CAREER 0237381 y un obsequio de Yahoo! Investigación. El tercer autor también fue parcialmente apoyado por una Beca de Investigación de Microsoft. 8. REFERENCIAS [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Lo. Aprendizaje para clasificar con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W. Hon. Adaptando el SVM de clasificación para la recuperación de documentos. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprendiendo un ranking a partir de preferencias por pares. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de precisión-recall y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2006. [8] D. Hawking. Resumen de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Resumen de la pista web TREC-2001. En Actas de TREC-2001, Nov. 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen amplio para regresión ordinal. Avances en clasificadores de márgenes amplios, 2000. [11] A. Herschtal y B. Raskutti. Optimizando el área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press. [14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Máquinas de vectores de soporte para clasificación en situaciones no estándar. Aprendizaje automático, 46:191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias entre términos. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Automático, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en la revista IR de documentación. Revista de Documentación, 33(4):294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims y Y. Altun. Métodos de margen amplio para variables de salida estructuradas e interdependientes. Revista de Investigación en Aprendizaje Automático (JMLR), 6(Sep):1453-1484, 2005. [20] V. Vapnik. Teoría del Aprendizaje Estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer, and R. Wolniewicz. 

Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimizando el rendimiento del clasificador mediante la aproximación a la estadística de Wilcoxon-Mann-Witney. En Actas de la Conferencia Internacional sobre Aprendizaje Automático (ICML), 2003.