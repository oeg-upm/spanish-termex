Utilizando Contextos de Consulta en la Recuperación de Información Jing Bai 1, Jian-Yun Nie 1, Hugues Bouchard 2, Guihong Cao 1 Departamento IRO, Universidad de Montreal CP. 6128, sucursal Centro-ville, Montreal, Quebec, H3C 3J7, Canadá {baijing, nie, caogui}@iro.umontreal.ca 2 Yahoo! La consulta del usuario es un elemento que especifica una necesidad de información, pero no es el único. Los estudios en literatura han encontrado muchos factores contextuales que influyen fuertemente en la interpretación de una consulta. Estudios recientes han intentado considerar los intereses de los usuarios mediante la creación de un perfil de usuario. Sin embargo, un solo perfil para un usuario puede no ser suficiente para una variedad de consultas del usuario. En este estudio, proponemos utilizar contextos específicos de la consulta en lugar de los centrados en el usuario, incluyendo el contexto alrededor de la consulta y el contexto dentro de la consulta. El primero especifica el entorno de una consulta, como el dominio de interés, mientras que el último se refiere a las palabras de contexto dentro de la consulta, lo cual es especialmente útil para la selección de relaciones de términos relevantes. En este artículo, ambos tipos de contexto se integran en un modelo de RI basado en modelado del lenguaje. Nuestros experimentos en varias colecciones de TREC muestran que cada uno de los factores de contexto aporta mejoras significativas en la efectividad de recuperación. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información - Modelos de recuperación Términos Generales Algoritmos, Rendimiento, Experimentación, Teoría. 1. Las consultas, especialmente las consultas cortas, no proporcionan una especificación completa de la necesidad de información. Muchos términos relevantes pueden estar ausentes de las consultas y los términos incluidos pueden ser ambiguos. Estos problemas han sido abordados en un gran número de estudios previos. Las soluciones típicas incluyen expandir la representación del documento o la consulta [19][35] aprovechando diferentes recursos [24][31], utilizando la desambiguación del sentido de las palabras [25], etc. En estos estudios, sin embargo, se ha asumido generalmente que la consulta es el único elemento disponible sobre la necesidad de información de los usuarios. En realidad, la consulta siempre se formula en un contexto de búsqueda. Como se ha encontrado en muchos estudios previos [2][14][20][21][26], los factores contextuales tienen una fuerte influencia en las valoraciones de relevancia. Estos factores incluyen, entre muchos otros, el dominio de interés de los usuarios, conocimientos, preferencias, etc. Todos estos elementos especifican los contextos alrededor de la consulta. Así que los llamamos contexto alrededor de la consulta en este documento. Se ha demostrado que la consulta de los usuarios debe ser colocada en su contexto para una interpretación correcta. Estudios recientes han investigado la integración de algunos contextos alrededor de la consulta [9][30][23]. Normalmente, un perfil de usuario se construye para reflejar los dominios de interés y antecedentes de los usuarios. Un perfil de usuario se utiliza para favorecer los documentos que están más estrechamente relacionados con el perfil. Sin embargo, un solo perfil de usuario puede agrupar una variedad de dominios diferentes, que no siempre son relevantes para una consulta específica. Por ejemplo, si un usuario que trabaja en informática emite una consulta Java hotel, los documentos sobre el lenguaje Java serán favorecidos incorrectamente. Una posible solución a este problema es utilizar perfiles o modelos relacionados con la consulta en lugar de centrarse en el usuario. En este artículo, proponemos modelar dominios de temas, entre los cuales se seleccionará el o los relacionados para una consulta dada. Este método nos permite seleccionar un contexto más apropiado y específico para la consulta. Otro factor contextual fuerte identificado en la literatura es el conocimiento del dominio, o relaciones de términos específicos del dominio, como programa→computadora en ciencias de la computación. Usando esta relación, uno sería capaz de expandir el programa de consulta con el término computadora. Sin embargo, el conocimiento de dominio está disponible solo para algunos dominios (por ejemplo, Medicina. La escasez de conocimiento de dominio ha llevado a la utilización de conocimiento general para la expansión de consultas [31], el cual es más accesible a partir de recursos como tesauros, o puede ser extraído automáticamente de documentos [24][27]. Sin embargo, el uso del conocimiento general da lugar a un enorme problema de ambigüedad del conocimiento [31]: a menudo no podemos determinar si una relación se aplica a una consulta. Por ejemplo, generalmente hay poca información disponible para determinar si el programa → computadora es aplicable a consultas de programa Java y programa de televisión. Por lo tanto, la relación se ha aplicado a todas las consultas que contienen el programa en estudios anteriores, lo que ha llevado a una expansión incorrecta para el programa de televisión. Al observar los dos ejemplos de consulta, sin embargo, las personas pueden determinar fácilmente si la relación es aplicable, considerando las palabras de contexto Java y TV. Entonces, la pregunta importante es cómo podemos utilizar estas palabras de contexto en las consultas para seleccionar las relaciones apropiadas a aplicar. Estas palabras de contexto forman un contexto dentro de la consulta. En algunos estudios previos [24][31], las palabras de contexto en una consulta se han utilizado para seleccionar términos de expansión sugeridos por relaciones de términos, que son, sin embargo, independientes del contexto (como programa→computadora). Aunque se observan mejoras en algunos casos, son limitadas. Sostenemos que el problema se origina en la falta de información de contexto necesaria en las relaciones mismas, y una solución más radical radica en la adición de contextos en las relaciones. El método que proponemos es agregar palabras de contexto a la condición de una relación, como {Java, programa} → computadora, para limitar su aplicabilidad al contexto adecuado. Este documento tiene como objetivo hacer contribuciones en los siguientes aspectos: • Modelo de dominio específico de consulta: Construimos modelos de dominio más específicos en lugar de un único modelo de usuario que agrupe todos los dominios. El dominio relacionado con una consulta específica es seleccionado (ya sea manual o automáticamente) para cada consulta. • Contexto dentro de la consulta: Integrarnos palabras de contexto en relaciones de términos para que solo se puedan aplicar relaciones apropiadas a la consulta. • Múltiples factores contextuales: Finalmente, proponemos un marco basado en un enfoque de modelado de lenguaje para integrar múltiples factores contextuales. Nuestro enfoque ha sido probado en varias colecciones de TREC. Los experimentos muestran claramente que ambos tipos de contexto pueden resultar en mejoras significativas en la efectividad de recuperación, y sus efectos son complementarios. También demostraremos que es posible determinar el dominio de la consulta de forma automática, lo que resulta en una efectividad comparable a la especificación manual del dominio. Este documento está organizado de la siguiente manera. En la sección 2, revisamos algunos trabajos relacionados e introducimos el principio de nuestro enfoque. La sección 3 presenta nuestro modelo general. Luego, las secciones 4 y 5 describen respectivamente el modelo de dominio y el modelo de conocimiento. La sección 6 explica el método para el entrenamiento de parámetros. Los experimentos se presentan en la sección 7 y las conclusiones en la sección 8. Hay muchos factores contextuales en IR: el dominio de interés de los usuarios, el conocimiento sobre el tema, las preferencias, la actualidad de los documentos, y así sucesivamente [2][14]. Entre ellos, el dominio de interés y conocimiento de los usuarios se consideran como uno de los más importantes [20][21]. En esta sección, revisamos algunos de los estudios en IR relacionados con estos aspectos. El dominio de interés y el contexto alrededor de la consulta. Un dominio de interés especifica un antecedente particular para la interpretación de una consulta. Se puede utilizar de diferentes maneras. La mayoría de las veces, se crea un perfil de usuario para abarcar todos los dominios de interés de un usuario [23]. En [5], un perfil de usuario contiene un conjunto de categorías temáticas de ODP (Proyecto del Directorio Abierto, http://dmoz.org) identificadas por el usuario. Los documentos (páginas web) clasificados en estas categorías se utilizan para crear un vector de términos, que representa todos los dominios de interés del usuario. Por otro lado, [9][15][26][30], así como la Búsqueda Personalizada de Google [12], utilizan los documentos leídos por el usuario, almacenados en la computadora del usuario o extraídos del historial de búsqueda del usuario. En todos estos estudios, observamos que se crea un único perfil de usuario (generalmente un modelo estadístico o vector) para un usuario sin distinguir los diferentes dominios temáticos. La aplicación sistemática del perfil de usuario puede sesgar incorrectamente los resultados para consultas no relacionadas con el perfil. Esta situación puede ocurrir con frecuencia en la práctica, ya que un usuario puede buscar una variedad de temas fuera de los dominios que ha buscado o identificado previamente. Una posible solución a este problema es la creación de múltiples perfiles, uno para un dominio de interés separado. Los dominios relacionados con una consulta son identificados luego de acuerdo a la consulta. Esto nos permitirá utilizar un perfil específico de consulta más apropiado, en lugar de uno centrado en el usuario. Este enfoque se utiliza en [18] en el que se utilizan directorios de ODP. Sin embargo, solo se ha llevado a cabo un experimento a pequeña escala. Un enfoque similar se utiliza en [8], donde se crean modelos de dominio utilizando categorías de ODP y las consultas de los usuarios se asignan manualmente a ellos. Sin embargo, los experimentos mostraron resultados variables. No está claro si los modelos de dominio pueden ser utilizados de manera efectiva en RI. En este estudio, también modelamos dominios de temas. Realizaremos experimentos tanto en la identificación automática como manual de dominios de consulta. Los modelos de dominio también se integrarán con otros factores. En la siguiente discusión, llamaremos al dominio del tema de una consulta un contexto alrededor de la consulta para contrastarlo con otro contexto dentro de la consulta que introduciremos. Debido a la falta de conocimiento específico del dominio, se han utilizado recursos de conocimiento general como Wordnet y relaciones de términos extraídas automáticamente para la expansión de consultas. En ambos casos, las relaciones se definen entre dos términos individuales, como t1→t2. Si una consulta contiene el término t1, entonces t2 siempre se considera como un candidato para la expansión. Como mencionamos anteriormente, nos enfrentamos al problema de la ambigüedad de las relaciones: algunas relaciones se aplican a una consulta y otras no deberían. Por ejemplo, el término "programa" aplicado a "computadora" no debería ser utilizado para referirse a un programa de televisión, aunque este último contenga programación. Sin embargo, hay poca información disponible en relación con la ayuda para determinar si un contexto de aplicación es apropiado. Para remediar este problema, se han propuesto enfoques para hacer una selección de términos de expansión después de la aplicación de relaciones [24][31]. Normalmente, se define algún tipo de relación global entre el término de expansión y toda la consulta, que suele ser la suma de sus relaciones con cada palabra de la consulta. Aunque algunos términos de expansión inapropiados pueden eliminarse porque están débilmente conectados a algunos términos de consulta, muchos otros permanecen. Por ejemplo, si la relación programa→computadora es lo suficientemente fuerte, la computadora tendrá una relación global fuerte con todo el programa de televisión de la consulta y seguirá siendo un término de expansión. Es posible integrar un control más fuerte sobre la utilización del conocimiento. Por ejemplo, [17] definió relaciones lógicas fuertes para codificar el conocimiento de diferentes dominios. Si la aplicación de una relación conduce a un conflicto con la consulta (o con otras piezas de evidencia), entonces no se aplica. Sin embargo, este enfoque requiere codificar todas las consecuencias lógicas, incluidas las contradicciones en el conocimiento, lo cual es difícil de implementar en la práctica. En nuestro estudio anterior [1], se propone un enfoque más simple y general para resolver el problema en su origen, es decir, la falta de información de contexto en las relaciones de términos: al introducir condiciones más estrictas en una relación, por ejemplo {Java, programa}→computadora y {algoritmo, programa}→computadora, la aplicabilidad de las relaciones se restringirá naturalmente a contextos correctos. Como resultado, la computadora se utilizará para ampliar consultas de programas Java o algoritmos de programas, pero no de programas de televisión. Este principio es similar al de [33] para la desambiguación del sentido de las palabras. Sin embargo, no asignamos explícitamente un significado a una palabra; más bien intentamos hacer diferencias entre los usos de las palabras en diferentes contextos. Desde este punto de vista, nuestro enfoque es más similar a la discriminación de sentido de las palabras [27]. En este artículo, utilizamos el mismo enfoque y lo integraremos en un modelo más global con otros factores contextuales. Dado que las palabras de contexto añadidas a las relaciones nos permiten explotar el contexto de palabras dentro de la consulta, llamamos a tales factores contexto dentro de la consulta. Dentro del contexto de la consulta existe en muchas consultas. De hecho, los usuarios a menudo no utilizan una sola palabra ambigua como Java como consulta (si son conscientes de su ambigüedad). Algunas palabras de contexto suelen usarse junto con ella. En estos casos, se crean contextos dentro de la consulta y pueden ser explotados. Perfil de consulta y otros factores Se han realizado muchos intentos en IR para crear perfiles específicos de consulta. Podemos considerar retroalimentación implícita o retroalimentación ciega [7][16][29][32][35] en esta familia. Se crea un modelo de retroalimentación a corto plazo para la consulta dada a partir de documentos de retroalimentación, el cual ha demostrado ser efectivo para capturar algunos aspectos de la intención de los usuarios detrás de la consulta. Para crear un buen modelo de consulta, se debe integrar un modelo de retroalimentación específico de la consulta. Hay muchos otros factores contextuales ([26]) con los que no tratamos en este artículo. Sin embargo, parece claro que muchos factores son complementarios. Como se encontró en [32], un modelo de retroalimentación crea un contexto local relacionado con la consulta, mientras que el conocimiento general o todo el corpus define un contexto global. Ambos tipos de contextos han demostrado ser útiles [32]. El modelo de dominio especifica otro tipo de información útil: refleja un conjunto de términos de fondo específicos para un dominio, por ejemplo, contaminación, lluvia, efecto invernadero, etc. para el dominio del Medio Ambiente. Estos términos suelen ser presupuestos cuando un usuario emite una consulta como limpieza de residuos en el dominio. Es útil agregarlos a la consulta. Observamos una clara complementariedad entre estos factores. Es útil entonces combinarlos juntos en un único modelo de IR. En este estudio, integraremos todos los factores mencionados anteriormente dentro de un marco unificado basado en modelado del lenguaje. Cada factor contextual de cada componente determinará un puntaje de clasificación diferente, y la clasificación final del documento combina todos ellos. Esto se describe en la siguiente sección. 3. MODELO IR GENERAL En el marco del modelado de lenguaje, una función de puntuación típica se define en la divergencia de Kullback-Leibler de la siguiente manera: ( ) ( ) ( ) ( )DQ Vt DQ KLtPtPDQScore θθθθ |||log|, −∝= ∑∈ (1) donde θD es un modelo de lenguaje (unigrama) creado para un documento D, θQ un modelo de lenguaje para la consulta Q, y V el vocabulario. El suavizado en el modelo de documentos se reconoce como crucial [35], y uno de los métodos comunes de suavizado es el suavizado de interpolación Jelinek-Mercer: ( ) ( ) ( ) ( )CDD tPtPtP θλθλθ ||1| +−= (2) donde λ es un parámetro de interpolación y θC el modelo de colección. En los enfoques básicos de modelado de lenguaje, el modelo de consulta se estima mediante la Estimación de Máxima Verosimilitud (MLE) sin ningún suavizado. En un entorno así, la operación básica de recuperación sigue estando limitada a la coincidencia de palabras clave, según unas pocas palabras en la consulta. Para mejorar la eficacia de la recuperación, es importante crear un modelo de consulta más completo que represente mejor la necesidad de información. En particular, todas las palabras relacionadas y supuestas deben incluirse en el modelo de consulta. Se han propuesto modelos de consulta más completos mediante varios métodos que utilizan documentos de retroalimentación [16][35] o relaciones de términos [1][10][34]. En estos casos, construimos dos modelos para la consulta: el modelo de consulta inicial que contiene solo los términos originales, y un nuevo modelo que contiene los términos añadidos. Luego se combinan a través de la interpolación. En este artículo, generalizamos este enfoque e integramos más modelos para la consulta. Utilicemos 0 Qθ para denotar el modelo de consulta original, F Qθ para el modelo de retroalimentación creado a partir de documentos de retroalimentación, Dom Qθ para un modelo de dominio y K Qθ para un modelo de conocimiento creado aplicando relaciones de términos. 0 Qθ puede ser creado mediante MLE. F Qθ ha sido utilizado en varios estudios previos [16][35]. En este documento, F Qθ se extrae utilizando los 20 documentos de retroalimentación ciega. Describiremos los detalles para construir Dom Qθ y K Qθ en las Secciones 4 y 5. Dado estos modelos, creamos el siguiente modelo de consulta final por interpolación: ∑∈ = Xi i QiQ tPtP )|()|( θαθ (3) donde X={0, Dom, K, F} es el conjunto de todos los modelos de componentes e iα (con 1=∑∈Xi iα ) son sus pesos de mezcla. Entonces, el puntaje del documento en la Ecuación (1) se extiende de la siguiente manera: ( ) ∑∑∑ ∈∈ ∈ == Xi ii Vt Xi D i Qi DQScoretPtPDQScore ),()|(log)|(, αθθα (4) donde )|(log)|(),( D Vt i Qi tPtPDQScore θθ∑∈ = es el puntaje de acuerdo a cada modelo de componente. Aquí podemos ver que nuestra estrategia de mejorar el modelo de consulta con factores contextuales es equivalente a la reorganización de documentos, que se utiliza en [5][15][30]. El problema restante es construir modelos de dominio y modelos de conocimiento y combinar todos los modelos (configuración de parámetros). Describimos esto en las siguientes secciones. 4. CONSTRUCCIÓN Y USO DE MODELOS DE DOMINIO Como en estudios anteriores, explotamos un conjunto de documentos ya clasificados en cada dominio. Estos documentos se pueden identificar de dos maneras diferentes: 1) Se puede aprovechar una jerarquía de dominio existente y los documentos clasificados manualmente en ellos, como ODP. En ese caso, una nueva consulta debería ser clasificada en los mismos dominios ya sea de forma manual o automática. 2) Un usuario puede definir sus propios dominios. Al asignar un dominio a sus consultas, el sistema puede recopilar un conjunto de respuestas a las consultas automáticamente, las cuales luego se consideran documentos dentro del dominio. Las respuestas podrían ser aquellas que el usuario haya leído, ojeado o considerado relevantes para una consulta en el dominio, o simplemente podrían ser los resultados de recuperación mejor clasificados. Un estudio anterior [4] ha comparado las dos estrategias anteriores utilizando las consultas TREC 51-150, para las cuales se ha asignado manualmente un dominio. Estos dominios han sido asignados a categorías de ODP. Se ha encontrado que ambos enfoques mencionados anteriormente son igualmente efectivos y dan lugar a un rendimiento comparable. Por lo tanto, en este estudio, solo utilizamos el segundo enfoque. Esta elección también está motivada por la posibilidad de comparar entre la asignación manual y automática de dominios a una nueva consulta. Esto se explicará detalladamente en nuestros experimentos. Cualquiera que sea la estrategia, obtendremos un conjunto de documentos para cada dominio, a partir del cual se puede extraer un modelo de lenguaje. Si se utiliza la estimación de máxima verosimilitud directamente en estos documentos, el modelo de dominio resultante contendrá tanto términos específicos del dominio como términos generales, y los primeros no surgirán. Por lo tanto, empleamos un proceso de EM para extraer la parte específica del dominio de la siguiente manera: asumimos que los documentos en un dominio son generados por un modelo específico del dominio (a ser extraído) y un modelo de lenguaje general (modelo de colección). Entonces, la probabilidad de un documento en el dominio puede formularse de la siguiente manera: ( ) ( ) ( ) ( )[ ] ( ) ∏∈ +−= Dt Dtc CDomDom tPtPDP ; ||1| θηθηθ (5) donde c(t; D) es el conteo de t en el documento D y η es un parámetro de suavizado (que se fijará en 0.5 como en [35]). El algoritmo EM se utiliza para extraer el modelo de dominio Domθ que maximiza P(Dom| θDom) (donde Dom es el conjunto de documentos en el dominio), es decir: ( ) ( ) ( ) ( )[ ] ( ) ∏ ∏∈ ∈ +−= = DomD Dt Dtc CDom DomDom tPtP DomP Dom Dom ; ||1maxarg |maxarg θηθη θθ θ θ (6) Este es el mismo proceso que se utiliza para extraer el modelo de retroalimentación en [35]. Es capaz de extraer las palabras más específicas del dominio de los documentos mientras filtra las palabras comunes del idioma. Esto se puede observar en la siguiente tabla, que muestra algunas palabras en el modelo de dominio de Medio Ambiente antes y después de las iteraciones de EM (50 iteraciones). Tabla 1. Probabilidades de términos antes/después de EM Término Inicial Final cambio Término Inicial Final cambio aire 0.00358 0.00558 + 56% año 0.00357 0.00052 - 86% medio ambiente 0.00213 0.00340 + 60% sistema 0.00212 7.13*e-6 - 99% lluvia 0.00197 0.00336 + 71% programa 0.00189 0.00040 - 79% contaminación 0.00177 0.00301 + 70% millón 0.00131 5.80*e-6 - 99% tormenta 0.00176 0.00302 + 72% hacer 0.00108 5.79*e-5 - 95% inundación 0.00164 0.00281 + 71% compañía 0.00099 8.52*e-8 - 99% tornado 0.00072 0.00125 + 74% presidente 0.00077 2.71*e-6 - 99% efecto invernadero 0.00034 0.00058 + 72% mes 0.00073 3.88*e-5 - 95% Dado un conjunto de modelos de dominio, los relacionados deben asignarse a una nueva consulta. Esto se puede hacer manualmente por el usuario o automáticamente por el sistema utilizando la clasificación de consultas. Vamos a comparar ambos enfoques. La clasificación de consultas ha sido investigada en varios estudios [18][28]. En este estudio, utilizamos un método de clasificación simple: el dominio seleccionado es aquel cuyo puntaje de divergencia KL de las consultas es el más bajo, es decir: )|(log)|(minarg 0 Dom Qt Q Dom Q tPtP Dom θθθ θ ∑∈ = (7) Este método de clasificación es una extensión de Naïve Bayes como se muestra en [22]. El puntaje dependiendo del modelo de dominio es entonces el siguiente: ∑∈ = Vt D Dom QDom tPtPDQScore )|(log)|(),( θθ (8) Aunque la ecuación anterior requiere el uso de todos los términos en el vocabulario, en la práctica, solo los términos más fuertes en el modelo de dominio son útiles y los términos con bajas probabilidades suelen ser ruido. Por lo tanto, solo conservamos los 100 términos más fuertes. La misma estrategia se utiliza para el modelo de conocimiento. Aunque los modelos de dominio son más refinados que un solo perfil de usuario, los temas en un solo dominio aún pueden ser muy diferentes, lo que hace que el modelo de dominio sea demasiado grande. Esto es especialmente cierto para dominios amplios como Ciencia y tecnología definidos en las consultas de TREC. Usar un modelo de dominio tan grande como antecedente puede introducir muchos términos de ruido. Por lo tanto, construimos un modelo de subdominio más relacionado con la consulta dada, utilizando un subconjunto de documentos dentro del dominio que están relacionados con la consulta. Estos documentos son los documentos mejor clasificados recuperados con la consulta original dentro del dominio. Este enfoque es de hecho una combinación de modelos de dominio y retroalimentación. En nuestros experimentos, veremos que esta especificación adicional del subdominio es necesaria en algunos casos, pero no en todos, especialmente cuando también se utiliza el modelo de retroalimentación. 5. EXTRACCIÓN DE RELACIONES DE TÉRMINOS DEPENDIENTES DEL CONTEXTO DE DOCUMENTOS En este artículo, extraemos relaciones de términos de la colección de documentos de forma automática. En general, una relación de términos puede ser representada como A→B. Tanto A como B han sido restringidos a términos individuales en estudios anteriores. Un solo término en A significa que la relación es aplicable a todas las consultas que contienen ese término. Como explicamos anteriormente, esta es la fuente de muchas aplicaciones incorrectas. La solución que proponemos es agregar más términos de contexto en A, de modo que sea aplicable solo cuando todos los términos en A aparezcan en una consulta. Por ejemplo, en lugar de crear una relación independiente del contexto Java→programa, crearemos {Java, computadora}→programa, lo que significa que el programa se selecciona cuando tanto Java como computadora aparecen en una consulta. El término añadido en la condición especifica un contexto más estricto para aplicar la relación. Llamamos a este tipo de relación relación dependiente del contexto. En principio, la adición no está restringida a un término. Sin embargo, haremos esta restricción debido a las siguientes razones: • Las consultas de los usuarios suelen ser muy cortas. La adición de más términos a la condición creará muchas relaciones raramente aplicables; en la mayoría de los casos, una palabra ambigua como Java puede ser efectivamente desambiguada por una palabra de contexto útil como computadora u hotel; la adición de más términos también conducirá a una mayor complejidad de espacio y tiempo para extraer y almacenar relaciones de términos. La extracción de relaciones de tipo {tj, tk} → ti se puede realizar utilizando algoritmos de minería de reglas de asociación [13]. Aquí, utilizamos un análisis de co-ocurrencia simple. Las ventanas de tamaño fijo (10 palabras en nuestro caso) se utilizan para obtener recuentos de co-ocurrencia de tres términos, y la probabilidad )|( kji tttP se determina de la siguiente manera: ∑= lt kjlkjikji tttctttctttP ),,(),,()|( (9) donde ),,( kji tttc es el recuento de co-ocurrencias. Para reducir el requisito de espacio, aplicamos además los siguientes criterios de filtrado: • Los dos términos en la condición deben aparecer juntos al menos cierto número de veces en la colección (10 en nuestro caso) y deben estar relacionados. Utilizamos la siguiente información mutua puntual como medida de relación (MI > 0) [6]: )()( ),( log),( kj kj kj tPtP ttP ttMI = • La probabilidad de una relación debe ser mayor que un umbral (0.0001 en nuestro caso); Teniendo un conjunto de relaciones, el modelo de conocimiento correspondiente se define de la siguiente manera: )|()|()|( )|()|()|( 00 )( 0 )( QkQjkj Qtt i Qkjkj Qtt i K Q tPtPtttP ttPtttPtP kj kj θθ θθ ∑ ∑ ∈ ∈ = = (10) donde (tj tk)∈Q significa cualquier combinación de dos términos en la consulta. Esta es una extensión directa del modelo de traducción propuesto en [3] a nuestras relaciones dependientes del contexto. La puntuación según el modelo de Conocimiento se define entonces de la siguiente manera: ∑ ∑∈ ∈ = Vt DiQkQjkj Qtt iK i kj tPtPtPtttPDQScore )|(log)|()|()|(),( 00 )( θθθ (11) Nuevamente, solo se utilizan los 100 términos de expansión principales. 6. PARÁMETROS DEL MODELO Hay varios parámetros en nuestro modelo: λ en la Ecuación (2) y αi (i∈{0, Dom, K, F}) en la Ecuación (3). Dado que el parámetro λ solo afecta al modelo de documento, lo estableceremos con el mismo valor en todos nuestros experimentos. El valor λ=0.5 se determina para maximizar la efectividad de los modelos base (ver Sección 7.2) en los datos de entrenamiento: consultas TREC 1-50 y documentos en el Disco 2. Los pesos de la mezcla αi de los modelos de componentes se entrenan en los mismos datos de entrenamiento utilizando el siguiente método de búsqueda de línea [11] para maximizar la Precisión Promedio Media (MAP): cada parámetro se considera como una dirección de búsqueda. Comenzamos buscando en una dirección, probando todos los valores en esa dirección, mientras mantenemos los valores en otras direcciones sin cambios. Cada dirección se busca sucesivamente, hasta que no se observe ninguna mejora en la MAP. Para evitar quedar atrapados en un máximo local, comenzamos desde 10 puntos aleatorios y se selecciona la mejor configuración. 7. EXPERIMENTOS 7.1 Configuración Los datos principales de prueba son los de las pistas ad-hoc y de filtrado de TREC 1-3, que incluyen las consultas 1-150 y los documentos en los Discos 1-3. La elección de esta colección de pruebas se debe a la disponibilidad de un dominio especificado manualmente para cada consulta. Esto nos permite comparar con un enfoque que utiliza identificación automática de dominio. A continuación se muestra un ejemplo de tema: <num> Número: 103 <dom> Dominio: Ley y Gobierno <title> Tema: Reforma del Bienestar Solo utilizamos títulos de temas en todas nuestras pruebas. Las consultas 1-50 se utilizan para el entrenamiento y las consultas 51-150 para las pruebas. Se definen 13 dominios en estas consultas y su distribución entre los dos conjuntos de consultas se muestra en la Figura 1. Podemos ver que la distribución varía considerablemente entre dominios y entre los dos conjuntos de consultas. También hemos realizado pruebas con datos de TREC 7 y 8. Para esta serie de pruebas, cada colección se utiliza a su vez como datos de entrenamiento mientras que la otra se utiliza para pruebas. Algunas estadísticas de los datos se describen en la Tabla 2. Todos los documentos son preprocesados utilizando el stemmer de Porter en Lemur y se utiliza la lista de palabras vacías estándar. Algunas consultas (4, 5 y 3 en los tres conjuntos de consultas) solo contienen una palabra. Para estas consultas, el modelo de conocimiento no es aplicable. En los modelos de dominio, examinamos varias preguntas: • ¿Es útil incorporar el modelo de dominio cuando se especifica manualmente el dominio de consulta? • ¿Se puede determinar automáticamente el dominio de consulta si no está especificado? ¿Qué tan efectivo es este método? • Describimos dos formas de recopilar documentos para un dominio: ya sea utilizando documentos considerados relevantes para las consultas en el dominio o utilizando documentos recuperados para estas consultas. ¿Cómo se comparan? En el modelo de conocimiento, además de probar su efectividad, también queremos comparar las relaciones dependientes del contexto con las independientes del contexto. Finalmente, veremos el impacto de cada modelo de componente cuando se combinan todos los factores. 7.2 Métodos de referencia Se utilizan dos modelos de referencia: el modelo clásico de unigrama sin ninguna expansión, y el modelo con Retroalimentación. En todos los experimentos, se crean modelos de documentos utilizando suavizado de Jelinek-Mercer. Esta elección se realiza de acuerdo con la observación en [36] de que el método funciona muy bien para consultas largas. En nuestro caso, a medida que se expanden las consultas, tienen un rendimiento similar a las consultas largas. En nuestros tests preliminares, también encontramos que este método funcionó mejor que los otros métodos (por ejemplo, Dirichlet), especialmente para el método principal de línea base con modelo de retroalimentación. La Tabla 3 muestra la eficacia de recuperación en todas las colecciones. 7.3 Modelos de Conocimiento Este modelo se combina con ambos modelos base (con o sin retroalimentación). También comparamos el modelo de conocimiento dependiente del contexto con las relaciones de términos tradicionales independientes del contexto (definidas entre dos términos individuales), que se utilizan para ampliar las consultas. Este último selecciona términos de expansión con la relación global más fuerte con la consulta. Esta relación se mide por la suma de las relaciones con cada uno de los términos de la consulta. Este método es equivalente a [24]. También es similar al modelo de traducción [3]. Lo llamamos 0 5 10 15 20 25 30 35 Finanzas Ambientales Economía Internacional Finanzas Internacionales Política Internacional Relaciones Internacionales Derecho y Gobierno. Medicina y Biología. Política Militar. Ciencia y Tecnología. Economía de EE. UU. Política de EE. UU. Consulta 1-50 Consulta 51-150 Figura 1. Distribución de dominios Tabla 2. Estadísticas de la colección TREC Tamaño del documento (GB) Vocabulario # de documentos Disco de entrenamiento de consulta 2 0.86 350,085 231,219 Discos 1-50 Discos 1-3 Discos 1-3 3.10 785,932 1,078,166 51-150 Discos TREC7 4-5 1.85 630,383 528,155 351-400 Discos TREC8 4-5 1.85 630,383 528,155 401-450 Modelo de co-ocurrencia en la Tabla 4. La prueba t también se realiza para determinar la significancia estadística. Como podemos ver, las relaciones de simple co-ocurrencia pueden producir mejoras relativamente fuertes; pero las relaciones dependientes del contexto pueden producir mejoras mucho más fuertes en todos los casos, especialmente cuando no se utiliza retroalimentación. Todas las mejoras sobre el modelo de coocurrencia son estadísticamente significativas (esto no se muestra en la tabla). Las grandes diferencias entre los dos tipos de relación muestran claramente que las relaciones dependientes del contexto son más apropiadas para la expansión de consultas. Esto confirma la hipótesis que planteamos, que al incorporar información de contexto en las relaciones, podemos determinar mejor las relaciones apropiadas a aplicar y así evitar introducir términos de expansión inapropiados. El siguiente ejemplo puede confirmar aún más esta observación, donde mostramos los términos de expansión más fuertes sugeridos por ambos tipos de relación para la consulta #384 estación espacial luna: Relaciones de co-ocurrencia: año 0.016552 potencia 0.013226 tiempo 0.010925 1 0.009422 desarrollar 0.008932 oficina 0.008485 operar 0.008408 2 0.007875 tierra 0.007843 trabajo 0.007801 radio 0.007701 sistema 0.007627 construir 0.007451 000 0.007403 incluir 0.007377 estado 0.007076 programa 0.007062 nación 0.006937 abrir 0.006889 servicio 0.006809 aire 0.006734 espacio 0.006685 nuclear 0.006521 completo 0.006425 hacer 0.006410 compañía 0.006262 personas 0.006244 proyecto 0.006147 unidad 0.006114 general 0.006036 diario 0.006029 Relaciones dependientes del contexto: espacio 0.053913 mar 0.046589 tierra 0.041786 hombre 0.037770 programa 0.033077 proyecto 0.026901 base 0.025213 órbita 0.025190 construir 0.025042 misión 0.023974 llamada 0.022573 explorar 0.021601 lanzamiento 0.019574 desarrollar 0.019153 transbordador 0.016966 plan 0.016641 vuelo 0.016169 estación 0.016045 internacional 0.016002 energía 0.015556 operar 0.014536 potencia 0.014224 transporte 0.012944 construir 0.012160 nasa 0.011985 nación 0.011855 permanente 0.011521 japón 0.011433 apolo 0.010997 lunar 0.010898 En comparación con el modelo base con retroalimentación (Tab. 3), vemos que las mejoras realizadas por el modelo de conocimiento solo son ligeramente menores. Sin embargo, cuando ambos modelos se combinan, hay mejoras adicionales sobre el modelo de Retroalimentación, y estas mejoras son estadísticamente significativas en 2 de cada 3 casos. Esto demuestra que los impactos producidos por la retroalimentación y las relaciones de términos son diferentes y complementarios. Modelos de dominio En esta sección, probamos varias estrategias para crear y utilizar modelos de dominio, aprovechando la información del dominio del conjunto de consultas de diversas maneras. Estrategias para crear modelos de dominio: C1 - Con los documentos relevantes para las consultas dentro del dominio: esta estrategia simula el caso en el que tenemos un directorio existente en el que se incluyen documentos relevantes para el dominio. C2 - Con los 100 documentos principales recuperados con las consultas dentro del dominio: esta estrategia simula el caso en el que el usuario especifica un dominio para sus consultas sin juzgar la relevancia del documento, y el sistema recopila documentos relacionados de su historial de búsqueda. Estrategias para usar modelos de dominio: U1 - El modelo de dominio es determinado por el usuario manualmente. U2 - El modelo de dominio es determinado por el sistema. 7.4.1 Creación de modelos de dominio. Probamos las estrategias C1 y C2. En esta serie de pruebas, cada una de las consultas del 51 al 150 se utiliza sucesivamente como la consulta de prueba, mientras que las otras consultas y sus documentos relevantes (C1) o los documentos recuperados de mayor rango (C2) se utilizan para crear modelos de dominio. El mismo método se utiliza en las consultas del 1 al 50 para ajustar los parámetros. Tabla 3. Modelos de referencia Modelo Unigrama Coll. Medida Sin FB Con FB AvgP 0.1570 0.2344 (+49.30%) Recuperación /48 355 15 711 19 513 Discos 1-3 P@10 0.4050 0.5010 AvgP 0.1656 0.2176 (+31.40%) Recuperación /4 674 2 237 2 777 TREC7 P@10 0.3420 0.3860 AvgP 0.2387 0.2909 (+21.87%) Recuperación /4 728 2 764 3 237 TREC8 P@10 0.4340 0.4860 Tabla 4. Modelo de conocimiento Co-ocurrencia Modelo de conocimiento Col. Medida Sin FB Con FB Sin FB Con FB AvgP 0.1884 (+20.00%)++ 0.2432 (+3.75%)** 0.2164 (+37.83%)++ 0.2463 (+5.08%)** Recall /48 355 17 430 20 020 18 944 20 260 Discos1-3 P@10 0.4640 0.5160 0.5050 0.5120 AvgP 0.1823 (+10.08%)++ 0.2350 (+8.00%)* 0.2157 (+30.25%)++ 0.2401 (+10.34%)** Recall /4 674 2 329 2 933 2 709 2 985 TREC7 P@10 0.3780 0.3760 0.3900 0.3900 AvgP 0.2519 (+5.53%) 0.2926 (+0.58%) 0.2724 (+14.12%)++ 0.3007 (+3.37%) Recall /4 728 2 829 3 279 3 090 3 338 TREC8 P@10 0.4360 0.4940 0.4720 0.5000 (La columna SinFB se compara con el modelo base sin retroalimentación, mientras que ConFB se compara con el modelo base con retroalimentación. ++ y + significan cambios significativos en la prueba t con respecto al modelo base sin retroalimentación, a un nivel de p<0.01 y p<0.05, respectivamente. ** y * son similares pero se comparan con el modelo base con retroalimentación.) Tabla 5. Modelos de dominio con documentos relevantes (C1) Dominio Subdominio Colección. Medida Sin FB Con FB Sin FB Con FB AvgP 0.1700 (+8.28%)++ 0.2454 (+4.69%)** 0.1918 (+22.17%)++ 0.2461 (+4.99%)** Recall /48 355 16 517 20 141 17 872 20 212 Discos 1-3 (U1) P@10 0.4370 0.5130 0.4490 0.5150 AvgP 0.1715 (+3.56%)++ 0.2389 (+9.79%)* 0.1842 (+11.23%)++ 0.2408 (+10.66%)** Recall /4 674 2 270 2 965 2 428 2 987 TREC7 (U2) P@10 0.3720 0.3740 0.3880 0.3760 AvgP 0.2442 (+2.30%) 0.2957 (+1.65%) 0.2563 (+7.37%) 0.2967 (+1.99%) Recall /4 728 2 796 3 308 2 873 3 302 TREC8 (U2) P@10 0.4420 0.5000 0.4280 0.5020 Tabla 6. Modelos de dominio con los 100 documentos principales (C2) Dominio Subdominio Col. Medida Sin FB Con FB Sin FB Con FB AvgP 0.1718 (+9.43%)++ 0.2456 (+4.78%)** 0.1799 (+14.59%)++ 0.2452 (+4.61%)** Recall /48 355 16 558 20 131 17 341 20 155 Discos1-3 (U1) P@10 0.4300 0.5140 0.4220 0.5110 AvgP 0.1765 (+6.58%)++ 0.2395 (+10.06%)** 0.1785 (+7.79%)++ 0.2393 (+9.97%)** Recall /4 674 2 319 2 969 2 254 2 968 TREC7 (U2) P@10 0.3780 0.3820 0.3820 0.3820 AvgP 0.2434 (+1.97%) 0.2949 (+1.38%) 0.2441 (+2.26%) 0.2961 (+1.79%) Recall /4 728 2 772 3 318 2 734 3 311 TREC8 (U2) P@10 0.4380 0.4960 0.4280 0.5020 También comparamos los modelos de dominio creados con todos los documentos del dominio (Dominio) y con solo los 10 documentos recuperados principales en el dominio con la consulta (Sub-Dominio). En estos tests, utilizamos la identificación manual del dominio de consulta para los Discos 1-3 (U1), pero la identificación automática para TREC7 y 8 (U2). Primero, es interesante notar que la incorporación de modelos de dominio puede mejorar la efectividad de recuperación en todos los casos en general. Las mejoras en los Discos 1-3 y TREC7 son estadísticamente significativas. Sin embargo, las escalas de mejora son más pequeñas que al usar los modelos de Retroalimentación y Relación. Al observar la distribución de los dominios (Fig. 1), esta observación no es sorprendente: para muchos dominios, solo tenemos unas pocas consultas de entrenamiento, por lo tanto, pocos documentos dentro del dominio para crear modelos de dominio. Además, los temas en el mismo dominio pueden variar considerablemente, en particular en dominios amplios como la ciencia y la tecnología, la política internacional, etc. Segundo, observamos que los dos métodos para crear modelos de dominio funcionan igual de bien (Tab. 6 vs. Tab. 5). En otras palabras, proporcionar juicios de relevancia para las consultas no aporta mucha ventaja para el propósito de crear modelos de dominio. Esto puede parecer sorprendente. Un análisis muestra de inmediato la razón: un modelo de dominio (de la forma en que lo creamos) solo captura la distribución de términos en el dominio. Los documentos relevantes para todas las consultas dentro del dominio varían considerablemente. Por lo tanto, en algunos dominios grandes, los términos característicos tienen efectos variables en las consultas. Por otro lado, dado que solo utilizamos la distribución de términos, aunque los documentos principales recuperados para las consultas dentro del dominio sean irrelevantes, aún pueden contener términos característicos del dominio de manera similar a los documentos relevantes. Por lo tanto, ambas estrategias producen efectos muy similares. Este resultado abre la puerta a un método más simple que no requiere juicios de relevancia, por ejemplo, utilizando el historial de búsqueda. Tercero, sin el modelo de retroalimentación, los modelos de subdominio construidos con documentos relevantes funcionan mucho mejor que los modelos de dominio completo (Tabla 5). Sin embargo, una vez que se utiliza el modelo de retroalimentación, la ventaja desaparece. Por un lado, esto confirma nuestra hipótesis anterior de que un dominio puede ser demasiado grande para poder sugerir términos relevantes para nuevas consultas en el dominio. Indirectamente valida nuestra primera hipótesis de que un modelo o perfil de usuario único puede ser demasiado grande, por lo que se prefieren modelos de dominio más pequeños. Por otro lado, los modelos de subdominio capturan características similares al modelo de retroalimentación. Por lo tanto, cuando se utiliza este último, los modelos de subdominio se vuelven superfluos. Sin embargo, si los modelos de dominio se construyen con documentos de alta clasificación (Tabla 6), los modelos de subdominio hacen muchas menos diferencias. Esto se puede explicar por el hecho de que los dominios construidos con documentos de alto rango tienden a ser más uniformes que los documentos relevantes con respecto a la distribución de términos, ya que los documentos recuperados en la parte superior suelen tener una correspondencia estadística más fuerte con las consultas que los documentos relevantes. 7.4.2 Determinación Automática del Dominio de la Consulta No es realista pedir siempre a los usuarios que especifiquen un dominio para sus consultas. Aquí examinamos la posibilidad de identificar automáticamente los dominios de consulta. La Tabla 7 muestra los resultados con esta estrategia utilizando ambas estrategias para la construcción del modelo de dominio. Podemos observar que la efectividad es solo ligeramente menor que la de aquellas producidas con la identificación manual del dominio de consulta (Tab. 5 y 6, Modelos de dominio). Esto demuestra que la identificación automática de dominios es una forma de seleccionar un modelo de dominio tan efectiva como la identificación manual. Esto también demuestra la viabilidad de utilizar modelos de dominio para consultas cuando no se proporciona información de dominio. Al observar la precisión de la identificación automática de dominios, sin embargo, es sorprendentemente baja: para las consultas 51-150, solo el 38% de los dominios determinados corresponden a las identificaciones manuales. Esto es mucho menor que las tasas superiores al 80% reportadas en [18]. Un análisis detallado revela que la razón principal es la cercanía de varios dominios en las consultas de TREC (por ejemplo, Relaciones internacionales, política internacional, política. Sin embargo, en esta situación, los dominios incorrectos asignados a las consultas no siempre son irrelevantes e inútiles. Por ejemplo, incluso cuando una consulta en Relaciones Internacionales se clasifica en Política Internacional, este último dominio aún puede sugerir términos útiles para la consulta. Por lo tanto, la relativamente baja precisión de clasificación no significa una baja utilidad de los modelos de dominio. 7.5 Modelos completos Los resultados con el modelo completo se muestran en la Tabla 8. Este modelo integra todos los componentes descritos en este documento: modelo de consulta original, modelo de retroalimentación, modelo de dominio y modelo de conocimiento. Hemos probado ambas estrategias para crear modelos de dominio, pero las diferencias entre ellas son muy pequeñas. Por lo tanto, solo informamos los resultados con los documentos relevantes. Nuestra primera observación es que los modelos completos producen los mejores resultados. Todas las mejoras sobre el modelo base (con retroalimentación) son estadísticamente significativas. Este resultado confirma que la integración de factores contextuales es efectiva. En comparación con los otros resultados, observamos mejoras consistentes, aunque pequeñas en algunos casos, en todos los modelos parciales. Al observar los pesos de la mezcla, que pueden reflejar la importancia de cada modelo, observamos que los mejores ajustes en todas las colecciones varían en los siguientes rangos: 0.1≤α0 ≤0.2, 0.1≤αDom ≤0.2, 0.1≤αK ≤0.2 y 0.5≤αF ≤0.6. Vemos que el factor más importante es el modelo de retroalimentación. Este también es el único factor que produjo las mejoras más significativas sobre el modelo de consulta original. Esta observación parece indicar que este modelo tiene la mayor capacidad para capturar la información necesaria detrás de la consulta. Sin embargo, incluso con pesos más bajos, los otros modelos sí tienen un fuerte impacto en la efectividad final. Esto demuestra el beneficio de integrar más factores contextuales en RI. Tabla 7. Identificación automática del dominio de consulta (U2) Dom. con doc. rel. (C1) Dom. con doc. en el top-100 (C2) Coll. Medida Sin FB Con FB Sin FB Con FB AvgP 0.1650 (+5.10%)++ 0.2444 (+4.27%)** 0.1670 (+6.37%)++ 0.2449 (+4.48%)** Recuperación 16 343 20 061 16 414 20 090 Discos 1-3 (U2) P@10 0.4270 0.5100 0.4090 0.5140 Tabla 8. Modelos completos (C1) Todos los documentos. Colección de dominio. Medida Man. dom. id. (U1) Auto. dom. id. (U2) AvgP 0.2501 (+6.70%) ** 0.2489 (+6.19%) ** Recall /48 355 20 514 20 367 Discos 1-3 P@10 0.5200 0.5230 AvgP 0.2462 (+13.14%) ** Recall /4 674 3 014TREC7 P@10 N/A 0.3960 AvgP 0.3029 (+4.13%) ** Recall /4 728 3 321TREC8 P@10 N/A 0.5020 8. CONCLUSIONES Los enfoques tradicionales de IR suelen considerar la consulta como el único elemento disponible para satisfacer la necesidad de información del usuario. Muchos estudios previos han investigado la integración de algunos factores contextuales en los modelos de RI, típicamente mediante la incorporación de un perfil de usuario. En este artículo, argumentamos que un único perfil de usuario (o modelo) puede contener una gran variedad de temas diferentes, de modo que las nuevas consultas pueden estar sesgadas incorrectamente. De manera similar a algunos estudios previos, proponemos modelar dominios de temas en lugar del usuario. Investigaciones previas sobre el contexto se centraron en factores alrededor de la consulta. Mostramos en este artículo que los factores dentro de la consulta también son importantes, ya que ayudan a seleccionar las relaciones de términos apropiadas para aplicar en la expansión de la consulta. Hemos integrado los factores contextuales mencionados anteriormente, junto con el modelo de retroalimentación, en un solo modelo de lenguaje. Nuestros resultados experimentales confirman firmemente el beneficio de utilizar contextos en IR. Este trabajo también muestra que el marco de modelado del lenguaje es apropiado para integrar muchos factores contextuales. Este trabajo puede ser mejorado en varios aspectos, incluyendo otros métodos para extraer relaciones entre términos, integrar más palabras de contexto en las condiciones e identificar dominios de consulta. También sería interesante probar el método en la búsqueda web utilizando el historial de búsqueda del usuario. Investigaremos estos problemas en nuestra futura investigación. REFERENCIAS [1] Bai, J., Nie, J.Y., Cao, G., Relaciones de términos dependientes del contexto para la recuperación de información, EMNLP06, pp. 551-559, 2006. [2] Belkin, N.J., Interacción con textos: la recuperación de información como comportamiento de búsqueda de información, Information Retrieval93: Von der modellierung zu anwendung, pp. 55-66, Konstanz: Krause & Womser-Hacker, 1993. [3] Berger, A., Lafferty, J., Recuperación de información como traducción estadística, SIGIR99, pp. 222-229, 1999. [4] Bouchard, H., Nie, J.Y., Modelos de lenguaje aplicados a la búsqueda de información contextual, Conf. en Recherche dInformation et Applications (CORIA), Lyon, 2006. [5] Chirita, P.A., Paiu, R., Nejdl, W., Kohlschütter, C., Uso de metadatos de ODP para personalizar la búsqueda, SIGIR, pp. 178-185, 2005. [6] Church, K. W., Hanks, P., Normas de asociación de palabras, información mutua y lexicografía. ACL, pp. 22-29, 1989. [7] Croft, W. B., Cronen-Townsend, S., Lavrenko, V., Retroalimentación de relevancia y personalización: una perspectiva de modelado de lenguaje, En: El taller DELOS-NSF sobre Personalización y Sistemas de Recomendación en Bibliotecas Digitales, pp. 49-54, 2006. [8] Croft, W. B., Wei, X., Modelos de temas basados en contexto para la modificación de consultas, Informe Técnico CIIR, Universidad de Massachusetts, 2005. [9] Dumais, S., Cutrell, E., Cadiz, J., Jancke, G., Sarin, R., Robbins, D. C., Cosas que he visto: un sistema para la recuperación y reutilización de información personal, SIGIR03, pp. 72-79, 2003. [10] Fang, H., Zhai, C., Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información, SIGIR06, pp.115-122, 2006. [11] Gao, J., Qi, H., Xia, X., Nie, J.-Y., Modelo discriminativo lineal para la recuperación de información. SIGIR05, pp. 290-297, 2005. [12] Búsqueda personalizada de Google, http://www.google.com/psearch. [13] Hipp, J., Guntzer, U., Nakhaeizadeh, G., Algoritmos para la minería de reglas de asociación - una encuesta general y comparación. SIGKDD explorations, 2 (1), pp. 58-64, 2000. [14] Ingwersen, P., Jäverlin, K., Recuperación de información en contexto: IRiX, SIGIR Forum, 39: pp. 31-39, 2004. [15] Kim, H.-R., Chan, P.K., Ranking personalizado de resultados de búsqueda con jerarquías de interés de usuario aprendidas a partir de marcadores, Taller WEBKDD05 en ACM-KDD, pp. 32-43, 2005. [16] Lavrenko, V., Croft, W. B., Modelos de lenguaje basados en relevancia, SIGIR01, pp. 120-127, 2001. [17] Lau, R., Bruza, P., Song, D., Revisión de creencias para recuperación de información adaptativa, SIGIR04, pp. 130-137, 2004. [18] Liu, F., Yu,C., Meng, W., Búsqueda web personalizada mediante el mapeo de consultas de usuario a categorías, CIKM02, pp. 558-565. [19] Liu, X., Croft, W. B., Recuperación basada en clústeres utilizando modelos de lenguaje, SIGIR 04, pp. 186-193, 2004. [20] Morris, R.C., Hacia un servicio de información centrado en el usuario, JASIS, 45: pp. 20-30, 1994. [21] Park, T.K., Hacia una teoría de relevancia basada en el usuario: Un llamado a un nuevo paradigma de investigación, JASIS, 45: pp. 135-141, 1994. [22] Peng, F., Schuurmans, D., Wang, S. Mejora de clasificadores Naive Bayes con modelos de lenguaje estadístico. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Retr. 7(3-4): pp. 317-345, 2004. [23] Pitkow, J., Schütze, H., Cass, T., Cooley, R., Turnbull, D., Edmonds, A., Adar, E., Breuel, T., Búsqueda personalizada, Comunicaciones de ACM, 45: pp. 50-55, 2002. [24] Qiu, Y., Frei, H.P. Expansión de consulta basada en conceptos. SIGIR93, pp.160-169, 1993. [25] Sanderson, M., Recuperación con buen sentido, Inf. Ret., 2(1): pp. 49-69, 2000. [26] Schamber, L., Eisenberg, M.B., Nilan, M.S., Una reexaminación de la relevancia: Hacia una definición dinámica y situacional, Information Processing and Management, 26(6): pp. 755-774, 1990. [27] Schütze, H., Pedersen J.O., Un tesauro basado en coocurrencias y dos aplicaciones para la recuperación de información, Information Processing and Management, 33(3): pp. 307-318, 1997. [28] Shen, D., Pan, R., Sun, J-T., Pan, J.J., Wu, K., Yin, J., Yang, Q. Enriquecimiento de consultas para la clasificación de consultas web. ACMTOIS, 24(3): pp. 320-352, 2006. [29] Shen, X., Tan, B., Zhai, C., Recuperación de información sensible al contexto utilizando retroalimentación implícita, SIGIR05, pp. 43-50, 2005. [30] Teevan, J., Dumais, S.T., Horvitz, E., Personalización de la búsqueda a través del análisis automatizado de intereses y actividades, SIGIR05, pp. 449-456, 2005. [31] Voorhees, E., Expansión de consultas utilizando relaciones léxico-semánticas. SIGIR94, pp. 61-69, 1994. [32] Xu, J., Croft, W.B., Expansión de consultas utilizando análisis local y global de documentos, SIGIR96, pp. 4-11, 1996. [33] Yarowsky, D. Desambiguación de sentido de palabras no supervisada que rivaliza con métodos supervisados. ACL, pp. 189-196. 1995. [34] Zhou X., Hu X., Zhang X., Lin X., Song I-Y., Suavizado semántico sensible al contexto para el enfoque de modelado de lenguaje en la recuperación de información genómica, SIGIR06, pp. 170-177, 2006. [35] Zhai, C., Lafferty, J., Retroalimentación basada en modelos en el enfoque de modelado de lenguaje para la recuperación de información, CIKM01, pp. 403-410, 2001. [36] Zhai, C., Lafferty, J., Un estudio de métodos de suavizado para modelos de lenguaje aplicados a la recuperación de información ad-hoc. SIGIR, pp.334-342, 2001.