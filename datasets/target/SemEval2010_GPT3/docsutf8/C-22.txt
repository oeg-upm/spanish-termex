Recopilación de métricas en tiempo de ejecución para la adaptación de aplicaciones móviles con soporte de middleware. Hendrik Gani, Escuela de Ciencias de la Computación y Tecnología de la Información, Universidad RMIT, Melbourne, Australia hgani@cs.rmit.edu.au Caspar Ryan, Escuela de Ciencias de la Computación y Tecnología de la Información, Universidad RMIT, Melbourne, Australia caspar@cs.rmit.edu.au Pablo Rossi, Escuela de Ciencias de la Computación y Tecnología de la Información, Universidad RMIT, Melbourne, Australia pablo@cs.rmit.edu.au RESUMEN Este artículo propone, implementa y evalúa en términos de rendimiento en el peor caso, una estrategia de recopilación de métricas en línea para facilitar la adaptación de aplicaciones a través de la movilidad de objetos utilizando un marco de objetos móviles y middleware de soporte. La solución se basa en una representación abstracta del sistema de objetos móviles, que contiene contenedores que agregan métricas para cada componente específico, incluidos los administradores de host, los tiempos de ejecución y los objetos móviles. Una característica clave de la solución es la especificación de múltiples criterios configurables para controlar la medición y propagación de métricas a través del sistema. La plataforma MobJeX se utilizó como base para la implementación y prueba, con una serie de pruebas de laboratorio realizadas para medir la escalabilidad, eficiencia y la aplicación de criterios simples de medición y propagación para reducir la sobrecarga de recolección. Categorías y Descriptores de Asignaturas C.2.4 Sistemas Distribuidos; D.2.8 Métricas Términos Generales Medición, Rendimiento. 1. INTRODUCCIÓN Las diferentes capacidades de los dispositivos móviles, junto con las variadas velocidades, tasas de error y características de desconexión de las redes móviles [1], hacen difícil predecir de antemano el entorno de ejecución exacto de las aplicaciones móviles. Una solución que está recibiendo cada vez más atención en la comunidad de investigación es la adaptación de aplicaciones [2-7], en la que las aplicaciones ajustan su comportamiento en respuesta a factores como el uso de red, procesador o memoria. La adaptación efectiva requiere información detallada y actualizada tanto sobre el sistema como sobre el software en sí mismo. Las métricas relacionadas con la información del sistema en su totalidad (por ejemplo, carga del procesador, memoria y red) se denominan métricas ambientales [5], mientras que las métricas que representan el comportamiento de la aplicación se denominan métricas de software [8]. Además, el tipo de métricas necesarias para realizar la adaptación depende del tipo de adaptación requerida. Por ejemplo, la adaptación basada en servicios, en la que la calidad del servicio o el comportamiento del servicio se modifica en respuesta a los cambios en el entorno de ejecución, generalmente requiere métricas ambientales detalladas pero solo métricas de software simples [4]. Por otro lado, la adaptación a través de la movilidad de objetos [6] también requiere métricas de software detalladas [9] ya que la ubicación de los objetos depende de las características de ejecución de los propios objetos móviles. Con la excepción de MobJeX [6], los sistemas de objetos móviles existentes como Voyager [10], FarGo [11, 12] y JavaParty [13] no proporcionan adaptación automatizada, y por lo tanto carecen del proceso de recopilación de métricas necesario para respaldar este proceso. En el caso de MobJeX, aunque se ha implementado un motor de adaptación [5], las pruebas preliminares se realizaron utilizando métricas predefinidas sintéticas, ya que hay poco trabajo previo sobre la recopilación dinámica de métricas de software en marcos de objetos móviles y no existen medios existentes para recopilarlas automáticamente. Por consiguiente, la principal contribución de este artículo es una solución para la recolección de métricas dinámicas que respalda la adaptación a través de la movilidad de objetos para aplicaciones móviles. Este problema no es trivial ya que los marcos de objetos móviles típicos consisten en múltiples componentes de aplicación y middleware, por lo que la recopilación de métricas debe realizarse en diferentes ubicaciones y los resultados deben propagarse eficientemente al motor de adaptación. Además, en algunos casos, la ubicación donde se debe recopilar cada métrica no está fija (es decir, podría hacerse en varios lugares) y, por lo tanto, se debe tomar una decisión basada en la eficiencia de la solución elegida (ver sección 3). El resto de este documento está organizado de la siguiente manera: La Sección 2 describe la estructura general y la implementación de marcos de objetos móviles para comprender los desafíos relacionados con la recopilación, propagación y entrega de métricas, tal como se describe en la Sección 3. La sección 4 describe algunas pruebas iniciales y resultados, y la sección 5 concluye con un resumen, conclusiones y discusión sobre trabajos futuros. FONDO En general, una aplicación orientada a objetos consiste en objetos que colaboran para proporcionar la funcionalidad requerida por un dominio de problema dado. Los marcos de objetos móviles permiten que algunos de estos objetos sean etiquetados como objetos móviles, brindando soporte de middleware para que dichos objetos puedan ser movidos en tiempo de ejecución a otros hosts. Como mínimo, un marco de objetos móviles con al menos una aplicación móvil en ejecución consta de los siguientes componentes: tiempos de ejecución, objetos móviles y proxies [14], aunque la terminología utilizada por los marcos individuales puede diferir [6, 10-13]. Un tiempo de ejecución es un proceso contenedor para la gestión de objetos móviles. Por ejemplo, en FarGo [15] este componente es conocido como núcleo y en la mayoría de los sistemas se requieren tiempos de ejecución separados para permitir que diferentes aplicaciones se ejecuten de forma independiente, aunque este no es el caso de MobJeX, que puede ejecutar múltiples aplicaciones en un solo tiempo de ejecución utilizando hilos. Las aplicaciones en sí mismas comprenden objetos móviles, los cuales interactúan entre sí a través de proxies [14]. Se requieren proxies para cada objeto de destino con el que un objeto fuente se comunica, los cuales tienen la misma interfaz de método que el objeto en sí pero añaden funcionalidad de comunicación remota y seguimiento de objetos. Al migrar, los objetos de proxy se mueven con el objeto fuente. El sistema basado en Java MobJeX, que se utiliza como plataforma de implementación para la solución de recopilación de métricas descrita en este documento, agrega una serie de componentes de middleware adicionales. En primer lugar, un administrador de host (conocido como un servicio en MobJeX) proporciona un punto central de comunicación al ejecutarse en un puerto conocido por host, facilitando así la enumeración o búsqueda de componentes como tiempos de ejecución u objetos móviles. En segundo lugar, MobJeX tiene un contenedor de objetos móviles por aplicación llamado gestor de transporte (TM). Por lo tanto, los administradores de host y transporte se consideran en la solución proporcionada en la siguiente sección, pero podrían omitirse en el caso general. Finalmente, dependiendo del modo de adaptación, MobJeX puede tener un controlador de sistema centralizado que incorpora un motor de adaptación global para realizar una optimización en todo el sistema. 3. RECOLECCIÓN DE MÉTRICAS Esta sección discute el diseño y la derivación de una solución para recolectar métricas con el fin de apoyar la adaptación de aplicaciones a través de la migración de objetos. La solución, aunque implementada dentro del marco de MobJeX, se discute en su mayor parte en términos genéricos, excepto cuando se indica explícitamente que es específica de MobJeX. 3.1 Selección de Métricas Se han elegido las métricas de Ryan y Rossi [9] como base para esta solución, ya que están específicamente destinadas a la adaptación de aplicaciones móviles y han sido derivadas de una serie de modelos matemáticos y validadas empíricamente. Además, se demostró empíricamente que las métricas mejoraron el rendimiento de la aplicación en un escenario real de adaptación tras un cambio en el entorno de ejecución. Sin embargo, estaría fuera del alcance de este documento implementar y probar el conjunto completo de métricas enumeradas en [9], por lo que, con el fin de proporcionar un subconjunto no aleatorio útil, elegimos implementar el conjunto mínimo de métricas necesarias para llevar a cabo la adaptación local y global [9] y así satisfacer una variedad de escenarios reales de adaptación. Por lo tanto, la solución presentada en esta sección se discute principalmente en términos de estas métricas, aunque la estructura de la solución está destinada a apoyar la implementación de las métricas restantes, así como otras métricas no especificadas como aquellas relacionadas con la calidad y la utilización de recursos. Este subconjunto está listado a continuación y categorizado según el tipo de métrica. Se debe tener en cuenta que se utilizaron métricas adicionales con fines de implementación para derivar métricas fundamentales o asistir en la evaluación, y por lo tanto se definen en el contexto correspondiente cuando sea apropiado. 1. Métricas de software - Número de Invocaciones (NI), la frecuencia de invocaciones en los métodos de una clase. 2. Métricas de rendimiento - Tiempo de ejecución del método (ET), el tiempo tomado para ejecutar el cuerpo de un método (ms). - Tiempo de invocación del método (IT), el tiempo tomado para invocar un método, excluyendo el tiempo de ejecución del método (ms). 3. Métricas de utilización de recursos: Uso de memoria (MU), el uso de memoria de un proceso (en bytes). - Uso del procesador (PU), el porcentaje de la carga de la CPU de un host. - Uso de red (NU), el ancho de banda de red entre dos hosts (en bytes/seg). A continuación se presentan breves ejemplos de varios de estos indicadores para demostrar su uso en un escenario de adaptación. A medida que el Uso del Procesador (PU) en un determinado host aumenta, el Tiempo de Ejecución (ET) de un método dado ejecutado en ese host también aumenta [9], facilitando así la decisión de si mover un objeto con un alto ET a otro host con bajo PU. El Tiempo de Invocación (IT) muestra el sobrecosto de invocar un método específico, siendo el sobrecosto de invocación de empaquetar parámetros y transmitir datos remotos para una llamada remota varias órdenes de magnitud más alto que el costo de empujar y sacar datos de la pila de llamadas del método. En otras palabras, la invocación de métodos remotos es costosa y, por lo tanto, se debe evitar a menos que las ganancias obtenidas al mover un objeto a un host con más potencia de procesamiento (y así reducir el tiempo de ejecución) superen el mayor tiempo de invocación remota. Finalmente, el Número de Invocaciones (NI) se utiliza principalmente como un factor de ponderación o multiplicador para permitir que el motor de adaptación prediga el valor a lo largo del tiempo de una decisión de adaptación particular. 3.2 Medición de Métricas Esta subsección discute cómo se pueden obtener cada una de las métricas en el subconjunto bajo investigación en términos de medición directa o derivación, y dónde en el marco de objetos móviles dichas métricas deben ser medidas en realidad. De las métricas de recursos ambientales, el Uso del Procesador (PU) y el Uso de la Red (NU) están relacionados con una máquina individual, y por lo tanto pueden medirse directamente a través del subsistema de monitoreo de recursos que se instancia como parte del servicio MobJeX. Sin embargo, el Uso de Memoria (MU), que representa el estado de la memoria de un proceso en ejecución en lugar del uso de memoria de un host, debería ser recopilado dentro de un tiempo de ejecución individual. La medición de las métricas de Número de Invocaciones (NI) y Tiempo de Ejecución (ET) también se puede realizar a través de una medición directa, sin embargo, en este caso dentro de la implementación del objeto móvil (mobject) en sí mismo. NI implica simplemente incrementar un valor de contador al principio o al final de una llamada de método, dependiendo de la semántica deseada con respecto a las excepciones lanzadas, mientras que ET se puede medir comenzando un temporizador al principio del método y deteniéndolo al final del método, luego recuperando la duración registrada por el temporizador. Por el contrario, la recolección del Tiempo de Invocación (TI) no es tan directa, ya que el tiempo tomado para invocar un método solo se puede medir después de que el método termine su ejecución y regrese al llamante. Para recopilar métricas de TI, se necesita otra métrica adicional. Ryan y Rossi [9] definen el tiempo de respuesta métrico (RT), como el tiempo total que tarda una llamada a un método en finalizar, que es la suma de IT y ET. El Tiempo de Respuesta se puede medir directamente utilizando la misma técnica basada en temporizador que se utiliza para medir ET, aunque al inicio y al final de la llamada de proxy en lugar de la implementación del método. Una vez que se conoce el Tiempo de Respuesta (RT), se puede obtener el Tiempo de Ejecución (ET) restando RT de ET. Aunque esta derivación parece simple, en la práctica se complica por el hecho de que los valores de RT y ET a partir de los cuales se deriva el IT necesariamente se miden utilizando código de temporizador en diferentes ubicaciones, es decir. RT medido en el proxy, ET medido en el cuerpo del método de implementación del objeto. Además, los proxies no forman parte de la jerarquía de contención de MobJeX por definición, ya que aunque los proxies tienen una referencia a su objeto objetivo, no es eficiente que un objeto móvil (mobject) tenga referencias inversas a todos los numerosos proxies que lo referencian (uno por objeto fuente). Afortunadamente, este problema se puede resolver utilizando el mecanismo de propagación basado en push descrito en la sección 3.5, en el cual la métrica RT se empuja al mobjeto para que IT pueda derivarse del valor ET almacenado allí. El valor derivado de TI se almacena y se propaga según sea necesario de acuerdo con los criterios de la sección 3.6, cuya relación estructural se muestra en la Figura 1. 3.3 Inicio de la Medición Se identificó el enfoque de encuesta como el método más apropiado para recopilar métricas de utilización de recursos, como el Uso del Procesador (PU), Uso de la Red (NU) y Uso de la Memoria (MU), ya que no forman parte ni están relacionados con el flujo directo de la aplicación. Para medir PU o NU, el monitor de recursos sondea el Sistema Operativo para obtener la carga actual de la CPU o la red respectivamente. En el caso del Uso de Memoria (MU), la Máquina Virtual de Java (JVM) [16] es consultada para conocer la carga de memoria actual. Ten en cuenta que para minimizar el impacto en el tiempo de respuesta de la aplicación, la acción de sondeo debe realizarse de forma asíncrona en un hilo separado. Las métricas que son adecuadas para la recolección iniciada por la aplicación (es decir, como parte de una llamada de método normal) son métricas relacionadas con el software y el rendimiento, como el Número de Invocaciones (NI), Tiempo de Ejecución (ET) y Tiempo de Invocación (IT), que están explícitamente relacionadas con la invocación normal de un método, y por lo tanto pueden medirse directamente en este momento. 3.4 Agregación de Métricas En la solución presentada en este documento, todas las métricas recolectadas en el mismo lugar se agregan en un Contenedor de Métricas con contenedores individuales correspondientes a componentes funcionales en el marco de objetos móviles. La principal ventaja de agregar métricas en contenedores es que permite que se propaguen fácilmente como una unidad cohesiva a través de los componentes del marco de movilidad para que puedan ser entregadas al motor de adaptación, como se discute en la siguiente subsección. Ten en cuenta que este contenedor captura la diferente granularidad de los atributos de medición y sus métricas correspondientes. Considera el caso de medir el consumo de memoria. A un nivel grueso de granularidad, esto podría medirse para toda una aplicación o incluso un sistema, pero también podría medirse a nivel de un objeto individual; o para un nivel aún más fino de granularidad, el consumo de memoria durante la ejecución de un método específico. Como ejemplo del nivel de granularidad requerido para la adaptación basada en movilidad, el algoritmo de adaptación local propuesto por Ryan y Rossi [9] requiere métricas que representen tanto la duración de la ejecución de un método como el sobrecoste de la invocación de un método. El uso de contenedores de métricas facilita la recopilación de métricas en niveles de granularidad que van desde una sola máquina hasta el nivel individual de los métodos. Ten en cuenta que algunos contenedores de métricas no contienen objetos de métricas, ya que, como se describió anteriormente, la implementación de muestra solo utiliza un subconjunto de las métricas de adaptación de [9]. Sin embargo, por el bien de la consistencia y para promover la flexibilidad en cuanto a la adición de nuevas métricas en el futuro, estos contenedores aún se consideran en el diseño actual por completitud y para trabajos futuros. 3.5 Propagación y Entrega de Métricas La solución en este documento identifica dos etapas en el proceso de recolección y entrega de métricas. En primer lugar, la propagación de métricas a través de los componentes del marco de movilidad y, en segundo lugar, la entrega de esas métricas desde el gestor de host/servicio (o tiempo de ejecución si el gestor de host no está presente) al motor de adaptación. En cuanto a la propagación, en resumen, se propone que cuando un componente del sistema de nivel inferior detecta la llegada de una nueva actualización métrica (por ejemplo, un objeto móvil), la métrica se envía (posiblemente junto con otras métricas relevantes) al siguiente componente de nivel (es decir, el gestor de tiempo de ejecución o transporte que contiene el objeto móvil), que en una etapa posterior, nuevamente determinada por un criterio configurable (por ejemplo, cuando hay un número suficiente de objetos móviles cambiados), se enviará al siguiente componente de nivel (es decir, el gestor de host o el motor de adaptación). Un incentivo adicional para tratar la propagación por separado de la entrega se debe a la distinción entre la adaptación local y global [9]. La adaptación local se realiza mediante un motor que se ejecuta en el host local (por ejemplo, en MobJeX esto ocurriría dentro del servicio) y, por lo tanto, en este caso la fase de entrega sería una llamada interproceso local. Por el contrario, la adaptación global es manejada por un motor de adaptación centralizado que se ejecuta en un host remoto y, por lo tanto, la entrega de métricas se realiza a través de una llamada remota, y en el caso de que existan múltiples entornos de ejecución sin un administrador de host separado, el proceso de entrega sería aún más costoso. Por lo tanto, debido a la presencia de la latencia de comunicación en la red, es importante que el administrador del host pase la mayor cantidad de métricas posible al motor de adaptación en una invocación, lo que implica la necesidad de recopilar estas métricas en el administrador del host, a través de algún tipo de empuje o propagación, antes de enviarlas al motor de adaptación. Por consiguiente, se necesita mantener una representación o modelo abstracto del sistema [17]. Un modelo de este tipo contendría entidades de modelo, correspondientes a cada uno de los componentes principales del sistema, conectados en una jerarquía tipo árbol, que refleja precisamente la estructura y jerarquía de contención del sistema real. Adjuntar contenedores de métricas a entidades de modelo permite que una entidad de modelo que representa a un administrador de host sea entregada al motor de adaptación, lo que le permite acceder a todas las métricas en ese componente y en cualquiera de sus hijos (es decir, tiempos de ejecución y objetos móviles). Además, generalmente se esperaría que un motor de adaptación o controlador del sistema ya mantenga un modelo del sistema que no solo pueda ser reutilizado para la propagación, sino que también proporcione un medio efectivo para entregar información métrica desde el gestor del sistema al motor de adaptación. La relación entre las entidades del modelo y los contenedores de métricas se captura en la Figura 1. 3.6 Criterios de Propagación y Entrega Esta subsección propone criterios flexibles para permitir que cada componente decida cuándo debe propagar sus métricas al siguiente componente en línea (Figura 1), con el fin de reducir la sobrecarga incurrida cuando las métricas se propagan innecesariamente a través de los componentes del marco de movilidad y se entregan al motor de adaptación. Este documento propone cuatro tipos diferentes de criterios que se ejecutan en varias etapas del proceso de medición y propagación para determinar si la siguiente acción debe ser tomada o no. Este enfoque fue diseñado de tal manera que cuando un solo criterio no se cumple, los criterios siguientes no se prueban. Estos cuatro criterios se describen en las siguientes subsecciones. Criterio de Medición Métrica: Este criterio se adjunta a objetos Métricos individuales para decidir si se debe medir o no un nuevo valor métrico. Esto es especialmente útil en el caso en el que resulta costoso medir un métrica en particular. Además, este criterio puede ser utilizado como un mecanismo para limitar los requisitos de almacenamiento y la sobrecarga de manipulación en el caso de que se mantenga un historial métrico. Ejemplos simples podrían ser basados en el tiempo o la frecuencia, mientras que criterios más complejos podrían ser específicos del dominio para una métrica particular, o basados en la información almacenada en el historial de las métricas. Notificar Criterio de Contenedor de Métricas - Este criterio también está adjunto a objetos de Métricas individuales y se utiliza para determinar las circunstancias bajo las cuales el objeto de Métrica debe notificar a su Contenedor de Métricas. Esto se basa en la suposición de que puede haber casos en los que sea deseable medir y almacenar una métrica en el historial para el análisis del comportamiento temporal, pero aún no es lo suficientemente significativa como para notificar al MetricsContainer para su procesamiento adicional. Un ejemplo simple de este criterio sería basado en un umbral, en el cual el valor métrico más reciente se compara con el valor previamente almacenado para determinar si la diferencia es lo suficientemente significativa como para ser de interés para el MetricsContainer. Un criterio más complejo podría implicar el análisis de la historia para determinar si un patrón de cambios recientes es lo suficientemente significativo como para justificar un procesamiento adicional y la entrega de posibles métricas. Notificar Criterio de Entidad de Modelo - A diferencia de los dos criterios anteriores, este criterio está asociado con un MetricsContainer. Dado que un MetricsContainer puede tener varios objetos de Métrica, de los cuales tiene conocimiento explícito del dominio, es capaz de determinar si, cuándo y cuántos de estos métricos deben ser propagados a la ModelEntity y, por lo tanto, convertirse en candidatos para formar parte del proceso de empuje jerárquico de ModelEntity descrito a continuación. Esta toma de decisiones es facilitada por las notificaciones recibidas de los objetos Métricos individuales descritos anteriormente. Una implementación sencilla sería esperar un cierto número de actualizaciones antes de enviar una notificación a la entidad del modelo. Por ejemplo, dado que el objeto MobjectMetricsContainer contiene tres métricas, un criterio posible sería verificar si dos o más de las métricas han cambiado. Una implementación ligeramente más avanzada se puede lograr asignando un peso a cada métrica para indicar cuán significativa es en el proceso de toma de decisiones de adaptación. Criterio de empuje: El criterio de empuje se aplica a todas las ModelEntites que son contenedores, es decir, la TransportManagerModelEntity, RuntimeModelEntity y ServiceModelEntity, así como al caso especial del ProxyMetricsContainer. El propósito de este criterio es doble. Para el TransportManagerModelEntity esto sirve como un criterio para determinar la notificación ya que, al igual que con los criterios previamente descritos, se involucra una referencia local. Para las otras entidades de modelo, esto sirve como una oportunidad para determinar tanto cuándo como qué métricas deben ser enviadas al contenedor padre, donde en el caso de la ServiceModelEntity el padre es el motor de adaptación en sí mismo o en el caso del ProxyMetricsContainer el objetivo del envío es el MobjectMetricsContainer. Además, este criterio se evalúa utilizando información de dos fuentes. En primer lugar, responde a la notificación recibida de su propio MetricsContainer, pero lo más importante es que sirve para hacer un seguimiento de las notificaciones de sus ModelEntities secundarios para determinar cuándo y qué información de métricas debe ser enviada a su padre o destino. En el caso especializado del criterio de empuje para el proxy, la toma de decisiones se basa tanto en el ProxyMetricsContainer en sí mismo, como en la información acumulada de los ProxyMethodMetricsContainers individuales. Se debe tener en cuenta que un criterio de empuje no es necesario para un mobjeto, ya que no tiene ninguna responsabilidad de contención o agregación, ya que esto ya está en el Modelo de Servicio Entidad Servicio Métricas Contenedor Notificar Modelo de Entidad Criterio Modelo de Tiempo de Ejecución Entidad Tiempo de Ejecución Métricas Contenedor Notificar Modelo de Entidad Criterio Modelo de Gestor de Transporte Entidad Gestor de Transporte Métricas Contenedor Notificar Modelo de Entidad Criterio Criterio de Empuje Mobjeto Modelo de Entidad Mobjeto Método Métricas Notificar Modelo de Entidad Criterio Criterio de Empuje Criterio de Empuje Hacia el motor de adaptación Métricas del contenedor Notificar Métricas del contenedor Criterio Medir Métrica Criterio Métrica 1 Notificar Métricas del contenedor Criterio Notificar Métricas del contenedor Criterio Medir Métrica Criterio Proxy Método Métricas Contenedores RT Métrica Notificar Métricas del contenedor Criterio Proxy Métricas del contenedor Criterio Empuje Medir Métrica Criterio Métrica 2 Medir Métrica Criterio Métrica 1 1..n actualmente no implementado Notificar Métricas del contenedor Criterio Métrica 1 Métrica 2 Medir Métrica Criterio Medir Métrica Criterio Notificar Métricas del contenedor Criterio MU Métrica Medir Métrica Criterio Notificar Métricas del contenedor Criterio ET Métrica IT Métrica NI Métrica Medir Métrica Criterio Medir Métrica Criterio Medir Métrica Criterio Notificar Métricas del contenedor Criterio NU Métrica PU Métrica Medir Métrica Criterio Medir Métrica Criterio 1..n Figura 1. Descripción estructural de las relaciones jerárquicas y basadas en criterios entre Métricas, Contenedores de Métricas y Entidades de Modelo manejadas por el MobjectMetricsContainer y sus MobjectMethodMetricsContainers individuales. Aunque siempre es importante reducir el número de empujes, esto es especialmente importante desde un servicio a un motor de adaptación global centralizado, o desde un proxy a un mobject. Esto se debe a que estas relaciones implican una llamada remota [18] que es costosa debido a la configuración de la conexión y la sobrecarga de empaquetado y desempaquetado de datos, por lo que es más eficiente enviar una cantidad determinada de datos en forma agregada en lugar de enviar fragmentos más pequeños varias veces. Una implementación sencilla para reducir el número de empujes se puede hacer utilizando el concepto de un período de proceso [19], en cuyo caso la entidad del modelo acumula empujes de sus entidades secundarias hasta que el período de proceso expire, momento en el que empuja las métricas acumuladas a su entidad padre. Alternativamente, podría basarse en la frecuencia utilizando el conocimiento del dominio sobre el tipo de niños, por ejemplo, cuando un número significativo de objetos en una aplicación particular. TransportManager) ha experimentado cambios sustanciales. Para reducir el tamaño de los datos enviados, se consideraron dos tipos de envíos: envío superficial y envío profundo. Con un empuje superficial, se empuja una lista de contenedores de métricas que contienen métricas actualizadas. En un empuje profundo, la entidad del modelo en sí es empujada, junto con su contenedor de métricas y sus entidades secundarias, las cuales también tienen referencia a contenedores de métricas pero posiblemente métricas sin cambios. En el caso del proxy, un empuje profundo implica empujar el ProxyMetricsContainer y todos los ProxyMethodMetricsContainers, mientras que un empuje superficial significa solo los ProxyMethodMetricsContainers que cumplen con cierto criterio. 4. EVALUACIÓN Los tests preliminares presentados en esta sección tienen como objetivo analizar el rendimiento y la escalabilidad de la solución, y evaluar el impacto en la ejecución de la aplicación en términos de sobrecarga de recolección de métricas. Todos los tests fueron ejecutados utilizando dos PCs Pentium 4 de 3.0 GHz con 1,024 MB de RAM, ejecutando Java 1.4.2_08. Las dos máquinas estaban conectadas a un enrutador con una tercera computadora actuando como servidor de archivos y alojando el motor de adaptación externo implementado dentro del controlador del sistema MobJeX, simulando así un escenario de adaptación global. Dado que solo se podía ejecutar un número limitado de pruebas, esta evaluación optó por medir el peor escenario en el que se inició la recopilación de todas las métricas en mobjetos, donde el costo de propagación es mayor que para cualquier otra métrica recopilada en el sistema. Además, dado que realizar pruebas exhaustivas de criterios está más allá del alcance de este documento, se utilizaron dos tipos diferentes de criterios en las pruebas. El criterio de medición de métricas fue elegido, ya que esto representa el punto de partida del proceso de medición y puede controlar en qué circunstancias y con qué frecuencia se miden las métricas. Además, el criterio de empuje también se implementó en el servicio, con el fin de proporcionar una evaluación del control de la frecuencia de entrega de métricas al motor de adaptación. Todos los demás criterios (actualizar y enviar) se establecieron para que siempre significara que siempre se evaluaban como verdaderos y, por lo tanto, se publicaba una notificación. La Figura 2 muestra el sobrecosto de recolección de métricas en el mobject (MMCO), para diferentes números de mobjects y métodos cuando todos los criterios están configurados siempre para proporcionar la máxima medición y propagación de métricas y, por lo tanto, un escenario de rendimiento en el peor de los casos absoluto. Se puede observar que los factores independientes de aumentar el número de objetos y métodos de forma independiente son lineales. Aunque combinarlos juntos proporciona un crecimiento exponencial que es aproximadamente n-cuadrado, los resultados iniciales no son desalentadores, ya que entregar todas las métricas asociadas con 20 mobjetos, cada uno con 20 métodos (lo que constituye una aplicación bastante grande dado que los mobjetos suelen representar grupos de objetos de grano grueso) es aproximadamente 400ms, lo cual razonablemente se podría esperar compensar con ganancias de adaptación. Cabe destacar que, en contraste, el sobrecosto de recolección de métricas de proxy (PMCO) era relativamente pequeño y constante, menor a 5 ms, ya que en ausencia de un criterio de empuje de proxy (esto solo se implementó en el servicio), los datos de tiempo de respuesta (RT) para un solo método se empujan durante cada invocación. 50 150 250 350 450 550 1 5 10 15 20 25 Número de Mobjetos/Métodos Sobrecosto de recolección de métricas de Mobjeto MMCO (ms) Métodos Mobjetos Ambos Figura 2. Las características de rendimiento en el peor de los casos. El siguiente paso fue determinar la sobrecarga de recolección de métricas en porcentaje en comparación con el tiempo de ejecución para proporcionar información sobre las características de ejecución de objetos que serían adecuadas para la adaptación utilizando este enfoque de recolección de métricas. Claramente, no es práctico medir métricas y realizar adaptaciones en objetos con tiempos de ejecución cortos que no pueden beneficiarse de la ejecución remota en hosts con mayor capacidad de procesamiento, compensando así los costos operativos de TI de la ejecución remota en comparación con la local, así como el costo de la migración de objetos y el proceso de recolección de métricas en sí mismo. Además, para demostrar el efecto de utilizar criterios simples basados en frecuencia, los resultados de MMCO como porcentaje del tiempo de ejecución del método se representaron en un gráfico tridimensional en la Figura 3, donde el eje z representa la frecuencia utilizada tanto en el criterio de medición de métricas como en el criterio de empuje del motor de adaptación al servicio. Esto significa que para un valor de frecuencia de 5 (n=5), las métricas solo se miden en cada quinta llamada al método, lo que luego resulta en una notificación a través de la jerarquía de entidades del modelo al servicio, en esta misma quinta invocación. Además, el valor de n=5 también se aplicó al criterio de empuje de servicio para que las métricas solo se enviaran al motor de adaptación después de cinco notificaciones de este tipo, es decir, por ejemplo, cinco mobjects diferentes habían actualizado sus métricas. Estos resultados son alentadores, ya que incluso para el peor escenario de n=1, el sobrecoste de recopilación de métricas es aceptable, siendo del 20% para un método de duración de 1500ms (que es relativamente corto para un componente u objeto de nivel de servicio en una aplicación de clase empresarial distribuida), con trabajos previos sobre adaptación que muestran que dicho sobrecoste podría recuperarse fácilmente mediante las ganancias de eficiencia logradas por la adaptación [5]. Además, el tiempo de medición incluye la entrega de los resultados de forma síncrona a través de una llamada remota al motor de adaptación en un host diferente, lo cual normalmente se haría de forma asíncrona, reduciendo así aún más el impacto en el rendimiento de la ejecución del método. El gráfico también demuestra que incluso al utilizar criterios modestos para reducir la medición de métricas a niveles más realistas, tiene una mejora rápida en la sobrecarga de recolección al 20% durante 500 ms de ET. 0 1000 2000 3000 4000 5000 1 2 3 4 5 6 0 20 40 60 80 100 120 MMCO (%) ET (milisegundos) N (intervalo) MMCO (%) Figura 3. Características de rendimiento con criterios simples 5. RESUMEN Y CONCLUSIONES Dadas las dificultades de desarrollar aplicaciones móviles que se ejecuten en entornos dinámicos/heterogéneos, y el interés posterior en la adaptación de aplicaciones, este documento ha propuesto e implementado una estrategia de recopilación de métricas en línea para ayudar a dicha adaptación utilizando un marco de objetos móviles y middleware de soporte. Se realizaron estudios de laboratorio controlados para determinar el rendimiento en el peor de los casos, así como para mostrar la reducción en los costos de recolección al aplicar criterios simples de recolección. Además, pruebas adicionales proporcionaron una indicación inicial de las características de los objetos de aplicación (basadas en el tiempo de ejecución del método) que serían buenos candidatos para adaptación utilizando la implementación del peor caso de la estrategia de recopilación de métricas propuesta. Una característica clave de la solución fue la especificación de múltiples criterios configurables para controlar la propagación de métricas a través del sistema, reduciendo así la sobrecarga de recolección. Si bien la eficacia potencial de este enfoque se probó utilizando criterios simples, dada la flexibilidad del enfoque, creemos que hay muchas oportunidades para reducir significativamente los costos de recolección mediante el uso de criterios más sofisticados. Un enfoque podría basarse en mantener un historial de métricas para determinar el comportamiento temporal de las métricas y así tomar decisiones más inteligentes y conservadoras sobre si un cambio en una métrica en particular es probable que sea de interés para el motor de adaptación y, por lo tanto, debería servir como base para la notificación para su inclusión en la próxima actualización de métricas. Además, tal historial temporal también podría facilitar decisiones inteligentes con respecto a la recopilación de métricas, ya que, por ejemplo, una métrica que se sabe que es en su mayoría constante no necesita ser medida con frecuencia. El trabajo futuro también implicará la evaluación de una amplia gama de escenarios de adaptación en el marco de MobJeX para cuantificar las ganancias que se pueden obtener mediante la adaptación a través de la movilidad de objetos y así demostrar en la práctica la eficacia de la solución descrita en este documento. Finalmente, los autores desean explorar la aplicación de los conceptos de recopilación de métricas descritos en este documento a un sistema de gestión de contexto más general y reutilizable [20]. 6. REFERENCIAS 1. Katz, R.H., Adaptación y Movilidad en Sistemas de Información Inalámbrica. IEEE Comunicaciones Personales, 1994. 1: p. 6-17. 2. Hirschfeld, R. y Kawamura, K. Adaptación Dinámica del Servicio. en ICDCS Workshops04. 2004. 3. Lemlouma, T. y Layaida, N. Adaptación Consciente del Contexto para Dispositivos Móviles. en Actas de la Conferencia Internacional de IEEE sobre Gestión de Datos Móviles 2004. 2004. 4. Noble, B.D., y col. Adaptación ágil y consciente de la aplicación para la movilidad. en Proc. del 16º Simposio de la ACM sobre Sistemas Operativos y Principios SOSP. 1997. Saint-Malo, Francia. 5. Rossi, P. y Ryan, C. Una Evaluación Empírica de la Adaptación Local Dinámica para Aplicaciones Móviles Distribuidas. en Actas del Simposio Internacional de 2005 sobre Objetos y Aplicaciones Distribuidas (DOA 2005). 2005. Larnaca, Chipre: SpringerVerlag. 6. Ryan, C. y Westhorpe, C. Adaptación de aplicaciones a través de la movilidad de objetos transparente y portátil en Java. en el Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (DOA 2004). 2004. Larnaca, Chipre: SpringerVerlag. 7. da Silva e Silva, F.J., Endler, M. y Kon, F. Desarrollo de Aplicaciones Distribuidas Adaptativas: Una Visión General del Marco y Resultados Experimentales. en On The Move to Meaningful Internet Systems 2003: CoopIS, DOA y ODBASE (LNCS 2888). 2003. 8. Rossi, P. y Fernández, G. Definición y validación de métricas de diseño para aplicaciones distribuidas. en el Noveno Simposio Internacional de Métricas de Software. 2003. Sídney: IEEE. 9. Ryan, C. y Rossi, P. Métricas de software, rendimiento y utilización de recursos para aplicaciones móviles conscientes del contexto. en Actas del Simposio Internacional de Métricas de Software IEEE Metrics 2005. 2005. Como, Italia. 10. Recursion Software Inc. Voyager URL: http://www.recursionsw.com/voyager.htm. 2005. 11. 

Recursion Software Inc. Voyager URL: http://www.recursionsw.com/voyager.htm. 2005. 11. Holder, O., Ben-Shaul, I., y Gazit, H., Soporte del sistema para el diseño dinámico de aplicaciones distribuidas. 1998, Instituto de Tecnología Technion-Israel. p. 163 - 173. 12. Holder, O., Ben-Shaul, I., y Gazit, H. Diseño dinámico de aplicaciones distribuidas en FarGo. en la 21ª Conferencia Internacional. Ingeniería de Software (ICSE99). 1999: ACM Press. 13. Philippsen, M. y Zenger, M., JavaParty - Objetos Remotos Transparentes en Java. Concurrencia: Práctica y Experiencia, 1997. 9(11): p. 1225-1242. 14. Shapiro, M. Estructura y Encapsulamiento en Sistemas Distribuidos: el Principio del Proxy. en Proc. 6to Intl. Conferencia sobre Sistemas de Computación Distribuida. 1986. Cambridge, Massachusetts (EE. UU.): IEEE. 15. Gazit, H., Ben-Shaul, I., y Holder, O. Reubicación dinámica basada en monitoreo de componentes en Fargo. en Actas del Segundo Simposio Internacional sobre Sistemas de Agentes y Aplicaciones y Cuarto Simposio Internacional sobre Agentes Móviles. 2000. 16. Lindholm, T. y Yellin, F., Especificación de la Máquina Virtual de Java 2da Edición. 1999: Addison-Wesley. 17. Randell, L.G., Holst, L.G., y Bolmsjö, G.S. Desarrollo Incremental de Sistemas de Modelado de Simulación de Eventos Discretos a Gran Escala. en Actas de la 31ª conferencia sobre Simulación de Invierno. 1999. Phoenix, Arizona. 18. 

Fénix, Arizona. 18. Waldo, J., Llamadas a Procedimientos Remotos y Invocación de Métodos Remotos en Java. IEEE Concurrency, 1998. 6(3): p. 5-7. 19.
IEEE Concurrency, 1998. 6(3): p. 5-7. 19. Rolia, J. y Lin, B. Problemas de consistencia en las métricas de rendimiento de aplicaciones distribuidas. en Actas de la Conferencia de 1994 del Centro de Estudios Avanzados sobre Investigación Colaborativa. 1994. Toronto, Canadá. 20. Henricksen, K. y Indulska, J. Un marco de ingeniería de software para la computación pervasiva consciente del contexto. en Actas de la 2ª Conferencia de IEEE sobre Computación y Comunicaciones Pervasivas (PerCom). 2004. Orlando.