Migración en vivo de centros de datos a través de WANs: Un enfoque robusto cooperativo y consciente del contexto K.K. Ramakrishnan, Prashant Shenoy, Jacobus Van der Merwe AT&T Labs-Research / Universidad de Massachusetts RESUMEN Una preocupación significativa para los proveedores de servicios basados en Internet es la operación continua y la disponibilidad de servicios frente a interrupciones, ya sean planificadas o no planificadas. En este documento abogamos por un enfoque cooperativo y consciente del contexto para la migración de centros de datos a través de WANs para hacer frente a las interrupciones de manera no disruptiva. Buscamos específicamente lograr una alta disponibilidad de los servicios del centro de datos frente a cortes planificados e imprevistos de las instalaciones del centro de datos. Hacemos uso de tecnologías de virtualización de servidores para permitir la replicación y migración de funciones de servidor. Proponemos nuevas funciones de red para permitir la migración y replicación de servidores a través de redes de área amplia (por ejemplo, Internet), y finalmente demostramos la utilidad de la tecnología de replicación de almacenamiento inteligente y dinámica para garantizar que las aplicaciones tengan acceso a los datos ante cortes con objetivos de punto de recuperación muy estrictos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos Términos Generales Diseño, Confiabilidad 1. Una preocupación significativa para los proveedores de servicios basados en Internet es la operación continua y la disponibilidad de servicios frente a interrupciones, ya sean planificadas o no planificadas. Estas preocupaciones se ven agravadas por el aumento del uso de Internet para aplicaciones comerciales críticas para la misión y entretenimiento en tiempo real. Un corte de energía relativamente menor puede interrumpir e incomodar a un gran número de usuarios. Hoy en día, estos servicios se alojan casi exclusivamente en centros de datos. Los avances recientes en tecnologías de virtualización de servidores [8, 14, 22] permiten la migración en vivo de servicios dentro de un entorno de red de área local (LAN). En el entorno de LAN, estas tecnologías han demostrado ser una herramienta muy efectiva para habilitar la gestión del centro de datos de manera no disruptiva. No solo puede soportar eventos de mantenimiento planificados [8], sino que también puede ser utilizado de manera más dinámica para equilibrar automáticamente la carga entre los servidores físicos en un centro de datos [22]. Cuando se utilizan estas tecnologías en un entorno de LAN, los servicios se ejecutan en un servidor virtual, y los servicios de migración proporcionados por el marco de virtualización subyacente permiten que un servidor virtual se migre de un servidor físico a otro, sin un tiempo de inactividad significativo para el servicio o la aplicación. En particular, dado que el servidor virtual conserva la misma dirección de red que antes, no se interrumpen las interacciones a nivel de red en curso. Del mismo modo, en un entorno de red de área local (LAN), los requisitos de almacenamiento normalmente se cumplen a través de almacenamiento conectado a la red (NAS) o a través de una red de área de almacenamiento (SAN) que sigue siendo accesible desde la nueva ubicación del servidor físico para permitir el acceso continuo al almacenamiento. Desafortunadamente, en un entorno de área amplia (WAN), la migración de servidores en vivo no es tan fácil de lograr por dos razones: en primer lugar, la migración en vivo requiere que el servidor virtual mantenga la misma dirección de red para que, desde el punto de vista de la conectividad de red, el servidor migrado sea indistinguible del original. Si bien esto se logra fácilmente en un entorno de LAN compartida, no existen mecanismos actuales disponibles para lograr eficientemente la misma hazaña en un entorno de WAN. Segundo, si bien se han desarrollado mecanismos de replicación remota bastante sofisticados en el contexto de la recuperación ante desastres [20, 7, 11], estos mecanismos no son adecuados para la migración en vivo de centros de datos, ya que en general las tecnologías disponibles no son conscientes de la semántica a nivel de aplicación/servicio. En este documento esbozamos un diseño para la migración de servicios en vivo a través de WANs. Nuestro diseño hace uso de tecnologías existentes de virtualización de servidores y propone mecanismos de red y almacenamiento para facilitar la migración a través de una WAN. La esencia de nuestro enfoque es la migración cooperativa y consciente del contexto, donde un sistema de gestión de migración orquesta la migración del centro de datos en los tres subsistemas involucrados, a saber, las plataformas de servidores, la red de área amplia y el sistema de almacenamiento de discos. Si bien conceptualmente similar en naturaleza a la labor basada en LAN descrita anteriormente, el uso de tecnologías de migración a través de una red de área amplia presenta desafíos únicos y, hasta donde sabemos, no se ha logrado. Nuestra principal contribución es el diseño de un marco de trabajo que permitirá la migración a través de una WAN de todos los subsistemas involucrados en la habilitación de servicios de centro de datos. Describimos nuevos mecanismos, así como extensiones a las tecnologías existentes para permitir esto y delineamos la funcionalidad cooperativa y consciente del contexto necesaria en los diferentes subsistemas para habilitar esto. 262 2. MIGRACIÓN DE CENTRO DE DATOS EN VIVO A TRAVÉS DE REDES DE ÁREA AMPLIA Tres subsistemas esenciales están involucrados en los servicios de alojamiento en un centro de datos: En primer lugar, los servidores alojan la lógica de la aplicación o servicio. Segundo, los servicios suelen alojarse en un centro de datos para proporcionar acceso compartido a través de una red, ya sea Internet o redes privadas virtuales (VPN). Finalmente, la mayoría de las aplicaciones requieren almacenamiento en disco para guardar datos y la cantidad de espacio en disco y la frecuencia de acceso varían considerablemente entre diferentes servicios/aplicaciones. Las interrupciones, fallas o, en general, cortes de cualquier tipo de alguno de estos componentes causarán interrupción del servicio. Por esta razón, el trabajo previo y las prácticas actuales han abordado la robustez de los componentes individuales. Por ejemplo, los centros de datos suelen tener múltiples conexiones de red y dispositivos LAN redundantes para garantizar la redundancia a nivel de red. Del mismo modo, los servidores físicos están siendo diseñados con componentes redundantes intercambiables en caliente (discos, cuchillas de procesador, fuentes de alimentación, etc). Finalmente, la redundancia a nivel de almacenamiento puede ser proporcionada a través de tecnologías sofisticadas de espejo de datos. El enfoque de nuestro trabajo, sin embargo, se centra en el caso en el que dichos mecanismos de redundancia local no son suficientes. Específicamente, estamos interesados en garantizar la disponibilidad del servicio cuando el centro de datos en su totalidad no esté disponible, por ejemplo, debido a operaciones de mantenimiento en todo el centro de datos o a eventos catastróficos. Por lo tanto, nuestro enfoque básico es migrar servicios entre centros de datos a través de la red de área amplia (WAN). Por necesidad, al trasladar o migrar servicios de un centro de datos a otro es necesario considerar los tres componentes. Históricamente, dicha migración ha sido disruptiva en su naturaleza, requiriendo tiempo de inactividad de los servicios involucrados, o requiriendo técnicas de replicación de gran peso. En el último caso, las réplicas en funcionamiento simultáneo de un servicio pueden estar disponibles, lo que permite migrar o mantener un subconjunto del servicio sin afectar al servicio en su totalidad. Sostenemos que estos mecanismos existentes son insuficientes para satisfacer las necesidades de los servicios basados en red, incluidos los servicios en tiempo real, en términos de disponibilidad y funcionamiento continuo. En cambio, abogamos por un enfoque en el que los subsistemas de servidor, red y almacenamiento cooperen y coordinen acciones, de una manera que sea consciente del contexto del servicio para lograr una migración fluida a través de redes de área amplia. En esta sección describimos brevemente los bloques de construcción técnica que permitirían nuestra aproximación. Como se describe a continuación, algunos de estos bloques de construcción existen, o existen en parte, mientras que en otros casos utilizamos el deseo de alta disponibilidad de servicios como el impulsor de los cambios que estamos proponiendo. 2.1 Migración de Servidores Virtuales en Vivo El principal facilitador de nuestro enfoque son las capacidades de migración de servidores en vivo que se han desarrollado en el contexto de la virtualización de servidores en los últimos años [5, 8]. En este enfoque, un sistema operativo en ejecución completo (incluidas todas las aplicaciones activas) que se ejecuta como un servidor virtual se está transfiriendo de una máquina física a otra. Dado que el servidor virtual se migra en su totalidad, se migra tanto el estado de la aplicación como el del núcleo, incluido cualquier estado asociado con las conexiones de red en curso. Suponiendo que la accesibilidad a nivel de red a las direcciones de red de los servidores virtuales se mantenga después de la migración, la implicación es que las aplicaciones que se ejecutan en el servidor virtual experimentan muy poco tiempo de inactividad (del orden de decenas a cientos de milisegundos) y las conexiones de red en curso permanecen intactas. Para mantener la accesibilidad a nivel de red, la(s) dirección(es) IP asociada(s) con el servidor virtual debe(n) ser alcanzable(s) en el servidor físico al que se migra el servidor virtual. En un entorno de LAN, esto se logra ya sea emitiendo una respuesta ARP no solicitada para establecer la asociación entre la nueva dirección MAC y la dirección IP, o confiando en tecnologías de capa dos para permitir que el servidor virtual reutilice su dirección MAC (antigua). Debido a la dificultad de mover el nivel de red (es decir, direcciones IP) en un entorno enrutado no LAN, el uso de la migración de servidores en vivo como herramienta de gestión se ha limitado a los entornos LAN [22]. Sin embargo, la migración de servidores virtuales a través de áreas extensas también será una herramienta atractiva, específicamente para hacer frente a las interrupciones, y por lo tanto proponer mecanismos de redes para habilitar esto. Si las necesidades de almacenamiento en disco están siendo satisfechas con almacenamiento conectado a la red (NAS), el almacenamiento se convierte simplemente en otra aplicación basada en red y, por lo tanto, puede ser abordado de la misma manera con la migración basada en LAN. Los entornos de virtualización modernos también incluyen soporte para otras formas de almacenamiento (local) incluyendo redes de área de almacenamiento (SAN) [23]. Sin embargo, dado que proponemos utilizar la migración del servidor WAN como un medio para hacer frente a las interrupciones completas del centro de datos, estos mecanismos son inadecuados para nuestros propósitos y a continuación proponemos una extensión a las tecnologías de replicación remota que pueden trabajar en conjunto con la migración del servidor para minimizar el tiempo de inactividad del servicio. 2.2 Requisitos de red De la discusión anterior, un requisito clave para la migración del servidor en vivo a través de una WAN es la capacidad de que la(s) dirección(es) IP del servidor virtual sean accesibles en la nueva ubicación del centro de datos inmediatamente después de que la migración se haya completado. Esto presenta un desafío significativo por varias razones. Primero, a pesar de décadas de trabajo en esta área, la movilidad de direcciones IP sigue siendo un problema no resuelto que generalmente solo se aborda en escalas de tiempo de configuración manual. El segundo desafío proviene del hecho de que los protocolos de enrutamiento actuales son conocidos por tener problemas de convergencia que no son adecuados para las restricciones de tiempo impuestas por la migración en vivo. Tercero, en el entorno de redes WAN de hoy en día, los cambios de conectividad suelen ser iniciados y controlados por operadores de red o sistemas de gestión de red. Una vez más, esto no es adecuado para la migración del servidor WAN, donde es esencial que el software de migración, que está monitoreando de cerca el estado del proceso de migración del servidor, inicie este cambio en el momento adecuado. Nuestro enfoque para abordar los requisitos de red para la migración WAN en vivo se basa en las observaciones de que no todos los cambios de red en este enfoque son críticos en tiempo y además de que los cambios instantáneos se logran mejor de manera localizada. Específicamente, en nuestra solución, descrita en detalle en la Sección 3, permitimos que el software de migración inicie los cambios de red necesarios tan pronto como se haya identificado la necesidad de migración. Durante esta fase inicial, hacemos uso de tecnologías de túneles para establecer de manera preventiva la conectividad entre los centros de datos involucrados. Una vez que la migración del servidor esté completa, el software de migración inicia un cambio local para dirigir el tráfico hacia el nuevo centro de datos a través del túnel. Los cambios en la red a una escala de tiempo más lenta luego eliminan esta conexión de red local para un camino de red más óptimo hacia el nuevo centro de datos. 2.3 Requisitos de Replicación de Almacenamiento La disponibilidad de datos se aborda típicamente replicando los datos comerciales en un sistema de almacenamiento local/primario, a alguna ubicación remota desde donde se pueda acceder a ellos. Desde un punto de vista empresarial/usabilidad, dicha replicación remota está impulsada por dos métricas [9]. El primer 263 es el objetivo de punto de recuperación, que es el punto de datos consistente al que se pueden restaurar los datos después de un desastre. El segundo es el objetivo de tiempo de recuperación, que es el tiempo que se tarda en recuperarse hasta ese punto de datos consistente después de un desastre [13]. La replicación remota se puede clasificar ampliamente en las siguientes dos categorías: ¡ Replicación síncrona: cada bloque de datos escrito en un sistema de almacenamiento local se replica en la ubicación remota antes de que la operación de escritura local regrese. ¡ Replicación asíncrona: en este caso, se permite que los sistemas de almacenamiento local y remoto diverjan. La cantidad de divergencia entre las copias locales y remotas suele estar limitada por una cierta cantidad de datos o por una cierta cantidad de tiempo. La replicación síncrona suele recomendarse para aplicaciones, como bases de datos financieras, donde la consistencia entre los sistemas de almacenamiento local y remoto es una alta prioridad. Sin embargo, estas propiedades deseables tienen un costo. Primero, debido a que cada bloque de datos necesita ser replicado de forma remota, los sistemas de replicación síncrona no pueden beneficiarse de la consolidación de escrituras locales si los mismos bloques de datos son escritos repetidamente [16]. Segundo, debido a que los datos deben ser copiados a la ubicación remota antes de que la operación de escritura regrese, la replicación síncrona tiene un impacto directo en el rendimiento de la aplicación, ya que tanto la menor capacidad de transferencia como el aumento de la latencia del camino entre el sistema primario y el remoto se reflejan en el tiempo que tarda en completarse la escritura en el disco local. Una alternativa es utilizar la replicación asíncrona. Sin embargo, debido a que los sistemas locales y remotos pueden divergir, la replicación asíncrona siempre implica cierta pérdida de datos en caso de fallo del sistema principal. Sin embargo, debido a que las operaciones de escritura pueden ser agrupadas y encoladas, los sistemas de replicación asincrónica pueden mover datos a través de la red de una manera mucho más eficiente que los sistemas de replicación síncrona. Para la migración en vivo del servidor WAN, buscamos un sistema de replicación más flexible donde el modo pueda ser dictado por la semántica de la migración. Específicamente, para respaldar la migración de servidores en vivo, proponemos un sistema de replicación remota donde la transferencia inicial de datos entre los centros de datos se realiza a través de replicación asincrónica para beneficiarse de la eficiencia de ese modo de operación. Cuando la mayor parte de los datos hayan sido transferidos de esta manera, la replicación cambia a replicación síncrona en previsión de la finalización del paso de migración del servidor. El paso final de migración del servidor desencadena un cambio simultáneo al sistema de almacenamiento en el nuevo centro de datos. De esta manera, cuando el servidor virtual comienza a ejecutarse en el nuevo centro de datos, los requisitos de almacenamiento pueden ser satisfechos localmente. 3. En esta sección ilustramos cómo nuestro enfoque cooperativo y consciente del contexto puede combinar los bloques de construcción técnicos descritos en la sección anterior para realizar la migración en vivo de servidores a través de una red de área amplia. Demostramos cómo la coordinación de la virtualización de servidores y tecnologías de migración, el subsistema de replicación de almacenamiento y la red pueden lograr la migración en vivo de todo el centro de datos a través de la WAN. Utilizamos diferentes escenarios para demostrar nuestro enfoque. En la Sección 3.1 describimos cómo nuestro enfoque puede ser utilizado para lograr la migración segura en vivo de un centro de datos cuando se manejan eventos de mantenimiento planificados. En la Sección 3.2 mostramos el uso de la migración de servidores en vivo para mitigar los efectos de cortes o fallas no planificadas. 3.1 Cortes por mantenimiento Nos ocupamos de los cortes por mantenimiento en dos partes. Primero, consideramos el caso en el que el servicio no tiene (o tiene requisitos de almacenamiento muy limitados). Esto podría ser el caso, por ejemplo, con un elemento de red como una pasarela de voz sobre IP (VoIP). En segundo lugar, nos ocupamos del caso más general en el que el servicio también requiere la migración del almacenamiento de datos al nuevo centro de datos. Sin requerir que el almacenamiento sea migrado: Sin replicar el almacenamiento, los componentes principales que necesitamos coordinar son la migración del servidor y la movilidad de la red. La Figura 1 muestra el entorno donde la aplicación que se ejecuta en un servidor virtual VS debe ser trasladada de un servidor físico en el centro de datos A a un servidor físico en el centro de datos B. Antes del evento de mantenimiento, el sistema de gestión de migración coordinada (MMS) señalaría tanto al sistema de gestión de servidores como a la red que una migración es inminente. El sistema de gestión del servidor iniciaría la migración del servidor virtual desde el servidor físico a (¢¤£¦¥) al servidor físico b (¢¤£¦§). Después de una transferencia inicial del estado en bloque como preparación para la migración, el sistema de gestión del servidor reflejará cualquier cambio de estado entre los dos servidores virtuales. De manera similar, para la parte de la red, basándose en la señal recibida del MMS, el enrutador de borde del proveedor de servicios iniciará una serie de pasos para prepararse para la migración. Específicamente, como se muestra en la Figura 1(b), el sistema de migración hará que la red cree un túnel entre ¢©¨ y ¢©¨ que se utilizará posteriormente para transferir datos destinados a VS al centro de datos B. Cuando el MMS determina un punto conveniente para poner en pausa el VS, se envía otra señal tanto al sistema de gestión del servidor como a la red. Para el sistema de gestión del servidor, esta señal indicará la migración final del VS del centro de datos A al centro de datos B, es decir, después de esto el VS estará activo en el centro de datos B. Para la red, esta segunda señal permite que la ruta de datos de la red cambie localmente a la ubicación remota del centro de datos. Específicamente, a partir de este momento, cualquier tráfico destinado a la dirección del servidor virtual que llegue a ¢©¨©¥ será redirigido al túnel hacia ¢©¨©§ para su entrega en el centro de datos B. Ten en cuenta que en este punto, desde la perspectiva del servidor la migración está completa ya que la máquina virtual está ahora activa en el centro de datos B. Sin embargo, el tráfico fluye de manera subóptima primero hacia ¢©¨©¥ y luego a través del túnel hacia ¢©¨¤§. Para rectificar esta situación se requiere otro paso de networking. Específicamente, ¢©¨©§ comienza a anunciar una ruta más preferida para llegar a VS, que la ruta actualmente anunciada por ¢©¨¤¥. De esta manera, a medida que los PEs de ingreso a la red (de ¢©¨¤ a ¢©¨¤ en la Figura 1) reciben la ruta más preferida, el tráfico comenzará a fluir hacia ¢©¨©§ directamente y el túnel entre ¢©¨©¥ y ¢©¨©§ podrá ser desmantelado, lo que llevará al estado final mostrado en la Figura 1(c). Requerir migración de almacenamiento: Cuando el almacenamiento también debe ser replicado, es crítico que logremos el equilibrio adecuado entre el rendimiento (impacto en la aplicación) y el punto de recuperación o pérdida de datos cuando se produce el cambio al centro de datos remoto. Para lograr esto, permitimos que el almacenamiento se replique de forma asíncrona antes de cualquier inicio del evento de mantenimiento, o, asumiendo que la cantidad de datos a transferir es relativamente pequeña, la replicación asíncrona puede iniciarse en previsión de una migración que se espera que ocurra pronto. La replicación asíncrona durante esta fase inicial permite que la aplicación no experimente ningún impacto en el rendimiento. Sin embargo, cuando el evento de mantenimiento es inminente, el MMS enviaría una señal al sistema de replicación para cambiar de replicación asíncrona a replicación síncrona y garantizar que no haya pérdida de datos durante la migración. Cuando los datos se replican de forma síncrona, habrá un impacto en el rendimiento de la aplicación. Esto nos obliga a mantener al mínimo la exposición al tiempo que replicamos de forma síncrona. Cuando el MMS señala al sistema de almacenamiento la necesidad de cambiar a replicación síncrona, el sistema de almacenamiento completa todas las operaciones asincrónicas pendientes y luego procede a realizar todas las escrituras subsiguientes replicándolas de forma síncrona en el centro de datos remoto. Por lo tanto, entre la migración del servidor y la replicación síncrona, tanto el estado de la aplicación como todas las operaciones de almacenamiento se reflejan en los dos entornos de los dos centros de datos. Cuando todas las operaciones de escritura pendientes se copian, entonces, como en el caso anterior, ponemos en pausa la aplicación y se señaliza a la red para que redirija el tráfico al centro de datos remoto. A partir de este momento, tanto las operaciones de migración de almacenamiento como de servidores están completas y activadas en el centro de datos B. Como se mencionó anteriormente, el estado de la red aún necesita ser actualizado para garantizar un flujo óptimo de datos directamente al centro de datos B. Ten en cuenta que, si bien hemos descrito el proceso de migración del servidor en vivo como implicando al proveedor de servicios para la parte de redes, es posible que un proveedor de centro de datos realice un conjunto similar de funciones sin involucrar al proveedor de servicios. Específicamente, al crear un túnel entre los routers de borde del cliente (CE) en el centro de datos, y realizar conmutación local en el CE apropiado, en lugar de en el PE, el proveedor del centro de datos puede lograr la misma funcionalidad. 3.2 Interrupciones no planificadas Proponemos también utilizar migración cooperativa y consciente del contexto para hacer frente a las interrupciones no planificadas en el centro de datos. Hay múltiples consideraciones que entran en juego al gestionar las operaciones de un centro de datos para planificar y superar fallos a través de la migración. Algunos de estos son: (1) cantidad de gastos generales bajo operación normal para superar fallas anticipadas; (2) cantidad de pérdida de datos aceptable (objetivo de punto de recuperación - RPO); (3) cantidad de estado que debe ser migrado; y (4) tiempo disponible desde la falla anticipada hasta la ocurrencia del evento. En un extremo, uno podría incurrir en el gasto adicional de replicar completamente la aplicación en el sitio remoto. Esto tiene como consecuencia tanto el aumento de la carga de procesamiento y de red durante la operación normal, como el impacto en el rendimiento de la aplicación (latencia y rendimiento) en su totalidad. El otro extremo es garantizar únicamente la recuperación de datos y comenzar una nueva copia de la aplicación en el sitio remoto después de una interrupción. En este caso, el estado de la memoria de la aplicación, como las sesiones en curso, se pierden, pero los datos almacenados en el disco se replican y están disponibles en un estado consistente. Ni este enfoque de reserva en caliente ni el enfoque de reserva en frío descritos son deseables debido a la sobrecarga o la pérdida del estado de la memoria de la aplicación. Un enfoque intermedio es recuperar el control y el estado esencial de la aplicación, además de los datos almacenados en el disco, para minimizar aún más las interrupciones a los usuarios. Un espectro de enfoques son posibles. En un servidor de VoIP, por ejemplo, la información basada en sesiones puede ser reflejada sin reflejar los datos que fluyen a través de cada sesión. Más generalmente, esto señala la necesidad de hacer un punto de control del estado de algunas aplicaciones además de reflejar los datos en el disco. El punto de control del estado de la aplicación implica almacenar el estado de la aplicación ya sea periódicamente o de manera consciente de la aplicación, como lo hacen las bases de datos, y luego copiarlo al sitio remoto. Por supuesto, esto tiene como consecuencia que la aplicación solo pueda reiniciarse de forma remota en el límite del punto de control. Del mismo modo, para el almacenamiento se puede utilizar la replicación asíncrona con una instantánea periódica que garantice que todas las escrituras estén actualizadas en el sitio remoto en el momento de la creación de puntos de control. Algunas pérdidas de datos pueden ocurrir en caso de un fallo catastrófico no anticipado, pero el punto de recuperación puede ser bastante pequeño, dependiendo de la frecuencia de la aplicación de checkpoints y del estado de almacenamiento. La coordinación entre el checkpointing del estado de la aplicación y la instantánea del almacenamiento es clave para una migración exitosa que cumpla con los RPO deseados. La creación de puntos de control incrementales de la aplicación y el almacenamiento es clave para la eficiencia, y vemos técnicas existentes para lograr esto [4, 3, 11]. Por ejemplo, en lugar de reflejar la aplicación completa, se puede mantener una réplica virtualizada como un respaldo en caliente, en estado de reposo o hibernación, lo que permite cambiar rápidamente al estado previamente marcado. Para que el cambio sea fluido, además de replicar datos y recuperar el estado, se necesita soporte de red. Específicamente, al detectar la no disponibilidad del sitio primario, se activa el sitio secundario y se utiliza el mismo mecanismo descrito en la Sección 3.1 para redirigir el tráfico hacia el sitio secundario a través del túnel preestablecido. Se debe tener en cuenta que, para simplificar la exposición, asumimos aquí que la PE que realiza el cambio local no se ve afectada por la falla. Sin embargo, el enfoque puede ser fácilmente extendido para hacer uso de un cambio a un enrutador más profundo en la red. La cantidad de estado y almacenamiento que debe ser migrada puede variar ampliamente de una aplicación a otra. Puede haber muchas situaciones en las que, en principio, el servidor puede ser sin estado. Por ejemplo, un servidor proxy SIP puede no tener ningún estado persistente y la comunicación entre los clientes y el servidor proxy puede estar utilizando UDP. En tal caso, la actividad principal a realizar es en la red para trasladar la comunicación al nuevo sitio del centro de datos. Poco o ningún gasto adicional se incurre durante la operación normal para facilitar la migración a un nuevo centro de datos. La recuperación de fallos implica la ausencia de pérdida de datos y podemos hacer frente a fallos catastróficos casi instantáneamente. A medida que más estado se involucra con el servidor, se incurre en más sobrecarga para hacer checkpoint del estado de la aplicación y potencialmente para tomar instantáneas de almacenamiento, ya sea periódicamente o cuando la aplicación lo solicite. También significa que el RPO es una función del intervalo entre puntos de control, cuando tenemos que lidiar con fallas instantáneas. Cuanta más información avanzada tengamos sobre un fallo inminente, más efectivos podemos ser al migrar el estado al nuevo centro de datos, para así poder mantener un RPO más estricto cuando se reanuden las operaciones en el nuevo sitio. 4. TRABAJO RELACIONADO El trabajo previo sobre este tema se divide en varias categorías: migración de máquinas virtuales, replicación de almacenamiento y soporte de red. En el núcleo de nuestra técnica está la capacidad de encapsular aplicaciones dentro de máquinas virtuales que pueden ser migradas sin tiempos de inactividad de la aplicación [15]. La mayoría del software de máquinas virtuales, como Xen [8] y VMWare [14], admiten la migración en vivo de MVs que implican tiempos de inactividad extremadamente cortos que van desde decenas de milisegundos hasta un segundo; los detalles de las técnicas de migración en vivo de Xen se discuten en [8]. Como se indicó anteriormente, estas técnicas asumen que la migración se está realizando en una LAN. La migración de máquinas virtuales también ha sido estudiada en el sistema Shirako [10] y para entornos de grid [17, 19]. El software actual de máquinas virtuales cuenta con una función de suspensión y reanudación que se puede utilizar para respaldar la migración de WAN, pero con tiempos de inactividad [18, 12]. Recientemente se demostró la migración en vivo de WAN utilizando túneles IP en [21], donde se establece un túnel IP desde el servidor de origen al de destino para reenviar de forma transparente paquetes hacia y desde la aplicación; abogamos por un enfoque alternativo que asume el soporte del enrutador de borde. En el contexto del almacenamiento, existen numerosos productos comerciales que realizan replicación, como IBM Extended Remote Copy, HP Continuous Access XP y EMC RepliStor. Una excelente descripción de estos y otros, así como una taxonomía detallada de los diferentes enfoques para la replicación se puede encontrar en [11]. El sistema Ursa Minor argumenta que ningún modelo de falla único es óptimo para todas las aplicaciones y propone selecciones específicas de modelos de falla y esquemas de codificación de tipos de datos de apoyo para la replicación [1]. Recientemente, propusimos la noción de replicación con conciencia semántica [13], donde el sistema admite tanto la replicación síncrona como asíncrona de manera concurrente y utiliza señales del sistema de archivos para determinar si replicar una escritura particular de forma síncrona o asíncrona. En el contexto de soporte de red, nuestro trabajo está relacionado con el enfoque RouterFarm [2], que hace uso de cambios de red orquestados para lograr un mantenimiento casi sin interrupciones en los enrutadores de borde del proveedor. Además de estar en un área de aplicación diferente, nuestro enfoque difiere del trabajo de RouterFarm en dos aspectos. Primero, proponemos que los cambios de red requeridos sean activados por funcionalidades fuera de la red (en lugar de funciones de gestión de red dentro de la red). Segundo, debido a los estrictos requisitos de tiempo de la migración en vivo, esperamos que nuestro enfoque requiera una nueva funcionalidad del enrutador (en lugar de ser realizable a través de las interfaces de configuración existentes). Finalmente, el trabajo de computación orientado a la recuperación (ROC) enfatiza la recuperación de fallas en lugar de evitarlas [6]. En un espíritu similar al de ROC, abogamos por utilizar mecanismos de migración de máquinas virtuales en vivo a replicación de almacenamiento para respaldar cortes planeados y no planeados en los centros de datos (en lugar de replicación completa para enmascarar tales fallas). 5. CONCLUSIÓN Una preocupación significativa para los proveedores de servicios basados en Internet es la operación continua y la disponibilidad de servicios frente a interrupciones, ya sean planificadas o no planificadas. En este documento abogamos por un enfoque cooperativo y consciente del contexto para la migración de centros de datos a través de WANs para hacer frente a las interrupciones de manera no disruptiva. Buscamos lograr una alta disponibilidad de los servicios del centro de datos frente a tanto a las interrupciones planificadas como a las incidentales de las instalaciones del centro de datos. Abogamos por el uso de tecnologías de virtualización de servidores para permitir la replicación y migración de funciones de servidor. Propusimos nuevas funciones de red para permitir la migración y replicación de servidores a través de redes de área amplia (como Internet o una red privada virtual geográficamente distribuida), y finalmente demostramos la utilidad de la tecnología de replicación de almacenamiento inteligente y dinámica para garantizar que las aplicaciones tengan acceso a los datos ante cortes con objetivos de punto de recuperación muy estrictos. REFERENCIAS [1] M. Abd-El-Malek, W. V. Courtright II, C. Cranor, G. R. Ganger, J. Hendricks, A. J. Klosterman, M. Mesnier, M. Prasad, B. Salmon, R. R. Sambasivan, S. Sinnamohideen, J. D. Strunk, E. Thereska, M. Wachs y J. J. Wylie. Ursa minor: almacenamiento basado en clústeres versátil. Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento, diciembre de 2005. [2] Mukesh Agrawal, Susan Bailey, Albert Greenberg, Jorge Pastor, Panagiotis Sebos, Srinivasan Seshan, Kobus van der Merwe y Jennifer Yates. Routerfarm: Hacia un borde de red dinámico y manejable. Taller SIGCOMM sobre Gestión de Redes de Internet (INM), septiembre de 2006. [3] L. Alvisi. Comprendiendo el paradigma de registro de mensajes para enmascarar fallas del proceso. Tesis doctoral, Universidad de Cornell, enero de 1996. [4] L. Alvisi y K. Marzullo. Registro de mensajes: pesimista, optimista y causal. En Actas de la 15ª Conferencia Internacional sobre Sistemas de Computación Distribuida, páginas 229-236. IEEE Computer Society, junio de 1995. 266 [5] Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim Harris, Alex Ho, Rolf Neugebar, Ian Pratt y Andrew Warfield. Xen y el arte de la virtualización. En las Actas del Simposio de la ACM sobre Principios de Sistemas Operativos (SOSP), octubre de 2003. [6] A. Brown y D. A. Patterson. Abrazando el fracaso: Un caso para la computación orientada a la recuperación (roc). Simposio de Procesamiento de Transacciones de Alto Rendimiento de 2001, octubre de 2001. [7] K. Brown, J. Katcher, R. Walters y A. Watson. Snapmirror y snaprestore: Avances en la tecnología de instantáneas. Informe técnico de Network Appliance TR3043. www. ne t app. c om/t e c h_ l i br ar y/3043. ht ml . [8] C. Clark, K. Fraser, S. Hand, J. Hanse, E. Jul, C. Limpach, I. Pratt y A. Warfiel. Migración en vivo de máquinas virtuales. En Actas de NSDI, mayo de 2005. [9] Disaster Recovery Journal. Glosario de continuidad empresarial. ht t p: //www. dr j . c om/gl os s ar y/dr j gl os s ar y. ht ml . [10] Laura Grit, David Irwin, , Aydan Yumerefendi y Jeff Chase. Hospedaje de máquinas virtuales para clusters en red: Construyendo las bases para la orquestación autónoma. En el Primer Taller Internacional sobre Tecnología de Virtualización en Computación Distribuida (VTDC), noviembre de 2006. [11] M. Ji, A. Veitch y J. Wilkes. Seneca: Duplicación remota realizada correctamente. Conferencia Técnica Anual USENIX 2003, junio de 2003. [12] M. Kozuch y M. Satyanarayanan. Internet se suspende y se reanuda. En Actas del Cuarto Taller de Sistemas y Aplicaciones de Computación Móvil de IEEE, Calicoon, NY, junio de 2002. [13] Xiaotao Liu, Gal Niv, K. K. Ramakrishnan, Prashant Shenoy y Jacobus Van der Merwe. El caso para la replicación remota consciente de la semántica. En Proc. 2º Taller Internacional sobre Seguridad y Supervivencia de Almacenamiento (StorageSS 2006), Alexandria, VA, octubre de 2006. [14] Michael Nelson, Beng-Hong Lim y Greg Hutchins. Migración rápida y transparente para máquinas virtuales. En la Conferencia Técnica Anual de USENIX, 2005. [15] Mendel Rosenblum y Tal Garfinkel. Monitores de máquinas virtuales: Tecnología actual y tendencias futuras. Computadora, 38(5):39-47, 2005. [16] C. Ruemmler y J. Wilkes. Patrones de acceso a disco en Unix. Actas de Winter 1993 USENIX, enero de 1993. [17] Paul Ruth, Junghwan Rhee, Dongyan Xu, Rick Kennell y Sebastien Goasguen. Adaptación en vivo autónoma de entornos computacionales virtuales en una infraestructura de múltiples dominios. En la Conferencia Internacional de Computación Autónoma (ICAC) de IEEE, junio de 2006. [18] Constantine P. Sapuntzakis, Ramesh Chandra, Ben Pfaff, Jim Chow, Monica S. Lam y Mendel Rosenblum. Optimizando la migración de computadoras virtuales. En Actas del 5º Simposio sobre Diseño e Implementación de Sistemas Operativos, diciembre de 2002. [19] A. Sundararaj, A. Gupta y P. Dinda. Mejorando el rendimiento de las aplicaciones en entornos virtuales a través de la inferencia y adaptación en tiempo de ejecución. En el Decimocuarto Simposio Internacional sobre Computación Distribuida de Alto Rendimiento (HPDC), julio de 2005. [20] Corporación Symantec. Guía del administrador de Veritas Volume Replicator. ht t p: //f t p. s uppor t . ve r i t as . c om/pub/s uppor t / pr oduc t s /Vol ume _ Re pl i c at or /2%83842. pdf, edición 5.0, 2006. [21] F. Travostino, P. Daspit, L. Gommans, C. Jog, C. de Laat, J. Mambretti, I. Monga, B. van Oudenaarde, S. Raghunath y P. Wang. Migración en vivo sin interrupciones de máquinas virtuales sobre la red de área metropolitana/amplia. Elsevier Future Generations Computer Systems, 2006. [22] T. Wood, P. Shenoy, A. Venkataramani, y M. Yousif. Estrategias de caja negra y caja gris para la migración de máquinas virtuales. En Actas del Simposio Usenix sobre Diseño e Implementación de Sistemas en Red (NSDI), Cambridge, MA, abril de 2007. [23] ¿Una forma xen de virtualización iscsi? http://www.internetnews.com/dev-news/article.php/3669246, abril de 2007. 267