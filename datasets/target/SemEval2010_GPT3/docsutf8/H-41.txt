HITS en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, USA najork@microsoft.com Hugo Zaragoza ∗ Yahoo! 

Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com RESUMEN Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, cuando se utilizan en combinación con un algoritmo de recuperación de texto de última generación que explota el texto del ancla. Medimos su efectividad utilizando tres medidas comunes de rendimiento: la clasificación recíproca media, la precisión media promedio y las mediciones normalizadas de ganancia acumulada descontada. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda en anchura de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.9 mil millones de URL distintas; y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta con un promedio de 2,383 resultados, de los cuales aproximadamente 17 fueron etiquetados por jueces. Descubrimos que HITS supera a PageRank, pero es tan efectivo como el grado de entrada de la página web. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Almacenamiento y recuperación de información - proceso de búsqueda, proceso de selección Términos Generales Algoritmos, Medición, Experimentación 1. Las características del grafo de enlaces, como el grado de entrada y el PageRank, han demostrado mejorar significativamente el rendimiento de los algoritmos de recuperación de texto en la web. Se cree que el algoritmo HITS también es de interés para la búsqueda web; hasta cierto punto, se puede esperar que HITS sea más informativo que otras características basadas en enlaces porque es dependiente de la consulta: intenta medir el interés de las páginas con respecto a una consulta dada. Sin embargo, hoy en día sigue sin estar claro si existen beneficios prácticos de HITS sobre otras medidas de grafo de enlaces. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web utilizan una representación del documento que incorpora el texto del anclaje de los documentos, es decir, el texto de los enlaces entrantes. Esto, al menos en cierta medida, tiene en cuenta el grafo de enlaces, de manera dependiente de la consulta. Comparar HITS con PageRank o con el grado de entrada empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el grafo de documentos. Si llevamos a cabo un experimento pequeño, nuestras conclusiones no se aplicarán a gráficos grandes como la web. Sin embargo, calcular eficientemente HITS en un grafo del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo crucial es clasificar en la parte superior de los diez o más documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar HITS a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado por humanos. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto del ancla. Esto es reconfortante: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante descubrir que HITS, una característica dependiente de la consulta, es tan efectiva como el grado de entrada de la página web, la característica basada en enlaces más simple. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto del ancla. El resto de este documento está estructurado de la siguiente manera: la Sección 2 revisa trabajos relacionados. La sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen con más detalle los algoritmos PageRank y HITS, y esbozan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece observaciones finales. TRABAJO RELACIONADO La idea de utilizar el análisis de hipervínculos para clasificar los resultados de búsqueda en la web surgió alrededor de 1997, y se manifestó en los algoritmos HITS [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, han dado lugar a una gran cantidad de investigaciones posteriores. Hay numerosos intentos de mejorar la efectividad de HITS y PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en HITS incluyen SALSA [19], Randomized HITS [20] y PHITS [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen TrafficRank [22], BlockRank [14], y TrustRank [11], entre otros. Otra línea de investigación se preocupa por analizar las propiedades matemáticas de HITS y PageRank. Por ejemplo, Borodin et al. [3] investigaron varias propiedades teóricas de PageRank, HITS, SALSA y PHITS, incluyendo su similitud y estabilidad, mientras que Bianchini et al. [2] estudiaron la relación entre la estructura del grafo web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron propiedades básicas de PageRank como la existencia y unicidad de un autovector y la convergencia de la iteración de potencia [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y HITS, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, resulta algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de HITS y de PageRank. Amento et al. [1] emplearon medidas cuantitativas, pero basaron sus experimentos en los conjuntos de resultados de solo 5 consultas y en el grafo web inducido por rastreos temáticos alrededor del conjunto de resultados de cada consulta. Un estudio más reciente realizado por Borodin et al. [4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenidos de Google, y un grafo de vecindario derivado al recuperar 50 enlaces entrantes por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un grafo web que abarca 2.9 mil millones de URL. NUESTROS CONJUNTOS DE DATOS Nuestra evaluación se basa en dos conjuntos de datos: un grafo web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro grafo web se basa en un rastreo web que se realizó de manera de búsqueda en amplitud y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hiperenlaces (después de eliminar los hiperenlaces duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2,433,985,395 URL en el conjunto de la frontera del rastreador que habían sido descubiertas, pero aún no descargadas. El grado medio de salida de las páginas web rastreadas es de 38.11; el grado medio de entrada de las páginas descubiertas (ya sea rastreadas o no) es de 6.10. Además, vale la pena señalar que hay mucha más variabilidad en los grados de entrada que en los grados de salida; algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de HITS. Nuestro conjunto de consultas fue producido muestreando 28,043 consultas del registro de consultas de búsqueda de MSN, y recuperando un total de 66,846,214 URLs de resultados para estas consultas (utilizando tecnología de motores de búsqueda comerciales), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro grafo web de 2.9 mil millones de URL no incluye todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (aproximadamente el 14.25%) estaban cubiertas por el gráfico. 485,656 de los resultados en el conjunto de consultas (aproximadamente el 0.73% de todos los resultados, o alrededor de 17.3 resultados por consulta) fueron evaluados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetados en una escala de seis puntos (las etiquetas siendo definitiva, excelente, buena, regular, mala y perjudicial). Los resultados fueron seleccionados para su evaluación en función de su ubicación en el motor de búsqueda comercial; en otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por algoritmos de clasificación preexistentes. Involucrar a un ser humano en el proceso de evaluación es extremadamente engorroso y costoso; sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto se debe a que aún no se han encontrado características de documentos que puedan estimar de manera efectiva la relevancia de un documento para una consulta de usuario. Dado que las características de coincidencia de contenido son muy poco confiables (y aún más las características de enlace, como veremos), necesitamos pedir a un humano que evalúe los resultados para comparar la calidad de las características. Evaluar los resultados de recuperación a partir de puntuaciones de documentos y juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad de recuperación de información. Una buena medida de rendimiento debería correlacionar con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre la puntuación y el juicio de un documento), o las medidas de correlación de orden (como el tau de Kendall entre la puntuación y los órdenes inducidos por el juicio) no son adecuadas. 4. En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas descontadas normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta su rango (asumiendo que el mejor documento tiene el rango más bajo). Una medida así es especialmente adecuada para los motores de búsqueda, ya que estudios han demostrado que los usuarios de motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG se normalizan para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que coincide completamente con la evaluación de los jueces humanos. El beneficio acumulado descontado en un umbral de rango particular T (DCG@T) se define como PT j=1 1 log(1+j) 2r(j) − 1 , donde r(j) es la calificación (0=detrimental, 1=mala, 2=regular, 3=buena, 4=excelente, y 5=definitiva) en el rango j. El NDCG se calcula dividiendo el DCG de un ranking por el DCG máximo posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificados de una consulta se define como el valor recíproco del rango del documento relevante de mayor rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los T documentos de mayor rango es relevante. El rango recíproco promedio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, sea rel(i) igual a 1 si el resultado en el rango i es relevante y 0 en caso contrario. La precisión P(j) en el rango j se define como 1 j Pj i=1 rel(i), es decir, la fracción de los resultados relevantes entre los j resultados de mayor rango. La precisión promedio (AP) en el umbral de rango k se define como Pk i=1 P (i)rel(i) Pn i=1 rel(i). La precisión media promedio (MAP) de un conjunto de consultas es el promedio de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados como justos o mejores se consideraban relevantes, y otra en la que todos los documentos calificados como buenos o mejores se consideraban relevantes. Por razones de espacio, solo informamos los valores de MAP y MRR calculados utilizando la última definición; el uso de la primera definición no cambia la naturaleza cualitativa de nuestros hallazgos. De manera similar, calculamos los valores de NDCG, MAP y MRR para una amplia gama de umbrales de rango; reportamos los resultados aquí en el rango 10; nuevamente, cambiar el umbral de rango nunca nos llevó a conclusiones diferentes. Recuerda que más del 99% de los documentos no tienen etiquetas. Decidimos tratar todos estos documentos como irrelevantes para la consulta. Para algunas consultas, sin embargo, no se han evaluado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que colocan nuevos documentos en la parte superior de la clasificación pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para su evaluación. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o búsquedas de artículos) y la mayoría de las veces estarán dentro del conjunto evaluado. 5. CALCULANDO EL PAGERANK EN UN GRÁFICO WEB GRANDE El PageRank es una medida independiente de consultas sobre la importancia de las páginas web, basada en la noción de endoso entre pares: Un hipervínculo de la página A a la página B se interpreta como un endoso del contenido de la página B por parte del autor de la página A. La siguiente definición recursiva captura esta noción de respaldo: R(v) = X (u,v)∈E R(u) Out(u) donde R(v) es la puntuación (importancia) de la página v, (u, v) es un borde (hipervínculo) de la página u a la página v contenido en el conjunto de bordes E del grafo web, y Out(u) es el grado de salida (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición adolece de una grave deficiencia: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación distinta de cero. Para superar esta deficiencia, Page et al. otorgan a cada página una puntuación mínima garantizada, dando lugar a la definición de PageRank estándar: R(v) = d |V | + (1 − d) X (u,v)∈E R(u) Out(u) donde |V | es el tamaño del conjunto de vértices (el número de páginas web conocidas), y d es un factor de amortiguación, generalmente establecido entre 0.1 y 0.2. Suponiendo que las puntuaciones se normalizan para sumar 1, PageRank puede ser visto como la distribución de probabilidad estacionaria de una caminata aleatoria en el grafo web, donde en cada paso de la caminata, el caminante con probabilidad 1 − d se mueve desde su nodo actual u a un nodo vecino v, y con probabilidad d selecciona un nodo de forma uniforme al azar de todos los nodos en el grafo y salta a él. En el límite, el caminante aleatorio se encuentra en el nodo v con probabilidad R(v). Un problema que debe abordarse al implementar PageRank es cómo tratar con nodos sumidero, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo de forma uniforme al azar y hacer la transición a él; esto es equivalente a agregar aristas desde cada nodo sumidero a todos los demás nodos en el grafo. Elegimos la alternativa de introducir un único nodo fantasma. Cada nodo sumidero tiene una arista hacia el nodo fantasma, y el nodo fantasma tiene una arista hacia sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando la iteración de potencia. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del momento de la consulta. Esta propiedad ha sido clave para el éxito de PageRank, ya que es un problema de ingeniería desafiante construir un sistema que pueda realizar cualquier cálculo no trivial en el grafo web en tiempo de consulta. Para calcular las puntuaciones de PageRank para los 2.9 mil millones de nodos en nuestro grafo web, implementamos una versión distribuida de PageRank. La computación consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen las URL de las páginas y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizado para calcular los puntajes de PageRank, y se convierten en un formato más compacto en el proceso. Específicamente, las URL se dividen entre las máquinas del clúster en función de un hash del componente host de las URL, y cada máquina en el clúster mantiene una tabla que asigna la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente poblado, de manera que sean índices adecuados en la matriz que luego contendrá las puntuaciones de PageRank. El sistema luego traduce nuestro registro de páginas y sus hipervínculos asociados en una representación compacta donde tanto las URL de las páginas como las URL de los enlaces están representadas por sus enteros de 32 bits asociados. La codificación hash del componente del host de las URL garantiza que todas las URL del mismo host se asignen a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, están entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación en red requerida por la segunda etapa de la computación de puntuación distribuida. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlaces como el vector de PageRank actual residen en disco y se leen de forma secuencial; mientras que el nuevo vector de PageRank se mantiene en memoria. Representamos las puntuaciones de PageRank como números de punto flotante de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten al equipo remoto a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada una equipada con 16 GB de RAM, para calcular los puntajes estándar de PageRank para los 2.9 mil millones de URL que estaban contenidos en nuestro grafo web. Utilizamos un factor de amortiguamiento de 0.15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente dejó de disminuir, lo que indica que habíamos alcanzado tanto un punto fijo como las limitaciones que permitiría la aritmética de punto flotante de 64 bits. 0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces de retroceso muestreados por resultado NDCG@10 hits-aut-all hits-aut-ih hits-aut-id 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces de retroceso muestreados por resultado MAP@10 hits-aut-all hits-aut-ih hits-aut-id 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de enlaces de retroceso muestreados por resultado MRR@10 hits-aut-all hits-aut-ih hits-aut-id Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de HITS. Una fase de post-procesamiento utiliza los vectores finales de PageRank (uno por máquina) y la tabla que mapea las URL a enteros de 32 bits (que representan índices en cada vector de PageRank) para puntuar la URL de resultado en nuestro registro de consultas. Como se mencionó anteriormente, nuestro grafo web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntuación de PageRank calculada; todas las demás URL recibieron una puntuación de 0.6. HITS, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. HITS (que significa Hypertext Induced Topic Search) se basa en las siguientes dos intuiciones: Primero, los hipervínculos pueden ser vistos como recomendaciones temáticas: Un hipervínculo desde una página u dedicada al tema T a otra página v probablemente respalda la autoridad de v con respecto al tema T. Segundo, es probable que el conjunto de resultados de una consulta particular tenga cierta coherencia temática. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el grafo web, sino más bien solo en el vecindario de páginas contenidas en el conjunto de resultados, ya que este vecindario es más probable que contenga enlaces relevantes temáticamente. Pero mientras que el conjunto de nodos inmediatamente alcanzables desde el conjunto de resultados es manejable (dado que la mayoría de las páginas solo tienen un número limitado de hipervínculos incrustados en ellas), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere muestrear un subconjunto aleatorio de tamaño fijo de las páginas que enlazan a cualquier página de alto grado de entrada en el conjunto de resultados. Además, Kleinberg sugiere considerar solo los enlaces que cruzan los límites de los servidores, argumentando que los enlaces entre páginas en el mismo servidor (enlaces intrínsecos) probablemente sean de navegación o nepotismo y no relevantes desde el punto de vista temático. Dado un grafo web (V, E) con un conjunto de vértices V y un conjunto de aristas E ⊆ V × V, y el conjunto de URLs de resultados de una consulta (llamado conjunto raíz R ⊆ V) como entrada, HITS calcula un grafo de vecindad que consiste en un conjunto base B ⊆ V (el conjunto raíz y algunos de sus vértices vecinos) y algunas de las aristas en E inducidas por B. Para formalizar la definición del grafo de vecindad, es útil primero introducir un operador de muestreo y el concepto de un predicado de selección de enlaces. Dado un conjunto A, la notación Sn[A] selecciona n elementos de forma aleatoria y uniforme de A; Sn[A] = A si |A| ≤ n. Un predicado de sección de enlace P toma una arista (u, v) ∈ E. En este estudio, utilizamos los siguientes tres predicados de sección de enlace: all(u, v) ⇔ verdadero ih(u, v) ⇔ host(u) = host(v) id(u, v) ⇔ dominio(u) = dominio(v) donde host(u) denota el host del URL u, y dominio(u) denota el dominio del URL u. Por lo tanto, todo es cierto para todos los enlaces, mientras que ih es cierto solo para los enlaces entre hosts, e id es cierto solo para los enlaces entre dominios. El conjunto de enlaces salientes OP del conjunto raíz R con respecto a un predicado de selección de enlaces P se define como: OP = [ u∈R {v ∈ V : (u, v) ∈ E ∧ P(u, v)} El conjunto de enlaces entrantes IP s del conjunto raíz R con respecto a un predicado de selección de enlaces P y un valor de muestreo s se define como: IP s = [ v∈R Ss[{u ∈ V : (u, v) ∈ E ∧ P(u, v)}] El conjunto base BP s del conjunto raíz R con respecto. La definición de P y s es la siguiente: BP s = R ∪ IP s ∪ OP. El grafo de vecindad (BP s , NP s ) tiene el conjunto base BP s como su conjunto de vértices y un conjunto de aristas NP s que contiene aquellas aristas en E que están cubiertas por BP s y permitidas por P: NP s = {(u, v) ∈ E : u ∈ BP s ∧ v ∈ BP s ∧ P(u, v)}. Para simplificar la notación, escribimos B para denotar BP s y N para denotar NP s. Para cada nodo u en el grafo de vecindad, HITS calcula dos puntuaciones: una puntuación de autoridad A(u), estimando qué tan autoritario es u en el tema inducido por la consulta, y una puntuación de hub H(u), indicando si u es una buena referencia para muchas páginas autoritarias. Esto se hace utilizando el siguiente algoritmo: 1. Para todo u ∈ B, hacer H(u) := q 1 |B|, A(u) := q 1 |B|. 2. Repetir hasta que H y A converjan: (a) Para todo v ∈ B: A(v) := Σ(u,v)∈N H(u) (b) Para todo u ∈ B: H(u) := Σ(u,v)∈N A(v) (c) H := H 2, A := A 2 donde X 2 normaliza el vector X a una longitud unitaria en el espacio euclidiano, es decir, la suma de los cuadrados de sus elementos es igual a 1. En la práctica, implementar un sistema que pueda calcular HITS dentro de las restricciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consultas está en miles de consultas por segundo, y el tiempo de respuesta deseado para las consultas es muy inferior a un segundo) es un gran desafío de ingeniería. Entre otras cosas, el grafo web no puede almacenarse razonablemente en disco, ya que los tiempos de búsqueda de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de los límites de tiempo, y el grafo no cabe en la memoria principal de una sola máquina, incluso al utilizar las técnicas de compresión más agresivas. Para experimentar con HITS y otros algoritmos de clasificación basados en enlaces dependientes de consultas que requieren accesos no regulares a nodos y aristas arbitrarios en el grafo web, implementamos un sistema llamado Almacén de Hipervínculos Escalable, o SHS en resumen. SHS es una base de datos de propósito especial, distribuida en un número arbitrario de máquinas que mantiene una versión altamente comprimida del grafo web en memoria y permite una búsqueda muy rápida de nodos y aristas. En nuestro hardware, se tarda un promedio de 2 microsegundos en mapear una URL a un identificador de 64 bits llamado UID, 15 microsegundos en buscar todos los UID de enlace entrantes o salientes asociados con un UID de página, y 5 microsegundos en mapear un UID de vuelta a una URL (esta última funcionalidad no es requerida por HITS). El sobrecargo de RPC es de aproximadamente 100 microsegundos, pero la API de SHS permite que muchas consultas se agrupen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos de SHS, una que contiene todos los 17.6 mil millones de enlaces en nuestro grafo web (todos), otra que contiene solo enlaces entre páginas que están en hosts diferentes (ih, por inter-host), y otra que contiene solo enlaces entre páginas que están en dominios diferentes (id). Consideramos que dos URL pertenecen a hosts diferentes si las partes de host de los URL difieren (es decir, no intentamos determinar si dos nombres de host simbólicos distintos se refieren al mismo ordenador), y consideramos un dominio como el nombre comprado a un registrador (por ejemplo, consideramos que news.bbc.co.uk y www.bbc.co.uk son hosts diferentes que pertenecen al mismo dominio). Utilizando cada una de estas bases de datos, calculamos los puntajes de autoridad y de centro de HITS para varias parametrizaciones del operador de muestreo S, muestreando entre 1 y 100 enlaces de retroceso de cada página en el conjunto raíz. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente puntajes de autoridad y centralidad de 0, ya que no estaban conectadas a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún respaldo. Realizamos cuarenta y cinco cálculos de HITS diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, ih e id) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecutaba en seis máquinas (cada una equipada con 16 GB de RAM) y calculamos los puntajes de autoridad y de hub de HITS, una consulta a la vez. La combinación de mayor duración (utilizando toda la base de datos y muestreando 100 enlaces de retroceso de cada vértice del conjunto raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio. RESULTADOS EXPERIMENTALES Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían ser capaces de clasificar los documentos relevantes en este conjunto por encima de los no relevantes, y esto debería resultar en un aumento en cada medida de rendimiento sobre el conjunto de consultas. Estamos especialmente interesados en evaluar la utilidad de HITS y otras características basadas en enlaces. En principio, podríamos hacer esto ordenando los documentos en cada conjunto de resultados por su valor de característica y comparando los NDCGs resultantes. Llamamos a este ranking con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos HITS para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (all), solo enlaces entre hosts (ih) y solo enlaces entre dominios (id), con valores de muestreo de enlaces de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de enlaces de retroceso muestreados en el rendimiento de recuperación de las puntuaciones de autoridad de HITS. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de enlaces de retroceso muestreados, el eje vertical representa el rendimiento bajo la medida apropiada, y cada curva representa un esquema de selección de enlaces. El esquema id supera ligeramente al ih, y ambos superan ampliamente al esquema all: eliminar los vínculos nepotistas vale la pena. El rendimiento de todo el esquema aumenta a medida que se muestrean más enlaces de retroceso de cada vértice del conjunto raíz, mientras que el rendimiento de los esquemas id e ih alcanza su punto máximo entre 10 y 25 muestras y luego se estabiliza o incluso disminuye, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de HITS, ahora fijaremos el número de enlaces de retroceso muestreados en 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, conteo de enlaces de entrada y salida de todas las páginas, solo de diferentes hosts y solo de diferentes dominios (conjuntos de datos all, ih e id respectivamente), y un algoritmo de recuperación de texto que explota el texto del ancla: BM25F[24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, título, cuerpo y texto de anclaje. Este modelo ha demostrado ser una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene una serie de parámetros libres (2 por campo, 6 en nuestro caso); utilizamos los valores de parámetros descritos en [24]. .341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 grado-en-ih grado-en-id grado-en-todo hits-aut-ih-100 hits-aut-todo-100 hits-aut-id-10 pagerank hits-hub-todo-100 grado-salida-ih hits-hub-id-100 grado-salida-todo grado-salida-id hits-hub-ih-100 bm25f MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .355 .273 0.25 0.30 0.35 0.40 grado-en-id grado-en-ih grado-en-todo hits-aut-ih-100 hits-aut-todo-100 pagerank hits-aut-id-10 grado-salida-todo hits-hub-todo-100 grado-salida-ih hits-hub-ih-100 grado-salida-id hits-hub-id-10 bm25f MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) coinciden. Como era de esperar, BM25F supera con creces todas las características basadas en enlaces. Las características basadas en enlaces se dividen en dos grupos, con una notable disminución en el rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces entrantes (grado de entrada, PageRank y puntuaciones de autoridad HITS); y el grupo de peor rendimiento consiste en las características que se basan en el número y/o calidad de los enlaces salientes (grado de salida y puntuaciones de hub HITS). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas tienen un mejor rendimiento que sus contrapartes que utilizan todos los enlaces. Además, parece que utilizar solo enlaces interdominio (id) es ligeramente mejor que utilizar enlaces interanfitrión (ih). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coincide con nuestras expectativas; si acaso, resulta ligeramente sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación en absoluto. Por otro lado, resulta bastante sorprendente que las características de grado de entrada superen a PageRank en todas las medidas. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el grafo web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario de distancia 1 del conjunto de resultados. Asimismo, resulta sorprendente que características simples independientes de la consulta, como el grado de entrada, que podrían estimar la calidad global pero no capturar la relevancia para una consulta, superen en rendimiento a características dependientes de la consulta, como las puntuaciones de autoridad de HITS. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (en contraposición a las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces pueden estar fuertemente correlacionadas con las características textuales por varias razones, principalmente la correlación entre el grado de entrada y el número de coincidencias de anclaje textual. Por lo tanto, se debe considerar el efecto de las características basadas en enlaces en combinación con las características textuales. De lo contrario, podríamos encontrar una característica basada en enlaces que es muy buena de forma aislada pero está fuertemente correlacionada con características textuales y no produce una mejora general; y viceversa, podríamos encontrar una característica basada en enlaces que es débil de forma aislada pero mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las características basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como una puntuación de documento, utilizando la fórmula score(d) =Pn i=1 wiTi(Fi(d)), donde d es un documento (o par documento-consulta, en el caso de BM25F), Fi(d) (para 1 ≤ i ≤ n) es una característica extraída de d, Ti es una transformación, y wi es un peso escalar libre que necesita ser ajustado. Elegimos funciones de transformación que determinamos empíricamente que son adecuadas. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si asumimos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Ajustamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento, y utilizamos las 23,043 consultas restantes para medir el rendimiento de las funciones de puntuación derivadas de esta manera. Exploramos la combinación de pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas NDCG, MRR y MAP de estas combinaciones de características, junto con un puntaje base BM25F (la barra más a la derecha en cada gráfico), que fue calculado utilizando el mismo subconjunto de 23,045 consultas que se utilizaron como conjunto de pruebas para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F resulta en una mejora sustancial en el rendimiento en comparación con BM25F de forma individual. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, grado de entrada y puntuaciones de autoridad de HITS) funciona considerablemente mejor que la combinación con características basadas en enlaces salientes (puntuaciones de centro de HITS y grado de salida). 3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son comparativamente pequeñas, y el orden relativo de las combinaciones de características es bastante estable en todo el rango de MAP@10. Sin embargo, la combinación de BM25F con cualquier variante de in-degree, y en particular con id in-degree, supera consistentemente la combinación de BM25F con los puntajes de autoridad de PageRank o HITS, y puede ser calculada de manera mucho más fácil y rápida. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en el corpus de un motor de búsqueda que satisfacen Q. Lamentablemente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q sumando las frecuencias inversas de los documentos de los términos de consulta individuales que componen Q. La frecuencia inversa de documento (IDF) de un término t con respecto a un corpus C se define como logN/doc(t), donde doc(t) es el número de documentos en C que contienen t y N es el número total de documentos en C. Al sumar las IDFs de los términos de la consulta, hacemos la (errónea) suposición de que los términos de la consulta son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación al menos es correcta en términos generales. Dividimos nuestro conjunto de consultas en 13 grupos, cada grupo asociado con un intervalo de valores de IDF de consulta, y calculamos métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma individual) a las consultas en cada grupo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos limitaremos a las cuatro más interesantes: PageRank, puntuaciones de autoridad de id HITS, id in-degree y BM25F. La Figura 4 muestra el MAP@10 para los 13 grupos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales; los cubos en el extremo derecho representan consultas muy específicas. Las cifras en el eje x superior de cada gráfico muestran el número de consultas en cada categoría (por ejemplo, el cubo más a la derecha contiene 1,629 consultas). BM25F funciona mejor para consultas específicas de medios, alcanzando su punto máximo en los intervalos que representan la suma de IDF [12,14). En comparación, HITS alcanza su pico en el intervalo del cubo que representa la suma de IDF [4,6), y PageRank y el grado de entrada alcanzan su pico en el intervalo del cubo que representa el intervalo [6,8), es decir, consultas más generales. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe una evaluación a gran escala de la efectividad de HITS en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y grado de entrada, cuando se aplican de forma individual o en combinación con un algoritmo de recuperación de texto que explota el texto del ancla (BM25F). La evaluación se lleva a cabo con respecto a un gran número de consultas evaluadas por humanos, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Al evaluar las características basadas en enlaces de forma aislada, descubrimos que el grado de entrada de la página web supera al PageRank y es aproximadamente tan efectivo como las puntuaciones de autoridad de HITS. Las puntuaciones de los hubs de HITS y el grado de salida de la página web son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y hay una clara diferencia entre combinar BM25F con una característica basada en enlaces entrantes (indegree, PageRank o puntuaciones de autoridad HITS) y una característica basada en enlaces salientes (puntuaciones de hub HITS y out-degree), pero dentro de esos dos grupos la elección precisa de la característica basada en enlaces importa relativamente poco. Creemos que las medidas presentadas en este artículo proporcionan una evaluación sólida de los esquemas de clasificación basados en enlaces más conocidos. Hay muchas posibles variantes de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no afirmamos que este trabajo sea la última palabra sobre este tema, sino más bien el primer paso en un largo camino. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y HITS. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank en la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlaces, y el efecto de ponderar los hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y HITS, nos gustaría medir la efectividad de otros algoritmos de ranking basados en enlaces, como SALSA. Finalmente, estamos planeando experimentar con combinaciones de características más complejas. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. ACM Transactions on Internet Technology, 5(1):92-128, 2005. [3] A. Borodin, G. O. Roberts, y J. S. Rosenthal. Encontrando autoridades y centros a partir de estructuras de enlaces en la World Wide Web. En Actas de la 10ª Conferencia Internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Clasificación de análisis de enlaces: algoritmos, teoría y experimentos. ACM Transactions on Internet Technology, 5(1):231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 30(1-7):107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press. [7] D. Cohn y H. Chang. Aprendiendo a identificar de manera probabilística documentos autoritativos. En Actas de la 17ª Conferencia Internacional sobre Aprendizaje Automático, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de revistas. Ciencia, 178(4060):471-479, 1972. [10] Z. Gy¨ongyi y H. Garcia-Molina. Taxonomía del spam en la web. En el 1er Taller Internacional sobre Recuperación de Información Adversarial en la Web, 2005. [11] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con TrustRank. En Actas de la 30ª Conferencia Internacional sobre Bases de Datos Muy Grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información en la vida real: un estudio de las consultas de los usuarios en la web. ACM SIGIR Forum, 32(1):5-17, 1998. [13] K. Järvelin y J. Kekäläinen. Evaluación basada en la ganancia acumulada de técnicas de recuperación de información. ACM Transactions on Information Systems, 20(4):422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. Documentación Americana, 14(1):10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. En Proc. del 9º Simposio Anual de Algoritmos Discretos ACM-SIAM, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 1(3):2005, 335-380. [19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de la estructura de enlaces (SALSA) y el efecto TKC. Redes de Computadoras y Sistemas ISDN, 33(1-6):387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para análisis de enlaces. En Proc. de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Actas de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. ¿Prediciendo fama y fortuna: ¿Pagerank o grado de entrada? En Actas del Simposio de Computación de Documentos Australasiano, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas Web y HARD. En Actas de la 13ª Conferencia de Recuperación de Información de Texto, 2004.