Intercambiando los valores de reputación entre los modelos de reputación de agentes heterogéneos: una experiencia en la prueba de arte Anarosa A. F. Brandão1, Laurent Vercouter2, Sara Casare1 y Jaime Sichman1 1 Laboratório de Técnicas Inteligentes - EP/USP av. Prof. Luciano Gualberto, 158, Trav.3, 05508-970, São Paulo-Brasil +55 11 3091 5397 anarosabrandao@gmail.com, {sara.casare, jaime.sichman}@poli.usp.br 2 ecole nationale superérieure des Mines de Saint-Etienne 158, Cours Fauriel, 42023 Saint-Etienne Cedex 2, France Laurent.vercouter@emse.fr Resumen en MAS abierto a menudo es un problema lograr la interoperabilidad de los agentes. La heterogeneidad de sus componentes convierte el establecimiento de interacción o cooperación entre ellos en una tarea no trivial, ya que los agentes pueden usar diferentes modelos internos y la decisión sobre la confianza de otros agentes es una condición crucial para la formación de la cooperación de los agentes. En este artículo proponemos el uso de una ontología para tratar este problema. Experimentamos esta idea mejorando el modelo de reputación de arte con datos semánticos obtenidos de esta ontología. Estos datos se usan durante la interacción entre los agentes heterogéneos cuando se intercambian valores de reputación y pueden usarse para agentes que usan diferentes modelos de reputación. Categorías y descriptores de sujetos I.2.11 [Inteligencia artificial distribuida]: sistemas multiagentes Términos generales Diseño, experimentación, estandarización.1. Introducción Los sistemas multiagentes abiertos (MAS) están compuestos por agentes distribuidos autónomos que pueden ingresar y dejar a la sociedad de agentes en su testamento porque los sistemas abiertos no tienen un control centralizado sobre el desarrollo de sus piezas [1]. Dado que los agentes se consideran entidades autónomas, no podemos suponer que hay una manera de controlar su comportamiento interno. Estas características son interesantes para obtener sistemas flexibles y adaptativos, pero también crean nuevos riesgos sobre la confiabilidad y la robustez del sistema. Las soluciones a este problema se han propuesto por los modelos de confianza donde los agentes están dotados de un modelo de otros agentes que les permite decidir si pueden o no confiar en otro agente. Dicha decisión de confianza es muy importante porque es una condición esencial para la formación de la cooperación de los agentes. Los procesos de decisión de confianza utilizan el concepto de reputación como base de una decisión. La reputación es un tema que se ha estudiado en varias obras [4] [5] [8] [9] con diferentes enfoques, pero también con diferentes semánticas adjuntas al concepto de reputación. Casare y Sichman [2] [3] propusieron una ontología funcional de reputación (delantera) y algunas direcciones sobre cómo podría usarse para permitir la interoperabilidad entre los diferentes modelos de reputación de agentes. Este documento describe cómo se puede aplicar el frente para permitir la interoperabilidad entre los agentes que tienen diferentes modelos de reputación. Un resumen de este enfoque se esboza en el contexto de un Bed de prueba para la experimentación y comparación de modelos de confianza, el Bed Testbed [6].2. Se han propuesto la ontología funcional de la reputación (delantera) en los últimos años, se han propuesto varios modelos computacionales de reputación [7] [10] [13] [14]. Como ejemplo de investigación producida en el campo MAS, nos referimos a tres de ellos: un modelo de reputación cognitiva [5], una tipología de reputación [7] y el modelo de reputación utilizado en el sistema de arrepentimiento [9] [10]. Cada modelo incluye sus propios conceptos específicos que pueden no existir en otros modelos, o existir con un nombre diferente. Por ejemplo, la imagen y la reputación son dos conceptos centrales en el modelo de reputación cognitiva. Estos conceptos no existen en la tipología de la reputación o en el modelo de arrepentimiento. En la tipología de la reputación, podemos encontrar algunos conceptos similares, como la reputación directa y la reputación indirecta, pero hay algunas ligeras diferencias semánticas. De la misma manera, el modelo de arrepentimiento incluye cuatro tipos de reputación (directo, testigo, vecindario y sistema) que se superponen con los conceptos de otros modelos pero que no son exactamente lo mismo. La ontología funcional de la reputación (delantera) se definió como una base semántica común que subsume los conceptos de los principales modelos de reputación. El frente incluye, como su núcleo, los siguientes conceptos: naturaleza de reputación, roles involucrados en la formación y propagación de la reputación, fuentes de información para la reputación, evaluación de la reputación y mantenimiento de la reputación. La reputación conceptual de ontología se compone de conceptos como la representación individual, la groupreputación y la productreputación. La formación y propagación de la reputación implican varios roles, desempeñados por las entidades o agentes que participan en esos procesos. La ontología define el proceso de reputación y reputación de los conceptos. Además, la reputación se puede clasificar de acuerdo con el origen de las creencias y opiniones que pueden derivarse de varias fuentes. La ontología define el concepto de reputación de la reputación que puede ser la representación primaria o la reputación secundaria. La representación primaria está compuesta por conceptos observados, la reputación y la directrreputación y el concepto secundario se compone de conceptos tales como la representación propagada y la oportunidad colectiva. Se pueden encontrar más detalles sobre el frente en [2] [3].3. Mapeo de los modelos de reputación del agente a Fore Visser et al [12] sugieren tres formas diferentes de apoyar la integración semántica de diferentes fuentes de información: un enfoque centralizado, donde cada fuente de información está relacionada con una ontología de dominio común;un enfoque descentralizado, donde cada fuente de información está relacionada con su propia ontología;y un enfoque híbrido, donde cada fuente de información tiene su propia ontología y el vocabulario de estas ontologías está relacionado con una ontología común. Este último organiza el vocabulario global común para apoyar la comparación de ontologías de origen. Casare y Sichman [3] utilizaron el enfoque híbrido para mostrar que el frente sirve como una ontología común para varios modelos de reputación. Por lo tanto, teniendo en cuenta las ontologías que describen los modelos de reputación del agente, podemos definir un mapeo entre estas ontologías y el frente cada vez que las ontologías usan un vocabulario común. Además, la información sobre las asignaciones entre los modelos de reputación del agente y el frente se puede inferir directamente clasificando la ontología resultante a partir de la integración de un modelo de reputación dado y el frente en una herramienta de ontología con motor de razonamiento. Por ejemplo, un mapeo entre la ontología del modelo de reputación cognitiva y el frente relaciona la imagen de los conceptos y la reputación con la representación primaria y la reputación secundaria desde el principio, respectivamente. Además, un mapeo entre la tipología de la reputación y el frente relaciona los conceptos de reputación directa y reputación indirecta con la reputación primaria y la reputación secundaria desde el principio, respectivamente. Sin embargo, los conceptos dirigen la confianza y la reputación de los testigos del modelo de reputación del sistema de arrepentimiento se asignan a la representación primaria y la representación propagada desde el principio. Dado que la representación propagada es un subconcepto de la reputación secundaria, se puede inferir que la reputación de los testigos también se asigna a la reputación secundaria.4. Escenarios experimentales Usando el Bed de TRAT de ART para ejemplificar el uso de mapeos de la última sección, definimos un escenario en el que se implementen varios agentes utilizando diferentes modelos de reputación de agentes. Este escenario incluye la interacción de los agentes durante la simulación del juego definido por Art [6] para describir las formas en que la interoperabilidad es posible entre los diferentes modelos de confianza que usan el frente.4.1 La prueba de arte de Art, el Bed de la prueba de arte proporciona un motor de simulación en el que pueden ejecutarse varios agentes, utilizando diferentes modelos de confianza. La simulación consiste en un juego donde los agentes tienen que decidir confiar o no en otros agentes. El dominio de los juegos es la evaluación del arte, en la que los agentes deben evaluar el valor de las pinturas basadas en la información intercambiada entre otros agentes durante la interacción de los agentes. La información puede ser una transacción de opinión, cuando un agente pide a otros agentes que la ayuden en su evaluación de una pintura;o una transacción de reputación, cuando la información requerida es sobre la reputación de otro agente (un objetivo) para una era dada. Se pueden encontrar más detalles sobre el plato de prueba de arte en [6]. El modelo de reputación de Art Common se mejoró con los datos semánticos obtenidos de Fore. Se definió una arquitectura de agente general para la interoperabilidad [11] para permitir a los agentes razonar sobre la información recibida de las interacciones de reputación. Esta arquitectura contiene dos módulos principales: el Módulo de mapeo de reputación (RMM) que es responsable de mapear conceptos entre un modelo de reputación de agente y delantero;y el Módulo de razonamiento de reputación (RRM) que es responsable de tratar información sobre la reputación de acuerdo con el modelo de reputación del agente.4.2 Escenarios de transacción de reputación Si bien incluye el modelo de reputación común del arte al arte, lo hemos incrementado para permitir interacciones más ricas que implican transacciones de reputación. En esta sección describimos escenarios relacionados con las transacciones de reputación en el contexto de Art Testbed, pero el primero es válido para cualquier tipo de transacción de reputación y el segundo es específico para el dominio de ART.4.2.1 Escenario general Suponga que los agentes A, B y C se implementan de acuerdo con la arquitectura de agente general antes mencionado con el modelo de reputación común de arte mejorado, utilizando diferentes modelos de reputación. El agente A utiliza la tipología del modelo de reputación, el agente B utiliza el modelo de reputación cognitiva y el agente C utiliza el modelo de Remisión del Sistema. Considere la interacción sobre la reputación donde los agentes A y B reciben información del Agente C sobre la reputación del Agente Y. En la Figura 2 se muestra un panorama general de esta interacción. Ruébase de ontología (y, valor = 0.8, testigo de la reputación) c typol. Ontología (y, valor = 0.8, propagación propagada) un cogmod. Ontología (y, valor = 0.8, reputación) b (y, valor = 0.8, propagación propagada) (y, valor = 0.8, representación propagada) remetón ontología (y, valor = 0.8, testigo -reputación) C ontología de arrepentimiento (y, valor = 0.8,, 0.8,Testigo de la reputación) Remendo ontología (y, valor = 0.8, testigo -representación) (y, valor = 0.8, testigo -representación) c typol. Ontología (y, valor = 0.8, propagación propagada) un typol. Ontología (y, valor = 0.8, propagación propagada) typol. Ontología (Y, valor = 0.8, propagación propagada) (y, valor = 0.8, resreputación propagada) un cogmod. Ontología (y, valor = 0.8, reputación) B COGMOD. Ontología (y, valor = 0.8, reputación) Cogmod. Ontología (y, valor = 0.8, reputación) (y, valor = 0.8, reputación) b (y, valor = 0.8, reproducción propagada) (y, valor = 0.8, reputación propagada) (y, valor = 0.8, propagación propagated) (y,,,,,,,,,, y, y, y, y, y, y, y, y, y, la reputación de propagación) (y, y, y, y, y, y, y, y, y, y,Valor = 0.8, PropagatedReputation) Figura 1. Interacción sobre la reputación La reputación de testimonio de información del Agente C es tratada por su RMM y se envía como reproducción propagada a ambos agentes. La información correspondiente en el agente Un modelo de reputación se propaga la reputación y en el modelo de reputación del agente B es la reputación. La forma en que los agentes A y B hacen uso de la información depende de su modelo de reputación interna y su implementación de RRM.1048 El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 4.2.2 Escenario de arte considerando los mismos agentes A y B y el dominio de evaluación de arte del arte, otro escenario interesante describe la siguiente situación: el agente A pregunta al agente B sobre la información de los agentes que essabe que tiene habilidad en alguna época de pintura específica. En este caso, el agente A desea información sobre la reputación directa El agente B tiene sobre agentes que tienen habilidad en una era específica, como el cubismo. Siguiendo los mismos pasos del escenario anterior, el agente un mensaje se prepara en su RRM utilizando información de su modelo interno. Un panorama general de esta interacción está en la Figura 2. Typol. Ontology (agente =?, Valor =?, Habilidad = cubismo, reputación = directreputation) a (agente =?, Valor =?, Habilidad = cubismo, reputación = primariareputación) cogmod. Ontología (agente =?, Valor =?, Habilidad = cubismo, reputación = imagen) b typol. Ontology (agente =?, Valor =?, Habilidad = cubismo, reputación = directreputation) a (agente =?, Valor =?, Habilidad = cubismo, reputación = primariareputación) cogmod. Ontología (agente =?, Valor =?, Habilidad = cubismo, reputación = imagen) b Figura 2. La interacción sobre los tipos específicos de valores de reputación del agente B La respuesta al agente A se procesa en su RRM y está compuesto por tuplas (agente, valor, cubismo, imagen), donde el par (agente, valor) está compuesto por todos los agentes y la reputación asociadaValores cuyo agente B conoce su experiencia sobre el cubismo por su propia opinión. Esta respuesta se reenvía al RMM para ser traducido al modelo común enriquecido y se enviará al Agente A. Después de recibir la información enviada por el Agente B, el Agente A la procesa en su RMM y la traduce a su propio modelo de reputación para ser analizado por su RRM.5. Conclusión En este documento presentamos una propuesta para reducir la incompatibilidad entre los modelos de reputación mediante el uso de una arquitectura de agente general para la interacción de reputación que se basa en una ontología funcional de la reputación (delantera), utilizada como un modelo de reputación compartido a nivel mundial. Un módulo de mapeo de reputación permite a los agentes traducir información de su modelo de reputación interna en el modelo compartido y viceversa. El Bed de Test Test se ha enriquecido para usar la ontología durante las transacciones de agentes. Se describieron algunos escenarios para ilustrar nuestra propuesta y parecen ser una forma prometedora de mejorar el proceso de construcción de la reputación del solo uso de tecnologías existentes.6. Agradecimientos Anarosa A. F. Brandão cuenta con el apoyo de la subvención CNPQ/Brasil 310087/2006-6 y Jaime Sichman es parcialmente respaldado por las subvenciones CNPQ/Brasil 304605/2004-2, 482019/2004-2 y 506881/2004-1. Laurent Vercouter fue parcialmente apoyado por FAPESP Grant 2005/02902-5.7. REFERENCIAS [1] AGHA, G. A. Resumen Patrones de interacción: un paradigma de programación para sistemas distribuidos abiertos, en (eds) E. Najm y J.-B. Stefani, Métodos formales para sistemas distribuidos abiertos basados en objetos IFIP Transactions, 1997, Chapman Hall.[2] Casare, s.y Sichman, J.S. Hacia una ontología funcional de reputación, en Proc de la 4ta Conferencia Conjunta de INTL sobre agentes autónomos y sistemas de agentes múltiples (AAMAS05), Utrecht, Países Bajos, 2005, v.2, pp. 505-511.[3] Casare, S. y Sichman, J.S. Utilizando una ontología funcional de reputación para interoperar diferentes modelos de reputación de agentes, Journal of the Brasilian Computer Society, (2005), 11 (2), pp. 79-94.[4] Castelfranchi, C. y Falcone, R. Principios de confianza en MAS: anatomía cognitiva, importancia social y cuantificación. En Actas de ICMAS98, París, 1998, pp. 72-79.[5] Conte, R. y Paolucci, M. Reputación en sociedades artificiales: creencias sociales para el orden social, Kluwer Publ., 2002. [6] Fullam, K.;Klos, T.;Muller, G.;Sabater, J.;Topol, Z.;Barber, S. Rosenchein, J.;Vercouter, L. y Voss, M. Una especificación de la reputación de la reputación y la confianza del agente (ART): Experimentación y competencia por la confianza en las sociedades de los agentes. En Proc.del 4to intl. Conf Conf en agentes autónomos y sistemas multiagentes (AAMAS05), ACM, 2005, 512-158.[7] Mui, L.;Halberstadt, A.;Mohtashemi, M. Notas de reputación en sistemas de múltiples agentes: una revisión. En: Proc de 1st Intl. Conf.en agentes autónomos y sistemas de múltiples agentes (Aamas 2002), Bolonia, Italia, 2002, 1, 280-287.[8] Muller, G. y Vercouter, L. Monitoreo descentralizado de la comunicación de agentes con un modelo de reputación. En Agentes de confianza para confiar en las sociedades electrónicas, LNCS 3577, 2005, pp. 144-161.[9] Sabater, J. y Sierra, C. Lamento: reputación en sociedades gregarias. En Müller, J. et al (eds) Proc.del quinto intl. Conf.en Agentes Autónomos, Canadá, 2001, ACM, 194-195.[10] Sabater, J. y Sierra, C. Revisión sobre modelos de confianza y reputación computacionales. En: Revisión de inteligencia artificial, Kluwer Acad. Publ., (2005), v. 24, n.1, pp. 33 - 60. [11] Vercouter, L, Casare, S., Sichman, J. y Brandão, A. Una experiencia en la interoperabilidad de los modelos de reputación basada en una ontología funcional en Proc.del 20 Ijcai, Hyderabad, India, 2007, pp.617-622.[12] Visser, U.;Stuckenschmidt, H.;Wache, H. y Vogele, T. habilitando tecnologías para la interoperabilidad. En: En U. Visser y H. Pundt, eds, taller en el 14º Symp.de informática para la protección del medio ambiente, Bonn, Alemania, 2000, pp. 35-46.[13] Yu, B. y Singh, M.P. Un modelo probatorio de gestión de la reputación distribuida. En: Proc.de la primera articulación intl conf.en agentes autónomos y sistemas de múltiples agentes (Aamas 2002), Bolonia, Italia, 2002, Parte 1, pp. 294 - 301. [14] Zacharia, G. y Maes, P. Manejo de confianza a través de mecanismos de reputación. En: Applied Artificial Intelligence, 14 (9), 2000, pp. 881-907. El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 1049