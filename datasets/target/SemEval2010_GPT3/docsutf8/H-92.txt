Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. Eugene Agichtein, Microsoft Research eugeneag@microsoft.com Eric Brill, Microsoft Research brill@microsoft.com Susan Dumais, Microsoft Research sdumais@microsoft.com RESUMEN Mostramos que la incorporación de datos sobre el comportamiento del usuario puede mejorar significativamente el orden de los principales resultados en una configuración real de búsqueda web. Examinamos alternativas para incorporar retroalimentación en el proceso de clasificación y exploramos las contribuciones de la retroalimentación de usuarios en comparación con otras características comunes de búsqueda en la web. Informamos los resultados de una evaluación a gran escala con más de 3,000 consultas y 12 millones de interacciones de usuarios con un motor de búsqueda web popular. Mostramos que la incorporación de retroalimentación implícita puede aumentar otras características, mejorando la precisión de los algoritmos de clasificación de búsqueda web competitivos hasta en un 31% en comparación con el rendimiento original. Categorías y Descriptores de Asignaturas H.3.3 Búsqueda y Recuperación de Información - Retroalimentación de relevancia, proceso de búsqueda; H.3.5 Servicios de Información en Línea - Servicios basados en la web. Términos generales Algoritmos, Medición, Experimentación 1. INTRODUCCIÓN Millones de usuarios interactúan con los motores de búsqueda a diario. Ellos emiten consultas, siguen algunos de los enlaces en los resultados, hacen clic en anuncios, pasan tiempo en páginas, reformulan sus consultas y realizan otras acciones. Estas interacciones pueden servir como una valiosa fuente de información para ajustar y mejorar la clasificación de los resultados de búsqueda en la web y pueden complementar juicios explícitos más costosos. La retroalimentación implícita de relevancia para la clasificación y personalización se ha convertido en un área activa de investigación. El trabajo reciente de Joachims y otros explorando el feedback implícito en entornos controlados ha demostrado el valor de incorporar el feedback implícito en el proceso de clasificación. Nuestra motivación para este trabajo es comprender cómo se puede utilizar la retroalimentación implícita en un entorno operativo a gran escala para mejorar la recuperación. ¿Cómo se compara y complementa con la evidencia del contenido de la página, el texto del ancla o las características basadas en enlaces como inlinks o PageRank? Si bien es intuitivo que las interacciones de los usuarios con el motor de búsqueda web deberían revelar al menos alguna información que podría ser utilizada para la clasificación, estimar las preferencias de los usuarios en entornos reales de búsqueda web es un problema desafiante, ya que las interacciones reales tienden a ser más ruidosas de lo que comúnmente se asume en los entornos controlados de estudios previos. Nuestro artículo explora si la retroalimentación implícita puede ser útil en entornos realistas, donde la retroalimentación del usuario puede ser ruidosa (o adversa) y un motor de búsqueda web ya utiliza cientos de características y está altamente ajustado. Con este fin, exploramos diferentes enfoques para clasificar los resultados de búsqueda web utilizando el comportamiento real de los usuarios obtenido como parte de las interacciones normales con el motor de búsqueda web. Las contribuciones específicas de este artículo incluyen: • Análisis de alternativas para incorporar el comportamiento del usuario en la clasificación de búsqueda web (Sección 3). • Aplicación de un modelo robusto de retroalimentación implícita derivado de la minería de millones de interacciones de usuarios con un importante motor de búsqueda web (Sección 4). • Una evaluación a gran escala sobre consultas reales de usuarios y resultados de búsqueda, mostrando mejoras significativas derivadas de la incorporación de la retroalimentación del usuario (Sección 6). Resumimos nuestros hallazgos y discutimos extensiones al trabajo actual en la Sección 7, que concluye el artículo. ANTECEDENTES Y TRABAJO RELACIONADO Clasificar los resultados de búsqueda es un problema fundamental en la recuperación de información. La mayoría de los enfoques comunes se centran principalmente en la similitud entre la consulta y una página, así como en la calidad general de la página [3,4,24]. Sin embargo, con la creciente popularidad de los motores de búsqueda, la retroalimentación implícita (es decir, las acciones que los usuarios realizan al interactuar con el motor de búsqueda) se puede utilizar para mejorar las clasificaciones. Las medidas de relevancia implícitas han sido estudiadas por varios grupos de investigación. Un resumen de las medidas implícitas se recopila en Kelly y Teevan [14]. Esta investigación, si bien desarrolló valiosas ideas sobre medidas implícitas de relevancia, no se aplicó para mejorar la clasificación de los resultados de búsqueda en la web en entornos realistas. Estrechamente relacionado con nuestro trabajo, Joachims [11] recopiló medidas implícitas en lugar de medidas explícitas, introduciendo una técnica basada completamente en datos de clics para aprender funciones de clasificación. Fox et al. [8] exploraron la relación entre medidas implícitas y explícitas en la búsqueda web, y desarrollaron modelos bayesianos para correlacionar medidas implícitas y juicios explícitos de relevancia tanto para consultas individuales como para sesiones de búsqueda. Este trabajo consideró una amplia gama de comportamientos de usuario (por ejemplo, tiempo de permanencia, tiempo de desplazamiento, patrones de reformulación) además del popular comportamiento de clics. Sin embargo, el esfuerzo de modelado se centró en predecir juicios de relevancia explícitos a partir de acciones implícitas de los usuarios y no específicamente en aprender funciones de clasificación. Otros estudios sobre el comportamiento de los usuarios en la búsqueda web incluyen a Pharo y Järvelin [19], pero no se aplicaron directamente para mejorar la clasificación. Más recientemente, Joachims et al. [12] presentaron una evaluación empírica de la interpretación de la evidencia de clics. Al realizar estudios de seguimiento ocular y correlacionar las predicciones de sus estrategias con las calificaciones explícitas, los autores demostraron que es posible interpretar con precisión los clics en un entorno controlado de laboratorio. Desafortunadamente, no está claro en qué medida la investigación previa se aplica a la búsqueda web del mundo real. Al mismo tiempo, si bien el trabajo reciente (por ejemplo, [26]) sobre el uso de la información de clics para mejorar la clasificación de búsqueda en la web es prometedor, solo abarca un aspecto de las interacciones de los usuarios con los motores de búsqueda en la web. Nos basamos en investigaciones existentes para desarrollar técnicas robustas de interpretación del comportamiento del usuario para el entorno real de búsqueda en la web. En lugar de tratar a cada usuario como un experto confiable, agregamos información de múltiples trazas de sesiones de búsqueda de usuarios no confiables, como describimos en las siguientes dos secciones. 3. INTEGRANDO LA RETROALIMENTACIÓN IMPLÍCITA Consideramos dos enfoques complementarios para la clasificación con retroalimentación implícita: (1) tratar la retroalimentación implícita como evidencia independiente para clasificar resultados, y (2) integrar características de retroalimentación implícita directamente en el algoritmo de clasificación. Describimos a continuación los dos enfoques generales de clasificación. Las características específicas del feedback implícito se describen en la Sección 4, y los algoritmos para interpretar e incorporar el feedback implícito se describen en la Sección 5. 3.1 Feedback Implícito como Evidencia Independiente. El enfoque general es reordenar los resultados obtenidos por un motor de búsqueda web según los clics observados y otras interacciones de usuario para la consulta en sesiones de búsqueda anteriores. Cada resultado se le asigna una puntuación según la relevancia esperada/ satisfacción del usuario basada en interacciones previas, lo que resulta en un cierto orden de preferencia basado únicamente en las interacciones del usuario. Si bien ha habido un trabajo significativo en la fusión de múltiples clasificaciones, adaptamos un enfoque simple y robusto de ignorar las puntuaciones de los clasificadores originales, y en su lugar simplemente fusionamos los órdenes de clasificación. La razón principal para ignorar las puntuaciones originales es que, dado que los espacios de características y los algoritmos de aprendizaje son diferentes, las puntuaciones no son directamente comparables, y la re-normalización tiende a eliminar el beneficio de incorporar las puntuaciones del clasificador. Experimentamos con una variedad de funciones de fusión en el conjunto de desarrollo de consultas (y utilizando un conjunto de interacciones de un período de tiempo diferente de los conjuntos de evaluación final). Encontramos que una combinación heurística simple de fusión de rangos funciona bien y es robusta a variaciones en los valores de puntuación de los clasificadores originales. Para una consulta dada q, se calcula la puntuación implícita ISd para cada resultado d a partir de las características de interacción del usuario disponibles, lo que resulta en la clasificación implícita Id para cada resultado. Calculamos un puntaje combinado SM(d) para d al combinar los rangos obtenidos de la retroalimentación implícita, Id, con el rango original de d, Od: SM(d) = Od + wI * Id, si existe retroalimentación implícita; de lo contrario, SM(d) = Od. Donde el peso wI es un factor de escala ajustado heurísticamente que representa la importancia relativa de la retroalimentación implícita. Los resultados de la consulta se ordenan en valores decrecientes de SM para producir la clasificación final. Un caso especial de este modelo surge al establecer wI en un valor muy grande, lo que efectivamente obliga a que los resultados clicados se clasifiquen por encima de los resultados no clicados, una heurística intuitiva y efectiva que utilizaremos como referencia. Aplicar algoritmos de combinación de clasificadores y ordenadores más sofisticados puede resultar en mejoras adicionales, y es una dirección prometedora para trabajos futuros. El enfoque anterior asume que no hay interacciones entre las características subyacentes que producen la clasificación original de la búsqueda web y las características de retroalimentación implícitas. Ahora relajamos esta suposición al integrar características de retroalimentación implícita directamente en el proceso de clasificación. 3.2 Clasificación con Características de Retroalimentación Implícita Los motores de búsqueda web modernos clasifican los resultados en función de un gran número de características, incluidas las características basadas en el contenido (es decir, qué tan cerca coincide una consulta con el texto, el título o el texto de anclaje del documento) y las características de calidad de página independientes de la consulta (por ejemplo, PageRank del documento o del dominio). En la mayoría de los casos, se desarrollan métodos automáticos (o semiautomáticos) para ajustar la función de clasificación específica que combina estos valores de características. Por lo tanto, un enfoque natural es incorporar características de retroalimentación implícita directamente como características para el algoritmo de clasificación. Durante el entrenamiento o ajuste, el clasificador puede ser ajustado como antes pero con características adicionales. En tiempo de ejecución, el motor de búsqueda recuperaría las características de retroalimentación implícita asociadas con cada par de URL de consulta y resultado. Este modelo requiere que un algoritmo de clasificación sea robusto ante valores faltantes: más del 50% de las consultas a los motores de búsqueda web son únicas, sin disponer de retroalimentación implícita previa. Ahora describimos un clasificador que utilizamos para aprender sobre los conjuntos de características combinadas, incluyendo la retroalimentación implícita. 3.3 Aprendizaje para Clasificar los Resultados de Búsqueda en la Web Un aspecto clave de nuestro enfoque es aprovechar los avances recientes en el aprendizaje automático, en particular los algoritmos de clasificación entrenables para la búsqueda en la web y la recuperación de información (por ejemplo, [5, 11] y resultados clásicos revisados en [3]). En nuestro entorno, contamos con juicios explícitos de relevancia humana (etiquetas) para un conjunto de consultas de búsqueda en la web y resultados. Por lo tanto, una opción atractiva es utilizar una técnica de aprendizaje automático supervisado para aprender una función de clasificación que prediga mejor las evaluaciones de relevancia. RankNet es uno de esos algoritmos. Es un algoritmo de ajuste de red neuronal que optimiza los pesos de las características para que coincidan mejor con las preferencias de los usuarios proporcionadas explícitamente en pares. Si bien los algoritmos de entrenamiento específicos utilizados por RankNet están más allá del alcance de este documento, se describen en detalle en [5] e incluyen una evaluación exhaustiva y comparación con otros métodos de clasificación. Una característica atractiva de RankNet es su eficiencia tanto en el tiempo de entrenamiento como en el de ejecución: el ranking en tiempo de ejecución se puede calcular rápidamente y puede escalarse a la web, y el entrenamiento se puede realizar sobre miles de consultas y resultados juzgados asociados. Utilizamos una implementación de RankNet de 2 capas para modelar relaciones no lineales entre características. Además, RankNet puede aprender con muchas funciones de costo (diferenciables), por lo que puede aprender automáticamente una función de clasificación a partir de etiquetas proporcionadas por humanos, una alternativa atractiva a las técnicas de combinación de características heurísticas. Por lo tanto, también utilizaremos RankNet como un clasificador genérico para explorar la contribución de la retroalimentación implícita en diferentes alternativas de clasificación. 4. MODELO IMPLÍCITO DE RETROALIMENTACIÓN DEL USUARIO Nuestro objetivo es interpretar con precisión la retroalimentación ruidosa del usuario obtenida al rastrear las interacciones del usuario con el motor de búsqueda. Interpretar la retroalimentación implícita en un entorno real de búsqueda en la web no es una tarea fácil. Caracterizamos este problema en detalle en [1], donde motivamos y evaluamos una amplia variedad de modelos de actividades implícitas de usuario. El enfoque general es representar las acciones del usuario para cada resultado de búsqueda como un vector de características, y luego entrenar un clasificador en base a estas características para descubrir los valores de las características que indican resultados de búsqueda relevantes (y no relevantes). Primero resumimos brevemente nuestras características y modelo, y el enfoque de aprendizaje (Sección 4.2) para proporcionar suficiente información para replicar nuestros métodos de clasificación y los experimentos subsiguientes. 4.1 Representación de las acciones del usuario como características. Modelamos los comportamientos observados en la búsqueda web como una combinación de un "componente de fondo (es decir, ruido independiente de la consulta y relevancia en el comportamiento del usuario, incluidos sesgos posicionales con interacciones de resultados), y un "componente de relevancia (es decir, comportamiento específico de la consulta indicativo de la relevancia de un resultado para una consulta). Diseñamos nuestras características para aprovechar el comportamiento de usuario agregado. El conjunto de características está compuesto por características observadas directamente (calculadas directamente a partir de observaciones para cada consulta), así como características derivadas específicas de la consulta, calculadas como la desviación de la distribución general de valores independientes de la consulta para los valores de las características observadas directamente correspondientes. Las características utilizadas para representar las interacciones de los usuarios con los resultados de búsqueda en la web se resumen en la Tabla 4.1. Esta información se obtuvo a través de la instrumentación del lado del cliente opt-in de usuarios de un importante motor de búsqueda web. Incluimos las características tradicionales de retroalimentación implícita, como el recuento de clics en los resultados, así como nuestras características derivadas novedosas, como la desviación del número de clics observados para un par de consulta-URL dado del número esperado de clics en un resultado en la posición dada. También modelamos el comportamiento de navegación después de que se hace clic en un resultado, por ejemplo, el tiempo promedio de permanencia en la página para un par de consulta-URL dado, así como su desviación del tiempo de permanencia esperado (promedio). Además, el conjunto de características fue diseñado para proporcionar información esencial sobre la experiencia del usuario y hacer que la interpretación de la retroalimentación sea sólida. Por ejemplo, los usuarios de búsqueda en la web a menudo pueden determinar si un resultado es relevante al mirar el título del resultado, la URL y el resumen; en muchos casos, no es necesario mirar el documento original. Para modelar este aspecto de la experiencia del usuario, incluimos características como la superposición de palabras en el título y las palabras en la consulta (TitleOverlap) y la fracción de palabras compartidas por la consulta y el resumen del resultado. Características de clics Posición Posición de la URL en el ranking actual Frecuencia de clics Número de clics para esta consulta, par URL Probabilidad de clic Probabilidad de un clic para esta consulta y URL Desviación de clic Desviación de la probabilidad de clic esperada ¿Es el siguiente clic? 1 si se hizo clic en la siguiente posición, 0 de lo contrario ¿Es el clic anterior? 1 si se hizo clic en la posición anterior, 0 de lo contrario ¿Hay clic arriba? 1 si hay un clic arriba, 0 de lo contrario ¿Hay clic abajo? 1 si hay un clic abajo, 0 de lo contrario Características de navegación Tiempo en la página Tiempo de permanencia en la página Tiempo acumulado en la página Tiempo acumulado para todas las páginas siguientes después de la búsqueda Tiempo en el dominio Tiempo de permanencia acumulado para este dominio Tiempo en URL corta Tiempo acumulado en el prefijo de la URL, sin parámetros ¿Se siguió el enlace? 1 si se siguió el enlace al resultado, 0 de lo contrario ¿Coincidencia exacta de URL? 0 si se utilizó normalización agresiva, 1 de lo contrario ¿Redirigido? 1 si la URL inicial es la misma que la URL final, 0 de lo contrario ¿Camino desde la búsqueda? 1 si solo se siguieron enlaces después de la consulta, 0 de lo contrario Clics desde la búsqueda Número de saltos para llegar a la página desde la consulta Tiempo promedio de permanencia Tiempo promedio en la página para esta consulta Desviación del tiempo de permanencia Desviación del tiempo de permanencia promedio en la página Desviación acumulada Desviación del tiempo de permanencia acumulado promedio Desviación del dominio Desviación del tiempo de permanencia promedio en el dominio Características de texto de consulta Coincidencia de título Palabras compartidas entre la consulta y el título Coincidencia de resumen Palabras compartidas entre la consulta y el fragmento Coincidencia de URL de consulta Palabras compartidas entre la consulta y la URL Coincidencia de dominio de consulta Palabras compartidas entre la consulta y el dominio de la URL Longitud de la consulta Número de tokens en la consulta Superposición con la siguiente consulta Fracción de palabras compartidas con la siguiente consulta Tabla 4.1: Algunas características utilizadas para representar el historial de navegación posterior a la búsqueda para una consulta dada y una URL de resultado de búsqueda. Habiendo descrito nuestro conjunto de características, revisamos brevemente nuestro método general para derivar un modelo de comportamiento del usuario. 4.2 Derivación de un Modelo de Retroalimentación del Usuario Para aprender a interpretar el comportamiento observado del usuario, correlacionamos las acciones del usuario (es decir, las características en la Tabla 4.1 que representan las acciones) con los juicios explícitos del usuario para un conjunto de consultas de entrenamiento. Encontramos todas las instancias en nuestros registros de sesión donde se enviaron estas consultas al motor de búsqueda, y agregamos las características del comportamiento del usuario para todas las sesiones de búsqueda que involucran estas consultas. Cada par de consulta-URL observado está representado por las características en la Tabla 4.1, con valores promediados en todas las sesiones de búsqueda, y asignado una de las seis etiquetas de relevancia posibles, que van desde Perfecto hasta Malo, según los juicios explícitos de relevancia. Estos vectores de características etiquetados se utilizan como entrada para el algoritmo de entrenamiento RankNet (Sección 3.3), el cual produce un modelo de comportamiento de usuario entrenado. Este enfoque es particularmente atractivo ya que no requiere heurísticas más allá de la ingeniería de características. El modelo de comportamiento del usuario resultante se utiliza para ayudar a clasificar los resultados de búsqueda en la web, ya sea directamente o en combinación con otras características, como se describe a continuación. 5. CONFIGURACIÓN EXPERIMENTAL El objetivo final de incorporar retroalimentación implícita en la clasificación es mejorar la relevancia de los resultados de búsqueda web devueltos. Por lo tanto, comparamos los métodos de clasificación sobre un gran conjunto de consultas evaluadas con etiquetas de relevancia explícitas proporcionadas por jueces humanos. Para que la evaluación sea realista, obtuvimos una muestra aleatoria de consultas de registros de búsqueda web de un motor de búsqueda importante, con resultados asociados y rastros de acciones de usuario. Describimos este conjunto de datos en detalle a continuación. Nuestros indicadores se describen en la Sección 5.2 que utilizamos para evaluar las alternativas de clasificación, enumeradas en la Sección 5.3 en los experimentos de la Sección 6. 5.1 Conjuntos de datos Comparamos nuestros métodos de clasificación en una muestra aleatoria de 3,000 consultas de los registros de consultas del motor de búsqueda. Las consultas fueron extraídas de los registros de manera uniforme al azar por token sin reemplazo, lo que resultó en una muestra de consultas representativa de la distribución general de consultas. En promedio, 30 resultados fueron etiquetados explícitamente por jueces humanos utilizando una escala de seis puntos que va desde Perfecto hasta Malo. En total, hubo más de 83,000 resultados con juicios de relevancia explícitos. Para calcular diversas estadísticas, se considerarán relevantes los documentos con la etiqueta Buena o mejor, y los documentos con etiquetas inferiores se considerarán no relevantes. Se debe tener en cuenta que los experimentos se realizaron sobre los resultados ya altamente clasificados por un motor de búsqueda web, lo cual corresponde a una experiencia de usuario típica que se limita al pequeño número de resultados altamente clasificados para una consulta típica de búsqueda web. Las interacciones de los usuarios fueron recopiladas durante un período de 8 semanas utilizando información voluntaria de participación. En total, se registraron más de 1.2 millones de consultas únicas, lo que resultó en más de 12 millones de interacciones individuales con el motor de búsqueda. Los datos consistían en las interacciones de los usuarios con el motor de búsqueda web (por ejemplo, hacer clic en un enlace de resultado, regresar a los resultados de búsqueda, etc.) realizadas después de enviar una consulta. Estas acciones fueron agregadas entre usuarios y sesiones de búsqueda y convertidas en características en la Tabla 4.1. Para crear los conjuntos de consultas de entrenamiento, validación y prueba, creamos tres divisiones aleatorias diferentes de 1,500 consultas de entrenamiento, 500 de validación y 1000 de prueba. Las divisiones se realizaron aleatoriamente por consulta, de modo que no hubiera superposición en las consultas de entrenamiento, validación y prueba. 5.2 Métricas de Evaluación Evaluamos los algoritmos de clasificación en una variedad de métricas de recuperación de información aceptadas, a saber, Precisión en K (P(K)), Ganancia Acumulada Descontada Normalizada (NDCG) y Precisión Promedio Media (MAP). Cada métrica se enfoca en un aspecto diferente del rendimiento del sistema, como describimos a continuación. • Precisión en K: Como la métrica más intuitiva, P(K) informa la fracción de documentos clasificados en los primeros K resultados que están etiquetados como relevantes. En nuestro entorno, requerimos que un documento relevante sea etiquetado como Bueno o superior. La posición de los documentos relevantes dentro de los primeros K no es relevante, por lo que esta métrica mide la satisfacción general del usuario con los resultados principales de K. • NDCG en K: NDCG es una medida de recuperación diseñada específicamente para la evaluación de búsqueda en la web [10]. Para una consulta dada q, los resultados clasificados se examinan desde el mejor clasificado hacia abajo, y el NDCG se calcula como: = +−= K j jr qq jMN 1 )( )1log(/)12( Donde Mq es una constante de normalización calculada de manera que un orden perfecto obtendría un NDCG de 1; y cada r(j) es una etiqueta de relevancia entera (0=Malo y 5=Perfecto) del resultado devuelto en la posición j. Ten en cuenta que los documentos sin etiquetar y los documentos malos no contribuyen a la suma, pero reducirán el NDCG para la consulta al empujar hacia abajo los documentos etiquetados relevantes, disminuyendo sus contribuciones. NDCG es muy adecuado para la evaluación de búsquedas en la web, ya que recompensa de manera más intensa los documentos relevantes en los resultados mejor clasificados que aquellos clasificados más bajos. • MAP: La precisión promedio para cada consulta se define como la media de la precisión en los valores de K calculados después de que se recuperó cada documento relevante. El valor MAP final se define como la media de las precisiones promedio de todas las consultas en el conjunto de pruebas. Esta métrica es el resumen de un solo valor más comúnmente utilizado de una ejecución sobre un conjunto de consultas. 5.3 Métodos de clasificación comparados. Recuerde que nuestro objetivo es cuantificar la efectividad del comportamiento implícito para la búsqueda web real. Una dimensión es comparar la utilidad de la retroalimentación implícita con otra información disponible para un motor de búsqueda web. Específicamente, comparamos la efectividad de los comportamientos implícitos de los usuarios con la coincidencia basada en el contenido, las características de calidad de la página estática y combinaciones de todas las características. • BM25F: Como referencia sólida de búsqueda web, utilizamos la puntuación BM25F, que se utilizó en uno de los sistemas con mejor rendimiento en la pista web TREC 2004 [23,27]. BM25F y sus variantes han sido extensamente descritas y evaluadas en la literatura de IR, por lo tanto, sirven como una línea base sólida y reproducible. La variante BM25F que utilizamos en nuestros experimentos calcula puntuaciones de coincidencia separadas para cada campo de un documento de resultado (por ejemplo, texto del cuerpo, título y texto del enlace) e incorpora información de enlaces independiente de la consulta (por ejemplo, PageRank, ClickDistance y profundidad de URL). La función de puntuación y la ajuste específico del campo se describen en detalle en [23]. Tenga en cuenta que BM25F no considera directamente la retroalimentación explícita o implícita para ajuste. • RN: La clasificación producida por un clasificador de redes neuronales (RankNet, descrito en la Sección 3.3) que aprende a clasificar los resultados de búsqueda web al incorporar BM25F y un gran número de características estáticas y dinámicas adicionales que describen cada resultado de búsqueda. Este sistema aprende automáticamente los pesos de todas las características (incluido el puntaje BM25F para un documento) basándose en etiquetas humanas explícitas para un gran conjunto de consultas. Un sistema que incorpora una implementación de RankNet actualmente está siendo utilizado por un importante motor de búsqueda y puede considerarse representativo del estado del arte en la búsqueda web. • BM25F-RerankCT: La clasificación producida al incorporar estadísticas de clics para reordenar los resultados de búsqueda web clasificados por BM25F arriba. El clic es un caso especial particularmente importante de retroalimentación implícita, y se ha demostrado que se correlaciona con la relevancia de los resultados. Este es un caso especial del método de clasificación en la Sección 3.1, con el peso wI establecido en 1000 y la clasificación Id es simplemente el número de clics en el resultado correspondiente a d. En efecto, esta clasificación coloca en la parte superior todos los resultados de búsqueda web devueltos con al menos un clic (y los ordena en orden decreciente por número de clics). La clasificación relativa de los resultados restantes no cambia y se insertan debajo de todos los resultados clicados. Este método sirve como nuestro método de reordenamiento de retroalimentación implícita de referencia. La clasificación producida al reordenar los resultados de BM25F utilizando todas las características del comportamiento del usuario (Sección 4). Este método aprende un modelo de preferencias de usuario correlacionando los valores de las características con etiquetas de relevancia explícitas utilizando el algoritmo de red neuronal RankNet (Sección 4.2). En tiempo de ejecución, para una consulta dada se calcula la puntuación implícita Ir para cada resultado r con características de interacción de usuario disponibles, y se produce el ranking implícito. La clasificación combinada se calcula como se describe en la Sección 3.1. Basándonos en los experimentos realizados sobre el conjunto de desarrollo, fijamos el valor de wI en 3 (el efecto del parámetro wI para este clasificador resultó ser insignificante). • BM25F+All: Clasificación derivada al entrenar el aprendiz RankNet (Sección 3.3) sobre el conjunto de características del puntaje BM25F, así como todas las características de retroalimentación implícita (Sección 3.2). Utilizamos la implementación de 2 capas de RankNet [5] entrenada en las consultas y etiquetas de los conjuntos de entrenamiento y validación. • RN+All: Clasificación derivada al entrenar el algoritmo de clasificación RankNet de 2 capas (Sección 3.3) sobre la unión de todas las características de retroalimentación de contenido, dinámicas e implícitas (es decir, todas las características descritas anteriormente, así como todas las nuevas características de retroalimentación implícita que introdujimos). Los métodos de clasificación anteriores abarcan el rango de la información utilizada para clasificar, desde no utilizar la retroalimentación implícita o explícita en absoluto (es decir, BM25F) hasta un motor de búsqueda web moderno que utiliza cientos de características y está ajustado en base a juicios explícitos (RN). Como mostraremos a continuación, incorporar el comportamiento del usuario en estos sistemas de clasificación mejora drásticamente la relevancia de los documentos devueltos. 6. RESULTADOS EXPERIMENTALES El feedback implícito para la clasificación de búsquedas en la web puede ser explotado de diversas formas. Comparamos métodos alternativos para explotar la retroalimentación implícita, tanto reordenando los resultados principales (es decir, los métodos BM25F-RerankCT y BM25F-RerankAll que reordenan los resultados de BM25F), como integrando directamente las características implícitas en el proceso de clasificación (es decir, los métodos RN+ALL y BM25F+All que aprenden a clasificar los resultados sobre la retroalimentación implícita y otras características). Comparamos nuestros métodos con baselines sólidos (BM25F y RN) sobre las medidas NDCG, Precisión en K y MAP definidas en la Sección 5.2. Los resultados se promediaron en tres divisiones aleatorias del conjunto de datos completo. Cada división contenía 1500 consultas de entrenamiento, 500 de validación y 1000 de prueba, todos los conjuntos de consultas disjuntos. Primero presentamos los resultados de las 1000 consultas de prueba (es decir, incluyendo las consultas para las cuales no hay medidas implícitas, por lo que utilizamos las clasificaciones web originales). Luego profundizamos para examinar los efectos en la reorganización de los intentos de búsqueda con más detalle, analizando dónde el feedback implícito resultó más beneficioso. Primero experimentamos con diferentes métodos de volver a clasificar la salida de los resultados de búsqueda de BM25F. Las figuras 6.1 y 6.2 informan sobre NDCG y Precisión para BM25F, así como para las estrategias de volver a clasificar los resultados con retroalimentación del usuario (Sección 3.1). Incorporar todos los comentarios de los usuarios (ya sea en el marco de reordenamiento o como características directamente al aprendiz) resulta en mejoras significativas (utilizando una prueba t de dos colas con p=0.01) tanto sobre la clasificación original de BM25F como sobre el reordenamiento solo con clics. La mejora es consistente en los 10 mejores resultados y es mayor para el mejor resultado: NDCG en 1 para BM25F+All es de 0.622 en comparación con 0.518 de los resultados originales, y la precisión en 1 también aumenta de 0.5 a 0.63. Basándonos en estos resultados, utilizaremos el clasificador de combinación de características directas (es decir, BM25F+All) para comparaciones posteriores que involucren retroalimentación implícita. Curiosamente, el uso solo de clics, aunque proporciona un beneficio significativo sobre la clasificación original de BM25F, no es tan efectivo como considerar el conjunto completo de características en la Tabla 4.1. Mientras analizamos el comportamiento del usuario (y las características de los componentes más efectivos) en un documento separado [1], vale la pena dar un ejemplo concreto del tipo de ruido inherente en la retroalimentación real de los usuarios en el entorno de búsqueda web. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 2 3 5 Posición del resultado Frecuencia de clics relativa PTR=2 PTR=3 PTR=5 Figura 6.3: Frecuencia relativa de clics para consultas con diferentes Posiciones del Resultado Relevante Superior (PTR). Si los usuarios solo consideraran la relevancia de un resultado para su consulta, harían clic en los resultados más relevantes en la parte superior. Desafortunadamente, como han demostrado Joachims y otros, la presentación también influye de manera bastante dramática en los resultados en los que los usuarios hacen clic. Los usuarios a menudo hacen clic en los resultados por encima del relevante, presumiblemente porque los resúmenes cortos no proporcionan suficiente información para hacer evaluaciones precisas de relevancia y han aprendido que, en promedio, los elementos mejor clasificados son relevantes. La Figura 6.3 muestra las frecuencias relativas de clics para consultas con elementos relevantes conocidos en posiciones distintas a la primera posición; la posición del resultado relevante superior (PTR) varía de 2 a 10 en la figura. Por ejemplo, para consultas con el primer resultado relevante en la posición 5 (PTR=5), hay más clics en los resultados no relevantes en posiciones más altas que en el primer resultado relevante en la posición 5. Como veremos, el aprendizaje sobre un conjunto de características de comportamiento más amplio resulta en una mejora sustancial en la precisión en comparación con solo el clic. Ahora consideramos incorporar el comportamiento del usuario en un conjunto de características mucho más amplio, RN (Sección 5.3) utilizado por un importante motor de búsqueda web. RN incorpora BM25F, características basadas en enlaces y cientos de otras características. La Figura 6.4 informa sobre NDCG en K y la Figura 6.5 informa sobre Precisión en K. Curiosamente, aunque las clasificaciones originales de RN son significativamente más precisas que BM25F solo, la incorporación de características de retroalimentación implícita (BM25F+All) da como resultado una clasificación que supera significativamente a las clasificaciones originales de RN. En otras palabras, la retroalimentación implícita incorpora suficiente información para reemplazar las cientos de otras características disponibles para el aprendiz de RankNet entrenado en el conjunto de características RN. 0.5 0.52 0.54 0.56 0.58 0.6 0.62 0.64 0.66 0.68 0.7 1 2 3 4 5 6 7 8 9 10K NDCG RN RN+All BM25 BM25+All Figura 6.4: NDCG en K para BM25F, BM25F+All, RN y RN+All para diferentes K Además, enriquecer las características de RN con el conjunto de retroalimentación implícita muestra una ganancia significativa en todas las medidas, permitiendo que RN+All supere a todos los demás métodos. Esto demuestra la naturaleza complementaria de la retroalimentación implícita con otras características disponibles para un motor de búsqueda web de última generación. 0.4 0.45 0.5 0.55 0.6 0.65 1 3 5 10 Precisión RN RN+Todo BM25 BM25+Todo Figura 6.5: Precisión en K para BM25F, BM25F+Todo, RN y RN+Todo para diferentes valores de K. Resumimos el rendimiento de los diferentes métodos de clasificación en la Tabla 6.1. Informamos el puntaje de Precisión Promedio Media (MAP) para cada sistema. Aunque no es intuitivo de interpretar, el MAP permite la comparación cuantitativa en una sola métrica. Las ganancias marcadas con * son significativas a un nivel de p=0.01 utilizando una prueba t de dos colas. Ganancia MAP P(1) Ganancia BM25F 0.184 - 0.503BM25F-Rerank-CT 0.215 0.031* 0.577 0.073* BM25F-RerankImplicit 0.218 0.003 0.605 0.028* BM25F+Implicit 0.222 0.004 0.620 0.015* RN 0.215 - 0.597RN+All 0.248 0.033* 0.629 0.032* Tabla 6.1: Precisión Promedio (MAP) para todas las estrategias. Hasta ahora hemos informado resultados promediados en todas las consultas del conjunto de pruebas. Desafortunadamente, menos de la mitad tuvo interacciones suficientes para intentar un nuevo ranking. De las 1000 consultas en la prueba, entre el 46% y el 49%, dependiendo de la división entre entrenamiento y prueba, tenían suficiente información de interacción para hacer predicciones (es decir, hubo al menos 1 sesión de búsqueda en la que el usuario hizo clic en al menos 1 URL de resultado). Esto no es sorprendente: la búsqueda en la web tiene una distribución de cola pesada y hay muchas consultas únicas. Ahora consideramos el rendimiento en las consultas para las cuales estaban disponibles las interacciones de los usuarios. La Figura 6.6 informa sobre el NDCG para el subconjunto de las consultas de prueba con las características de retroalimentación implícita. Las ganancias en el primer puesto son dramáticas. El NDCG en 1 de BM25F+All aumenta de 0.6 a 0.75 (un aumento relativo del 31%), logrando un rendimiento comparable al de RN+All operando sobre un conjunto de características mucho más rico. 0.6 0.65 0.7 0.75 0.8 1 3 5 10K NDCG RN RN+All BM25 BM25+All Figura 6.6: NDCG en K para BM25F, BM25F+All, RN y RN+All en consultas de prueba con interacciones de usuario. Del mismo modo, las ganancias en precisión en el top 1 son sustanciales (Figura 6.7) y es probable que sean evidentes para los usuarios de búsqueda web. Cuando se dispone de retroalimentación implícita, el sistema BM25F+All devuelve el documento relevante en la parte superior 1 casi el 70% del tiempo, en comparación con el 53% del tiempo cuando la retroalimentación implícita no es considerada por el sistema BM25F original. 0.45 0.5 0.55 0.6 0.65 0.7 1 3 5 10K Precisión RN RN+All BM25 BM25+All Figura 6.7: Precisión en K NDCG en K para BM25F, BM25F+All, RN y RN+All en consultas de prueba con interacciones de usuario Resumimos los resultados en la medida MAP para las consultas intentadas en la Tabla 6.2. Las mejoras en MAP son tanto sustanciales como significativas, siendo más pronunciadas que las mejoras en el clasificador BM25F. Ahora analizamos los casos en los que la retroalimentación implícita resultó ser más útil. La Figura 6.8 informa las mejoras de MAP sobre la ejecución de BM25F base para cada consulta con MAP inferior a 0.6. Ten en cuenta que la mayoría de la mejora es para consultas con bajo rendimiento (es decir, MAP < 0.1). Curiosamente, la incorporación de información sobre el comportamiento del usuario disminuye la precisión para consultas con un puntaje MAP original alto. Una posible explicación es que estas consultas fáciles tienden a ser de navegación (es decir, tener una única respuesta apropiada altamente clasificada), y las interacciones de los usuarios con resultados de menor rango pueden indicar necesidades de información divergentes que son mejor atendidas por los resultados menos populares (con calificaciones de relevancia global correspondientemente bajas). Para resumir nuestros resultados experimentales, la incorporación de retroalimentación implícita en un entorno real de búsqueda web resultó en mejoras significativas sobre las clasificaciones originales, utilizando tanto BM25F como RN como líneas de base. Nuestro amplio conjunto de características implícitas, como el tiempo en la página y las desviaciones del comportamiento promedio, ofrece ventajas sobre el uso exclusivo del clic como indicador de interés. Además, incorporar características de retroalimentación implícita directamente en la función de clasificación aprendida es más efectivo que utilizar la retroalimentación implícita para volver a clasificar. Las mejoras observadas en grandes conjuntos de pruebas de consultas (1,000 en total, entre 466 y 495 con retroalimentación implícita disponible) son tanto sustanciales como estadísticamente significativas. 7. CONCLUSIONES Y TRABAJOS FUTUROS En este artículo exploramos la utilidad de incorporar retroalimentación implícita ruidosa obtenida en un entorno real de búsqueda web para mejorar la clasificación de búsqueda web. Realizamos una evaluación a gran escala con más de 3,000 consultas y más de 12 millones de interacciones de usuarios con un motor de búsqueda importante, estableciendo la utilidad de incorporar retroalimentación implícita ruidosa para mejorar la relevancia de la búsqueda web. Comparamos dos alternativas para incorporar retroalimentación implícita en el proceso de búsqueda, a saber, reordenar con retroalimentación implícita e incorporar directamente características de retroalimentación implícita en la función de clasificación entrenada. Nuestros experimentos mostraron una mejora significativa sobre los métodos que no consideran la retroalimentación implícita. Las ganancias son particularmente dramáticas para el resultado superior K=1 en la clasificación final, con mejoras de precisión de hasta un 31%, y las ganancias son sustanciales para todos los valores de K. Nuestros experimentos mostraron que el feedback implícito del usuario puede mejorar aún más el rendimiento de la búsqueda web, cuando se incorpora directamente con características populares basadas en contenido y enlaces. Curiosamente, la retroalimentación implícita es especialmente valiosa para consultas con una clasificación original deficiente de resultados (por ejemplo, MAP inferior a 0.1). Una dirección prometedora para trabajos futuros es aplicar la investigación reciente sobre la predicción automática de la dificultad de las consultas, e intentar incorporar únicamente retroalimentación implícita para las consultas difíciles. Como otra dirección de investigación, estamos explorando métodos para extender nuestras predicciones a las consultas previamente no vistas (por ejemplo, el agrupamiento de consultas), lo cual debería mejorar aún más la experiencia de búsqueda en la web de los usuarios. AGRADECIMIENTOS Agradecemos a Chris Burges y Matt Richardson por la implementación de RankNet para nuestros experimentos. También agradecemos a Robert Ragno por sus valiosas sugerencias y muchas discusiones. 8. REFERENCIAS [1] E. Agichtein, E. Brill, S. Dumais y R. Ragno, Aprendizaje de modelos de interacción del usuario para predecir las preferencias de resultados de búsqueda web. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006 [2] J. Allan, Resumen de la Pista HARD en TREC 2003, Recuperación de Alta Precisión de Documentos, 2003 [3] R. Baeza-Yates y B. Ribeiro-Neto, Recuperación de Información Moderna, Addison-Wesley, 1999. [4] S. Brin y L. Page, Anatomía de un Motor de Búsqueda Web Hipertextual a Gran Escala, en Actas de WWW, 1997 [5] C.J.C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender, Aprendizaje para clasificación utilizando descenso de gradiente, en Actas de la Conferencia Internacional sobre Aprendizaje Automático, 2005 [6] D.M. Chickering, The WinMine Toolkit, Informe Técnico de Microsoft MSR-TR-2002-103, 2002 [7] M. Claypool, D. Brown, P. Lee y M. Waseda. Inferir el interés del usuario. IEEE Internet Computing. 2001 [8] S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White. Evaluando medidas implícitas para mejorar la experiencia de búsqueda. En ACM Transactions on Information Systems, 2005 [9] J. Goecks y J. Shavlick. Aprendiendo los intereses de los usuarios observando de manera discreta su comportamiento normal. En Actas del Taller de IJCAI sobre Aprendizaje Automático para Filtrado de Información. 1999. [10] K Jarvelin y J. Kekalainen. Métodos de evaluación IR para recuperar documentos altamente relevantes. En las Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000 [11] T. Joachims, Optimización de Motores de Búsqueda Utilizando Datos de Clics. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (SIGKDD), 2002 [12] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay, Interpretación precisa de los datos de clics como retroalimentación implícita, Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005 [13] T. Joachims, Haciendo práctico el aprendizaje SVM a gran escala. Avances en Métodos de Núcleo, en Aprendizaje de Vectores de Soporte, MIT Press, 1999 [14] D. Kelly y J. Teevan, Retroalimentación implícita para inferir preferencias de usuario: una bibliografía. En el Foro SIGIR, 2003 [15] J. Konstan, B. Miller, D. Maltz, J. Herlocker, L. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. En Comunicaciones de ACM, 1997. [16] M. Morita y Y. Shinoda, Filtrado de información basado en análisis del comportamiento del usuario y recuperación de texto de mejor coincidencia. Actas de la Conferencia de la ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 1994 [17] D. Oard y J. Kim. Retroalimentación implícita para sistemas de recomendación. En Actas del Taller de Sistemas de Recomendación de la AAAI. 1998 [18] D. Oard y J. Kim. Modelando el contenido de la información utilizando el comportamiento observable. En Actas de la 64ª Reunión Anual de la Sociedad Americana de Ciencia de la Información y Tecnología. 2001 [19] N. Pharo, N. y K. Järvelin. El método SST: una herramienta para analizar los procesos de búsqueda de información en la web. En Information Processing & Management, 2004 [20] P. Pirolli, El Uso de la Pista de Información Próxima para Buscar Contenido Distal en la World Wide Web. Trabajando con la tecnología en mente: Brunswikiano. Recursos para Ciencia Cognitiva e Ingeniería, Oxford University Press, 2004 [21] F. Radlinski y T. Joachims, Cadenas de Consulta: Aprendizaje para Clasificar a partir de Retroalimentación Implícita. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (SIGKDD), 2005. [22] F. Radlinski y T. Joachims, Evaluando la Robustez del Aprendizaje a partir de Retroalimentación Implícita, en Actas del Taller de ICML sobre Aprendizaje en Búsqueda Web, 2005 [23] S. E. Robertson, H. Zaragoza y M. Taylor, Extensión simple de BM25 a múltiples campos ponderados, en Actas de la Conferencia sobre Información y Gestión del Conocimiento (CIKM), 2004 [24] G. Salton y M. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, 1983 [25] E.M. Voorhees, D. Harman, Resumen de TREC, 2001 [26] G.R. Xue, H.J. Zeng, Z. Chen, Y. Yu, W.Y. -> Zeng, Z. Chen, Y. Yu, W.Y. Ma, W.S. Xi, y W.G. Fan, Optimizing web search using web clickthrough data, en Actas de la Conferencia sobre Información y Gestión del Conocimiento (CIKM), 2004 [27] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC 13: Pistas Web y Duras. En Actas de TREC 2004