Estudiando el uso de destinos populares para mejorar la interacción en la búsqueda web Ryen W. White Microsoft Research One Microsoft Way Redmond, WA 98052 ryenw@microsoft.com Mikhail Bilenko Microsoft Research One Microsoft Way Redmond, WA 98052 mbilenko@microsoft.com Silviu Cucerzan Microsoft Research One Microsoft Way Redmond, WA 98052 silviu@microsoft.com RESUMEN Presentamos una característica novedosa de interacción en la búsqueda web que, para una consulta dada, proporciona enlaces a sitios web visitados con frecuencia por otros usuarios con necesidades de información similares. Estos destinos populares complementan los resultados de búsqueda tradicionales, permitiendo la navegación directa a recursos autorizados sobre el tema de la consulta. Los destinos se identifican utilizando el historial de búsqueda y el comportamiento de navegación de muchos usuarios a lo largo de un período de tiempo prolongado, cuyo comportamiento colectivo proporciona una base para calcular la autoridad de la fuente. Describimos un estudio de usuario que comparó la sugerencia de destinos con la sugerencia previamente propuesta de consultas relacionadas, así como con la búsqueda web tradicional sin ayuda. Los resultados muestran que la búsqueda mejorada por sugerencias de destinos supera a otros sistemas para tareas exploratorias, con el mejor rendimiento obtenido al analizar el comportamiento pasado de los usuarios a nivel de consulta. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información - proceso de búsqueda. Términos generales Factores Humanos, Experimentación. 1. INTRODUCCIÓN El problema de mejorar las consultas enviadas a los sistemas de Recuperación de Información (IR) ha sido estudiado extensamente en la investigación de IR [4][11]. Las formulaciones alternativas de consultas, conocidas como sugerencias de consulta, pueden ofrecerse a los usuarios después de una consulta inicial, permitiéndoles modificar la especificación de sus necesidades proporcionadas al sistema, lo que conduce a un mejor rendimiento de recuperación. La reciente popularidad de los motores de búsqueda en la web ha permitido sugerencias de consultas que se basan en el comportamiento de reformulación de consultas de muchos usuarios para hacer recomendaciones de consultas basadas en interacciones previas de usuarios [10]. Aprovechar los procesos de toma de decisiones de muchos usuarios para la reformulación de consultas tiene sus raíces en la indexación adaptativa [8]. En los últimos años, la aplicación de tales técnicas se ha vuelto posible a una escala mucho mayor y en un contexto diferente al que se propuso en los primeros trabajos. Sin embargo, los enfoques basados en la interacción para la sugerencia de consultas pueden ser menos efectivos cuando la necesidad de información es exploratoria, ya que una gran proporción de la actividad del usuario para tales necesidades de información puede ocurrir más allá de las interacciones con el motor de búsqueda. En casos en los que la búsqueda dirigida es solo una fracción del comportamiento de búsqueda de información de los usuarios, la utilidad de los clics de otros usuarios sobre el espacio de los resultados mejor clasificados puede ser limitada, ya que no abarca el comportamiento de navegación posterior. Al mismo tiempo, la navegación del usuario que sigue las interacciones con el motor de búsqueda proporciona un respaldo implícito de los recursos web preferidos por los usuarios, lo cual puede ser especialmente valioso para tareas de búsqueda exploratoria. Por lo tanto, proponemos aprovechar una combinación del historial de búsqueda y del comportamiento de navegación pasado de los usuarios para mejorar las interacciones de búsqueda en la web de los usuarios. Los complementos del navegador y los registros del servidor proxy proporcionan acceso a los patrones de navegación de los usuarios que trascienden las interacciones con los motores de búsqueda. En trabajos anteriores, dichos datos se han utilizado para mejorar la clasificación de resultados de búsqueda por Agichtein et al. [1]. Sin embargo, este enfoque solo considera las estadísticas de visitas a las páginas de forma independiente, sin tener en cuenta las posiciones relativas de las páginas en los caminos de navegación posteriores a la consulta. Radlinski y Joachims [13] han utilizado esa inteligencia colectiva de los usuarios para mejorar la precisión de recuperación mediante el uso de secuencias de reformulaciones de consultas consecutivas, sin embargo, su enfoque no considera las interacciones de los usuarios más allá de la página de resultados de búsqueda. En este artículo, presentamos un estudio de usuario de una técnica que aprovecha el comportamiento de búsqueda y navegación de muchos usuarios para sugerir páginas web populares, denominadas destinos en adelante, además de los resultados de búsqueda regulares. Los destinos pueden no estar entre los resultados mejor clasificados, no contener los términos buscados, o incluso no estar indexados por el motor de búsqueda. En cambio, son páginas a las que otros usuarios suelen llegar con frecuencia después de enviar consultas iguales o similares y luego alejarse de los resultados de búsqueda inicialmente seleccionados. Conjeturamos que los destinos populares entre un gran número de usuarios pueden capturar la experiencia colectiva del usuario para las necesidades de información, y nuestros resultados respaldan esta hipótesis. En trabajos anteriores, ODay y Jeffries [12] identificaron la teletransportación como una estrategia de búsqueda de información empleada por los usuarios al saltar a sus destinos de información previamente visitados, mientras que Anderson et al. [2] aplicaron principios similares para apoyar la navegación rápida de sitios web en dispositivos móviles. En [19], Wexelblat y Maes describen un sistema para apoyar la navegación dentro del dominio basado en los rastros de navegación de otros usuarios. Sin embargo, no tenemos conocimiento de que tales principios se apliquen a la búsqueda en la Web. La investigación en el área de sistemas de recomendación también ha abordado problemas similares, pero en áreas como la pregunta-respuesta [9] y comunidades en línea relativamente pequeñas [16]. Quizás la instancia más cercana de teletransportación es la oferta de varios accesos directos dentro del dominio debajo del título de un resultado de búsqueda por parte de los motores de búsqueda. Si bien estos pueden basarse en el comportamiento del usuario y posiblemente en la estructura del sitio, el usuario ahorra como máximo un clic con esta función. Por el contrario, nuestro enfoque propuesto puede llevar a los usuarios a ubicaciones más allá de los resultados de búsqueda, ahorrando tiempo y brindándoles una perspectiva más amplia sobre la información relacionada disponible. El estudio de usuario realizado investiga la efectividad de incluir enlaces a destinos populares como una característica adicional de la interfaz en las páginas de resultados de motores de búsqueda. Comparamos dos variantes de este enfoque con la sugerencia de consultas relacionadas y la búsqueda web sin ayuda, y buscamos respuestas a preguntas sobre: (i) la preferencia del usuario y la efectividad de la búsqueda para tareas de búsqueda de elementos conocidos y exploratorias, y (ii) la distancia preferida entre la consulta y el destino utilizada para identificar destinos populares a partir de registros de comportamiento pasado. Los resultados indican que sugerir destinos populares a los usuarios que intentan realizar tareas exploratorias proporciona los mejores resultados en aspectos clave de la experiencia de búsqueda de información, mientras que sugerir refinamientos de consulta es más deseable para tareas de elementos conocidos. El resto del documento está estructurado de la siguiente manera. En la Sección 2 describimos la extracción de rastros de búsqueda y navegación de los registros de actividad de los usuarios, y su uso para identificar los destinos principales para nuevas consultas. La sección 3 describe el diseño del estudio de usuarios, mientras que las secciones 4 y 5 presentan los hallazgos del estudio y su discusión, respectivamente. Concluimos en la Sección 6 con un resumen. 2. BUSCAR RUTAS Y DESTINOS Utilizamos registros de actividad web que contenían la actividad de búsqueda y navegación recopilada con permiso de cientos de miles de usuarios durante un período de cinco meses entre diciembre de 2005 y abril de 2006. Cada entrada de registro incluía un identificador de usuario anónimo, una marca de tiempo, un identificador único de ventana del navegador y la URL de una página web visitada. Esta información fue suficiente para reconstruir secuencias temporalmente ordenadas de páginas vistas a las que nos referimos como rutas. En esta sección, resumimos la extracción de senderos, sus características y destinos (puntos finales de los senderos). Una descripción detallada y análisis exhaustivo de la extracción de rutas se presentan en [20]. 2.1 Extracción de rutas Para cada usuario, los registros de interacción se agruparon según la información del identificador del navegador. Dentro de cada instancia del navegador, la navegación del participante se resumió como un camino conocido como rastro del navegador, desde la primera hasta la última página web visitada en ese navegador. Dentro de algunas de estas rutas se encontraban rutas de búsqueda que se originaron con una consulta enviada a un motor de búsqueda comercial como Google, Yahoo!, Windows Live Search y Ask. Son estas rutas de búsqueda las que utilizamos para identificar destinos populares. Después de originarse con el envío de una consulta a un motor de búsqueda, los rastros continúan hasta un punto de terminación donde se asume que el usuario ha completado su actividad de búsqueda de información. Las rutas deben contener páginas que sean: páginas de resultados de búsqueda, páginas de inicio de motores de búsqueda o páginas conectadas a una página de resultados de búsqueda a través de una secuencia de hiperenlaces clicados. La extracción de rutas de búsqueda utilizando esta metodología también contribuye en cierta medida a manejar la multitarea, donde los usuarios realizan múltiples búsquedas simultáneamente. Dado que los usuarios pueden abrir una nueva ventana del navegador (o pestaña) para cada tarea [18], cada tarea tiene su propio rastro de navegación, y un rastro de búsqueda distinto correspondiente. Para reducir la cantidad de ruido de páginas no relacionadas con la tarea de búsqueda activa que pueden contaminar nuestros datos, las rutas de búsqueda se terminan cuando ocurre uno de los siguientes eventos: (1) un usuario regresa a su página de inicio, revisa correos electrónicos, inicia sesión en un servicio en línea (por ejemplo, MySpace o del.ico.us), escribe una URL o visita una página marcada como favorita; (2) una página se visualiza durante más de 30 minutos sin actividad; (3) el usuario cierra la ventana del navegador activa. Si una página (en el paso i) cumple alguno de estos criterios, se asume que el rastro termina en la página anterior (es decir, en el paso i - 1). Hay dos tipos de rastros de búsqueda que consideramos: rastros de sesión y rastros de consulta. Las rutas de sesión trascienden múltiples consultas y terminan solo cuando se cumple uno de los tres criterios de terminación mencionados anteriormente. Las rutas de consulta utilizan los mismos criterios de terminación que las rutas de sesión, pero también se terminan al enviar una nueva consulta a un motor de búsqueda. Aproximadamente se extrajeron 14 millones de rastros de consultas y 4 millones de rastros de sesiones de los registros. Ahora describimos algunas características del sendero. 2.2 Análisis del Sendero y Destino. La Tabla 1 presenta estadísticas resumidas para los senderos de consulta y sesión. Las diferencias en la interacción del usuario entre el último dominio en el recorrido (Dominio n) y todos los dominios visitados anteriormente (Dominios 1 a (n - 1)) son particularmente importantes, ya que resaltan la riqueza de datos de comportamiento del usuario que no son capturados por los registros de interacciones con motores de búsqueda. Las estadísticas son promedios de todos los senderos con dos o más pasos (es decir, aquellos senderos donde al menos un resultado de búsqueda fue clickeado). Tabla 1. Estadísticas resumidas (promedios) para rutas de búsqueda. Las estadísticas sugieren que los usuarios generalmente navegan lejos de la página de resultados de búsqueda (es decir, alrededor de 5 pasos) y visitan una variedad de dominios durante el transcurso de su búsqueda. En promedio, los usuarios visitan 2 dominios únicos (que no son motores de búsqueda) por rastro de consulta, y un poco más de 4 dominios únicos por rastro de sesión. Esto sugiere que los usuarios a menudo no encuentran toda la información que buscan en el primer dominio que visitan. Para las rutas de consulta, los usuarios también visitan más páginas y pasan significativamente más tiempo en el último dominio de la ruta en comparación con todos los dominios anteriores combinados. Estas distinciones de los últimos dominios en las rutas pueden indicar interés del usuario, utilidad de la página o relevancia de la página. Predicción de destino: para consultas frecuentes, los destinos más populares identificados a partir de los registros de actividad web podrían simplemente almacenarse para consultas futuras en el momento de la búsqueda. Sin embargo, hemos encontrado que durante el período de seis meses cubierto por nuestro conjunto de datos, el 56.9% de las consultas son únicas, y el 97% de las consultas ocurren 10 veces o menos, representando el 19.8% y el 66.3% de todas las búsquedas respectivamente (estos números son comparables a los reportados en estudios anteriores de registros de consultas de motores de búsqueda [15,17]). Por lo tanto, un enfoque basado en búsqueda evitaría que pudiéramos sugerir destinos de manera confiable para una gran parte de las búsquedas. Para superar este problema, utilizamos un modelo de predicción basado en términos simples. Como se discutió anteriormente, extraemos dos tipos de destinos: destinos de consulta y destinos de sesión. Para ambos tipos de destinos, obtenemos un corpus de pares consulta-destino y lo utilizamos para construir una representación de vector de términos de destinos que es análoga a la representación clásica tf.idf de documentos en IR tradicional [14]. Entonces, dado una nueva consulta q que consiste en k términos t1...tk, identificamos los destinos con la puntuación más alta utilizando la siguiente función de similitud: 1 Prueba t de medidas independientes: t(~60M) = 3.89, p < .001 2 La relevancia temática de los destinos fue probada para un subconjunto de alrededor de diez mil consultas para las cuales teníamos juicios humanos. La calificación promedio de la mayoría de los destinos se encuentra entre buena y excelente. La inspección visual de aquellos que no estaban dentro de este rango reveló que muchos eran relevantes pero no tenían juicios, o estaban relacionados pero tenían una asociación de consulta indirecta (por ejemplo, petfooddirect.com para la consulta [perros]). Donde los pesos de la consulta y del término de destino se calcularon utilizando el peso estándar tf.idf y el peso tf.idf suavizado normalizado por sesión, explorar algoritmos alternativos para la predicción de destino sigue siendo un desafío interesante para trabajos futuros, los resultados del estudio descrito en las secciones posteriores demuestran que este enfoque proporciona resultados sólidos y efectivos. 3. Para examinar la utilidad de los destinos, estudiamos investigando las percepciones y el rendimiento en cuatro sistemas de búsqueda web, dos con sugerencias de destino. Estas sugerencias se calculan utilizando el registro de consultas del motor durante el período de tiempo utilizado para rastrear cada consulta objetivo, recuperamos dos conjuntos de sugerencias candidatas que contienen la consulta objetivo como subcadena. Un conjunto contiene las consultas más frecuentes, mientras que el segundo conjunto contiene las consultas frecuentes que siguieron a la consulta objetivo en que la consulta candidata se puntúa multiplicando su frecuencia suavizada por su frecuencia suavizada de seguimiento en sesiones de búsqueda anteriores, utilizando suavizado de Laplace. Al puntuar B, se devuelven seis sugerencias de consulta de alto rango. Se encuentran seis sugerencias, el retroceso iterativo se realiza en sufijos progresivamente más largos de la consulta objetivo; un si se describe en [10]. Se ofrecieron sugerencias en un recuadro ubicado en la página de resultados, adyacente a los resultados de la búsqueda. Coloque la posición de las sugerencias en la página. Figura 1b vista de la sección de la página de resultados que contiene la oferta para la consulta [telescopio Hubble]. A la izquierda de la coma, están muy y correctamente. Durante la tarea de predicción, los resultados del usuario indican que este simple estudio incluyó a un usuario de 36 sujetos. Este motor de búsqueda es el motor. A los sujetos previos, como los buscados por Baseline, se les realiza una consulta adicional antes de la generación de la búsqueda inicial. Para sugerencias que constan de 100 montones de 100 troncos cada uno. Cada mes en general, la consulta objetivo se basa en estos. Si se realizan menos de rformadas utilizando una estrategia similar en la parte superior derecha de la 1a muestra cómo se ve un zoom de las sugerencias de cada consulta (a) Posición de las sugerencias (b) Zoo Figura 1. La presentación de sugerencias de consulta en la sugerencia es un ícono similar a un progreso b de popularidad normalizado. Haciendo clic en una sugerencia r resulta para esa consulta. 3.1.3 Sistema 3: QueryDestination QueryDestination utiliza una interfaz similar a Sin embargo, en lugar de mostrar refinamientos de consulta, QueryDestination sugiere hasta seis destinos visitados por otros usuarios que enviaron consultas similares, y se calcula como se describe en la sección anterior muestra la posición de la sugerencia de destino en la página. La figura 2b muestra una vista ampliada de las páginas de destino sugeridas para la consulta [hubb (a) Posición de destinos (b) Zoológico Figura 2. Para mantener la interfaz despejada, el título de la página se muestra al pasar el cursor sobre la URL de la página (mostrada en el nombre del destino, hay un icono clickeable para ejecutar una búsqueda con el dominio actualmente mostrado para la consulta actual). Mostramos destinos en lugar de aumentar su clasificación en los resultados de búsqueda, ya que se desvían de la consulta original (por ejemplo, aquellos temas que no contienen los términos de la consulta original). Funcionalidad de la interfaz en SessionDestination QueryDestination. La única diferencia entre la definición de los puntos finales de la ruta para consultas es el uso de destinos. QueryDestination dirige a los usuarios a terminar en la actividad o similar que SessionDestination dirige a los usuarios a los dominios al final de la sesión de búsqueda que sigue a las consultas. Esto disminuye el efecto de múltiples (es decir, solo nos importa dónde terminan los usuarios después de la subordinación en lugar de dirigir a los buscadores a posiblemente irre pueden preceder a una reformulación de la consulta. 3.2 Preguntas de investigación Estábamos interesados en determinar el valor de p. Para hacer esto, intentamos responder a las siguientes re 3. Para mejorar la confiabilidad, de manera similar a QueryS solo se muestran si su popularidad supera una frecuencia sugerida mediana QuerySuggestion. barra que codifica sus recupera nuevas búsquedas a QuerySuggestion. nts para los destinos enviados con frecuencia similar a la sección actual.3 Figura 2a ons en la porción de resultados de la búsqueda le telescopio]. destinos enviados eryDestination. e de cada destino en la Figura 2b). El siguiente n que permite al usuario ithin el destino una lista separada, en lugar de que puedan centrarse temáticamente en s relacionados). La tion es análoga a n los dos sistemas se ed en la computación top los otros dominios otros rias. Por el contrario, otros usuarios visitan iteraciones de consultas activas o similares (enviando todas las consultas), dominios relevantes que son destinos populares. Preguntas de investigación: Sugerencia, destinos umbral de frecuencia. P1: ¿Son los destinos populares preferibles y más efectivos que las sugerencias de refinamiento de consulta y la búsqueda web sin ayuda para: a. Búsquedas bien definidas (tareas de elementos conocidos)? b. Búsquedas mal definidas (tareas exploratorias)? RQ2: ¿Deberían tomarse los destinos populares del final de las rutas de consulta o del final de las rutas de sesión? 3.3 Sujetos 36 sujetos (26 hombres y 10 mujeres) participaron en nuestro estudio. Fueron reclutados a través de un anuncio por correo electrónico dentro de nuestra organización, donde ocupan una variedad de puestos en diferentes divisiones. La edad promedio de los sujetos fue de 34.9 años (máx=62, mín=27, DE=6.2). Todos están familiarizados con la búsqueda en la web y realizan un promedio de 7.5 búsquedas al día (DE=4.1). Treinta y un sujetos (86.1%) informaron tener conciencia general de las refinaciones de consulta ofrecidas por los motores de búsqueda web comerciales. 3.4 Tareas Dado que la tarea de búsqueda puede influir en el comportamiento de búsqueda de información [4], hicimos del tipo de tarea una variable independiente en el estudio. Construimos seis tareas de elementos conocidos y seis tareas exploratorias abiertas que se rotaron entre sistemas y sujetos como se describe en la siguiente sección. La Figura 3 muestra ejemplos de los dos tipos de tareas. Tarea de identificación de elementos conocidos: Identifica tres tormentas tropicales (huracanes y tifones) que hayan causado daños materiales y/o pérdida de vidas. Tarea exploratoria: Estás considerando comprar un teléfono de Voz sobre Protocolo de Internet (VoIP). Quieres aprender más sobre la tecnología VoIP y los proveedores que ofrecen el servicio, y seleccionar el proveedor y teléfono que mejor se adapten a ti. Figura 3. Ejemplos de tareas de ítem conocido y exploratorias. Las tareas exploratorias se formularon como situaciones de tareas de trabajo simuladas [5], es decir, escenarios de búsqueda cortos que fueron diseñados para reflejar necesidades de información de la vida real. Estas tareas generalmente requerían que los sujetos recopilaran información de antecedentes sobre un tema o reunieran suficiente información para tomar una decisión informada. Las tareas de búsqueda de elementos conocidos requerían la búsqueda de elementos específicos de información (por ejemplo, actividades, descubrimientos, nombres) para los cuales el objetivo estaba bien definido. Una clasificación de tareas similar ha sido utilizada con éxito en trabajos anteriores [21]. Las tareas fueron tomadas y adaptadas de la pista interactiva de la Conferencia de Recuperación de Texto (TREC) [7], y preguntas planteadas en comunidades de preguntas y respuestas (Yahoo! Respuestas, Google Respuestas y Windows Live QnA. Para motivar a los sujetos durante sus búsquedas, les permitimos seleccionar dos tareas de ítems conocidos y dos tareas exploratorias al comienzo del experimento de entre las seis posibilidades para cada categoría, antes de ver alguno de los sistemas o de que se les describiera el estudio. Antes del experimento, todas las tareas fueron probadas piloto con un pequeño número de sujetos diferentes para ayudar a garantizar que fueran comparables en dificultad y selectividad (es decir, la probabilidad de que una tarea fuera elegida dadas las alternativas). El análisis post-hoc de la distribución de tareas seleccionadas por los sujetos durante el estudio completo no mostró preferencia por ninguna tarea en ninguna de las categorías. 3.5 Diseño y Metodología El estudio utilizó un diseño experimental dentro de sujetos. El sistema tenía cuatro niveles (correspondientes a los cuatro sistemas experimentales) y las tareas de búsqueda tenían dos niveles (correspondientes a los dos tipos de tarea). El sistema y el tipo de tarea se contrarrestaron de acuerdo con un diseño de cuadrado latino-griego. Los sujetos fueron evaluados de forma independiente y cada sesión experimental duró hasta una hora. Seguimos el siguiente procedimiento: 1. A la llegada, se les pidió a los sujetos que seleccionaran dos tareas de ítems conocidos y dos tareas exploratorias de las seis tareas de cada tipo. 2. A los sujetos se les proporcionó un resumen del estudio en forma escrita que les fue leído en voz alta por el experimentador. Los sujetos completaron un cuestionario demográfico centrado en aspectos de la experiencia de búsqueda. 4. Para cada una de las cuatro condiciones de interfaz: a. A los sujetos se les dio una explicación de la funcionalidad de la interfaz que duró alrededor de 2 minutos. A los sujetos se les indicó intentar la tarea en el sistema asignado buscando en la Web, y se les asignaron hasta 10 minutos para hacerlo. c. Al completar la tarea, se les pidió a los sujetos que completaran un cuestionario posterior a la búsqueda. 5. Después de completar las tareas en los cuatro sistemas, los sujetos respondieron a un cuestionario final comparando sus experiencias en los sistemas. 6. Los sujetos fueron agradecidos y compensados. En la siguiente sección presentamos los hallazgos de este estudio. 4. RESULTADOS En esta sección utilizamos los datos derivados del experimento para abordar nuestras hipótesis sobre las sugerencias de consulta y destinos, proporcionando información sobre el efecto del tipo de tarea y la familiaridad con el tema cuando sea apropiado. En este análisis se utiliza la prueba estadística paramétrica y el nivel de significancia se establece en < 0.05, a menos que se indique lo contrario. En esta sección presentamos los hallazgos sobre cómo los sujetos percibieron los sistemas que utilizaron. Las respuestas a los cuestionarios post-búsqueda (por sistema) y finales se utilizan como base para nuestro análisis. 4.1.1 Proceso de búsqueda Para abordar la primera pregunta de investigación, se buscaba obtener información sobre la percepción de los sujetos acerca de la experiencia de búsqueda en cada uno de los cuatro sistemas. En los cuestionarios posteriores a la búsqueda, pedimos a los sujetos que completaran cuatro diferenciales semánticos de 5 puntos indicando sus respuestas a la declaración de actitud: La búsqueda que les pedimos que realizaran fue. Los estímulos emparejados ofrecidos como respuestas fueron: relajante/estresante, interesante/aburrido, tranquilo/cansado y fácil/difícil. Los valores diferenciales promedio obtenidos se muestran en la Tabla 1 para cada sistema y cada tipo de tarea. El valor correspondiente a la diferencial "Todo" representa la media de las tres diferenciales diferentes, proporcionando una medida general de los sentimientos de los sujetos. Tabla 1. Percepciones del proceso de búsqueda (menor = mejor). Cada celda en la Tabla 1 resume las respuestas de los sujetos para 18 pares de sistemas de tareas (18 sujetos que realizaron una tarea de elemento conocido en Baseline (B), 18 sujetos que realizaron una tarea exploratoria en QuerySuggestion (QS), etc.). La respuesta más positiva en todos los sistemas para cada par de tarea diferencial se muestra en negrita. Aplicamos un análisis de varianza de dos vías (ANOVA) a cada diferencial en los cuatro sistemas y dos tipos de tarea. Los sujetos encontraron la búsqueda más fácil en QuerySuggestion y QueryDestination que en los otros sistemas para tareas de elementos conocidos. Para tareas exploratorias, solo las búsquedas realizadas en QueryDestination fueron más fáciles que en los otros sistemas. Los sujetos indicaron que las tareas exploratorias en los tres sistemas no basales eran más estresantes (es decir, menos relajantes) que las tareas de elementos conocidos. Como discutiremos con más detalle en la Sección 4.1.3, los sujetos consideraron la familiaridad de Baseline como una fortaleza, y podrían haber tenido dificultades para intentar una tarea más compleja mientras aprendían una nueva característica de la interfaz, como sugerencias de consulta o destino. 4.1.2 Soporte de Interfaz Solicitamos la opinión de los sujetos sobre el soporte de búsqueda ofrecido por QuerySuggestion, QueryDestination y SessionDestination. Se utilizaron las siguientes escalas de Likert y diferenciales semánticos: • Escala de Likert A: Usar este sistema mejora mi efectividad para encontrar información relevante. (Efectividad) • Escala de Likert B: Las consultas/destinos sugeridos me ayudaron a acercarme a mi objetivo de información. (CercaDelObjetivo) • Escala de Likert C: Reutilizaría las consultas/destinos sugeridos si me encontrara con una tarea similar en el futuro. (Reutilización) • Diferencial semántico A: Las consultas/destinos sugeridos por el sistema fueron: relevante/irrelevante, útil/inútil, apropiado/inapropiado. No incluimos esto en el cuestionario posterior a la búsqueda cuando los sujetos utilizaron el sistema de Línea Base, ya que se refieren a opciones de soporte de interfaz que Línea Base no ofrecía. La Tabla 2 presenta las respuestas promedio para cada una de estas escalas y diferenciales, utilizando las etiquetas después de cada una de las primeras tres escalas Likert en la lista con viñetas anterior. Los valores de los tres diferenciales semánticos están incluidos en la parte inferior de la tabla, al igual que su promedio general bajo Todos. Tabla 2. Percepciones de apoyo del sistema (menor = mejor). La escala / Diferencial Exploratorio de Elementos Conocidos QS QD SD QS QD SD Efectividad 2.7 2.5 2.6 2.8 2.3 2.8 CercaDelObjetivo 2.9 2.7 2.8 2.7 2.2 3.1 Reutilización 2.9 3 2.4 2.5 2.5 3.2 1 Relevante 2.6 2.5 2.8 2.4 2 3.1 2 Útil 2.6 2.7 2.8 2.7 2.1 3.1 3 Apropiado 2.6 2.4 2.5 2.4 2.4 2.6 Todos {1,2,3} 2.6 2.6 2.6 2.6 2.3 2.9 Los resultados muestran que los tres sistemas experimentales mejoraron la percepción de los sujetos sobre su efectividad de búsqueda en comparación con la línea base, aunque solo QueryDestination lo hizo de manera significativa.8 Un examen más detallado del tamaño del efecto (medido usando Cohens d) reveló que QueryDestination afecta de manera más positiva la efectividad de la búsqueda.9 QueryDestination también parece acercar a los sujetos a su objetivo de información (CercaDelObjetivo) más que QuerySuggestion o 4 fácil: F(3,136) = 4.71, p = .0037; pruebas post hoc de Tukey: todos los p ≤ .008 5 fácil: F(3,136) = 3.93, p = .01; pruebas post hoc de Tukey: todos los p ≤ .012 6 relajante: F(1,136) = 6.47, p = .011 7 Esta pregunta estaba condicionada por el uso de los sujetos de la línea base y sus experiencias previas de búsqueda en la web. 8 F(3,136) = 4.07, p = .008; pruebas post hoc de Tukey: todos los p ≤ .002 9 QS: d(K,E) = (.26, .52); QD: d(K,E) = (.77, 1.50); SD: d(K,E) = (.48, .28) SessionDestination, aunque solo para tareas de búsqueda exploratoria.10 Comentarios adicionales sobre QuerySuggestion indicaron que los sujetos lo veían como una conveniencia (para evitarles escribir una reformulación) en lugar de una forma de influir drásticamente en el resultado de su búsqueda. Para búsquedas exploratorias, los usuarios se beneficiaron más al ser dirigidos a fuentes de información alternativas que de sugerencias para refinamientos iterativos de sus consultas. Nuestros hallazgos también muestran que nuestros sujetos sintieron que QueryDestination produjo sugerencias más relevantes y útiles para tareas exploratorias que los otros sistemas. Todas las demás diferencias observadas entre los sistemas no fueron estadísticamente significativas. La diferencia en el rendimiento entre QueryDestination y SessionDestination se explica por el enfoque utilizado para generar destinos (descrito en la Sección 2). Las recomendaciones de destinos de sesión provienen de los recorridos de sesión de los usuarios finales que a menudo trascienden múltiples consultas. Esto aumenta la probabilidad de que los cambios de tema afecten negativamente su relevancia. 4.1.3 Clasificación del sistema En el cuestionario final que siguió a la finalización de todas las tareas en todos los sistemas, se pidió a los sujetos que clasificaran los cuatro sistemas en orden descendente según sus preferencias. La Tabla 3 presenta la clasificación promedio asignada a cada uno de los sistemas. Tabla 3. Clasificación relativa de sistemas (menor = mejor). Estos resultados indican que los sujetos prefirieron en general Sugerencia de Consulta y Destino de Consulta. Sin embargo, ninguna de las diferencias entre las calificaciones de los sistemas es significativa. Una posible explicación para que estos sistemas hayan sido calificados más alto podría ser que, aunque los sistemas de destino populares tuvieron un buen desempeño en búsquedas exploratorias y QuerySuggestion tuvo un buen desempeño en búsquedas de elementos conocidos, una clasificación general fusiona estos dos desempeños. Esta clasificación relativa refleja las percepciones generales de los sujetos, pero no los separa por cada categoría de tarea. En general, parecía haber una ligera preferencia por QueryDestination, pero como muestran otros resultados, el efecto del tipo de tarea en las percepciones de los sujetos es significativo. El cuestionario final también incluyó preguntas abiertas que pedían a los sujetos que explicaran su clasificación del sistema, y describieran lo que les gustaba y no les gustaba de cada sistema: Baseline: Los sujetos que prefirieron Baseline comentaron sobre la familiaridad del sistema (por ejemplo, era familiar y no terminé usando las sugerencias (S36)). Aquellos que no preferían este sistema no les gustaba la falta de soporte para la formulación de consultas (puede ser difícil si no eliges buenos términos de búsqueda (S20)) y la dificultad para localizar documentos relevantes (por ejemplo, difícil de encontrar lo que estaba buscando (S13); tecnología actual poco ágil (S30)). Los sujetos que calificaron QuerySuggestion más alto comentaron sobre el soporte rápido para la formulación de consultas (por ejemplo, fue útil para (1) ahorrar tiempo escribiendo (2) generar nuevas ideas para la expansión de la consulta (S12); me ayuda a redactar mejor el término de búsqueda (S24); hizo que mi próxima consulta fuera más fácil (S21)). Aquellos que no preferían este sistema criticaron la calidad de las sugerencias (por ejemplo, No relevante (S11); Popular 10 F(2,102) = 5.00, p = .009; Pruebas post-hoc de Tukey: todos los p ≤ .012 11 F(2,102) = 4.01, p = .01; α = .0167 12 Pruebas post-hoc de Tukey: todos los p ≥ .143 13 ANOVA de medidas repetidas de un solo factor: F(3,105) = 1.50, p = .22 las consultas no eran lo que estaba buscando (S18)) y la calidad de los resultados a los que llevaron (por ejemplo, Los resultados (después de hacer clic en las sugerencias) eran de baja calidad (S35); En última instancia, no útiles (S1)). Los sujetos que prefirieron este sistema comentaron principalmente sobre el apoyo para acceder a nuevas fuentes de información (por ejemplo, proporcionando áreas / dominios potencialmente útiles y nuevos para explorar (S27)) y evitando la necesidad de navegar por estas páginas (útil para intentar ir directamente al grano y dirigirse a donde otros pueden haber encontrado respuestas sobre el tema (S3)). Aquellos que no preferían este sistema comentaron sobre la falta de especificidad en los dominios sugeridos (Deberían simplemente enlazar a una consulta específica del sitio, no al sitio en sí mismo (S16); Los sitios no eran muy específicos (S24); Demasiado general/vago (S28)), y la calidad de las sugerencias (No relevantes (S11); Irrelevantes (S6)). Los sujetos que prefirieron este sistema comentaron sobre la utilidad de los dominios sugeridos (las sugerencias tienen mucho sentido al proporcionar asistencia de búsqueda y parecían ayudar muy bien). Sin embargo, más sujetos comentaron sobre la falta de relevancia de las sugerencias (por ejemplo, no parecían confiables, no fueron de mucha ayuda (S30); Irrelevantes, no son de mi estilo (S21), y la necesidad relacionada de incluir explicaciones sobre por qué se ofrecieron las sugerencias (por ejemplo, resultados de baja calidad, no se presentó suficiente información (S35)). Estos comentarios muestran una amplia gama de perspectivas sobre diferentes aspectos de los sistemas experimentales. Es obvio que se necesita trabajar en mejorar la calidad de las sugerencias en todos los sistemas, pero los sujetos parecían distinguir los ajustes en los que cada uno de estos sistemas puede ser útil. Aunque todos los sistemas a veces pueden ofrecer sugerencias irrelevantes, los sujetos parecían preferir tenerlas en lugar de no tenerlas (por ejemplo, un sujeto comentó que las sugerencias eran útiles en algunos casos y inofensivas en todos (S15)). 4.1.4 Resumen Los hallazgos obtenidos de nuestro estudio sobre las percepciones de los sujetos de los cuatro sistemas indican que los sujetos tienden a preferir QueryDestination para las tareas exploratorias y QuerySuggestion para las búsquedas de elementos conocidos. Las sugerencias para refinar incrementalmente la consulta actual pueden ser preferidas por los buscadores en tareas de elementos conocidos cuando podrían haber pasado por alto su objetivo de información. Sin embargo, cuando la tarea es más exigente, los buscadores aprecian sugerencias que tienen el potencial de influir drásticamente en la dirección de una búsqueda o mejorar significativamente la cobertura del tema. 4.2 Tareas de Búsqueda Para obtener una mejor comprensión de cómo los sujetos se desempeñaron durante el estudio, analizamos los datos capturados sobre sus percepciones de la completitud de la tarea y el tiempo que les llevó completar cada tarea. 4.2.1 Percepciones de los Sujetos En el cuestionario posterior a la búsqueda, se les pidió a los sujetos que indicaran en una escala Likert de 5 puntos el grado en que estaban de acuerdo con la siguiente afirmación de actitud: Creo que he tenido éxito en mi desempeño en esta tarea (Éxito). Además, se les pidió que completaran tres diferenciales semánticos de 5 puntos indicando su respuesta a la declaración de actitud: La tarea que les pedimos que realizaran fue: Los estímulos emparejados ofrecidos como posibles respuestas fueron claros/poco claros, simples/ complejos y familiares/ no familiares. La Tabla 4 presenta la respuesta promedio a estas afirmaciones para cada sistema y tipo de tarea. Aunque los sistemas de destino proporcionaron soporte para la búsqueda dentro de un dominio, los sujetos principalmente optaron por ignorarlo. Tabla 4. Percepciones de la tarea y el éxito de la tarea (menor = mejor). Las respuestas de los sujetos demuestran que los usuarios sintieron que sus búsquedas habían sido más exitosas utilizando QueryDestination para tareas exploratorias que con los otros tres sistemas (es decir, hubo una interacción de dos vías entre estas dos variables). Además, los sujetos percibieron un sentido de finalización significativamente mayor con tareas de elementos conocidos que con tareas exploratorias. Los sujetos también encontraron que las tareas de elementos conocidos eran más simples, claras y familiares. Estas respuestas confirman las diferencias en la naturaleza de las tareas que habíamos previsto al planificar el estudio. Como se ilustra en los ejemplos de la Figura 3, las tareas de elementos conocidos requerían que los sujetos recuperaran un conjunto finito de respuestas (por ejemplo, encontrar tres cosas interesantes para hacer durante una visita de fin de semana a Kioto, Japón). En contraste, las tareas exploratorias eran multifacéticas y requerían que los sujetos averiguaran más sobre un tema o encontraran suficiente información para tomar una decisión. El punto final en tales tareas estaba menos definido y pudo haber afectado la percepción de los sujetos sobre cuándo habían completado la tarea. Dado que no hubo diferencia en las tareas intentadas en cada sistema, teóricamente la percepción de la simplicidad, claridad y familiaridad de las tareas debería haber sido la misma para todos los sistemas. Sin embargo, observamos un claro efecto de interacción entre el sistema y la percepción de los sujetos sobre las tareas reales. 4.2.2 Tiempo de finalización de la tarea Además de pedir a los sujetos que indiquen en qué medida sintieron que la tarea estaba completada, también monitoreamos el tiempo que les llevó indicar al experimentador que habían terminado. El tiempo transcurrido desde que el sujeto comenzó a formular su primera consulta hasta que indicó que había terminado fue monitoreado utilizando un cronómetro y registrado para un análisis posterior. Se utilizó un cronómetro en lugar de un registro del sistema para esto, ya que queríamos registrar el tiempo independientemente de las interacciones del sistema. La Figura 4 muestra el tiempo promedio de finalización de tareas para cada sistema y cada tipo de tarea. Figura 4. Tiempo medio de finalización de la tarea (± SEM). 15 F(3,136) = 6.34, p = .001 16 F(1,136) = 18.95, p < .001 17 F(1,136) = 6.82, p = .028; Las tareas de elementos conocidos también fueron más simples en QS (F(3,136) = 3.93, p = .01; Prueba post hoc de Tukey: p = .01); α = .167 Exploratorio de elementos conocidos 0 100 200 300 400 500 600 Categorías de tareas Baseline QSuggest Tiempo (segundos) Sistemas 348.8 513.7 272.3 467.8 232.3 474.2 359.8 472.2 QDestination SDestination Como se puede ver en la figura anterior, los tiempos de finalización de las tareas de elementos conocidos difieren considerablemente entre los sistemas.18 Los sujetos que intentan estas tareas en QueryDestination y QuerySuggestion las completan en menos tiempo que los sujetos en Baseline y SessionDestination.19 Como se discutió en la sección anterior, los sujetos estaban más familiarizados con las tareas de elementos conocidos y sintieron que eran más simples y claras. La línea base pudo haber tardado más que los otros sistemas, ya que los usuarios no contaban con apoyo adicional y tuvieron que formular sus propias consultas. Los sujetos generalmente sintieron que las recomendaciones ofrecidas por SessionDestination tenían poca relevancia y utilidad. Por consiguiente, el tiempo de finalización aumentó ligeramente entre estos dos sistemas, quizás porque los sujetos evaluaron el valor de las sugerencias propuestas, pero obtuvieron poco beneficio de ellas. Los tiempos de finalización de las tareas exploratorias fueron aproximadamente iguales en los cuatro sistemas, aunque el tiempo en Baseline fue ligeramente mayor. Dado que estas tareas no tenían criterios de terminación claramente definidos (es decir, el sujeto decidía cuándo habían recopilado suficiente información), los sujetos generalmente pasaban más tiempo buscando y consultaban una gama más amplia de fuentes de información que en las tareas de elementos conocidos. El análisis resumido de la percepción de los sujetos sobre las tareas de búsqueda y los aspectos de la finalización de la tarea muestra que el sistema de sugerencia de consultas hizo que los sujetos se sintieran más exitosos (y que la tarea fuera más simple, clara y familiar) para las tareas de elementos conocidos. Por otro lado, se demostró que QueryDestination llevaba a percepciones más elevadas de éxito en la búsqueda y facilidad, claridad y familiaridad de la tarea para las tareas exploratorias. Los tiempos de finalización de tareas en ambos sistemas fueron significativamente más bajos que en los otros sistemas para tareas de elementos conocidos. 4.3 Interacción de sujetos Ahora nos enfocamos en nuestro análisis en las interacciones observadas entre los buscadores y los sistemas. Además de obtener comentarios sobre cada sistema de nuestros sujetos, también registramos varios aspectos de su interacción con cada sistema en archivos de registro. En esta sección, analizamos tres aspectos de interacción: iteraciones de consultas, clics en resultados de búsqueda y compromiso del sujeto con las características adicionales de la interfaz ofrecidas por los tres sistemas no basales. 4.3.1 Consultas y Clics en Resultados Los buscadores suelen interactuar con los sistemas de búsqueda al enviar consultas y hacer clic en los resultados de búsqueda. Aunque nuestro sistema ofrece funcionalidades adicionales de interfaz, comenzamos esta sección analizando el comportamiento de consulta y clics de nuestros sujetos para comprender mejor cómo llevaron a cabo las actividades de búsqueda principales. La Tabla 5 muestra el número promedio de iteraciones de consulta y resultados de búsqueda clicados para cada par sistema-tarea. El valor promedio en cada celda se calcula para 18 sujetos en cada tipo de tarea y sistema. Tabla 5. Iteraciones promedio de consulta y clics en resultados (por tarea). Los sujetos presentaron menos consultas y clics en los resultados de búsqueda en QueryDestination que en cualquiera de los otros sistemas. Como se discutió en la sección anterior, los sujetos que utilizaron este sistema se sintieron más exitosos en sus búsquedas, sin embargo, mostraron menos interacciones tradicionales de consulta y clic en los resultados necesarios para el éxito de la búsqueda en sistemas de búsqueda tradicionales. Puede ser el caso de que las consultas de los sujetos en este sistema fueran más efectivas, pero es más probable que interactuaran menos con el sistema a través de estos medios y optaran por utilizar los destinos populares en su lugar. En general, los sujetos presentaron la mayoría de las consultas en QuerySuggestion, lo cual no es sorprendente ya que este sistema anima activamente a los buscadores a volver a enviar consultas refinadas de forma iterativa. Los sujetos interactuaron de manera similar con los sistemas Baseline y SessionDestination, quizás debido a la baja calidad de los destinos populares en este último. Para investigar esto y problemas relacionados, a continuación analizaremos el uso de las sugerencias en los tres sistemas no basales. 4.3.2 Uso de las Sugerencias Para determinar si los sujetos encontraron útiles las características adicionales, medimos en qué medida se utilizaron cuando se proporcionaron. El uso de sugerencias se define como la proporción de consultas enviadas para las cuales se ofrecieron sugerencias y al menos una sugerencia fue seleccionada. La tabla 6 muestra el uso promedio para cada sistema y categoría de tarea. Tabla 6. Aceptación de sugerencias (los valores son porcentajes). Los resultados indican que la Sugerencia de Consulta se utilizó más para tareas de elementos conocidos que el Destino de Sesión, y el Destino de Consulta se utilizó más que todos los demás sistemas para las tareas exploratorias. Para objetivos bien especificados en la búsqueda de elementos conocidos, los sujetos parecían utilizar más intensamente la refinación de consultas. Por el contrario, cuando los sujetos estaban explorando, parecía que se beneficiaban más de la recomendación de fuentes adicionales de información. Los sujetos seleccionaron casi el doble de destinos por consulta al usar QueryDestination en comparación con SessionDestination. Como se discutió anteriormente, esto puede explicarse por la menor relevancia y utilidad percibida de los destinos recomendados por SessionDestination. Un análisis resumido de los datos de interacción de registro recopilados durante el estudio indica que, aunque los sujetos enviaron menos consultas y hicieron clic en menos resultados de búsqueda en QueryDestination, su compromiso con las sugerencias fue mayor en este sistema, especialmente para tareas de búsqueda exploratoria. Las consultas refinadas propuestas por QuerySuggestion fueron las más utilizadas para las tareas de elementos conocidos. Parece haber una clara división entre los sistemas: QuerySuggestion fue preferido para tareas de elementos conocidos, mientras que QueryDestination proporcionó soporte más utilizado para tareas exploratorias. 5. DISCUSIÓN E IMPLICACIONES Los hallazgos prometedores de nuestro estudio sugieren que los sistemas que ofrecen destinos populares conducen a búsquedas más exitosas y eficientes en comparación con la sugerencia de consultas y la búsqueda web no asistida. Los sujetos parecían preferir QuerySuggestion para las tareas de ítems conocidos en las que el objetivo de búsqueda de información estaba bien definido. Si la consulta inicial no recupera información relevante, entonces los sujetos 22 F(2,355) = 4.67, p = .01; pruebas post-hoc de Tukey: p = .006 23 pruebas post-hoc de Tukey: todos los p ≤ .027 24 QD: MK = 1.8, ME = 2.1; SD: MK = 1.1, ME = 1.2; F(1,231) = 5.49, p = .02; pruebas post-hoc de Tukey: todos los p ≤ .003; (M representa la media). Agradezco el apoyo para decidir qué refinamientos hacer en la consulta. A partir del examen de las consultas que los sujetos introdujeron para las búsquedas de elementos conocidos en todos los sistemas, parecía que utilizaban la consulta inicial como punto de partida, y añadían o eliminaban términos individuales dependiendo de los resultados de la búsqueda. El cuestionario posterior a la búsqueda pidió a los sujetos que seleccionaran de una lista de explicaciones propuestas (o que ofrecieran sus propias explicaciones) sobre por qué utilizaron las refinaciones de consulta recomendadas. Tanto para las tareas de elementos conocidos como para las tareas exploratorias, alrededor del 40% de los sujetos indicaron que seleccionaron una sugerencia de consulta porque querían ahorrar tiempo escribiendo una consulta, mientras que menos del 10% de los sujetos lo hicieron porque las sugerencias representaban nuevas ideas. Por lo tanto, los sujetos parecían ver QuerySuggestion como una conveniencia que ahorra tiempo, en lugar de como una forma de impactar drásticamente en la efectividad de la búsqueda. Las dos variantes de recomendación de destinos que consideramos, QueryDestination y SessionDestination, ofrecieron sugerencias que diferían en su proximidad temporal a la consulta actual. La calidad de los destinos parecía afectar las percepciones de los sujetos sobre ellos y su desempeño en la tarea. Como se discutió anteriormente, los dominios que se encuentran al final de una sesión de búsqueda completa (como en SessionDestination) son más propensos a no estar relacionados con la consulta actual, y por lo tanto es menos probable que constituyan sugerencias valiosas. Los sistemas de destino, en particular QueryDestination, tuvieron el mejor rendimiento para las tareas de búsqueda exploratoria, donde los sujetos podrían haberse beneficiado de la exposición a fuentes de información adicionales cuya relevancia temática para la consulta de búsqueda es indirecta. Al igual que con QuerySuggestion, se pidió a los sujetos que ofrecieran explicaciones sobre por qué seleccionaron los destinos. Sobre ambos tipos de tareas, sugirieron que los destinos fueron seleccionados porque captaron su atención (40%), representaban nuevas ideas (25%), o los usuarios no pudieron encontrar lo que estaban buscando (20%). Las respuestas menos populares fueron querer ahorrar tiempo escribiendo la dirección (7%) y que el destino fuera popular (3%). La respuesta positiva a las sugerencias de destinos por parte de los sujetos del estudio proporciona direcciones interesantes para mejoras en el diseño. Nos sorprendió saber que los sujetos no encontraron útiles las barras de popularidad, o apenas utilizaron la funcionalidad de búsqueda dentro del sitio, lo que invita a rediseñar estos componentes. Los sujetos también señalaron que les gustaría ver resúmenes basados en consultas para cada destino sugerido para apoyar una selección más informada, así como la categorización de destinos con la capacidad de profundizar en cada categoría. Dado que QuerySuggestion y QueryDestination funcionan bien en escenarios de tareas distintas, integrar ambos en un solo sistema es una dirección futura interesante. Esperamos implementar algunas de estas ideas a escala web en futuros sistemas, lo que permitirá la evaluación basada en registros a través de grandes grupos de usuarios. 6. CONCLUSIONES Presentamos un enfoque novedoso para mejorar la interacción de los usuarios en la búsqueda web al proporcionar enlaces a sitios web visitados con frecuencia por buscadores anteriores con necesidades de información similares. Se realizó un estudio de usuarios en el que evaluamos la efectividad de la técnica propuesta en comparación con un sistema de refinamiento de consultas y una búsqueda en la web sin ayuda. Los resultados de nuestro estudio revelaron que: (i) los sistemas que sugieren refinamientos de consultas fueron preferidos para tareas de búsqueda de elementos conocidos, (ii) los sistemas que ofrecen destinos populares fueron preferidos para tareas de búsqueda exploratoria, y (iii) los destinos deben ser extraídos del final de las rutas de consulta, no de las rutas de sesión. En general, las sugerencias de destinos populares influenciaron estratégicamente las búsquedas de una manera que no se puede lograr con enfoques de sugerencias de consultas, al ofrecer una nueva forma de resolver problemas de información y mejorar la experiencia de búsqueda de información para muchos buscadores web. REFERENCIAS [1] Agichtein, E., Brill, E. & Dumais, S. (2006). Mejorando la clasificación de búsqueda en la web al incorporar información sobre el comportamiento del usuario. En Proc. SIGIR, 19-26. [2] Anderson, C. et al. (2001).
SIGIR, 19-26. [2] Anderson, C. y col. (2001). Navegación web adaptativa para dispositivos inalámbricos. En Proc. IJCAI, 879-884. [3] Anick, P. (2003). Utilizando retroalimentación terminológica para el refinamiento de la búsqueda en la web: Un estudio basado en registros. En Proc. SIGIR, 88-95. [4] Beaulieu, M. (1997). Experimentos con interfaces para apoyar la expansión de consultas. J. Doc. 53, 1, 8-19. [5] Borlund, P. (2000). 

J. Doc. 53, 1, 8-19. [5] Borlund, P. (2000). Componentes experimentales para la evaluación de sistemas interactivos de recuperación de información. J. Doc. 56, 1, 71-90. [6] Downey et al. (2007). 

J. Doc. 56, 1, 71-90. [6] Downey et al. (2007). Modelos de búsqueda y navegación: idiomas, estudios y aplicaciones. En Proc. IJCAI, 1465-72. [7] Dumais, S.T. & Belkin, N.J. (2005). 

IJCAI, 1465-72. [7] Dumais, S.T. & Belkin, N.J. (2005). Las pistas interactivas de TREC: poniendo al usuario en la búsqueda. En Voorhees, E.M. y Harman, D.K. (eds.) TREC: Experimento y Evaluación en Recuperación de Información. Cambridge, MA: MIT Press, 123-153. [8] Furnas, G. W. (1985). 

Cambridge, MA: MIT Press, 123-153. [8] Furnas, G. W. (1985). Experiencia con un esquema de indexación adaptativa. En Proc. CHI, 131-135. [9] Hickl, A. et al. (2006). 

CHI, 131-135. [9] Hickl, A. y col. (2006). FERRET: Interacción de preguntas y respuestas para entornos del mundo real. En Proc. de COLING/ACL, 25-28. [10] Jones, R., et al. (2006). Generando sustituciones de consulta. En Proc. WWW, 387-396. [11] Koenemann, J. & Belkin, N. (1996). 

WWW, 387-396. [11] Koenemann, J. & Belkin, N. (1996). Un caso para la interacción: un estudio del comportamiento y la efectividad de la recuperación de información interactiva. En Proc. CHI, 205-212. [12] ODay, V. & Jeffries, R. (1993). 

CHI, 205-212. [12] ODay, V. & Jeffries, R. (1993). Orientación en un paisaje de información: cómo los buscadores de información van de aquí para allá. En Proc. CHI, 438-445. [13] Radlinski, F. & Joachims, T. (2005). 

CHI, 438-445. [13] Radlinski, F. & Joachims, T. (2005). Cadenas de consulta: Aprendizaje para clasificar a partir de retroalimentación implícita. En Proc. KDD, 239-248. [14] Salton, G. & Buckley, C. (1988) Enfoques de ponderación de términos en la recuperación automática de textos. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a complete sentence for me to translate to Spanish? Procesado. Manage. 24, 513-523. [15] Silverstein, C. et al. (1999).

Gestión. 24, 513-523. [15] Silverstein, C. et al. (1999). Análisis de un registro de consultas de un motor de búsqueda web muy grande. SIGIR Forum 33, 1, 6-12. [16] Smyth, B. et al. (2004). 

Foro SIGIR 33, 1, 6-12. [16] Smyth, B. y col. (2004). Explotando la repetición de consultas y la regularidad en un motor de búsqueda web adaptativo basado en la comunidad. Usuario Mod. Adaptarse al usuario. Int. 14, 5, 382-423. [17] Spink, A. et al. (2002).
Int. 14, 5, 382-423. [17] Spink, A. y col. (2002). Tendencias de búsqueda en la web en Estados Unidos versus Europa. SIGIR Forum 36, 2, 32-38. [18] Spink, A., et al. (2006).

Foro SIGIR 36, 2, 32-38. [18] Spink, A., et al. (2006). Realización de múltiples tareas durante sesiones de búsqueda en la web. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Procesado. Manage., 42, 1, 264-275. [19] Wexelblat, A. & Maes, P. (1999).

Gestión., 42, 1, 264-275. [19] Wexelblat, A. & Maes, P. (1999). Huellas: herramientas ricas en historia para la búsqueda de información. En Proc. CHI, 270-277. [20] White, R.W. & Drucker, S.M. (2007). 

CHI, 270-277. [20] White, R.W. & Drucker, S.M. (2007). Investigando la variabilidad del comportamiento en la búsqueda web. En Proc. WWW, 21-30. [21] White, R.W. & Marchionini, G. (2007).
WWW, 21-30. [21] White, R.W. & Marchionini, G. (2007). Examinando la efectividad de la expansión de consultas en tiempo real. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate into Spanish? Procesado. Gestión. 43, 685-704.