Vocabulary Detección de término hablado independiente Jonathan Mamou Ibm Haifa Investigation Labs Haifa 31905, Israel mamuu@il.ibm.com Bhuvana Ramabhadran, Olivier Siohan Ibm T. J. Watson Research Center Yorktown Heights, N.Y. 10598, USA {Bhuvana, Siohan@Us.ibm.Resumen Estamos interesados en recuperar información de datos del habla como noticias de transmisión, conversaciones telefónicas y reuniones de mesa redonda. Hoy en día, la mayoría de los sistemas utilizan grandes herramientas de reconocimiento de voz continuo de vocabulario para producir transcripciones de palabras;Las transcripciones se indexan y los términos de consulta se recuperan del índice. Sin embargo, los términos de consulta que no son parte del vocabulario de los reconocedores no se pueden recuperar, y el retiro de la búsqueda se ve afectado. Además de la transcripción de palabras de salida, los sistemas avanzados proporcionan también transcripciones fonéticas, contra las cuales los términos de consulta pueden coincidir fonéticamente. Dichas transcripciones fonéticas sufren de menor precisión y no pueden ser una alternativa a las transcripciones de palabras. Presentamos un sistema independiente de vocabulario que puede manejar consultas arbitrarias, explotando la información proporcionada al tener transcripciones de palabras y transcripciones fonéticas. Un reconocimiento de voz genera redes de confusión de palabras y redes fonéticas. Las transcripciones están indexadas para el procesamiento de consultas y el propósito de clasificación. El valor del método propuesto se demuestra por el alto rendimiento relativo de nuestro sistema, que recibió la clasificación general más alta para los datos del habla en inglés de EE. UU. En la reciente evaluación de detección de términos hablados NIST [1]. Categorías y descriptores de asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información Términos generales Algoritmos 1. INTRODUCCIÓN La cantidad rápida y creciente de datos hablados requiere soluciones para indexar y buscar estos datos. El enfoque clásico consiste en convertir las transcripciones de discurso a palabras utilizando una gran herramienta de reconocimiento de voz continuo de vocabulario (LVCSR). En la última década, la mayoría de los esfuerzos de investigación en la recuperación de datos hablados se han centrado en extender las técnicas clásicas de IR a las transcripciones de palabras. Algunos de estos trabajos se han realizado en el marco de las pistas de recuperación de documentos hablados de NIST TREC y son descritos por Garofolo et al.[12]. Estas pistas se centraron en la recuperación de un corpus de noticias de transmisión habladas por profesionales. Una de las conclusiones de esas pistas fue que la efectividad de la recuperación depende principalmente de la precisión de las transcripciones. Si bien la precisión de los sistemas de reconocimiento de voz automático (ASR) depende del escenario y el entorno, los sistemas de vanguardia alcanzaron una precisión de más del 90% en la transcripción de dichos datos. En 2000, Garofolo et al.concluyó que la recuperación de documentos hablados es un problema resuelto [12]. Sin embargo, un inconveniente significativo de tales enfoques es que la búsqueda en consultas que contienen términos fuera del vocabulario (OOV) no devolverán ningún resultado. Los términos de OOV faltan palabras del vocabulario del sistema ASR y se reemplazan en la transcripción de salida por alternativas que son probables, dado el modelo acústico de reconocimiento y el modelo de lenguaje. Se ha observado experimentalmente que más del 10% de las consultas de los usuarios pueden contener términos de OOV [16], ya que las consultas a menudo se relacionan con entidades nombradas que generalmente tienen una cobertura deficiente en el vocabulario ASR. Los efectos de los términos de consulta de OOV en la recuperación de datos hablados son discutidos por Woodland et al.[28]. En muchas aplicaciones, la tasa de OOV puede empeorar con el tiempo a menos que el vocabulario de los reconocedores se actualice periódicamente. Otro enfoque consiste en convertir el discurso en transcripciones fonéticas y representar la consulta como una secuencia de teléfonos. La recuperación se basa en la búsqueda de la secuencia de teléfonos que representan la consulta en las transcripciones fonéticas. El principal inconveniente de este enfoque es la alta tasa de error inherente de las transcripciones. Por lo tanto, dicho enfoque no puede ser una alternativa a las transcripciones de palabras, especialmente para los términos de consulta in-vocabulario (iv) que forman parte del vocabulario del sistema ASR. Una solución sería combinar los dos enfoques diferentes presentados anteriormente: indexamos ambas transcripciones de palabras y transcripciones fonéticas;Durante el procesamiento de la consulta, la información se recupera del índice de palabras para términos IV y del índice fonético para términos OOV. Nos gustaría poder procesar también consultas híbridas, es decir, consultas que incluyen términos IV y OOV. En consecuencia, necesitamos fusionar piezas de información recuperadas del índice de palabras y el índice fonético. La información de proximidad sobre los ocurrencias de los términos de consulta se requiere para la búsqueda de frases y para la clasificación basada en la proximidad. En el IR clásico, las tiendas índice para cada ocurrencia de un término, su compensación. Por lo tanto, no podemos fusionar listas de publicación recuperadas por índice fonético con las recuperadas por el índice de palabras ya que el desplazamiento de los ocurrencias recuperados de los dos índices diferentes no es comparable. El único elemento de comparación entre transcripciones fonéticas y de palabras son las marcas de tiempo. No se ha realizado ningún trabajo previo que combine palabras y enfoque fonético en la búsqueda de frases. Presentamos un esquema novedoso para la recuperación de información que consiste en el almacenamiento, durante el proceso de indexación, para cada unidad de indexación (teléfono o palabra) su marca de tiempo. Buscamos consultas fusionando la información recuperada de los dos índices diferentes, índice de palabras e índice fonético, de acuerdo con las marcas de tiempo de los términos de la consulta. Analizamos la efectividad de la recuperación de este enfoque en los datos de evaluación de detección de términos hablados de NIST [1]. El papel está organizado de la siguiente manera. Describimos el procesamiento de audio en la Sección 2. Los métodos de indexación y recuperación se presentan en la Sección 3. La configuración experimental y los resultados se dan en la Sección 4. En la Sección 5, damos una visión general del trabajo relacionado. Finalmente, concluimos en la Sección 6. 2. Sistema automático de reconocimiento de voz Utilizamos un sistema ASR para transcribir datos del habla. Funciona en modo independiente del altavoz. Para los mejores resultados de reconocimiento, un modelo acústico independiente del hablante y un modelo de lenguaje están entrenados de antemano en datos con características similares. Por lo general, ASR genera redes que pueden considerarse como gráficos acíclicos dirigidos. Cada vértice en una red se asocia con una marca de tiempo y cada borde (u, v) está etiquetado con una hipótesis de palabra o teléfono y su probabilidad previa, que es la probabilidad de la señal delimitada por las marcas de tiempo de los vértices u y v, dado.la hipótesis. La mejor transcripción de ruta se obtiene de la red utilizando técnicas de programación dinámica. Mangu et al.[18] y Hakkani-Tur et al.[13] propone una representación compacta de una red de palabras llamada red de confusión de palabras (WCN). Cada borde (U, V) está etiquetado con una hipótesis de la palabra y su probabilidad posterior, es decir, la probabilidad de la palabra dada la señal. Una de las principales ventajas de WCN es que también proporciona una alineación para todas las palabras en la red. Como se explica en [13], los tres pasos principales para construir un WCN a partir de una red de palabras son los siguientes: 1. Calcule las probabilidades posteriores para todos los bordes en la palabra red.2. Extraiga una ruta de la palabra red (que puede ser el 1 mejor, el más largo o cualquier ruta aleatoria), y llamarlo la ruta pivote de la alineación.3. Visite la palabra red, y alinee todas las transiciones con el pivote, fusionando las transiciones que corresponden a la misma palabra (o etiqueta) y ocurren en el mismo intervalo de tiempo sumando sus probabilidades posteriores. La mejor ruta de un WCN se obtiene de la ruta que contiene las mejores hipótesis. Como se indica en [18], aunque los WCN son más compactos que las redes de palabras, en general, la mejor ruta obtenida de WCN tiene una mejor precisión de la palabra que la ruta de 1 mejor obtenida de la red de palabras correspondiente. Las estructuras típicas de una red y un WCN se dan en la Figura 1. Figura 1: Estructuras típicas de una red y un WCN.3. Modelo de recuperación El principal problema con la recuperación de la información de los datos hablados es la baja precisión de la transcripción, particularmente en términos de interés, como entidades nombradas y palabras de contenido. En general, la precisión de una transcripción de Word se caracteriza por su tasa de error de palabras (WER). Hay tres tipos de errores que pueden ocurrir en una transcripción: sustitución de un término que es parte del discurso por otro término, la eliminación de un término hablado que es parte del discurso y la inserción de un término que no es parte del discurso. Las sustituciones y deleciones reflejan el hecho de que no se reconoce una ocurrencia de un término en la señal del habla. Estas fallas reducen el retiro de la búsqueda. Las sustituciones e inserciones reflejan el hecho de que un término que no es parte de la señal del habla aparece en la transcripción. Estas fallas reducen la precisión de la búsqueda. El retiro de búsqueda se puede mejorar expandiendo la transcripción con palabras adicionales. Estas palabras se pueden tomar de las otras alternativas proporcionadas por el WCN;Es posible que estas alternativas se hayan hablado, pero no fueron la mejor opción del ASR. Tal expansión tiende a corregir las sustituciones y las deleciones y, en consecuencia, podría mejorar el recuerdo, pero probablemente reducirá la precisión. Usando un modelo de clasificación apropiado, podemos evitar la disminución de la precisión. Mamou et al.han presentado en [17] la mejora en el retiro y el mapa buscando en WCN en lugar de considerar solo la 1 mejor transcripción de palabras de ruta en el contexto de la recuperación de documentos hablados. Hemos adaptado este modelo de búsqueda IV a la detección de términos. En las transcripciones de palabras, los términos de OOV se eliminan o se sustituyen. Por lo tanto, el uso de transcripciones fonéticas es más deseable. Sin embargo, debido a su baja precisión, hemos preferido usar solo la mejor ruta extraída de las redes fonéticas. Mostraremos que el uso de transcripciones fonéticas tiende a mejorar el retiro sin afectar demasiado la precisión, utilizando una clasificación apropiada.3.1 Tarea de detección de documentos hablados Como se indica en el Plan de Evaluación STD 2006 [2], la tarea consiste en encontrar todas las coincidencias exactas de una consulta específica en un corpus determinado de datos del habla. Una consulta es una frase que contiene varias palabras. Las consultas son texto y no del habla. Tenga en cuenta que esta tarea es diferente de la tarea más clásica de la recuperación de documentos hablados. Las transcripciones manuales del discurso no son proporcionadas, pero los evaluadores utilizan para encontrar verdaderos acontecimientos. Por definición, las verdaderas ocurrencias de una consulta se encuentran automáticamente buscando las transcripciones manuales utilizando la siguiente regla: la brecha entre las palabras adyacentes en una consulta debe ser inferior a 0.5 segundos en el discurso correspondiente. Para evaluar los resultados, cada ocurrencia de salida del sistema se considera correcta o no de acuerdo con si está cerca en el tiempo a una verdadera ocurrencia de la consulta recuperada de las transcripciones manuales;Se juzga como correcto si el punto medio de la ocurrencia de salida del sistema es menor o igual a 0.5 segundos desde el período de tiempo de una verdadera ocurrencia de la consulta.3.2 Indexación Hemos utilizado el mismo proceso de indexación para WCN y transcripciones fonéticas. Cada aparición de una unidad de indexación (palabra o teléfono) U en una transcripción d se indexa con la siguiente información: • El tiempo de inicio t de la ocurrencia de u, • la duración d de la ocurrencia de u. Además, para la indexación de WCN, almacenamos • El nivel de confianza de la aparición de U en el momento t que se evalúa por su probabilidad posterior PR (U | T, D), • El rango de la ocurrencia de U entre las otras hipótesiscomenzando al mismo tiempo t, rango (u | t, d). Tenga en cuenta que, dado que la tarea es encontrar coincidencias exactas de las consultas de frases, no hemos filtrado palabras de parada y el corpus no tiene vistas antes de indexar.3.3 Búsqueda a continuación, presentamos nuestro enfoque para lograr la tarea STD utilizando los índices descritos anteriormente. Los términos se extraen de la consulta. Se da el vocabulario de las transcripciones de palabras de construcción del sistema ASR. Los términos que forman parte de este vocabulario son términos IV;Los otros términos son OOV. Para un término de consulta IV, la lista de publicación se extrae del índice de palabras. Para un término de consulta OOV, el término se convierte en una secuencia de teléfonos utilizando un modelo de n-gram de entropía máxima articular [10]. Por ejemplo, el término prosodia se convierte en la secuencia de teléfonos (P, R, Aa, Z, Ih, D, Iy). La lista de publicación de cada teléfono se extrae del índice fonético. El siguiente paso consiste en fusionar las diferentes listas de publicación de acuerdo con la marca de tiempo de los ocurrencias para crear resultados que coincidan con la consulta. Primero, verificamos que las palabras y los teléfonos aparecen en el orden correcto de acuerdo con sus tiempos de comienzo. En segundo lugar, verificamos que la brecha en el tiempo entre palabras y teléfonos adyacentes sea razonable. Continuación de los requisitos de la evaluación de STD, la distancia en el tiempo entre dos términos de consulta adyacentes debe ser inferior a 0.5 segundos. Para la búsqueda de OOV, verificamos que la distancia en el tiempo entre dos teléfonos adyacentes de un término de consulta es menor que 0.2 segundos;Este valor se ha determinado empíricamente. De tal manera, podemos reducir el efecto de los errores de inserción, ya que permitimos inserciones entre las palabras y los teléfonos adyacentes. Nuestro procesamiento de consultas no permite sustituciones y deleciones. Ejemplo: consideremos la investigación de la prosodia de la consulta de frases. El término prosodia es OOV y el término investigación es IV. El término prosodia se convierte en la secuencia de teléfonos (P, R, A, Z, In, Diy). La lista de publicación de cada teléfono se extrae del índice fonético. Fusionamos las listas de publicación de los teléfonos de tal manera que la secuencia de teléfonos aparece en el orden correcto y la brecha en el tiempo entre los pares de teléfonos (P, R), (R, AA), (AA, Z), (Z, (Z,ih), (ih, d), (d, iy) es inferior a 0.2 segundos. Obtenemos ocurrencias del término prosodia. La lista de publicación de la investigación se extrae del índice de palabras y la fusionamos con los ocurrencias que se encuentran para la prosodia de tal manera que aparecen en el orden correcto y la distancia en el tiempo entre la prosodia y la investigación es inferior a 0.5 segundos. Tenga en cuenta que nuestro modelo de indexación permite buscar diferentes tipos de consultas: 1. Consultas que contienen solo términos IV utilizando el índice de palabras.2. Consultas que contienen solo términos OOV utilizando el índice fonético.3. Consultas de palabras clave que contienen términos IV y OOV utilizando el índice de palabras para términos IV y el índice fonético para términos OOV;Para el procesamiento de consultas, los diferentes conjuntos de coincidencias se unifican si los términos de consulta tienen o semántica e se cruzan si los términos de consulta tienen y semántica.4. Consultas de frases que contienen términos IV y OOV;Para el procesamiento de consultas, las listas de publicación de los términos IV recuperados del índice de palabras se fusionan con las listas de publicación de los términos OOV recuperados del índice fonético. La fusión es posible ya que hemos almacenado las marcas de tiempo para cada unidad de indexación (palabra y teléfono) en ambos índices. La evaluación de STD se ha centrado en el cuarto tipo de consulta. Es la tarea más difícil ya que necesitamos combinar listas de publicación recuperadas de los índices fonéticos y de palabras.3.4 Ranking Dado que los términos IV y los términos OOV se recuperan de dos índices diferentes, proponemos dos funciones diferentes para obtener una ocurrencia de un término;Posteriormente, se asigna un puntaje agregado a la consulta en función de los puntajes de los términos de consulta. Debido a que la tarea es la detección de términos, no utilizamos un criterio de frecuencia de documento para clasificar los ocurrencias. Consideremos una consulta q = (k0, ..., kn), asociada con un vector de impulso b = (b1, ..., bj). Este vector asocia un factor de impulso a cada rango de las diferentes hipótesis;Los factores de aumento se normalizan entre 0 y 1. Si el rango R es más grande que J, suponemos BR = 0. 3.4.1 En la clasificación de término de vocabulario para la clasificación de términos IV, extendemos el trabajo de Mamou et al.[17] Sobre la recuperación de documentos hablados a la detección de términos. Utilizamos la información proporcionada por el índice Word. Definimos la puntuación de puntaje (k, t, d) de una palabra clave k que ocurre a una vez t en la transcripción d, por la siguiente fórmula: puntaje (k, t, d) = brank (k | t, d) × pr pr)(k | t, d) Tenga en cuenta que 0 ≤ puntaje (k, t, d) ≤ 1. 3.4.2 Fuera de la clasificación de términos de vocabulario para la clasificación de términos OOV, utilizamos la información proporcionada por el índice fonético. Le damos un rango más alto a ocurrencias de términos OOV que contienen teléfonos cerca (con el tiempo) entre sí. Definimos una función de puntuación relacionada con la brecha promedio en el tiempo entre los diferentes teléfonos. Consideremos una palabra clave K convertida a la secuencia de teléfonos (PK 0, ..., PK L). Definimos el puntaje de puntaje normalizado (k, tk 0, d) de una palabra clave k = (pk 0, ..., pk l), donde cada PK I ocurre en el tiempo TK I con una duración de DK I en la transcripción D, mediante la siguiente fórmula: puntaje (k, tk 0, d) = 1-l i = 1 5 × (tk i-(tk i-1 + dk i-1)). Tenga en cuenta que de acuerdo con lo que hemos sido exigidoEn la Sección 3.3, tenemos ∀1 ≤ I ≤ L, 0 <tk I - (tk i - 1 + dk i - 1) <0.2 segundos, 0 <5 × (tk i - (tk i - 1 + dk i−1)) <1, y en consecuencia, 0 <puntaje (k, tk 0, d) ≤ 1. La duración de la aparición de palabras clave es tk l - tk 0 + dk l. Ejemplo: consideremos la secuencia (P, R, Aa, Z, Ih, D, Iy) y dos ocurrencias diferentes de la secuencia. Para cada teléfono, damos el tiempo de inicio y la duración en segundo lugar. Ocurrencia 1: (p, 0.25, 0.01), (r, 0.36, 0.01), (aa, 0.37, 0.01), (z, 0.38, 0.01), (ih, 0.39, 0.01), (d, 0.4, 0.01), (iy, 0.52, 0.01). Ocurrencia 2: (p, 0.45, 0.01), (r, 0.46, 0.01), (aa, 0.47, 0.01), (z, 0.48, 0.01), (ih, 0.49, 0.01), (d, 0.5, 0.01), (iy, 0.51, 0.01). Según nuestra fórmula, la puntuación de la primera ocurrencia es 0.83 y la puntuación de la segunda ocurrencia es 1. En la primera ocurrencia, probablemente haya cierta inserción o silencio entre los teléfonos P y R, y entre el teléfono D e iy. El silencio puede deberse al hecho de que los teléfonos pertenecen a dos palabras diferentes y, por lo tanto, no es una ocurrencia del término prosodia.3.4.3 Combinación La puntuación de una ocurrencia de una consulta Q en el tiempo T0 en el documento D se determina mediante la multiplicación de la puntuación de cada palabra clave KI, donde cada ki ocurre en el tiempo TI con una duración DI en la transcripción d: puntaje(Q, t0, d) = n i = 0 puntaje (ki, ti, d) γn Tenga en cuenta que de acuerdo con lo que hemos aplazado en la sección 3.3, tenemos ∀1 ≤ i ≤ n, 0 <ti-(ti-1 +di - 1) <0.5 seg. Nuestro objetivo es estimar para cada ocurrencia que se encuentra en la probabilidad de que aparezca la consulta. Es diferente del IR clásico que tiene como objetivo clasificar los resultados y no obtenerlos. Dado que la probabilidad de tener una falsa alarma es inversamente proporcional a la longitud de la consulta de la frase, hemos aumentado el puntaje de consultas por un exponente γN, que está relacionado con el número de palabras clave en la frase. Hemos determinado empíricamente el valor de γn = 1/n. El tiempo de inicio de la ocurrencia de la consulta se determina por el tiempo de inicio T0 del primer término de consulta y la duración de la ocurrencia de consulta por tn - t0 + dn.4. Experimentos 4.1 Configuración experimental Nuestro corpus consiste en el conjunto de evaluación proporcionado por NIST para la evaluación STD 2006 [1]. Incluye tres tipos de fuente diferentes en inglés de EE. UU.: Tres horas de noticias de transmisión (BNEWS), tres horas de discurso de telefonía conversacional (CTS) y dos horas de reuniones de la sala de conferencias (ConfMTG). Como se muestra en la Sección 4.2, estas diferentes colecciones tienen diferentes precisiones. CTS y ConfMTG son un discurso espontáneo. Para los experimentos, hemos procesado el conjunto de consultas proporcionado por NIST que incluye 1100 consultas. Cada consulta es una frase que contiene entre uno a cinco términos, términos comunes y raros, términos que están en las transcripciones manuales y las que no lo son. La prueba y la determinación de los valores empíricos se han logrado en otro conjunto de datos y consultas del habla, el conjunto de desarrollo, también proporcionado por NIST. Hemos utilizado el sistema ASR de IBM Research Prototype, descrito en [26], para transcribir datos del habla. Hemos producido WCN para los tres tipos de fuentes diferentes.Las mejores transcripciones fonéticas se generaron solo para BNEW y CTS, ya que las transcripciones fonéticas ConfMTG tienen una precisión demasiado baja. Hemos adaptado Juru [7], una biblioteca de búsqueda de texto completo escrita en Java, para indexar las transcripciones y almacenar las marcas de tiempo de las palabras y teléfonos;Los resultados de la búsqueda se han recuperado como se describe en la Sección 3. Para cada ocurrencia de la consulta dada, nuestro sistema sale: la ubicación del término en el registro de audio (comienza el tiempo y la duración), la puntuación que indica qué tan probable es la aparición de consulta (como se define en la Sección 3.4) y una dura(binaria) decisión sobre si la detección es correcta. Medimos la precisión y el recuerdo comparando los resultados obtenidos sobre las transcripciones automáticas (solo los resultados que tienen una decisión dura verdadera) con los resultados obtenidos sobre las transcripciones manuales de referencia. Nuestro objetivo es evaluar la capacidad del enfoque de recuperación sugerido para manejar los datos del habla transcritos. Por lo tanto, cuanto más cerca sean los resultados automáticos de los resultados manuales, mejor será la efectividad de búsqueda sobre las transcripciones automáticas. Los resultados devueltos de la transcripción manual para una consulta dada se consideran relevantes y se espera que se recuperen con los puntajes más altos. Este enfoque para medir la efectividad de la búsqueda utilizando datos manuales como referencia es muy común en la investigación de recuperación del habla [25, 22, 8, 9, 17]. Además del retiro y la precisión, utilizamos las medidas de evaluación definidas por NIST para la evaluación de STD de 2006 [2]: el valor real ponderado por término (ATWV) y el valor máximo ponderado (MTWV). El valor ponderado por el término (TWV) se calcula primero calculando las probabilidades de falsa y falsa alarma para cada consulta por separado, luego utilizando estos y una probabilidad previa (elegida arbitrariamente) para calcular valores específicos de la consulta, y finalmente promediando estos valores específicos de la consultaSobre todas las consultas Q para producir un valor general del sistema: TWV (θ) = 1 - promedioq {pmiss (q, θ) + β × pf a (q, θ)} donde β = c v (pr - 1 q - 1).θ es el umbral de detección. Para la evaluación, la relación costo/valor, C/V, se ha determinado a 0.1 y la probabilidad previa de una consulta PRQ a 10−4. Por lo tanto, β = 999.9. Las probabilidades de falsa y falsa alarma para una consulta dada Q son funciones de θ: pmiss (q, θ) = 1 - ncorrect (q, θ) ntrue (q) pf a (q, θ) = nspurious (q, θ) nnt (q) Corpus Wer (%) Subr (%) delr (%) INSR (%) BNews WCN 12.7 49 42 9 CTS WCN 19.6 51 38 11 Confmtg WCN 47.4 47 49 3 Tabla 1: Wer y distribución de los tipos de error sobre la palabra 1-Capasa ruta extraída de WCN para los diferentes tipos de fuente.donde: • nCorrect (Q, θ) es el número de detecciones correctas (recuperadas por el sistema) de la consulta Q con una puntuación mayor o igual a θ.• Nspurious (Q, θ) es el número de detecciones espurias de la consulta Q con una puntuación mayor o igual a θ.• Ntrue (Q) es el número de ocurrencias verdaderas de la consulta Q en el corpus.• NNT (Q) es el número de oportunidades para la detección incorrecta de la consulta Q en el corpus;Son las pruebas de consulta no objetivo. Se ha definido mediante la siguiente fórmula: Nnt (Q) = TsPeech - Ntrue (Q). Tspech es la cantidad total de discurso en la colección (en segundos). ATWV es el valor real ponderado por término;Es el valor de detección alcanzado por el sistema como resultado de la salida del sistema y la salida de decisión binaria para cada supuesto ocurrencia. Varía de −∞ a +1. MTWV es el valor máximo ponderado a término en el rango de todos los valores posibles de θ. Varía de 0 a +1. También hemos proporcionado la curva de compensación de errores de detección (DET) [19] de la probabilidad de Miss (PMIS) frente a la probabilidad de falsa alarma (PF A). Hemos utilizado la herramienta Stdeval para extraer los resultados relevantes de las transcripciones manuales y para calcular ATWV, MTWV y la curva DET. Hemos determinado empíricamente los siguientes valores para el vector de impulso definido en la Sección 3.4: Bi = 1 i.4.2 Análisis WER Utilizamos la tasa de error de la palabra (WER) para caracterizar la precisión de las transcripciones. Wer se define de la siguiente manera: S + D + I n × 100 donde n es el número total de palabras en el corpus, y S, I y D son el número total de errores de sustitución, inserción y eliminación, respectivamente. La tasa de error de sustitución (SUBR) se define por S S + D + I × 100. La tasa de error de eliminación (Delr) y la tasa de error de inserción (INSR) se definen de manera similar. La Tabla 1 proporciona el WER y la distribución de los tipos de error sobre las transcripciones de la ruta de 1 mejor extraídas de WCN. El WER de las transcripciones fonéticas de 1 mejor ruta es aproximadamente dos veces peor que el WER de las transcripciones de palabras. Esa es la razón por la que no hemos recuperado de las transcripciones fonéticas en los datos del habla ConfMTG.4.3 Umbral Theta Hemos determinado empíricamente un umbral de detección θ por tipo de fuente y la dura decisión de los acontecimientos que tienen una puntuación inferior a θ se establece en falso;Los eventos falsos devueltos por el sistema no se consideran recuperados y, por lo tanto, no se usan para calcular ATWV, precisión y retiro. El valor del umbral θ por tipo de fuente se informa en la Tabla 2. Está correlacionado con la precisión de las transcripciones. Básicamente, establecer un umbral tiene como objetivo eliminar de los acontecimientos recuperados, falsas alarmas sin agregar fallas. Cuanto mayor sea el que sea, mayor será el umbral θ. BNEWS CTS Confmtg 0.4 0.61 0.91 Tabla 2: Valores del umbral θ por tipo de fuente.4.4 Profección de recursos de procesamiento informamos en la Tabla 3 el perfil de recursos de procesamiento. Con respecto al tamaño del índice, tenga en cuenta que nuestro índice se comprime mediante técnicas de compresión del índice IR. El tiempo de indexación incluye tanto el procesamiento de audio (generación de transcripciones de palabras y fonéticas) como la construcción de los índices de búsqueda. Tamaño del índice 0.3267 MB/HS Tiempo de indexación 7.5627 HP/HS Uso de la memoria del índice 1653.4297 MB Velocidad de búsqueda 0.0041 SEC.P/HS Uso de la memoria de búsqueda 269.1250 MB Tabla 3: Profección de recursos de procesamiento.(HS: Horas de discurso. HP: horas de procesamiento.Sec.P: Segundos de procesamiento) 4.5 Medidas de recuperación Comparamos nuestro enfoque (WCN fonético) presentado en la Sección 4.1 con otro enfoque (1 mejor WCN fonético). La única diferencia entre estos dos enfoques es que, en 1 mejor WCN fonético, indexamos solo la 1 mejor ruta extraída del WCN en lugar de indexar todo el WCN. WCN fonético fue nuestro sistema principal para la evaluación y el mejor fonético de la WCN fue uno de nuestros sistemas de contraste. Precisión y retiro promedio, MTWV y ATWV en las 1100 consultas se dan en la Tabla 4. También proporcionamos la curva DET para el enfoque fonético de WCN en la Figura 2. El punto que maximiza el TWV, el MTWV, se especifica en cada curva. Tenga en cuenta que el rendimiento de la recuperación se ha evaluado por separado para cada tipo de fuente ya que la precisión del habla difiere por tipo de fuente como se muestra en la Sección 4.2. Como se esperaba, podemos ver que MTWV y ATWV disminuyen en más alto. El rendimiento de la recuperación se mejora cuando la medida BNews CTS confmtg WCN ATWV fonética 0.8485 0.7392 0.2365 MTWV 0.8532 0.7408 0.2508 Precisión 0.94 0.90 0.65 RECURS 512 Precisión 0.95 0.91 0.66 Recuerde 0.84 0.75 0.37Tabla 4: ATWV, MTWV, precisión y retiro por tipo de fuente. Figura 2: Curva DET para el enfoque fonético de WCN.Usando WCN relativamente a la mejor ruta. Se debe al hecho de que la probabilidad de Miss se mejora al indexar todas las hipótesis proporcionadas por los WCN. Esta observación confirma los resultados mostrados por Mamou et al.[17] En el contexto de la recuperación de documentos hablados. El ATWV que hemos obtenido está cerca del MTWV;Hemos combinado nuestro modelo de clasificación con umbral apropiado θ para eliminar los resultados con una puntuación más baja. Por lo tanto, se reduce el efecto de falsas alarmas agregadas por WCNS. El enfoque fonético de WCN se utilizó en la reciente evaluación de NIST ETS y recibió la clasificación general más alta entre once participantes. A modo de comparación, el sistema que se clasificó en tercer lugar, obtuvo un ATWV de 0.8238 para BNEWS, 0.6652 para CTS y 0.1103 para ConfMTG.4.6 Influencia de la duración de la consulta en el rendimiento de la recuperación Hemos analizado el rendimiento de la recuperación de acuerdo con la duración promedio de las ocurrencias en las transcripciones manuales. El conjunto de consultas se dividió en tres cuantiles diferentes de acuerdo con la duración;Hemos informado en la Tabla 5 ATWV y MTWV de acuerdo con la duración. Podemos ver que nos desempeñamos mejor en consultas más largas. Una de las razones es el hecho de que el sistema ASR es más preciso en palabras largas. Por lo tanto, se justificó aumentar la puntuación de los resultados con el exponente γN, como se explica en la Sección 3.4.3, de acuerdo con la longitud de la consulta.cuantil 0-33 33-66 66-100 BNews ATWV 0.7655 0.8794 0.9088 MTWV 0.7819 0.8914 0.9124 CTS ATWV 0.6545 0.8308 0.8378 MTWV 0.6551 0.8727 0.8479 confmtg ATWV 5 0.4109 0.3880 Tabla 5: ATWV, MTWV según la duración de la consultaocurrencias por tipo de fuente.4.7 Procesamiento de consultas OOV vs. IV Hemos elegido al azar tres conjuntos de consultas de los conjuntos de consultas proporcionados por NIST: 50 consultas que contienen solo términos IV;50 consultas que contienen solo términos OOV;y 50 consultas híbridas que contienen términos IV y OOV. El siguiente experimento se ha logrado en la colección BNews y los términos IV y OOV se han determinado de acuerdo con el vocabulario del sistema BNEWS ASR. Nos gustaría comparar tres enfoques diferentes de recuperación: usar solo el índice de palabras;usando solo índice fonético;combinando palabras e índices fonéticos. La Tabla 6 resume el rendimiento de la recuperación de acuerdo con cada enfoque y con cada tipo de consultas. El uso de un enfoque basado en palabras para tratar con consultas OOV y híbridas afecta drásticamente el rendimiento de la recuperación;La precisión y el recuerdo son nulos. El uso de un enfoque basado en el teléfono para tratar consultas IV afecta también el rendimiento de la recuperación en relación con el enfoque basado en palabras. Como se esperaba, el enfoque que combina los índices de palabras y fonéticos presentados en la Sección 3 conduce al mismo rendimiento de recuperación que el enfoque de la palabra para las consultas IV y al mismo rendimiento de recuperación que el enfoque fonético para las consultas OOV. Este enfoque siempre supera a los demás y justifica el hecho de que necesitamos combinar la búsqueda de palabras y fonéticas.5. Trabajo relacionado en la última década, los esfuerzos de investigación en la recuperación de datos hablados se han centrado en extender técnicas clásicas de IR a documentos hablados. Algunos de estos trabajos se han realizado en el contexto de las evaluaciones de recuperación de documentos hablados de TREC y son descritos por Garofolo et al.[12]. Se utiliza un sistema LVCSR para transcribir el discurso a las mejores transcripciones de palabras de ruta. Las transcripciones se indexan como texto limpio: para cada ocurrencia, su documento, su desplazamiento de palabras e información adicional se almacenan en el índice. Se utiliza un sistema IR genérico sobre el texto para detectar palabras y búsqueda como lo describen Brown et al.[6] y James [14]. Esta palabra fonética de palabras de estratíndex y precisión fonética retiro de precisión recordar precisión recuerdo IV consultas 0.8 0.96 0.11 0.77 0.8 0.96 consultas Oov 0 0 0.13 0.79 0.13 0.79 Consultas híbridas 0 0 0.15 0.71 0.89 0.83 Tabla 6: Comparación de palabras y enfoque fonético en IV y OOV y OOV y OOV y OOV y OOV y OOV y OOV y OOVconsultas Egy funciona bien para transcripciones como las colecciones de noticias de transmisión que tienen un WER bajo (en el rango de 15%-30%) y son redundantes por naturaleza (la misma información se habla varias veces en diferentes modales). Además, los algoritmos se han probado principalmente en consultas largas establecidas en inglés simple y la recuperación de tales consultas es más sólido contra los errores de reconocimiento de voz. Un enfoque alternativo consiste en usar redes de palabras para mejorar la efectividad de SDR. Singhal et al.[24, 25] propone agregar algunos términos a la transcripción para aliviar las fallas de recuperación debido a errores ASR. Desde una perspectiva IR, una forma clásica de traer nuevos términos es la expansión del documento utilizando un corpus similar. Su enfoque consiste en el uso de redes de palabras para determinar qué palabras devueltas por un algoritmo de expansión del documento deben agregarse a la transcripción original. La necesidad de usar un algoritmo de expansión de documentos estaba justificado por el hecho de que las redes de palabras con las que trabajaban, carecen de información sobre las probabilidades de palabras. Chelba y Acero en [8, 9] proponen una red de palabras más compacta, la red posterior específica de posición (PSPL). Esta estructura de datos es similar a WCN y conduce a un índice más compacto. La compensación de los términos en los documentos del habla también se almacena en el índice. Sin embargo, el marco de evaluación se lleva a cabo en conferencias que están relativamente planificadas, en contraste con el discurso conversacional. Su modelo de clasificación se basa en el término nivel de confianza, pero no tiene en cuenta el rango del término entre las otras hipótesis. Mamou et al.[17] propone un modelo para la recuperación de documentos hablados utilizando WCN para mejorar el retiro y el mapa de la búsqueda. Sin embargo, en los trabajos anteriores, no se aborda el problema de las consultas que contienen términos de OOV. Los enfoques populares para tratar las consultas de OOV se basan en transcripciones de sub-palabras, donde las sub-palabras son típicamente teléfonos, sílabas o fragmentos de palabras (secuencias de teléfonos) [11, 20, 23]. El enfoque clásico consiste en el uso de transcripciones fonéticas. Las transcripciones se indexan de la misma manera que las palabras en el uso de técnicas de recuperación de texto clásico;Durante el procesamiento de la consulta, la consulta se representa como una secuencia de teléfonos. La recuperación se basa en la búsqueda de la cadena de teléfonos que representan la consulta en la transcripción fonética. Para tener en cuenta las altas tasas de error de reconocimiento, algunos otros sistemas utilizan transcripciones más ricas como redes fonéticas. Son atractivos ya que acomodan las condiciones de alta tasa de error, así como permiten que se usen consultas OOV [15, 3, 20, 23, 21, 27]. Sin embargo, las redes fonéticas contienen muchos bordes que se superponen a tiempo con la misma etiqueta fonética y son difíciles de indexar. Además, además de la mejora en el recuerdo de la búsqueda, la precisión se ve afectada ya que las redes fonéticas a menudo son inexactas. En consecuencia, los enfoques fonéticos deben usarse solo para la búsqueda de OOV;Para buscar consultas que contengan también términos IV, esta técnica afecta el rendimiento de la recuperación en comparación con el enfoque basado en palabras. Saraclar y Sproat en [22] muestran una mejora en la precisión de la detección de palabras para consultas IV y OOV, utilizando redes fonéticas y de palabras, donde se puede derivar una medida de confianza de una palabra o un teléfono. Proponen tres estrategias de recuperación diferentes: buscar tanto la palabra como los índices fonéticos y unificar los dos conjuntos diferentes de resultados;Busque el índice de palabras para consultas IV, busque consultas fonéticas para consultas OOV;Busque el índice de palabras y si no se devuelve ningún resultado, busque el índice fonético. Sin embargo, no se propone una estrategia para tratar las consultas de frases que contienen términos IV y OOV. Amir et al.En [5, 4] propone fusionar un enfoque de palabra con un enfoque fonético en el contexto de la recuperación de videos. Sin embargo, la transcripción fonética se obtiene de un texto a la conversión fonética de la mejor ruta de la transcripción de la palabra y no se basa en una decodificación fonética de los datos del habla. Un tema importante a considerar al observar el estado del arte en la recuperación de los datos hablados es la falta de un conjunto de pruebas común y los términos de consulta apropiados. Este artículo utiliza dicha tarea y la evaluación de STD es un buen resumen del rendimiento de diferentes enfoques en las mismas condiciones de prueba.6. Conclusiones Este trabajo estudia cómo la detección de términos hablados independientes de vocabulario puede realizarse de manera eficiente en diferentes fuentes de datos. Anteriormente, los enfoques fonéticos y basados en palabras se han utilizado para IR en los datos del habla. El primero sufre de baja precisión y el segundo del vocabulario limitado del sistema de reconocimiento. En este documento, hemos presentado un modelo independiente de vocabulario de indexación y búsqueda que combina ambos enfoques. El sistema puede lidiar con todo tipo de consultas, aunque las frases que deben combinarse para la recuperación, información extraída de dos índices diferentes, un índice de palabras y un índice fonético. La puntuación de los términos OOV se basa en la proximidad (en el tiempo) entre los diferentes teléfonos. La puntuación de los términos IV se basa en la información proporcionada por el WCNS. Hemos mostrado una mejora en el rendimiento de la recuperación cuando se usa todos los WCN y no solo en la mejor ruta y cuando se utilizan un índice fonético para la búsqueda de términos de consulta OOV. Este enfoque siempre supera a los otros enfoques utilizando solo el índice de palabras o el índice fonético. Como trabajo futuro, compararemos nuestro modelo para la búsqueda de OOV en las transcripciones fonéticas con un modelo de recuperación basado en la distancia de edición.7. Agradecimientos Jonathan Mamou agradece a David Carmel y Ron Hoory por sus discusiones útiles e interesantes.8. Referencias [1] Sitio web de evaluación de Término hablado de NIST, http://www.nist.gov/speech/tests/std/.[2] Plan de evaluación NIST Termking Terme (STD) 2006, http://www.nist.gov/speech/tests/std/docs/std06-evalplan-v10.pdf.[3] C. Allauzen, M. Mohri y M. Saraclar. Indexación general de autómatas ponderados: aplicación a recuperación de expresión hablada. En Actas del Taller de HLT-NAACL 2004 sobre enfoques interdiciplinarios para la indexación y recuperación del habla, Boston, MA, EE. UU., 2004. [4] A. Amir, M. Berg y H. Permuter. Comentarios de relevancia mutua para la formulación de consultas multimodales en la recuperación de video. En Mir 05: Actas del 7º Taller Internacional de ACM Sigmm sobre recuperación de información multimedia, páginas 17-24, Nueva York, NY, EE. UU., 2005. ACM Press.[5] A. Amir, A. Efrat y S. Srinivasan. Avances en la manchación de palabras fonéticas. En CIKM 01: Actas de la Décima Conferencia Internacional sobre Gestión de Información y Conocimiento, páginas 580-582, Nueva York, NY, EE. UU., 2001. ACM Press.[6] M. Brown, J. Foote, G. Jones, K. Jones y S. Young. Indexación del discurso de vocabulario abierto para la recuperación de correo de voz y video. En Actas ACM Multimedia 96, páginas 307-316, Hong-Kong, noviembre de 1996. [7] D. Carmel, E. Amitay, M. Herscovici, Y. S. Maarek, Y. Petruschka y A. Soffer. Juru en TREC 10Experimentos con poda de índice. En Actas de la Décima Conferencia de Recuperación de Textos (TREC-10). Instituto Nacional de Normas y Tecnología. NIST, 2001. [8] C. Chelba y A. Acero. Indexación de incertidumbre para la búsqueda de documentos hablados. En Interspeech 2005, páginas 61-64, Lisboa, Portugal, 2005. [9] C. Chelba y A. Acero. Posición Vueltas posteriores específicas para indexar el habla. En Actas de la 43a Conferencia Anual de la Asociación de Lingüística Computacional (ACL), Ann Arbor, MI, 2005. [10] S. Chen. Modelos condicionales y conjuntos para la conversión de grafema a fonema. En EuroSpeech 2003, Ginebra, Suiza, 2003. [11] M. Clements, S. Robertson y M. Miller. La búsqueda fonética aplicada a los módulos de aprendizaje de distancia en línea. En el Taller de Procesamiento de señales digitales, 2002 y el 2º Taller de Educación de Procesamiento de señales. Actas de 2002 IEEE 10, páginas 186-191, 2002. [12] J. Garofolo, G. Auzanne y E. Voorhees. La pista de recuperación de documentos de TREC: una historia de éxito. En Actas de la Novena Conferencia de Recuperación de Textos (TREC-9). Instituto Nacional de Normas y Tecnología. NIST, 2000. [13] D. Hakkani-Tur y G. Riccardi. Un algoritmo general para la descomposición de la matriz de gráficos de Word. En Actas de la Conferencia de Internación IEEE sobre Acústica, Procesamiento de habla y señal (ICASSP), páginas 596-599, Hong-Kong, 2003. [14] D. James. La aplicación de técnicas de recuperación de información clásica a documentos hablados. Tesis doctoral, Universidad de Cambridge, Downing College, 1995. [15] D. A. James. Un sistema para la recuperación de temas sin restricciones de las transmisiones de Radio News. En Proc. ICASSP 96, páginas 279-282, Atlanta, GA, 1996. [16] B. Logan, P. Moreno, J. V. Thong y E. Whittaker. Un estudio experimental de un sistema de indexación de audio para la web. En Actas de ICSLP, 1996. [17] J. Mamou, D. Carmel y R. Hoory. Recuperación de documentos hablados de las conversaciones del centro de llamadas. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 51-58, Nueva York, NY, EE. UU., 2006. ACM Press.[18] L. Mangu, E. Brill y A. Stolcke. Encontrar consenso en el reconocimiento de voz: minimización de errores de palabras y otras aplicaciones de redes de confusión. Computer Speech and Language, 14 (4): 373-400, 2000. [19] A. Martin, G. Doddington, T. Kamm, M. Ordowski y M. Przybocki. La curva DET en la evaluación del rendimiento de la tarea de detección. En Proc. EuroSpeech 97, páginas 1895-1898, Rhodes, Grecia, 1997. [20] K. Ng y V. W. Zue. Enfoques basados en subvenciones para la recuperación de documentos hablados. Speech Commun., 32 (3): 157-186, 2000. [21] Y. Peng y F. Seide. Búsqueda rápida de vocabulario de dos etapas en discurso espontáneo. En acústica, habla y procesamiento de señales. Actas.(ICASSP). IEEE International Conference, Volumen 1, páginas 481-484, 2005. [22] M. Saraclar y R. Sproat. Búsqueda basada en la red para la recuperación de expresión hablada. En HLT-Naacl 2004: PRINCIPIOS PRINCIPALES, Páginas 129-136, Boston, Massachusetts, EE. UU., 2004. [23] F. Seide, P. Yu, C. Ma y E. Chang. Búsqueda independiente del vocabulario en el discurso espontáneo. En ICASSP-2004, IEEE International Conference on Acoustics, Speech and Signal Processing, 2004. [24] A. Singhal, J. Choi, D. Hindle, D. Lewis y F. Pereira. AT&T en TREC-7. En Actas de la Séptima Conferencia de Recuperación de Textos (TREC-7). Instituto Nacional de Normas y Tecnología. NIST, 1999. [25] A. Singhal y F. Pereira. Expansión del documento para la recuperación del habla. En Sigir 99: Actas de la 22a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 34-41, Nueva York, NY, EE. UU., 1999. ACM Press.[26] H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon y G. Zweig. El sistema de telefonía conversacional IBM 2004 para una transcripción rica. En Actas de la Conferencia Internacional IEEE sobre Acústica, Procesamiento de discursos y señales (ICASSP), marzo de 2005. [27] K. Thambiratnam y S. Sridharan. Búsquedas dinámicas de la contabilidad telefónica de la matrícula para el vocabulario sin restricciones muy rápido y preciso. En acústica, habla y procesamiento de señales. Actas.(ICASSP). IEEE International Conference, 2005. [28] P. C. Woodland, S. E. Johnson, P. Jourlin y K. S. Jones. Efectos de las palabras fuera del vocabulario en la recuperación de documentos hablados (sesión de carteles). En Sigir 00: Actas de la 23a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 372-374, Nueva York, NY, EE. UU., 2000. ACM Press.