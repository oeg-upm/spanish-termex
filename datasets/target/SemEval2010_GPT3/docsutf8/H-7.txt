Modelado jerárquico de usuarios bayesianos eficiente para sistemas de recomendación. Yi Zhang, Jonathan Koren Escuela de Ingeniería Universidad de California Santa Cruz Santa Cruz, CA, EE. UU. {yiz, jonathan}@soe.ucsc.edu RESUMEN Un sistema de recomendación personalizado basado en contenido aprende perfiles específicos de usuarios a partir de la retroalimentación del usuario para poder proporcionar información adaptada a los intereses de cada usuario individual. Un sistema que atiende a millones de usuarios puede aprender un perfil de usuario mejor para un usuario nuevo, o un usuario con poca retroalimentación, al tomar prestada información de otros usuarios a través del uso de un modelo jerárquico bayesiano. Aprender los parámetros del modelo para optimizar la verosimilitud conjunta de los datos de millones de usuarios es muy costoso computacionalmente. El algoritmo EM comúnmente utilizado converge muy lentamente debido a la escasez de datos en aplicaciones de IR. Este documento propone una nueva técnica de aprendizaje rápido para aprender un gran número de perfiles de usuario individuales. La eficacia y eficiencia del algoritmo propuesto están justificadas por la teoría y demostradas en datos reales de usuarios de Netflix y MovieLens. Categorías y Descriptores de Asignaturas: B.3.3 [Búsqueda y Recuperación de Información]: Filtrado de información Términos Generales: Algoritmos 1. La personalización es el futuro de la Web y ha logrado un gran éxito en aplicaciones industriales. Por ejemplo, las tiendas en línea, como Amazon y Netflix, ofrecen recomendaciones personalizadas de productos o servicios adicionales basadas en el historial de un usuario. Ofertas recientes como My MSN, My Yahoo!, My Google y Google News han atraído mucha atención debido a su capacidad potencial para inferir los intereses de un usuario a partir de su historial. Un tema importante de personalización estudiado en la comunidad de recuperación de información es el de los sistemas de recomendación personalizados basados en el contenido. Estos sistemas aprenden perfiles específicos de usuario a partir de la retroalimentación del usuario para poder recomendar información adaptada a los intereses de cada usuario sin necesidad de que el usuario realice una consulta explícita. Aprender los perfiles de usuario es el problema central de estos sistemas. Un perfil de usuario suele ser un clasificador que puede identificar si un documento es relevante para el usuario o no, o un modelo de regresión que indica qué tan relevante es un documento para el usuario. Uno de los principales desafíos de construir un sistema de recomendación o personalización es que el perfil aprendido para un usuario en particular suele ser de baja calidad cuando la cantidad de datos de ese usuario en particular es pequeña. Esto se conoce como el problema de inicio en frío. Esto significa que cualquier usuario nuevo debe soportar un rendimiento inicial deficiente hasta que se proporcione suficiente retroalimentación de ese usuario para aprender un perfil de usuario confiable. Se ha realizado mucha investigación sobre cómo mejorar la precisión de clasificación cuando la cantidad de datos de entrenamiento etiquetados es pequeña. El enfoque de aprendizaje semisupervisado combina datos no etiquetados y etiquetados juntos para lograr este objetivo [26]. Otro enfoque es utilizar el conocimiento del dominio. Los investigadores han modificado diferentes algoritmos de aprendizaje, como NaïveBayes [17], regresión logística [7] y SVMs [22], para integrar el conocimiento del dominio en un clasificador de texto. El tercer enfoque consiste en tomar datos de entrenamiento de otros recursos [5][7]. La efectividad de estos enfoques diferentes es mixta, debido a qué tan bien se ajusta la suposición del modelo subyacente a los datos. Un enfoque bien recibido para mejorar el rendimiento del sistema de recomendación para un usuario en particular es tomar prestada información de otros usuarios a través de un enfoque de modelado jerárquico bayesiano. Varios investigadores han demostrado que este enfoque intercambia eficazmente entre la información compartida y la específica del usuario, aliviando así el bajo rendimiento inicial para cada usuario[27][25]. Para aprender un modelo jerárquico bayesiano, el sistema generalmente intenta encontrar los parámetros del modelo más probables para los datos dados. Un sistema de recomendación maduro generalmente funciona para millones de usuarios. Es bien sabido que aprender los parámetros óptimos de un modelo jerárquico bayesiano es computacionalmente costoso cuando hay miles o millones de usuarios. El algoritmo EM es una técnica comúnmente utilizada para el aprendizaje de parámetros debido a su simplicidad y garantía de convergencia. Sin embargo, un sistema de recomendación basado en contenido a menudo maneja documentos en un espacio de dimensiones muy altas, en el que cada documento está representado por un vector muy disperso. Con un análisis cuidadoso del algoritmo EM en este escenario (Sección 4), encontramos que el EM tering, o filtrado colaborativo basado en elementos. En este documento, las palabras filtrado y recomendación se utilizan indistintamente. El algoritmo converge muy lentamente debido a la escasez de las variables de entrada. También encontramos que actualizar el parámetro del modelo en cada iteración de EM es costoso, con una complejidad computacional de O(MK), donde M es el número de usuarios y K es el número de dimensiones. Este documento modifica el algoritmo EM estándar para crear un algoritmo de aprendizaje mejorado, al que llamamos algoritmo EM modificado. La idea básica es que en lugar de calcular la solución numérica para todos los parámetros del perfil de usuario, derivamos la solución analítica de los parámetros para algunas dimensiones de características, y en el paso M utilizamos la solución analítica en lugar de la solución numérica estimada en el paso E para esos parámetros. Esto reduce considerablemente la computación en una sola iteración de EM, y también tiene el beneficio de aumentar la velocidad de convergencia del algoritmo de aprendizaje. La técnica propuesta no solo está bien respaldada por la teoría, sino también por los resultados experimentales. La organización de las partes restantes de este documento es la siguiente: La Sección 3 describe el marco de modelado de regresión lineal jerárquica bayesiana utilizado para recomendaciones basadas en contenido. La sección 4 describe cómo aprender los parámetros del modelo utilizando el algoritmo EM estándar, junto con el uso de la nueva técnica propuesta en este artículo. La configuración experimental y los resultados utilizados para validar la técnica de aprendizaje propuesta se informan en las Secciones 5 y 6. La sección 7 resume y ofrece observaciones finales. 2. TRABAJO RELACIONADO Proporcionar recomendaciones personalizadas a los usuarios ha sido identificado como un problema muy importante en la comunidad de IR desde la década de 1970. Los enfoques que se han utilizado para resolver este problema pueden clasificarse aproximadamente en dos categorías principales: filtrado basado en contenido versus filtrado colaborativo. El filtrado basado en contenido estudia el escenario en el que un sistema de recomendación monitorea un flujo de documentos y envía documentos que coinciden con un perfil de usuario al usuario correspondiente. El usuario puede leer los documentos entregados y proporcionar retroalimentación explícita de relevancia, la cual el sistema de filtrado utiliza para actualizar el perfil del usuario mediante modelos de recuperación de retroalimentación de relevancia (por ejemplo,). Modelos booleanos, modelos de espacio vectorial, modelos probabilísticos tradicionales [20], redes de inferencia [3] y modelos de lenguaje [6]) o algoritmos de aprendizaje automático (por ejemplo, Máquinas de Vectores de Soporte (SVM), agrupamiento de K vecinos más cercanos (K-NN), redes neuronales, regresión logística o Winnow [16] [4] [23]. El filtrado colaborativo va más allá de simplemente usar el contenido de un documento para recomendar elementos a un usuario, aprovechando la información de otros usuarios con gustos y preferencias similares en el pasado. Se han utilizado heurísticas basadas en memoria y enfoques basados en modelos en la tarea de filtrado colaborativo [15] [8] [2] [14] [12] [11]. Este artículo contribuye a la investigación de recomendaciones basadas en contenido al mejorar la eficiencia y efectividad de los modelos lineales jerárquicos bayesianos, los cuales tienen una sólida base teórica y un buen rendimiento empírico en tareas de recomendación[27][25]. Este artículo no tiene la intención de comparar el filtrado basado en contenido con el filtrado colaborativo ni de afirmar cuál es mejor. Creemos que cada uno complementa al otro, y que el filtrado basado en contenido es extremadamente útil para manejar nuevos documentos/artículos con poco o ningún feedback del usuario. Similar a otros investigadores[18][1][21], encontramos que un sistema de recomendación será más efectivo cuando se combinan ambas técnicas. Sin embargo, esto está fuera del alcance de este documento y, por lo tanto, no se discute aquí. 3. REGRESIÓN LINEAL HIERÁRQUICA BAYESIANA Suponga que hay M usuarios en el sistema. La tarea del sistema es recomendar documentos que sean relevantes para cada usuario. Para cada usuario, el sistema aprende un modelo de usuario a partir del historial de los usuarios. En el resto de este documento, utilizaremos las siguientes notaciones para representar las variables en el sistema. m = 1, 2, ..., M: El índice para cada usuario individual. M es el número total de usuarios. wm: El parámetro del modelo de usuario asociado con el usuario m. wm es un vector de dimensión K. j = 1, 2, ..., Jm: El índice para un conjunto de datos para el usuario m. Jm es el número de datos de entrenamiento para el usuario m. Dm = {(xm,j, ym,j)}: Un conjunto de datos asociado con el usuario m. xm,j es un vector de dimensión K que representa el j-ésimo documento de entrenamiento del usuario m. ym,j es un escalar que representa la etiqueta del documento xm,j. k = 1, 2, ..., K: El índice dimensional de la variable de entrada x. El enfoque de modelado jerárquico bayesiano ha sido ampliamente utilizado en aplicaciones reales de recuperación de información. Los modelos lineales jerárquicos bayesianos generalizados, uno de los modelos jerárquicos bayesianos más simples, son comúnmente utilizados y han logrado un buen rendimiento en tareas de filtrado colaborativo [25] y filtrado adaptativo basado en contenido [27]. La Figura 1 muestra la representación gráfica de un modelo jerárquico bayesiano. En este gráfico, cada modelo de usuario está representado por un vector aleatorio wm. Suponemos que un modelo de usuario se muestrea aleatoriamente de una distribución previa P(w|Φ). El sistema puede predecir la etiqueta de usuario y de un documento x dado una estimación de wm (o distribución de wms) utilizando una función y = f(x, w). El modelo se llama modelo lineal jerárquico bayesiano generalizado cuando y = f(wT x) es cualquier modelo lineal generalizado como regresión logística, SVM y regresión lineal. Para estimar de manera confiable el modelo de usuario wm, el sistema puede obtener información de otros usuarios a través de la prior Φ = (µ, Σ). Ahora observamos un modelo comúnmente utilizado donde y = wT x + , donde ∼ N(0, σ2 ) es un ruido aleatorio [25][27]. Suponga que cada modelo de usuario wm es una muestra independiente de una distribución poblacional P(w|Φ), la cual está regida por un hiperparámetro desconocido Φ. Que la distribución previa del modelo de usuario w sea una distribución gaussiana con parámetro Φ = (µ, Σ), que es la distribución previa comúnmente utilizada para modelos lineales. µ = (µ1, µ2, ..., µK) es un vector de K dimensiones que representa la media de la distribución gaussiana, y Σ es la matriz de covarianza de la gaussiana. Normalmente, se utiliza una distribución Normal N(0, aI) y una distribución Inverse Wishart P(Σ) ∝ |Σ|− 1 2 b exp(−1 2 ctr(Σ−1 )) como hiperprior para modelar la distribución previa de µ y Σ respectivamente. Yo es la matriz identidad de dimensión K, y a, b y c son números reales. Con esta configuración, tenemos el siguiente modelo para el sistema: 1. µ y Σ se muestrean de N(0, aI) e IWν (aI), respectivamente. 2. La primera dimensión de x es una variable ficticia que siempre es igual a 1. Figura 1: Ilustración de las dependencias de variables en el modelo jerárquico. La calificación, y, para un documento, x, está condicionada al documento y al modelo de usuario, wm, asociado con el usuario m. Los usuarios comparten información sobre sus modelos a través de la prior, Φ = (µ, Σ). Para cada usuario m, wm se muestrea aleatoriamente de una distribución Normal: wm ∼ N(µ, Σ2 ) 3. Para cada elemento xm,j, ym,j se muestrea aleatoriamente de una distribución Normal: ym,j ∼ N(wT mxm,j, σ2). Que θ = (Φ, w1, w2, ..., wM) represente los parámetros de este sistema que necesitan ser estimados. La verosimilitud conjunta de todas las variables en el modelo probabilístico, que incluye los datos y los parámetros, es: P(D, θ) = P(Φ) m P(wm|Φ) j P(ym,j|xm,j, wm) (1) Para simplificar, asumimos que a, b, c y σ son proporcionados al sistema. 4. APRENDIZAJE DE PARÁMETROS DEL MODELO Si se conoce el prior Φ, encontrar el óptimo wm es sencillo: se trata de una regresión lineal simple. Por lo tanto, nos enfocaremos en estimar Φ. La solución a priori máxima de Φ se da por ΦMAP = arg max Φ P(Φ|D) (2) = arg max Φ P(Φ, D) P(D) (3) = arg max Φ P(D|Φ)P(Φ) (4) = arg max Φ w P(D|w, Φ)P(w|Φ)P(Φ)dw (5) Encontrar la solución óptima para el problema anterior es desafiante, ya que necesitamos integrar sobre todos los w = (w1, w2, ..., wM), que son variables ocultas no observadas. 4.1 Algoritmo EM para Modelos Lineales Jerárquicos Bayesianos En la Ecuación 5, Φ es el parámetro que necesita ser estimado, y el resultado depende de las variables latentes no observadas w. Este tipo de problema de optimización suele resolverse mediante el algoritmo EM. Aplicando EM al problema anterior, el conjunto de modelos de usuario w son las variables ocultas no observables y tenemos: Q = w P(w|µ, Σ2 , Dm) log P(µ, Σ2 , w, D)dw. Basándonos en la derivación de las fórmulas EM presentadas en [24], tenemos los siguientes pasos de Expectation-Maximization para encontrar los hiperparámetros óptimos. Por razones de espacio, omitimos la derivación en este artículo ya que no es el enfoque de nuestro trabajo. Paso E: Para cada usuario m, estime la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual del prior Φ = (µ, Σ2 ). ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ) (6) Σ2 m = ((Σ2 )−1 + Sxx,m σ2 )−1 (7) donde Sxx,m = j xm,jxT m,j Sxy,m = j xm,jym,j Paso M: Optimice el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E. µ = 1 M m ¯wm (8) Σ2 = 1 M m Σ2 m + ( ¯wm − µ)( ¯wm − µ)T (9) Muchos sistemas de IR impulsados por aprendizaje automático utilizan una estimación puntual de los parámetros en diferentes etapas del sistema. Sin embargo, estamos estimando la distribución posterior de las variables en el paso E. Esto evita el sobreajuste de wm a los datos de un usuario en particular, que pueden ser pequeños y ruidosos. Una discusión detallada sobre este tema aparece en [10]. 4.2 Nuevo Algoritmo: EM Modificado. Aunque el algoritmo EM es ampliamente estudiado y utilizado en aplicaciones de aprendizaje automático, utilizar el proceso EM mencionado anteriormente para resolver modelos lineales jerárquicos bayesianos en sistemas de recuperación de información a gran escala sigue siendo demasiado costoso computacionalmente. En esta sección, describimos por qué la tasa de aprendizaje del algoritmo EM es lenta en nuestra aplicación e introducimos una nueva técnica para hacer que el aprendizaje del modelo lineal jerárquico bayesiano sea escalable. La derivación del nuevo algoritmo de aprendizaje estará basada en el algoritmo EM descrito en la sección anterior. Primero, las matrices de covarianza Σ2 , Σ2 m suelen ser demasiado grandes para ser computacionalmente factibles. Por simplicidad, y como práctica común en IR, no modelamos la correlación entre características. Así aproximamos estas matrices con matrices diagonales de dimensión K. En el resto del documento, utilizamos estos símbolos para representar sus aproximaciones diagonales: Σ2 =     σ2 1 0 .. 0 0 σ2 2 .. 0 .. .. .. .. 0 0 .. σ2 K     Σ2 m =     σ2 m,1 0 .. 0 0 σ2 m,2 .. 0 .. .. .. .. 0 0 .. σ2 m,K     En segundo lugar, y lo más importante, el espacio de entrada es muy disperso y hay muchas dimensiones que no están relacionadas con un usuario particular en una aplicación de recuperación de información real. Por ejemplo, consideremos un sistema de recomendación de películas, con la variable de entrada x representando una película en particular. Para la j-ésima película que el usuario m ha visto, sea xm,j,k = 1 si el director de la película es Jean-Pierre Jeunet (indexado por k). Aquí asumimos que si este director dirigió una película específica está representado por la k-ésima dimensión. Si el usuario m nunca ha visto una película dirigida por Jean-Pierre Jeunet, entonces la dimensión correspondiente siempre es cero (xm,j,k = 0 para todos los j). Una desventaja importante del algoritmo EM es que la importancia de una característica, µk, puede estar fuertemente dominada por usuarios que nunca han encontrado esta característica (es decir, j xm,j,k = 0) en el paso M (Ecuación 8). Suponga que 100 de cada 1 millón de usuarios han visto la película dirigida por Jean-Pierre Jeunet, y que los espectadores han calificado todas sus películas como excelentes. Intuitivamente, él es un buen director y el peso para él (µk) debería ser alto. Antes de la iteración de EM, el valor inicial de µ suele establecerse en 0. Dado que los otros 999,900 usuarios no han visto esta película, sus pesos correspondientes (w1,k, w2,k, ..., wm,k..., w999900,k) para ese director serían muy pequeños inicialmente. Por lo tanto, el peso correspondiente del director en el µk anterior en el primer paso M sería muy bajo, y la varianza σm,k será grande (Ecuaciones 8 y 7). Es indeseable que los usuarios que nunca han visto ninguna película producida por el director influyan tanto en la importancia del director. Esto hace que la convergencia del algoritmo EM estándar sea muy lenta. Ahora veamos si podemos mejorar la velocidad de aprendizaje del algoritmo. Sin pérdida de generalidad, asumamos que la k-ésima dimensión de la variable de entrada x no está relacionada con un usuario particular m. Lo que queremos decir es que xm,j,k = 0 para todo j = 1, ..., Jm. Es sencillo demostrar que la k-ésima fila y la k-ésima columna de Sxx,m están completamente llenas de ceros, y que la k-ésima dimensión de Sxy,m también se anula. Por lo tanto, la dimensión k correspondiente de la media de los modelos de usuario, ¯wm, debería ser igual a la del anterior: ¯wm,k = µk, con la covarianza correspondiente de σm,k = σk. En el paso M, el algoritmo EM estándar utiliza la solución numérica de la distribución P(wm|Dm, Φ) estimada en el paso E (Ecuación 8 y Ecuación 7). Sin embargo, las soluciones numéricas son muy poco confiables para ¯wm,k y σm,k cuando la k-ésima dimensión no está relacionada con el m-ésimo usuario. Un enfoque mejor es utilizar las soluciones analíticas ¯wm,k = µk, y σm,k = σk para los pares no relacionados (m, k), junto con la solución numérica estimada en el paso E para los otros pares (m, k). Así obtenemos el siguiente nuevo algoritmo EM similar: Paso E modificado: Para cada usuario m, estimar la distribución del modelo de usuario P(wm|Dm, Φ) = N(wm; ¯wm, Σ2 m) basada en la estimación actual de σ , µ, Σ2 . ¯wm = ((Σ2 )−1 + Sxx,m σ2 )−1 ( Sxy,m σ2 + (Σ2 )−1 µ)(10) σ2 m,k = ((σ2 k)−1 + sxx,m,k σ2 )−1 (11) donde sxx,m,k = j x2 m,j,k y sxy,m,k = j xm,j,kym,j Paso M modificado Optimizar el prior Φ = (µ, Σ2 ) basado en la estimación del último paso E para pares de usuario-característica relacionados. El paso M utiliza implícitamente la solución analítica para pares de usuario-característica no relacionados. µk = 1 Mk m:relacionado ¯wm,k (12) σ2 k = 1 Mk m:relacionado σ2 m,k + ( ¯wm,k − µk)( ¯wm,k − µk)T (13) donde Mk es el número de usuarios relacionados con la característica k. Solo estimamos la diagonal de Σ2 m y Σ, ya que estamos utilizando la aproximación diagonal de las matrices de covarianza. Para estimar ¯wm, solo necesitamos calcular las soluciones numéricas para las dimensiones que están relacionadas con el usuario m. Para estimar σ2 k y µk, solo sumamos sobre los usuarios que están relacionados con la k-ésima característica. Hay dos beneficios principales del nuevo algoritmo. Primero, dado que solo se necesitan los pares relacionados (m, k) en el paso M modificado, la complejidad computacional en una sola iteración de EM es mucho menor cuando los datos son dispersos y muchos de los pares (m, k) no están relacionados. En segundo lugar, los parámetros estimados en el paso M modificado (Ecuaciones 12 - 13) son más precisos que el paso M estándar descrito en la Sección 4.1 porque se utilizaron soluciones analíticas exactas ¯wm,k = µk y σm,k = σk para los pares no relacionados (m, k) en el nuevo algoritmo en lugar de una solución aproximada como en el algoritmo estándar. METODOLOGÍA EXPERIMENTAL 5.1 Conjunto de Datos de Evaluación Para evaluar la técnica propuesta, utilizamos los siguientes tres conjuntos de datos principales (Tabla 1): Datos de MovieLens: Este conjunto de datos fue creado combinando las valoraciones de relevancia del conjunto de datos de MovieLens[9] con documentos de la Base de Datos de Películas en Internet (IMDB). MovieLens permite a los usuarios clasificar cuánto disfrutaron una película específica en una escala del 1 al 5. Esta calificación de simpatía se utilizó como una medida de cuán relevante es el documento que representa la película correspondiente para el usuario. Consideramos los documentos con puntuaciones de 4 o 5 como relevantes, y los documentos con una puntuación de 1 a 3 como irrelevantes para el usuario. MovieLens proporcionó juicios de relevancia sobre 3,057 documentos de 6,040 usuarios diferentes. En promedio, cada usuario calificó 151 películas, de las cuales 87 fueron consideradas relevantes. La puntuación promedio para un documento fue de 3.58. Los documentos que representan cada película fueron construidos a partir de la porción de la base de datos de IMDB que está disponible para descarga pública[13]. Basándonos en esta base de datos, creamos un documento por película que contenía la información relevante sobre ella (por ejemplo, directores, actores, etc.). Tabla 1: Estadísticas del conjunto de datos. En Reuters, el número de calificaciones para un usuario simulado es el número de documentos relevantes para el tema correspondiente. Datos Usuarios Documentos Calificaciones por Usuario MovieLens 6,040 3,057 151 Netflix-todos 480,189 17,770 208 Netflix-1000 1000 17,770 127 Reuters-C 34 100,000 3949 Reuters-E 26 100,000 1632 Reuters-G 33 100,000 2222 Reuters-M 10 100,000 6529 Datos de Netflix: Este conjunto de datos fue construido combinando documentos sobre películas obtenidos de la web con un conjunto de juicios de relevancia de clientes reales de alquiler de películas de Netflix[19]. Netflix proporciona públicamente las evaluaciones de relevancia de 480,189 clientes anónimos. Hay alrededor de 100 millones de calificaciones en una escala del 1 al 5 para 17,770 documentos. Similar a MovieLens, consideramos documentos con puntuaciones de 4 o 5 de agradabilidad como relevantes. Este número se redujo a 1000 clientes mediante muestreo aleatorio. El cliente promedio en el conjunto de datos reducido proporcionó 127 juicios, de los cuales 70 fueron considerados relevantes. La puntuación promedio de los documentos es de 3.55. Datos de Reuters: Este es el Corpus de Reuters, Volumen 1. Cubre 810,000 noticias en inglés de Reuters desde el 20 de agosto de 1996 hasta el 19 de agosto de 1997. Solo se utilizaron las primeras 100,000 noticias en nuestros experimentos. El corpus de Reuters viene con una jerarquía de temas. Cada documento se asigna a una de varias ubicaciones en el árbol jerárquico. El primer nivel del árbol contiene cuatro temas, denotados como C, E, M y G. Para los experimentos en este artículo, el árbol fue cortado en el nivel 1 para crear cuatro árboles más pequeños, cada uno de los cuales corresponde a un conjunto de datos más pequeño: Reuters-E, Reuters-C, Reuters-M y Reuters-G. Para cada conjunto de datos pequeño, creamos varios perfiles, un perfil para cada nodo en un subárbol, para simular múltiples usuarios, cada uno con una definición de relevancia relacionada pero separada. Todos los perfiles de usuario en una sub-rama se supone que comparten la misma distribución de modelo previo. Dado que este corpus indica explícitamente solo los documentos relevantes para un tema (usuario), todos los demás documentos se consideran irrelevantes. 5.2 Evaluación Diseñamos los experimentos para responder a las siguientes tres preguntas: 1. ¿Necesitamos hacer el esfuerzo de utilizar un enfoque bayesiano y aprender una distribución a priori de otros usuarios? 2. ¿El nuevo algoritmo funciona mejor que el algoritmo EM estándar para aprender el modelo lineal jerárquico bayesiano? 3. ¿Puede el nuevo algoritmo aprender rápidamente muchos modelos de usuario? Para responder a la primera pregunta, comparamos los modelos jerárquicos bayesianos con los modelos de regresión lineal regularizados Norm-2 comúnmente utilizados. De hecho, el enfoque comúnmente utilizado es equivalente al modelo aprendido al final de la primera iteración de EM. Para responder a la segunda pregunta, comparamos el nuevo algoritmo propuesto con el algoritmo EM estándar para ver si el nuevo algoritmo de aprendizaje es mejor. Para responder a la tercera pregunta, probamos la eficiencia del nuevo algoritmo en todo el conjunto de datos de Netflix, donde aproximadamente medio millón de modelos de usuario deben ser aprendidos juntos. Para los conjuntos de datos de MovieLens y Netflix, la efectividad del algoritmo se midió mediante el error cuadrático medio, mientras que en el conjunto de datos de Reuters se utilizó el error de clasificación porque era más informativo. Primero evaluamos el rendimiento en cada usuario individual, y luego estimamos el promedio macro sobre todos los usuarios. Se realizaron pruebas estadísticas (pruebas t) para determinar si los resultados son significativos. Para los experimentos en los conjuntos de datos de MovieLens y Netflix, utilizamos una muestra aleatoria del 90% de cada usuario para entrenamiento, y el resto para pruebas. En el conjunto de datos de Reuters, debido a que hay demasiados documentos relevantes para cada tema en el corpus, utilizamos una muestra aleatoria del 10% de cada tema para el entrenamiento, y el 10% de los documentos restantes para las pruebas. Para todas las ejecuciones, establecimos (a, b, c, Σ) = (0.1, 10, 0.1, 1) manualmente. 6. RESULTADOS EXPERIMENTALES Las Figuras 2, 3 y 4 muestran que en todos los conjuntos de datos, el enfoque de modelado jerárquico bayesiano tiene una mejora estadísticamente significativa sobre el modelo de regresión lineal regularizado, que es equivalente a los modelos jerárquicos bayesianos aprendidos en la primera iteración. Un análisis adicional muestra una correlación negativa entre la cantidad de datos de entrenamiento para un usuario y la mejora que obtiene el sistema. Esto sugiere que la información prestada de otros usuarios tiene mejoras más significativas para usuarios con menos datos de entrenamiento, lo cual es lo esperado. Sin embargo, la fuerza de la correlación varía entre los conjuntos de datos, y la cantidad de datos de entrenamiento no es la única característica que influirá en el rendimiento final. Las Figuras 2 y 3 muestran que el nuevo algoritmo propuesto funciona mejor que el algoritmo EM estándar en los conjuntos de datos de Netflix y MovieLens. Esto no es sorprendente ya que el número de pares de características-usuarios relacionados es mucho menor que el número de pares de características-usuarios no relacionados en estos dos conjuntos de datos, por lo que se espera que el nuevo algoritmo propuesto funcione mejor. La Figura 4 muestra que los dos algoritmos funcionan de manera similar en el conjunto de datos de Reuters-E. La precisión del nuevo algoritmo es similar a la del algoritmo EM estándar en cada iteración. Los patrones generales son muy similares en otros subconjuntos de Reuters. Un análisis adicional muestra que solo el 58% de los pares usuario-característica no están relacionados en este conjunto de datos. Dado que el número de pares usuario-característica no relacionados no es extremadamente grande, la dispersión no es un problema grave en el conjunto de datos de Reuters. Por lo tanto, los dos algoritmos de aprendizaje se desempeñan de manera similar. Los resultados sugieren que solo en un corpus donde el número de pares usuario-característica no relacionados es mucho mayor que el número de pares relacionados, como en el conjunto de datos de Netflix, la técnica propuesta obtendrá una mejora significativa sobre el EM estándar. Sin embargo, los experimentos también muestran que cuando la suposición no se cumple, el nuevo algoritmo no afecta el rendimiento. Aunque la técnica propuesta es más rápida que la estándar. Figura 2: Rendimiento en un subconjunto de Netflix con 1,000 usuarios. El nuevo algoritmo es estadísticamente significativamente mejor que el algoritmo EM en las iteraciones 2 a 10. Los modelos lineales regularizados con norma-2 son equivalentes a los modelos jerárquicos bayesianos aprendidos en la primera iteración, y son estadísticamente significativamente peores que los modelos jerárquicos bayesianos. Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional 1 2 3 4 5 6 7 8 9 10 0.33 0.34 0.35 0.36 0.37 0.38 0.39 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional Figura 3: Rendimiento en un subconjunto de MovieLens con 1,000 usuarios. El nuevo algoritmo es significativamente mejor estadísticamente que el algoritmo EM en las iteraciones 2 a 17 (evaluado con error cuadrático medio). 1 6 11 16 21 0.5 1 1.5 2 2.5 3 3.5 Iteraciones ErrorCuadráticoMedio Nuevo Algoritmo EM Tradicional 1 6 11 16 21 0.35 0.4 0.45 0.5 0.55 0.6 0.65 Iteraciones Error de Clasificación Nuevo Algoritmo EM Tradicional Figura 4: Rendimiento en un subconjunto de Reuters-E con 26 perfiles. Las actuaciones en Reuters-C, Reuters-M, Reuters-G son similares. 1 2 3 4 5 0.011 0.0115 0.012 0.0125 0.013 0.0135 0.014 Iteraciones Error cuadrático medio Nuevo algoritmo EM tradicional EM 1 2 3 4 5 0.0102 0.0104 0.0106 0.0108 0.011 0.0112 0.0114 Iteraciones Error de clasificación Nuevo algoritmo EM tradicional EM, ¿realmente puede aprender rápidamente millones de modelos de usuario? Nuestros resultados muestran que el algoritmo EM modificado converge rápidamente, y 2-3 iteraciones del EM modificado darían como resultado una estimación confiable. Evaluamos el algoritmo en todo el conjunto de datos de Netflix (480,189 usuarios, 159,836 características y 100 millones de valoraciones) ejecutándolo en un solo PC con CPU (2GB de memoria, P4 3GHz). El sistema completó una iteración EM modificada en aproximadamente 4 horas. Esto demuestra que la técnica propuesta puede manejar eficientemente sistemas a gran escala como Netflix. CONCLUSIÓN El aprendizaje de perfiles de usuario basado en contenido es un problema importante y es clave para proporcionar recomendaciones personales a un usuario, especialmente para recomendar nuevos elementos con un pequeño número de calificaciones. El enfoque de modelado jerárquico bayesiano se está convirtiendo en un enfoque importante para el aprendizaje de perfiles de usuario debido a su capacidad teóricamente justificada para ayudar a un usuario a través de la transferencia de información de otros usuarios mediante hiperpriors. Este artículo examinó la debilidad del enfoque de aprendizaje basado en EM popular para modelos lineales jerárquicos bayesianos y propuso una técnica de aprendizaje mejorada llamada EM Modificado. Demostramos que la nueva técnica es teóricamente más eficiente computacionalmente que el algoritmo EM estándar. La evaluación en los conjuntos de datos de MovieLens y Netflix demostró la efectividad de la nueva técnica cuando los datos son dispersos, lo que significa que la proporción de pares de usuario-característica relacionados con respecto a los pares no relacionados es pequeña. La evaluación en el conjunto de datos de Reuters mostró que la nueva técnica tuvo un rendimiento similar al algoritmo EM estándar cuando la condición de dispersión no se cumple. En general, es mejor utilizar el nuevo algoritmo ya que es tan simple como el EM estándar, el rendimiento es igual o mejor que el del EM, y la complejidad computacional es menor en cada iteración. Vale la pena mencionar que aunque el espacio de problemas original no sea disperso, la dispersión puede crearse artificialmente cuando un sistema de recomendación utiliza técnicas de selección de características específicas del usuario para reducir el ruido y la complejidad del modelo del usuario. La técnica propuesta también puede adaptarse para mejorar el aprendizaje en dicho escenario. También demostramos que la técnica propuesta puede aprender medio millón de perfiles de usuario a partir de 100 millones de valoraciones en unas pocas horas con una sola CPU. La investigación es importante porque la escalabilidad es una preocupación importante para los investigadores al utilizar el enfoque de modelado lineal jerárquico bayesiano para construir un sistema a gran escala práctico, a pesar de que la literatura ha demostrado la efectividad de los modelos en muchas aplicaciones. Nuestro trabajo es un paso importante en el camino para hacer que los modelos lineales jerárquicos bayesianos sean más prácticos. La nueva técnica propuesta se puede adaptar fácilmente para ejecutarse en un clúster de máquinas, y así acelerar aún más el proceso de aprendizaje para manejar un sistema a mayor escala con cientos de millones de usuarios. La investigación tiene mucho potencial para beneficiar a las personas utilizando el algoritmo EM en muchos otros problemas de IR, así como en problemas de aprendizaje automático. El algoritmo EM es una técnica de aprendizaje automático comúnmente utilizada. Se utiliza para encontrar los parámetros del modelo en muchos problemas de IR donde los datos de entrenamiento son muy dispersos. Aunque nos estamos centrando en los modelos lineales jerárquicos bayesianos para recomendación y filtrado, la nueva idea de utilizar una solución analítica en lugar de una solución numérica para pares de usuario-característica no relacionados en el paso M podría adaptarse a muchos otros problemas. 8. AGRADECIMIENTOS Agradecemos a Wei Xu, David Lewis y a los revisores anónimos por sus valiosos comentarios sobre el trabajo descrito en este artículo. Parte del trabajo fue apoyado por Yahoo, Google, el Instituto de Almacenamiento de Datos a Escala Peta y el Instituto de Gestión de Datos Científicos Escalables. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son responsabilidad de los autores y no reflejan necesariamente las de los patrocinadores. REFERENCIAS [1] C. Basu, H. Hirsh y W. Cohen. Recomendación como clasificación: Utilizando información social y basada en contenido en la recomendación. En Actas de la Decimoquinta Conferencia Nacional de Inteligencia Artificial, 1998. [2] J. S. Breese, D. Heckerman y C. Kadie. Análisis empírico de algoritmos predictivos para filtrado colaborativo. Informe técnico, Microsoft Research, One Microsoft Way, Redmond, WA 98052, 1998. [3] J. Callan. Filtrado de documentos con redes de inferencia. En Actas de la Decimonovena Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 262-269, 1996. [4] N. Cancedda, N. Cesa-Bianchi, A. Conconi, C. Gentile, C. Goutte, T. Graepel, Y. Li, J. M. Renders, J. S. Taylor y A. Vinokourov. Método del núcleo para el filtrado de documentos. En la Undécima Conferencia de Recuperación de Información de Texto (TREC11). Instituto Nacional de Normas y Tecnología, publicación especial 500-249, 2003. [5] C. Chelba y A. Acero. Adaptación del capitalizador de entropía máxima: Poca información puede ayudar mucho. En D. Lin y D. Wu, editores, Actas de EMNLP 2004, páginas 285-292, Barcelona, España, julio de 2004. Asociación de Lingüística Computacional. [6] B. Croft y J. Lafferty, editores. Modelado de lenguaje para recuperación de información. Kluwer, 2002. [7] A. Dayanik, D. D. Lewis, D. Madigan, V. Menkov y A. Genkin. Construyendo distribuciones a priori informativas a partir del conocimiento del dominio en la clasificación de textos. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 493-500, Nueva York, NY, EE. UU., 2006. ACM Press. [8] J. Delgado y N. Ishii. Predicción basada en memoria ponderada para sistemas de recomendación. En el Taller ACM SIGIR99 sobre Sistemas de Recomendación, 1999. [9] GroupLens. Movielens. http://www.grouplens.org/taxonomy/term/14, 2006. [10] D. Heckerman. Un tutorial sobre el aprendizaje con redes bayesianas. En M. Jordan, editor, Aprendizaje en Modelos Gráficos. Kluwer Academic, 1998. [11] J. L. Herlocker, J. 

Kluwer Academic, 1998. [11] J. L. Herlocker, J. A. Konstan, A. Borchers y J. Riedl. Un marco algorítmico para realizar filtrado colaborativo. En SIGIR 99: Actas de la 22ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 230-237, Nueva York, NY, EE. UU., 1999. ACM Press. [12] T. Hofmann y J. Puzicha. Modelos de clases latentes para filtrado colaborativo. En IJCAI 99: Actas de la Decimosexta Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 688-693, San Francisco, CA, EE. UU., 1999. Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB).
Morgan Kaufmann Publishers Inc. [13] I. M. D. (IMDB). Base de datos de películas en internet. http://www.imdb.com/interfaces/, 2006. [14] R. Jin, J. Y. Chai y L. Si. Un esquema de ponderación automática para filtrado colaborativo. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 337-344, Nueva York, NY, EE. UU., 2004. ACM Press. [15] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon y J. Riedl. GroupLens: Aplicando filtrado colaborativo a las noticias de Usenet. Comunicaciones de la ACM, 40(3):77-87, 1997. [16] D. Lewis. Aplicando máquinas de vectores de soporte a las tareas de filtrado y enrutamiento por lotes de TREC-2001. En Actas de la Undécima Conferencia de Recuperación de Texto (TREC-11), 2002. [17] B. Liu, X. Li, W. S. Lee y P. Yu. Clasificación de texto mediante etiquetado de palabras. En Actas de la Decimonovena Conferencia Nacional de Inteligencia Artificial (AAAI-2004), 25-29 de julio de 2004. [18] P. Melville, R. J. Mooney y R. Nagarajan. Filtrado colaborativo potenciado por contenido para recomendaciones mejoradas. En Actas de la Decimoctava Conferencia Nacional de Inteligencia Artificial (AAAI-2002), Edmonton, Canadá, 2002. [19] Netflix. Premio Netflix. http://www.netflixprize.com (visitado el 30 de noviembre de 2006), 2006. [20] S. Robertson y K. Sparck-Jones. Ponderación de la relevancia de los términos de búsqueda. En Journal of the American Society for Information Science, volumen 27, páginas 129-146, 1976. [21] J. Wang, A. P. de Vries y M. J. T. Reinders. Unificando enfoques de filtrado colaborativo basados en usuarios y en elementos mediante la fusión de similitudes. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 501-508, Nueva York, NY, EE. UU., 2006. ACM Press. [22] X. Wu y R. K. Srihari. Incorporando conocimientos previos con máquinas de vectores de soporte de margen ponderado. En Proc. Conferencia de Minería de Datos y Descubrimiento de Conocimiento de ACM (ACM SIGKDD 2004), agosto de 2004. [23] Y. Yang, S. Yoo, J. Zhang y B. Kisiel. Robustez de los métodos de filtrado adaptativo en una evaluación de referencia cruzada. En Actas de la 28ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2005. [24] K. Yu, V. Tresp y A. Schwaighofer. Aprendiendo procesos gaussianos de múltiples tareas. En ICML 05: Actas de la 22ª conferencia internacional sobre aprendizaje automático, páginas 1012-1019, Nueva York, NY, EE. UU., 2005. ACM Press. [25] K. Yu, V. Tresp, y S. Yu. Un marco bayesiano jerárquico no paramétrico para el filtrado de información. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 353-360. ACM Press, 2004. [26] X. Zhu. 

ACM Press, 2004. [26] X. Zhu. Revisión de la literatura sobre aprendizaje semisupervisado. Informe técnico, Universidad de Wisconsin - Madison, 9 de diciembre de 2006. [27] P. Zigoris y Y. Zhang. Perfilado de usuario bayesiano adaptativo con retroalimentación explícita e implícita. En la Conferencia sobre Gestión de la Información y el Conocimiento 2006, 2006.