Aplicaciones autoadaptativas en la red Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de Sistemas Informáticos, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Resumen Las redes de computadoras son inherentemente heterogéneas y dinámicas. Un problema importante en la computación en malla es la selección de recursos, es decir, encontrar un conjunto de recursos adecuado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la red. Las soluciones existentes para estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación a partir de estas estadísticas. Luego, ajustamos el conjunto de recursos para que se adapte mejor a las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos, y por lo tanto puede generar mejoras significativas en el rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos para la Red. Categorías y Descriptores de Asignaturas C.2.4 [REDES DE COMUNICACIÓN DE COMPUTADORAS]: Sistemas Distribuidos-Aplicaciones Distribuidas; C.4 [RENDIMIENTO DE SISTEMAS]: Técnicas de Medición, Técnicas de Modelado Términos Generales Algoritmos, Medición, Rendimiento, Experimentación 1. En los últimos años, la computación en malla se ha convertido en una verdadera alternativa a la computación paralela tradicional. Una red proporciona una gran potencia computacional, y por lo tanto ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo. Sin embargo, la complejidad de los entornos de Grid es muchas veces mayor que la de las máquinas paralelas tradicionales como los clústeres y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cálculo de manera que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera experimental. En un entorno de cuadrícula, este problema es aún más difícil debido a la heterogeneidad de recursos: los nodos de cálculo tienen diversas velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local (LAN) de baja latencia y alta velocidad de banda ancha hasta redes de área amplia (WAN) de alta latencia y posiblemente baja velocidad de banda ancha. Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la red varían con el tiempo: los enlaces de red o los nodos de cálculo pueden sobrecargarse, o los nodos de cálculo pueden volverse no disponibles debido a fallos o porque han sido reclamados por una aplicación de mayor prioridad. Además, nuevos y mejores recursos pueden estar disponibles. Para mantener un nivel de rendimiento razonable, la aplicación necesita adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares, cuando se detecta un problema de rendimiento o cuando se disponen de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, se estima el tiempo de ejecución de la aplicación para algunos conjuntos de recursos y se selecciona el conjunto que produce el tiempo de ejecución más corto para la ejecución. Predecir el tiempo de ejecución de la aplicación en un conjunto dado de recursos, sin embargo, requiere conocimiento sobre la aplicación. Normalmente, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere de una experiencia que los programadores de aplicaciones pueden no tener. En este artículo, presentamos y evaluamos un enfoque alternativo para la adaptación de aplicaciones y la selección de recursos que no requiere un modelo de rendimiento. Iniciamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, recopilamos periódicamente información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos en el que se está ejecutando la aplicación agregando o eliminando nodos de cálculo o incluso clústeres enteros. Nuestra estrategia de adaptación utiliza el trabajo de Eager et al. (10) para determinar la eficiencia y trata de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para mantenerse entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación en malla. Nuestro trabajo asume que la aplicación es maleable y puede ejecutarse (eficientemente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación). Se encarga de todos los casos siguientes: • adaptar automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante la computación • migrar (parte de) una computación lejos de recursos sobrecargados • eliminar recursos con enlaces de comunicación deficientes que ralentizan la computación • añadir nuevos recursos para reemplazar a los recursos que han fallado. No debería utilizar equilibrio de carga estático o ser muy sensible a las latencias de amplia área. Hemos aplicado nuestras ideas a aplicaciones de dividir y conquistar, que cumplen con estos requisitos. La técnica de divide y vencerás ha demostrado ser un paradigma atractivo para programar aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede ser extendido a otras clases de aplicaciones con las suposiciones dadas. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones de división y conquista habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y demostraremos que nuestro enfoque produce importantes mejoras de rendimiento (aproximadamente del 10 al 60 %) en los escenarios mencionados anteriormente. El resto de este documento está estructurado de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red eléctrica. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco de trabajo Satin. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro. 2. Antecedentes y suposiciones En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se están ejecutando en múltiples sitios al mismo tiempo, donde los sitios son clústeres o supercomputadoras. También asumimos que los procesadores de los sitios son accesibles utilizando un sistema de programación en cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores pertenecientes a un sitio están conectados por una LAN rápida con baja latencia y alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre los sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la columna vertebral de Internet podrían convertirse en cuellos de botella, lo que causaría que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y vencerás. Sin embargo, creemos que nuestra metodología también puede ser utilizada para otros tipos de aplicaciones. En esta sección resumimos las suposiciones sobre las aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y abandonan la computación en curso. En (23), mostramos cómo las aplicaciones de dividir y conquistar pueden hacerse tolerantes a fallos y maleables. Los procesadores pueden ser añadidos o removidos en cualquier momento durante la computación con poco costo adicional. La segunda suposición es que la aplicación puede ejecutarse eficientemente en procesadores con velocidades diferentes. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámico, como el robo de trabajo utilizado por aplicaciones de divide y vencerás (19). Además, las aplicaciones maestro-trabajador suelen utilizar estrategias de equilibrio de carga dinámico (por ejemplo, MW - un marco para escribir aplicaciones maestro-trabajador habilitadas para la cuadrícula (12)). Consideramos que es una suposición razonable para una aplicación de red, ya que las aplicaciones para las cuales el procesador más lento se convierte en un cuello de botella no podrán utilizar eficientemente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de gran área, para que pueda ejecutarse eficientemente en una cuadrícula de gran área. Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación dada y adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional a la computación que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de la aplicación. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de los procesadores de aplicaciones para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o quitar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben ser eliminados. Durante este proceso, el coordinador aprende los requisitos de la aplicación recordando las características de los procesadores eliminados. Estos requisitos se utilizan luego para guiar la incorporación de nuevos procesadores. 3.1 Eficiencia promedio ponderada En la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan realizando trabajo útil en lugar de estar inactivos o comunicándose con otros procesadores (10). eficiencia = 1 n ∗ n i=0 (1 − sobrecarga i ) donde n es el número de procesadores y sobrecarga i es la fracción de tiempo que el i-ésimo procesador pasa inactivo o comunicándose. La eficiencia indica el beneficio de utilizar múltiples procesadores. Normalmente, la eficiencia disminuye a medida que se añaden nuevos procesadores al cálculo. Por lo tanto, lograr una alta aceleración (y por ende un bajo tiempo de ejecución) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es aquel para el cual la proporción de eficiencia respecto al tiempo de ejecución se maximiza. Agregar procesadores más allá de este número aporta poco beneficio. Este número suele ser difícil de encontrar, pero en (10) se demostró teóricamente que si se utilizan el número óptimo de procesadores, la eficiencia es de al menos el 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias significativas en el rendimiento. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada. La eficiencia ponderada promedio se calcula como 1 n ∗ n i=0 velocidadi ∗ (1 − sobrecargai ). El trabajo útil realizado por un procesador (1 − sobrecargai) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene una velocidad = 1, para los demás se cumple: 0 < velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como rápidos que pasan una gran fracción del tiempo inactivos. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficios que agregar procesadores rápidos. En el mundo heterogéneo, apenas es beneficioso añadir procesadores si la eficiencia es menor al 50% a menos que el procesador añadido sea más rápido que algunos de los procesadores actualmente utilizados. Agregar procesadores más rápidos podría ser beneficioso independientemente de la eficiencia. 3.2 Monitoreo de aplicaciones Cada procesador mide el tiempo que pasa comunicándose o estando inactivo. La computación se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan sus costos indirectos durante este período como el porcentaje del tiempo que pasaron inactivos o comunicándose en este período. Además del gasto general, cada procesador también calcula el gasto de comunicación entre clústeres y dentro de un clúster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, las cuales dependen de la aplicación y del tamaño del problema utilizado. Dado que es impráctico ejecutar la aplicación completa de 122 en cada procesador por separado, utilizamos benchmarks específicos de la aplicación. Actualmente utilizamos la misma aplicación con un tamaño de problema pequeño como referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional por parte del programador para encontrar el tamaño correcto del problema y posiblemente para producir archivos de entrada para este tamaño de problema, lo cual puede ser difícil. En el futuro, planeamos generar puntos de referencia automáticamente seleccionando un subconjunto aleatorio del grafo de tareas de la aplicación original. Los puntos de referencia deben ser ejecutados periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga con otra aplicación (para máquinas de tiempo compartido). Existe un compromiso entre la precisión de las mediciones de velocidad y la sobrecarga que conlleva. Cuanto más largo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más se ejecute, más rápido se detectan los cambios en la velocidad del procesador. En nuestra implementación actual, el programador de la aplicación especifica la longitud del benchmark (al especificar su tamaño de problema) y la máxima sobrecarga que se le permite causar. Los procesadores ejecutan la prueba de referencia a una frecuencia tal que no exceda la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador, lo que nos permitiría evitar ejecutar la evaluación comparativa si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de referencia. Tenga en cuenta que el sobrecosto de la evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones maestro-trabajador con tareas de tamaño igual o similar. La velocidad del procesador podría entonces medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de divide y vencerás suelen presentar una estructura muy irregular. Los tamaños de las tareas pueden variar por muchas órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades de los procesadores al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como el promedio de sobrecarga inter-cluster o las sobrecargas en cada clúster. Los relojes de los procesadores no están sincronizados entre sí ni con el reloj del coordinador. Cada procesador decide por separado cuándo es el momento de enviar datos. Ocasionalmente, el coordinador puede omitir datos al final de un período de monitoreo, por lo que debe utilizar los datos del período de monitoreo anterior para estos procesadores. Esto provoca pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación. 3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede Emax, el coordinador solicita nuevos procesadores al planificador. El número de procesadores solicitados depende de la eficiencia actual: a mayor eficiencia, se solicitan más procesadores. El coordinador comienza a retirar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que utilizamos son Emax = 50%, porque sabemos que agregar procesadores cuando la eficiencia es más baja no tiene sentido, y Emin = 30%. Una eficiencia del 30% o menos podría indicar problemas de rendimiento como ancho de banda bajo o procesadores sobrecargados. En ese caso, eliminar los procesadores defectuosos será beneficioso para la aplicación. Una eficiencia tan baja también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, quitar algunos procesadores puede que no sea beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los procesadores más deficientes. La maldad de un procesador se determina mediante la siguiente fórmula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i). El procesador se considera malo si tiene baja velocidad (1 speed es grande) y un alto sobrecosto inter-cluster (ic overhead). Un alto sobrecosto intercluster indica que el ancho de banda hacia este clúster de procesadores es insuficiente. Eliminar procesadores ubicados en un único clúster es deseable ya que disminuye la cantidad de comunicación de área amplia. Por lo tanto, se prefieren los procesadores pertenecientes al peor clúster. La función inWorstCluster(i) devuelve 1 para los procesadores que pertenecen al peor clúster y 0 en caso contrario. La maldad de los grupos se calcula de manera similar a la maldad de los procesadores: maldad del grupo i = α ∗ 1 velocidadi + β ∗ sobrecargai. La velocidad de un grupo es la suma de las velocidades de los procesadores normalizada a la velocidad del grupo más rápido. El gasto general de un clúster es un promedio de los gastos entre clústeres del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen de manera empírica. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, basados en la observación de que un gasto en sobrecarga de ic > 0.2 indica problemas de ancho de banda y procesadores con velocidad < 0.05 no contribuyen a la computación. Además, cuando uno de los clústeres tiene un sobrecosto inter-clúster excepcionalmente alto (mayor a 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la columna vertebral de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el grupo en lugar de calcular la mala calidad del nodo y eliminar los nodos peores. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos abandonan la computación. La Figura 1 muestra una vista esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no está soportada, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas para la Grid: • Si una aplicación se inicia en menos procesadores de los que permite su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como haya recursos adicionales disponibles). Por el contrario, si una aplicación se inicia en más procesadores de los que puede utilizar eficientemente, se liberará una parte de los procesadores. • Si una aplicación se está ejecutando en un conjunto adecuado de recursos pero después de un tiempo algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, los recursos sobrecargados serán eliminados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el coordinador de adaptación intentará añadir nuevos recursos. Por lo tanto, la aplicación será migrada de recursos sobrecargados. • Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, si el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados serán eliminados. Si es necesario, el componente de adaptación intentará agregar otros recursos. • Si durante el cálculo una parte sustancial de los procesadores falla, el componente de adaptación intentará agregar nuevos recursos para reemplazar a los procesadores fallidos. 123 0 2000 4000 6000 tiempo de ejecución (segundos). Escenario 0 a b c Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, escenarios 0-5, añaden nodos más rápidamente nodos disponibles si se calcula la eficiencia promedio ponderada E wa esperar y recopilar estadísticas clasificar nodos eliminar los peores nodos waE Ewa Y N N Y arriba si abajo si Emin maxE Figura 1. Estrategia de adaptación • Si el grado de paralelismo de la aplicación cambia durante la computación, el número de nodos en los que se está ejecutando la aplicación se ajustará automáticamente. Se pueden realizar mejoras adicionales, pero requieren funcionalidades adicionales del planificador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar agregando nodos a una computación. Actualmente, agregamos cualquier nodo que nos proporcione el planificador. Sin embargo, sería más eficiente preguntar por los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, pasando un punto de referencia al planificador de la red, para que pueda medir las velocidades del procesador de una manera específica para la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los clústeres y supercomputadoras suelen ser homogéneos. Un enfoque alternativo sería clasificar los procesadores según parámetros como la velocidad de reloj y el tamaño de la caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que utilizar una prueba de referencia específica de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de la aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se ajusta cada vez que se elimina un clúster con una alta sobrecarga entre clústeres. El ancho de banda entre cada par de clústeres se estima durante la computación midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de red. Tales límites pueden ser pasados al planificador para evitar añadir recursos inapropiados. Es especialmente importante al migrar de recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente utilizamos listas negras: simplemente no permitimos agregar recursos que eliminamos anteriormente. Esto significa, sin embargo, que no podemos utilizar estos recursos incluso si la causa del problema de rendimiento desaparece, por ejemplo, el ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar migraciones oportunísticas, es decir, migrar a recursos mejores cuando son descubiertos. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no tomará ninguna acción, incluso si se disponen de recursos mejores. Permitir la migración oportunista requiere, una vez más, la capacidad de especificar al programador de tareas qué recursos son mejores (más rápidos, con un ancho de banda mínimo determinado) y recibir notificaciones cuando dichos recursos estén disponibles. Los planificadores de red existentes, como GRAM de la Herramienta Globus, no admiten esa funcionalidad. Los desarrolladores del metaplanificador KOALA (15) recientemente han iniciado un proyecto cuyo objetivo es proporcionar soporte para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de ampliar nuestra estrategia de adaptabilidad para apoyar la migración oportunista y mejorar la selección inicial de recursos. Implementación. Incorporamos nuestro mecanismo de adaptación en Satin, un marco de trabajo en Java para crear aplicaciones de división y conquista habilitadas para la cuadrícula. Con Satin, el programador anota el código secuencial con primitivas de divide y vencerás y compila el código anotado con un compilador especial de Satin que genera el código de comunicación y equilibrio de carga necesario. Satin utiliza un algoritmo de equilibrio de carga muy eficiente y consciente de la cuadrícula: Cluster-aware Random Work Stealing (CRS) (19), que oculta las latencias de área amplia al superponer el robo local y remoto. Satin también proporciona tolerancia a fallos transparente y maleabilidad (23). Con Satin, quitar y añadir procesadores a una computación en curso conlleva poco sobrecosto. Instrumentamos el sistema de tiempo de ejecución Satin para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como Satin están implementados completamente en Java sobre la biblioteca de comunicación Ibis (21). El núcleo de Ibis también está implementado en Java. El sistema resultante, por lo tanto, es altamente portable (debido a la propiedad de Java de escribir una vez, ejecutar en cualquier lugar), lo que permite que el software se ejecute sin modificaciones en una cuadrícula heterogénea. Ibis también proporciona el Registro Ibis. El Registro proporciona, entre otros servicios, un servicio de membresía a los procesadores que participan en la computación. El coordinador de adaptación utiliza el Registro para descubrir los procesos de aplicación, y los procesos de aplicación utilizan este servicio para descubrirse mutuamente. El Registro también ofrece detección de fallos (además de la detección de fallos proporcionada por los canales de comunicación). Finalmente, el Registro proporciona la posibilidad de enviar señales a los procesos de la aplicación. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan abandonar la computación. Actualmente, el Registro está implementado como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9) - un middleware de supercomputación peer-to-peer que permite la asignación sencilla de procesadores en múltiples clústeres y/o supercomputadoras. Zorilla proporciona programación consciente de la localidad, la cual intenta asignar procesadores que estén ubicados cerca uno del otro en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación consciente del ancho de banda, que intenta maximizar el ancho de banda total en el sistema. Zorilla puede ser fácilmente reemplazado por otro planificador de cuadrícula. En el futuro, planeamos integrar nuestro componente de adaptación con GAT (3), que se está convirtiendo en un estándar en la comunidad de la red y KOALA (15), un planificador que proporciona co-asignación sobre middleware de red estándar, como el Globus Toolkit (11). Evaluación del rendimiento En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de manera que la eficiencia sea alrededor del 50%) y no se presentan problemas como redes y procesadores sobrecargados, procesadores que se bloquean, etc. Este escenario nos permite medir el sobrecosto del soporte de adaptación. Los escenarios restantes son típicos para entornos de red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento graves, como procesadores sobrecargados o enlaces de red saturados. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza ningún benchmarking (para medir la velocidad de los procesadores). En el escenario ideal, 0 5 10 15 número de iteración 0 200 400 600 duración de la iteración (seg.) comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos comenzando en 8 nodos comenzando en 16 nodos comenzando en 24 nodos sin adaptación con adaptación Figura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación carga de CPU introducida nodos sobrecargados eliminados comenzaron a agregar nodos 36 nodos alcanzados Figura 4. Durante las iteraciones de Barnes-Hut con/sin adaptación, medimos adicionalmente el rendimiento de una aplicación con la recopilación de estadísticas y la realización de pruebas de referencia activadas, pero sin realizar adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir el costo adicional de realizar pruebas de rendimiento y recopilar estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área amplia DAS-2 (8), que consiste en cinco clústeres ubicados en cinco universidades holandesas. Uno de los grupos consiste en 72 nodos, los otros en 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los clústeres están conectados por la columna vertebral de Internet de la universidad holandesa. En nuestros experimentos, utilizamos la simulación N-cuerpos de Barnes-Hut. BarnesHut simula la evolución de un gran conjunto de cuerpos bajo la influencia de fuerzas (gravitacionales o electrostáticas). La evolución de N cuerpos se simula en iteraciones de pasos de tiempo discretos. Escenario 5.1: sobrecarga de adaptabilidad En este escenario, la aplicación se inicia en 36 nodos. Los nodos están divididos de manera equitativa en 3 grupos (12 nodos en cada grupo). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, recopilación de estadísticas y pruebas de rendimiento) activado pero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Los tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra el sobrecosto del soporte de adaptación. En este experimento es alrededor del 15%. Casi todos los gastos generales provienen de la comparación con estándares. El punto de referencia se ejecuta de 1 a 2 veces por período de monitoreo. Este sobrecosto se puede reducir al aumentar la duración del período de monitoreo y disminuir la frecuencia de referencia. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, ya que el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de larga duración no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de red del mundo real suelen necesitar horas, días o incluso semanas para completarse. Para tales aplicaciones, se puede utilizar un período de monitoreo mucho más largo y mantener mucho más bajo el costo de adaptación. Por ejemplo, con la aplicación de Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga disminuye al 6%. Cabe destacar que combinar la evaluación comparativa con el monitoreo de la carga del procesador (como se describe en la Sección 3.2) reduciría la sobrecarga de la evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los benchmarks solo necesitarían ejecutarse al inicio del cálculo. 5.2 Escenario 1: expansión a más nodos. En este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede utilizar eficientemente. Esto puede ocurrir porque el usuario no conoce el número correcto de nodos o porque no había suficientes nodos disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1a), 16 (Escenario 1b) y 24 (Escenario 1c). Los nodos estaban ubicados en 1 o 2 grupos. En cada uno de los tres subescenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 clústeres. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (Escenario 1a), un 35% (Escenario 1b) y un 12% (Escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (Escenario 1a), 1.7 (Escenario 1b) y 1.2 (Escenario 1c), lo que nos permite concluir que las ganancias en el tiempo total de ejecución serían aún mayores si la aplicación se ejecutara durante más de 15 iteraciones. Escenario 2: procesadores sobrecargados En este escenario, iniciamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 200 segundos, introdujimos una carga pesada y artificial en los procesadores de uno de los grupos. Una situación así puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de las iteraciones de ambas versiones, adaptativa y no adaptativa. Después de introducir la carga, la iteración 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (seg.) sin adaptación con adaptación un clúster está mal conectado clúster mal conectado eliminado comenzó a agregar nodos 36 nodos alcanzados Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de iteración (seg.) sin adaptación con adaptación un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados clúster mal conectado eliminado 2 nodos ligeramente sobrecargados Figura 6. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, las CPUs sobrecargadas y la duración de un enlace de red sobrecargado aumentaron por un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que desencadenó la adición de nuevos nodos y la aplicación se expandió nuevamente a 38 nodos. Por lo tanto, los nodos sobrecargados fueron reemplazados por nodos mejores, lo que devolvió la duración de la iteración a los valores iniciales. Esto redujo el tiempo total de ejecución en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Simulamos que la conexión ascendente a uno de los clústeres estaba sobrecargada y el ancho de banda en esta conexión ascendente se redujo a aproximadamente 100 KB/s. Para simular un ancho de banda bajo, utilizamos las técnicas de conformación de tráfico descritas en (6). Las duraciones de las iteraciones en este experimento se muestran en la Figura 5. Las duraciones de las iteraciones de la versión no adaptativa muestran una variación enorme: desde 170 hasta 890 segundos. La versión adaptativa eliminó el grupo mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y nuevos nodos fueron añadidos gradualmente hasta que su número alcanzó los 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 60% (Figura 2). Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado. En este escenario, ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Nuevamente, simulamos una conexión ascendente sobrecargada a uno de los clústeres. Además, simulamos procesadores con velocidades heterogéneas al insertar una carga artificial relativamente ligera en los procesadores de uno de los grupos restantes. Las duraciones de las iteraciones se muestran en la Figura 6. Nuevamente, la versión no adaptativa muestra una gran variación en las duraciones de las iteraciones: desde 200 hasta 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, dado que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada solo aumenta a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se añaden ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si se añadieran estos nodos a la aplicación (lo que podría desencadenar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Sin embargo, la adaptación redujo el tiempo total de ejecución en un 30% (Figura 2). Escenario 5.6: nodos que fallan. En el último escenario, también ejecutamos la aplicación en 36 nodos distribuidos en 3 clústeres. Después de 500 segundos, 2 de cada 3 grupos se bloquean. Las duraciones de las iteraciones se muestran en la Figura 7. Después del choque, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó la adición de nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que hizo que la duración de la iteración volviera a ser de alrededor de 100 segundos. El tiempo total de ejecución se redujo en un 13% (Figura 2). Trabajo relacionado: Varios proyectos de Grid abordan la cuestión de la selección y adaptación de recursos. En GrADS (18) y ASSIST (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examina un número de posibles conjuntos de recursos y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta una degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. GrADS utiliza la relación entre los tiempos de ejecución predichos (de ciertas fases de la aplicación) y los tiempos de ejecución reales como indicador del rendimiento de la aplicación. ASSIST utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares maestro-trabajador) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 número de iteración 0 200 400 600 800 1000 duración de la iteración (segundos) sin adaptación con adaptación 2 de 3 clústeres se bloquean, comenzaron a agregar nodos 36 nodos alcanzados Figura 7. Las duraciones de las iteraciones de Barnes-Hut con/sin adaptación, el modelo de colapso de CPUs es conocido, el problema de encontrar un conjunto óptimo de recursos (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-completo. Actualmente, tanto GrADS como ASSIST examinan solo un subconjunto de todos los posibles conjuntos de recursos y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la red disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que pueden ser examinados en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento solo es adecuada para aplicaciones iterativas o regulares. Cactus (2) y GridWay (14) no utilizan modelos de rendimiento. Sin embargo, estos marcos son solo adecuados para aplicaciones secuenciales (GridWay) o de un solo sitio (Cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y el número de procesadores en un clúster (Cactus) se utilizan para clasificar los recursos y se selecciona el recurso con la clasificación más alta. La aplicación se migra si se detecta una degradación del rendimiento o se descubren recursos mejores. Tanto Cactus como GridWay utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que solo es adecuada para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede ser utilizada para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el proyecto AppLeS (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basándose en dicho modelo se construye un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor horario de aplicación en este conjunto. Los agentes de programación de AppLeS se escriben caso por caso y no pueden ser reutilizados para otra aplicación. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, aplicaciones maestro-trabajador (plantilla AMWAT) y aplicaciones de barrido de parámetros (plantilla APST). La migración no es compatible con el software AppLeS. En (13), se estudia el problema de programar aplicaciones maestro-trabajador. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar la cantidad adecuada de trabajadores. El enfoque aquí es similar al nuestro en el sentido de que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de la aplicación en tiempo de ejecución y ajusta el número de trabajadores para acercarse al número ideal. Conclusiones y trabajo futuro En este artículo, investigamos el problema de la selección y adaptación de recursos en entornos de grid. Los enfoques existentes para estos problemas suelen asumir la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Iniciamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite conocer ciertos requisitos de la aplicación, como el número de procesadores necesarios o los requisitos de ancho de banda de las aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no resulta en el conjunto óptimo de recursos, sino en un conjunto razonable de recursos, es decir, un conjunto libre de diversos cuellos de botella de rendimiento como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la cuadrícula. Las decisiones de adaptación se basan en la eficiencia promedio ponderada, una extensión del concepto de eficiencia paralela definido para máquinas paralelas tradicionales y homogéneas. Si la eficiencia promedio ponderada cae por debajo de cierto nivel, el coordinador de adaptación comienza a eliminar los nodos más deficientes. La maldad de los nodos está definida por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se añaden nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos para entornos de red: expandir a más nodos o reducir a menos nodos si la aplicación se inició en un número inapropiado de procesadores, eliminar nodos inadecuados y reemplazarlos por otros mejores, reemplazar procesadores fallidos, etc. La aplicación se adapta completamente de forma automática a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de trabajo de división y conquista Satin y lo evaluamos en el supercomputador distribuido DAS-2, demostrando que nuestro enfoque puede generar mejoras significativas en el rendimiento (de hasta un 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Sin embargo, esto requiere planificadores de red con funcionalidades más sofisticadas de las que existen actualmente. También se necesita realizar más investigaciones para reducir la sobrecarga de comparación. Por ejemplo, la información sobre la carga de la CPU podría utilizarse para disminuir la frecuencia de evaluación del rendimiento. Otra línea de investigación que deseamos investigar es utilizar control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de maldad del nodo podría ser refinada en tiempo de ejecución basándose en la efectividad de las decisiones de adaptación previas. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en un gran número de nodos (cientos o miles). Este problema puede resolverse implementando una jerarquía de coordinadores: un subcoordinador por clúster que recopila y procesa estadísticas de su clúster y un coordinador principal que recopila la información de los subcoordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del proyecto Laboratorio Virtual para e-Ciencia (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencia de los Países Bajos (OC&W) y forma parte del programa de innovación en TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptabilidad de programas/componentes en paralelo. En ParCo 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano del cactus: Experimentos con el descubrimiento y asignación de recursos en un entorno de cuadrícula. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la red - una visión general de gridlab. Revista Internacional de Aplicaciones de Computación de Alto Rendimiento, 17(4):449-466, Ago. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe y E. A. Cervecero. ATLAS: Una infraestructura para la computación global. En el 7º Taller Europeo de ACM SIGOPS sobre Soporte de Sistemas para Aplicaciones Mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la red utilizando AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Abr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en programar un modelador de tráfico. En el 5to Simposio de IEEE sobre Computadoras y Comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. GridSAT: Un solucionador SAT distribuido basado en Chaff para la red. En la conferencia ACM/IEEE sobre Supercomputación de 2003, página 37, 2003. [8] El Supercomputador Distribuido ASCI (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport y H. E. Bal. Co-asignación simple consciente de la localidad en supercomputación entre pares. En el 6º Taller Internacional sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eager, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.
Transacciones de IEEE en Computadoras, 38(3):408-423, Mar. 1989. [11] I. Fomentar. Herramienta Globus versión 4: Software para sistemas orientados a servicios. En la Conferencia Internacional de IFIP sobre Redes y Computación Paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones maestro-trabajador en la malla computacional. En el 9º Simposio Internacional de la IEEE sobre Computación Distribuida de Alto Rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones maestro-trabajador en la rejilla computacional. En el 1er Taller Internacional de Computación en Red IEEE/ACM, páginas 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, e I. M. Llorente. Un marco para la ejecución adaptativa en rejillas. Software - Práctica y Experiencia, 34(7):631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el planificador de asignación conjunta KOALA en multiclústeres. En el 5to Simposio Internacional de IEEE/ACM sobre Computación en Clúster y la GRID, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de las aplicaciones paralelas a grandes diferencias en ancho de banda y latencia en interconexiones de dos capas. En el 5to Simposio Internacional. En Arquitectura de Computadoras de Alto Rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por tablas de transposición en la búsqueda distribuida. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Adaptabilidad automática en la computación en malla. Concurrencia y Computación: Práctica y Experiencia, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio de carga eficiente para aplicaciones de dividir y conquistar de amplia área. En el 8vo ACM SIGPLAN Symp. sobre Principios y Prácticas de Programación Paralela, páginas 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satin: Programación en cuadrícula simple y eficiente basada en Java. Computación escalable: Práctica y experiencia, 6(3):19-32, septiembre de 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. Ibis: un entorno de programación en malla flexible y eficiente basado en Java. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.

Concurrencia y Computación: Práctica y Experiencia, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio de pronóstico del clima de la red: Un servicio de pronóstico del rendimiento de recursos distribuidos para la metacomputación. Revista de Sistemas Informáticos de Generación Futura, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallos, maleabilidad y migración para aplicaciones de dividir y conquistar en la red. En el Simposio Internacional de Procesamiento Paralelo y Distribuido, Abril de 2005. 129