Sugerencia de consultas multilingües utilizando registros de consultas de diferentes idiomas Wei Gao1* , Cheng Niu2 , Jian-Yun Nie3 , Ming Zhou2 , Jian Hu2 , Kam-Fai Wong1 , Hsiao-Wuen Hon2 1 Universidad China de Hong Kong, Hong Kong, China {wgao, kfwong}@se.cuhk.edu.hk 2 Microsoft Research Asia, Beijing, China {chengniu, mingzhou, jianh, hon}@microsoft.com 3 Université de Montréal, Montréal, QC, Canadá nie@iro.umontreal.ca RESUMEN La sugerencia de consultas tiene como objetivo sugerir consultas relevantes para una consulta dada, lo que ayuda a los usuarios a especificar mejor sus necesidades de información. Anteriormente, los términos sugeridos son principalmente en el mismo idioma que la consulta de entrada. En este artículo, lo extendemos a la sugerencia de consultas entre idiomas (CLQS): para una consulta en un idioma, sugerimos consultas similares o relevantes en otros idiomas. Esto es muy importante para los escenarios de recuperación de información entre idiomas (CLIR) y para la puja de palabras clave entre idiomas para la publicidad en motores de búsqueda. En lugar de depender de las tecnologías de traducción de consultas existentes para CLQS, presentamos un medio efectivo para mapear la consulta de entrada de un idioma a consultas del otro idioma en el registro de consultas. Información importante monolingüe y multilingüe como relaciones de traducción de palabras y estadísticas de co-ocurrencia de palabras, etc. se utilizan para estimar la similitud de consultas multilingües con un modelo discriminativo. Los benchmarks muestran que el sistema CLQS resultante supera significativamente a un sistema base basado en la traducción de consultas basada en diccionario. Además, el CLQS resultante se prueba con tareas de CLIR de francés a inglés en colecciones de TREC. Los resultados demuestran una mayor efectividad que los métodos tradicionales de traducción de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información - Formulación de consultas Términos Generales Algoritmos, Rendimiento, Experimentación, Teoría. 1. La sugerencia de consultas es una funcionalidad que ayuda a los usuarios de un motor de búsqueda a especificar mejor su necesidad de información, ya sea reduciendo o ampliando el alcance de la búsqueda con consultas sinónimas y consultas relevantes, o sugiriendo consultas relacionadas que han sido utilizadas con frecuencia por otros usuarios. Los motores de búsqueda, como Google, Yahoo!, MSN, Ask Jeeves, han implementado la funcionalidad de sugerencia de consultas como una valiosa adición a su método de búsqueda principal. Además, la misma tecnología se ha utilizado para recomendar términos de puja a los anunciantes en línea en el mercado de búsqueda de pago por rendimiento [12]. La sugerencia de consulta está estrechamente relacionada con la expansión de consulta, la cual amplía la consulta original con nuevos términos de búsqueda para reducir el alcance de la búsqueda. Pero a diferencia de la expansión de consultas, la sugerencia de consultas tiene como objetivo sugerir consultas completas que han sido formuladas por los usuarios para que la integridad y coherencia de la consulta se conserven en las consultas sugeridas. Los métodos típicos para la sugerencia de consultas explotan los registros de consultas y las colecciones de documentos, asumiendo que en el mismo período de tiempo, muchos usuarios comparten intereses similares o iguales, los cuales pueden expresarse de diferentes maneras [12, 14, 26]. Al sugerir las formulaciones relacionadas y frecuentemente utilizadas, se espera que la nueva consulta pueda abarcar más documentos relevantes. Sin embargo, todos los estudios existentes trataron sobre sugerencias de consultas monolingües y, hasta donde sabemos, no hay ningún estudio publicado sobre sugerencias de consultas entre idiomas (CLQS). CLQS tiene como objetivo sugerir consultas relacionadas pero en un idioma diferente. Tiene amplias aplicaciones en la World Wide Web: para la búsqueda entre idiomas o para sugerir términos de oferta relevantes en un idioma diferente. Se puede abordar 1 CLQS como un problema de traducción de consultas, es decir, sugerir las consultas que son traducciones de la consulta original. Los diccionarios, el gran tamaño de los corpus paralelos y los sistemas comerciales de traducción automática existentes se pueden utilizar para la traducción. Sin embargo, este tipo de enfoques generalmente se basan en conocimientos y datos estáticos. No puede reflejar de manera efectiva los intereses rápidamente cambiantes de los usuarios de la Web. Además, hay algunos problemas con las consultas traducidas en el idioma de destino. Por ejemplo, los términos traducidos pueden ser traducciones razonables, pero no son comúnmente utilizados en el idioma de destino. Por ejemplo, la consulta en francés aliment biologique se traduce como biologic food por la herramienta de traducción de Google, sin embargo, la formulación correcta en la actualidad debería ser organic food. Por lo tanto, existen muchos casos de desajuste entre los términos traducidos y los términos realmente utilizados en el idioma de destino. Esta discrepancia hace que los términos sugeridos en el idioma de destino sean ineficaces. Un pensamiento natural para resolver esta discrepancia es mapear las consultas en el idioma de origen y las consultas en el idioma de destino, utilizando el registro de consultas de un motor de búsqueda. Explotamos el hecho de que los usuarios de los motores de búsqueda en el mismo período de tiempo tienen intereses similares, y envían consultas sobre temas similares en diferentes idiomas. Como resultado, es probable que una consulta escrita en un idioma fuente tenga un equivalente en un registro de consultas en el idioma de destino. En particular, si el usuario tiene la intención de realizar CLIR, entonces es aún más probable que su consulta original tenga su correspondiente incluida en el registro de consultas del idioma de destino. Por lo tanto, si un candidato para CLQS aparece con frecuencia en el registro de consultas, es más probable que sea el adecuado para ser sugerido. En este artículo, proponemos un método para calcular la similitud entre la consulta en el idioma de origen y la consulta en el idioma de destino mediante la explotación, además de la información de traducción, de un amplio espectro de información bilingüe y monolingüe, como las co-ocurrencias de términos, los registros de consultas con datos de clics, etc. Un modelo discriminativo se utiliza para aprender la similitud de consultas entre idiomas basado en un conjunto de consultas traducidas manualmente. El modelo se entrena optimizando la similitud entre lenguajes para ajustarse mejor a la similitud monolingüe entre una consulta y la traducción de la otra consulta. Además de ser evaluado como un módulo independiente, el sistema CLQS resultante se prueba como un nuevo medio de traducción de consultas en la tarea CLIR en las colecciones de TREC. Los resultados muestran que este nuevo método de traducción es más efectivo que el método tradicional de traducción de consultas. El resto de este documento está organizado de la siguiente manera: la Sección 2 introduce el trabajo relacionado; la Sección 3 describe en detalle el modelo discriminativo para estimar la similitud de consultas entre idiomas; la Sección 4 presenta un nuevo enfoque de IRCL utilizando sugerencias de consultas entre idiomas como puente a través de las barreras del idioma. La sección 5 discute los experimentos y las pruebas de referencia; finalmente, el artículo concluye en la Sección 6. TRABAJO RELACIONADO La mayoría de los enfoques de CLIR realizan una traducción de consulta seguida de una IR monolingüe. Normalmente, las consultas se traducen utilizando un diccionario bilingüe [22], un software de traducción automática [9] o un corpus paralelo [20]. A pesar de los diversos tipos de recursos utilizados, las palabras fuera de vocabulario (OOV) y la desambiguación de la traducción son los dos principales cuellos de botella para la Recuperación de Información en Lenguaje Cruzado (CLIR) [20]. En [7, 27], las traducciones de términos OOV se extraen de la Web utilizando un motor de búsqueda. En [17], el conocimiento bilingüe se adquiere basado en el análisis del texto de anclaje. Además, las estadísticas de co-ocurrencia de palabras en el idioma de destino se han utilizado para la desambiguación de la traducción. Sin embargo, se puede argumentar que una traducción precisa de consultas puede no ser necesaria para la Recuperación de Información en Lenguaje Cruzado (CLIR). De hecho, en muchos casos, es útil introducir palabras aunque no sean traducciones directas de ninguna palabra de la consulta, pero estén estrechamente relacionadas con el significado de la consulta. Esta observación ha llevado al desarrollo de técnicas de expansión de consultas multilingües (CLQE) [2, 16, 18]. [2] informa sobre la mejora en la Recuperación de Información en Lenguaje Cruzado (CLIR) mediante la expansión post-traducción. [16] desarrolla un modelo de relevancia multilingüe aprovechando las estadísticas de co-ocurrencia multilingüe en textos paralelos. [18] realiza una comparación de rendimiento en múltiples técnicas de CLQE, incluyendo la expansión pre-traducción y la expansión post-traducción. Sin embargo, existe una falta de un marco unificado para combinar el amplio espectro de recursos y los avances recientes de las técnicas de minería para CLQE. CLQS es diferente de CLQE en que tiene como objetivo sugerir consultas completas que han sido formuladas por usuarios en otro idioma. Dado que CLQS explota registros de consultas actualizados, se espera que para la mayoría de las consultas de los usuarios, podamos encontrar formulaciones comunes sobre estos temas en el registro de consultas en el idioma de destino. Por lo tanto, CLQS también desempeña un papel en adaptar la formulación original de la consulta a las formulaciones comunes de temas similares en el idioma de destino. Los registros de consultas han sido utilizados con éxito para la RI monolingüe [8, 12, 15, 26], especialmente en sugerencias de consultas monolingües [12] y en la relación de términos semánticamente relevantes para la expansión de consultas [8, 15]. En [1], se ha utilizado el registro de consultas en el idioma objetivo para ayudar en la traducción de consultas en la Recuperación de Información en Lenguaje Cruzado (CLIR). 3. Estimación de la similitud de consultas entre idiomas. Un motor de búsqueda tiene un registro de consultas que contiene consultas de usuarios en diferentes idiomas dentro de un cierto período de tiempo. Además de los términos de búsqueda, también se registra la información de clics. Por lo tanto, sabemos qué documentos han sido seleccionados por los usuarios para cada consulta. Dada una consulta en el idioma de origen, nuestra tarea de CLQS es determinar una o varias consultas similares en el idioma de destino a partir del registro de consultas. El problema clave con la sugerencia de consultas entre idiomas es cómo aprender una medida de similitud entre dos consultas en diferentes idiomas. Aunque se han estudiado diversas medidas de similitud estadística para términos monolingües [8, 26], la mayoría de ellas se basan en estadísticas de co-ocurrencia de términos y apenas pueden aplicarse directamente en entornos multilingües. Para definir una medida de similitud entre idiomas, es necesario utilizar al menos una herramienta o recurso de traducción. Por lo tanto, la medida se basa tanto en la relación de traducción como en la similitud monolingüe. En este documento, dado que nuestro propósito es proporcionar una medida actualizada de similitud de consultas, puede que no sea suficiente utilizar únicamente un recurso de traducción estático. Por lo tanto, también integramos un método para buscar posibles traducciones en la web. Este método es particularmente útil para tratar términos OOV. Dado un conjunto de recursos de diferentes naturalezas, la siguiente pregunta es cómo integrarlos de manera fundamentada. En este artículo, proponemos un modelo discriminativo para aprender la medida de similitud apropiada. El principio es el siguiente: asumimos que tenemos una medida razonable de similitud de consultas monolingües. Para cualquier ejemplo de consulta de entrenamiento para el cual exista una traducción, su medida de similitud (con cualquier otra consulta) se transpone a su traducción. Por lo tanto, tenemos el valor deseado de similitud entre idiomas para este ejemplo. Luego utilizamos un modelo discriminativo para aprender la función de similitud entre idiomas cruzados que se ajuste mejor a estos ejemplos. En las siguientes secciones, primero describamos en detalle el modelo discriminativo para la estimación de similitud de consultas entre idiomas. Luego introducimos todas las características (información monolingüe y multilingüe) que utilizaremos en el modelo discriminativo. 3.1 Modelo Discriminativo para Estimar la Similitud de Consultas Multilingües En esta sección, proponemos un modelo discriminativo para aprender similitudes de consultas multilingües de manera fundamentada. El principio es el siguiente: para una similitud razonable entre dos consultas monolingües, se puede deducir un correspondiente entre una consulta y la traducción de otra consulta en un idioma cruzado. En otras palabras, para un par de consultas en diferentes idiomas, su similitud interlingüística debería ajustarse a la similitud monolingüe entre una consulta y la traducción de la otra consulta. Por ejemplo, la similitud entre las páginas de consulta francesas jaunes (es decir, páginas amarillas en inglés) y la consulta en inglés del directorio telefónico debería ser igual a la similitud monolingüe entre la traducción de la consulta francesa de páginas amarillas y directorio telefónico. Hay muchas formas de obtener una medida de similitud monolingüe entre términos, por ejemplo, la información mutua basada en la co-ocurrencia de términos y el 2 χ. Cualquiera de ellos puede ser utilizado como objetivo para ajustar la función de similitud entre idiomas cruzados. De esta manera, la estimación de la similitud de consultas entre idiomas se formula como una tarea de regresión de la siguiente manera: Dada una consulta en el idioma fuente fq, una consulta en el idioma objetivo eq y una similitud de consultas monolingüe MLsim, la similitud de consultas entre idiomas correspondiente CLsim se define de la siguiente manera: ),(),( eqMLefCL qTsimqqsim f = (1) donde fqT es la traducción de fq al idioma objetivo. Basándose en la Ecuación (1), sería relativamente fácil crear un corpus de entrenamiento. Todo lo que se necesita es una lista de traducciones de consultas. Entonces, un sistema de sugerencia de consultas monolingüe existente puede ser utilizado para producir automáticamente una consulta similar para cada traducción, y crear el corpus de entrenamiento para la estimación de similitud entre idiomas. Otra ventaja es que es bastante fácil hacer uso de fuentes de información arbitrarias dentro de un marco de modelado discriminativo para lograr un rendimiento óptimo. En este artículo, se utiliza el algoritmo de regresión de máquina de vectores de soporte (SVM) [25] para aprender la función de similitud de términos entre idiomas. Dado un vector de funciones de características f entre fq y eq, ),( efCL ttsim se representa como un producto interno entre un vector de pesos y el vector de características en un espacio de kernel de la siguiente manera: )),((),( efefCL ttfwttsim φ•= (2) donde φ es el mapeo del espacio de características de entrada al espacio de kernel, y w es el vector de pesos en el espacio de kernel que será aprendido por el entrenamiento de regresión SVM. Una vez que se aprende el vector de peso, la Ecuación (2) se puede utilizar para estimar la similitud entre consultas de diferentes idiomas. Queremos señalar que en lugar de regresión, definitivamente se puede simplificar la tarea como una clasificación binaria u ordinal, en cuyo caso CLQS puede ser categorizado según etiquetas de clase discontinuas, por ejemplo, relevante e irrelevante, o una serie de niveles de relevancia, por ejemplo, altamente relevante, débilmente relevante e irrelevante. En ambos casos, se puede recurrir a enfoques de clasificación discriminativa, como una SVM o un modelo de entropía máxima, de manera directa. Sin embargo, el formalismo de regresión nos permite clasificar completamente las consultas sugeridas en función de la puntuación de similitud dada por la Ecuación (1). Las Ecuaciones (1) y (2) construyen un modelo de regresión para la estimación de similitud de consultas entre idiomas. En las siguientes secciones, se presentarán la medida de similitud de consultas monolingües (ver Sección 3.2) y las funciones de características utilizadas para la regresión SVM (ver Sección 3.3). 3.2 Medida de similitud de consultas monolingües basada en información de clics. Cualquier medida de similitud de términos monolingües puede ser utilizada como objetivo de regresión. En este artículo, seleccionamos la medida de similitud de consultas monolingües presentada en [26], la cual reporta un buen rendimiento al utilizar la información de clics de los usuarios de búsqueda en los registros de consultas. La razón para elegir esta similitud monolingüe es que está definida en un contexto similar al nuestro, según un registro de usuario que refleja la intención y el comportamiento de los usuarios. Por lo tanto, podemos esperar que la similitud de términos entre idiomas aprendida a partir de esto también pueda reflejar la intención y expectativa de los usuarios. Siguiendo [26], nuestra similitud de consulta monolingüe se define combinando tanto la similitud basada en el contenido de la consulta como la coincidencia en los clics en el registro de consultas. Primero, la similitud de contenido entre dos consultas p y q se define de la siguiente manera: similitud_contenido = (3) donde xkn es el número de palabras clave en una consulta x, qpKN es el número de palabras clave comunes en las dos consultas. En segundo lugar, la similitud basada en clics se define de la siguiente manera, ))(),(( ),( ),( qrdprdMax qpRD qpsimilarity throughclick =− (4) donde )(xrd es el número de URL clicadas para una consulta x, y ),( qpRD es el número de URL comunes clicadas para dos consultas. Finalmente, la similitud entre dos consultas es una combinación lineal de las similitudes basadas en el contenido y en los clics, y se presenta de la siguiente manera: qpsimilarity = α * qpsimilaritycontent + β * qpsimilaritythroughclick (5) donde α y β son la importancia relativa de las dos medidas de similitud. En este documento, establecemos ,4.0=α y 6.0=β siguiendo la práctica en [26]. Las consultas con una medida de similitud mayor que un umbral con otra consulta serán consideradas como sugerencias de consulta monolingüe relevante (MLQS) para esta última. En este documento, el umbral se establece de forma empírica en 0.9. 3.3 Características utilizadas para aprender la medida de similitud de consultas entre idiomas. Esta sección presenta la extracción de consultas relevantes candidatas del registro con la ayuda de varios recursos monolingües y bilingües. Mientras tanto, se definen las funciones de características sobre la consulta de origen y los candidatos relevantes en la traducción cruzada. Algunos de los recursos que se están utilizando aquí, como el léxico bilingüe y los corpus paralelos, se utilizaron para la traducción de consultas en trabajos anteriores. Pero hay que tener en cuenta que los empleamos aquí como un medio auxiliar para encontrar candidatos relevantes en el registro en lugar de para obtener traducciones precisas. 3.3.1 Diccionario Bilingüe En esta subsección, se utiliza un diccionario bilingüe integrado en la casa que contiene 120,000 entradas únicas para recuperar consultas de candidatos. Dado que a cada palabra de origen puede asociarse múltiples traducciones, se realiza una desambiguación de la traducción basada en la co-ocurrencia [3, 10]. El proceso se presenta de la siguiente manera: Dada una consulta de entrada }{ ,2,1 fnfff wwwq K= en el idioma fuente, para cada término de consulta fiw , un conjunto de traducciones únicas son proporcionadas por el diccionario bilingüe D : },,{)( ,2,1 imiifi tttwD K= . Entonces, la cohesión entre las traducciones de dos términos de consulta se mide utilizando la información mutua que se calcula de la siguiente manera: )()( ),( log),()( , klij klij klijklij tPtP ttP ttPttMI = (6) donde . )( )(, ),( N tC tP N ttC ttP klij klij == Aquí ),( yxC es el número de consultas en el registro que contienen tanto x como y , )(xC es el número de consultas que contienen el término x , y N es el número total de consultas en el registro. Basándose en la cohesión término-término definida en la Ecuación (6), todas las posibles traducciones de consulta se clasifican utilizando la suma de la cohesión término-término ∑≠ = kiki klijqdict ttMITS f ,, ),()( . El conjunto de las 4 mejores traducciones de consultas se denota como )( fqTS. Para cada posible traducción de consulta )( fqTST∈, recuperamos todas las consultas que contienen las mismas palabras clave que T del registro del idioma objetivo. Las consultas recuperadas son consultas objetivo candidatas, y se les asigna )(TSdict como el valor de la característica Puntuación de Traducción Basada en Diccionario. 3.3.2 Corpora Paralelos Los corpora paralelos son recursos valiosos para la adquisición de conocimiento bilingüe. A diferencia del diccionario bilingüe, el conocimiento bilingüe aprendido de corpus paralelos asigna una probabilidad a cada candidato de traducción, lo cual es útil para adquirir traducciones de consultas dominantes. En este artículo se utiliza el corpus Europarl (un conjunto de textos paralelos en francés e inglés de las actas del Parlamento Europeo). El corpus está alineado por la primera oración. Luego, las alineaciones de palabras se derivan entrenando un modelo de traducción IBM 1 [4] utilizando GIZA++ [21]. El conocimiento bilingüe adquirido se utiliza para extraer consultas candidatas del registro de consultas. El proceso se presenta de la siguiente manera: Dado un par de consultas, fq en el idioma fuente y eq en el idioma destino, el Puntaje de Traducción Bi-Direccional se define de la siguiente manera: )|()|(),( 111 feIBMefIBMefIBM qqpqqpqqS = (7) donde )|(1 xypIBM es la probabilidad de traducción de secuencia de palabras dada por el modelo IBM 1 que tiene la siguiente forma: ∏∑= =+ = || 1 || 0 ||1 )|( )1|(| 1 )|( y j x i ijyIBM xyp x xyp (8) donde )|( ij xyp es la probabilidad de traducción de palabra a palabra derivada de los corpus alineados por palabras. La razón para usar la probabilidad de traducción bidireccional es para lidiar con el hecho de que palabras comunes pueden ser consideradas como posibles traducciones de muchas palabras. Al utilizar la traducción bidireccional, probamos si las palabras traducidas pueden ser traducidas de vuelta a las palabras originales. Esto es útil para enfocarse en la probabilidad de traducción hacia los candidatos de traducción más específicos. Ahora, dado una consulta de entrada fq, se recuperan las 10 consultas }{ eq con los puntajes de traducción bidireccional más altos con fq del registro de consultas, y ),(1 efIBM qqS en la Ecuación (7) se asigna como el valor para la característica Puntaje de Traducción Bidireccional. 3.3.3 Minería en línea para consultas relacionadas La traducción de palabras OOV es un cuello de botella de conocimiento importante para la traducción de consultas y CLIR. Para superar este cuello de botella de conocimiento, la minería web ha sido explotada en [7, 27] para adquirir traducciones de términos en inglés y chino basadas en la observación de que los términos chinos pueden co-ocurrir con sus traducciones en inglés en la misma página web. En esta sección, este enfoque de minería web se adapta para adquirir no solo traducciones, sino también consultas semánticamente relacionadas en el idioma de destino. Se asume que si una consulta en el idioma de destino coocurre con la consulta de origen en muchas páginas web, probablemente están relacionadas semánticamente. Por lo tanto, un método simple es enviar la consulta de origen a un motor de búsqueda (Google en nuestro caso) para páginas web en el idioma de destino con el fin de encontrar consultas relacionadas en el idioma de destino. Por ejemplo, al enviar una consulta en francés a páginas amarillas para buscar páginas en inglés, se devolverán los fragmentos en inglés que contengan las palabras clave páginas amarillas o directorio telefónico. Sin embargo, este enfoque simple puede inducir una cantidad significativa de ruido debido a los resultados no relevantes del motor de búsqueda. Para mejorar la relevancia de los fragmentos bilingües, ampliamos el enfoque simple mediante la siguiente modificación de la consulta: la consulta original se utiliza para buscar con las traducciones de palabras clave basadas en el diccionario, las cuales se unifican mediante los operadores ∧ (y) ∨ (O) en una sola consulta booleana. Por ejemplo, para una consulta dada abcq = donde el conjunto de entradas de traducción en el diccionario de para a es },,{ 321 aaa , b es },{ 21 bb y c es }{ 1c , emitimos 121321 )()( cbbaaaq ∧∨∧∨∨∧ como una consulta web. De los 700 fragmentos principales devueltos, se identifican las 10 consultas objetivo más frecuentes, y se asocian con la característica Frecuencia en los fragmentos. Además, utilizamos la Medida de Doble Verificación de Coocurrencia (CODC) para ponderar la asociación entre las consultas de origen y destino. La medida CODC se propone en [6] como una medida de asociación basada en el análisis de fragmentos, denominada modelo de Búsqueda Web con Doble Comprobación (WSDC). En el modelo WSDC, dos objetos a y b se consideran tener una asociación si b se puede encontrar utilizando a como consulta (proceso hacia adelante), y a se puede encontrar utilizando b como consulta (proceso hacia atrás) mediante una búsqueda web. El proceso hacia adelante cuenta la frecuencia de b en los primeros N fragmentos de la consulta a, denotado como )@( abfreq. De manera similar, el proceso inverso cuenta la frecuencia de la letra a en los primeros N fragmentos de la consulta b, denotado como )@( bafreq. Entonces, la puntuación de asociación de la asociación CODC se define de la siguiente manera: ⎪ ⎩ ⎪ ⎨ ⎧ =× = ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎣ ⎡ × de lo contrario, 0)@()@(si,0 ),( )( )@( )( )@( log α e ef f fe qfreq qqfreq qfreq qqfreq effe efCODC e qqfreqqqfreq qqS (9) CODC mide la asociación de dos términos en el rango entre 0 y 1, donde en los dos casos extremos, eq y fq no tienen asociación cuando 0)@( =fe qqfreq o 0)@( =ef qqfreq , y tienen la asociación más fuerte cuando )()@( ffe qfreqqqfreq = y )()@( eef qfreqqqfreq =. En nuestro experimento, α se establece en 0.15 siguiendo la práctica en [6]. Cualquier consulta extraída de la Web estará asociada con una característica Medida CODC con ),( efCODC qqS como su valor. 3.3.4 Sugerencia de Consulta Monolingüe Para todas las consultas candidatas 0Q que se están recuperando utilizando el diccionario (ver Sección 3.3.1), datos paralelos (ver Sección 3.3.2) y minería web (ver Sección 3.3.3), se llama al sistema de sugerencia de consultas monolingüe (descrito en la Sección 3.1) para producir consultas más relacionadas en el idioma objetivo. Para cada consulta de destino eq, su consulta de origen monolingüe )( eML qSQ se define como la consulta en 0Q con la mayor similitud monolingüe con eq, es decir, ),(maxarg)( 0 eeMLQqeML qqsimqSQ e ′= ∈′ (10) Luego, la similitud monolingüe entre eq y )( eML qSQ se utiliza como el valor de la Característica de Sugerencia de Consulta Monolingüe de eq. Para cualquier consulta de destino 0Qq∈, su Característica de Sugerencia de Consulta Monolingüe se establece en 1. Para cualquier consulta 0Qqe ∉, sus valores de Puntuación de Traducción Basada en Diccionario, Puntuación de Traducción Bidireccional, Frecuencia en el Fragmento y Medida CODC se establecen como iguales a los valores de características de )( eML qSQ. 3.4 Estimación de la Similitud de Consultas Cruzadas En resumen, se utilizan cuatro categorías de características para aprender la similitud de consultas entre idiomas. El algoritmo de regresión SVM [25] se utiliza para aprender los pesos en la Ecuación (2). En este artículo, se utiliza la herramienta LibSVM [5] para el entrenamiento de regresión. En la etapa de predicción, las consultas de los candidatos se clasificarán utilizando la puntuación de similitud de consulta entre idiomas cruzados calculada en términos de efefCL ttfwttsim φ•=, y las consultas con una puntuación de similitud inferior a un umbral se considerarán no relevantes. El umbral se aprende utilizando un conjunto de datos de desarrollo ajustando la salida de MLQSs. 4. CLIR BASADO EN SUGERENCIA DE CONSULTAS CRUZADAS En la Sección 3, presentamos un modelo discriminativo para la sugerencia de consultas cruzadas. Sin embargo, realizar una evaluación objetiva de un sistema de sugerencias de consultas no es una tarea trivial. En este artículo, proponemos utilizar CLQS como una alternativa a la traducción de consultas, y probamos su efectividad en tareas de recuperación de información multilingüe. El buen rendimiento resultante de CLIR corresponde a la alta calidad de las consultas sugeridas. Dado un conjunto de consultas relevantes }{ eq en el idioma de destino, se recomiendan consultas en el sistema de sugerencia de consultas interlingüe utilizando una consulta de origen fq. Luego se llama a un sistema de IR monolingüe basado en el modelo BM25 [23] utilizando cada }{ eqq∈ como consultas para recuperar documentos. Luego, los documentos recuperados se vuelven a clasificar en función de la suma de las puntuaciones BM25 asociadas con cada recuperación monolingüe. EVALUACIÓN DEL RENDIMIENTO En esta sección, compararemos el sistema de sugerencia de consultas multilingüe con el de sugerencia de consultas monolingüe, estudiando la contribución de diversas fuentes de información y probando su efectividad al ser utilizado en tareas de recuperación de información multilingüe. 5.1 Recursos de Datos En nuestros experimentos, el francés y el inglés son seleccionados como el idioma fuente y el idioma objetivo respectivamente. Esta selección se debe al hecho de que los registros de consultas a gran escala están fácilmente disponibles para estos dos idiomas. Un registro de consultas en inglés de un mes (que contiene 7 millones de consultas en inglés únicas con una frecuencia de ocurrencia mayor a 5) del motor de búsqueda de MSN se utiliza como el registro del idioma objetivo. Y se construye un sistema de sugerencia de consultas monolingüe basado en ello. Además, se seleccionan aleatoriamente 5,000 consultas en francés de un registro de consultas en francés (que contiene alrededor de 3 millones de consultas) y son traducidas manualmente al inglés por traductores profesionales de francés a inglés. De las 5,000 consultas en francés, 4,171 consultas tienen sus traducciones en el registro de consultas en inglés, y se utilizan para el entrenamiento y prueba de CLQS. Además, entre las 4,171 consultas en francés, el 70% se utilizan para el entrenamiento de similitud de consultas entre idiomas, el 10% se utiliza como datos de desarrollo para determinar el umbral de relevancia, y el 20% se utiliza para pruebas. Para recuperar las consultas relacionadas entre idiomas, se utiliza un léxico bilingüe francés-inglés desarrollado internamente (que contiene 120,000 entradas únicas) y el corpus Europarl. Además de evaluar el CLQS como un sistema independiente, el CLQS también se prueba como un sistema de traducción de consultas para tareas de CLIR. Basado en la observación de que el rendimiento de CLIR depende en gran medida de la calidad de las consultas sugeridas, este referente mide la calidad de CLQS en términos de su efectividad para ayudar a CLIR. Para realizar dicho benchmark, utilizamos los documentos de datos CLIR de TREC6 (AP88-90 newswire, 750MB) con 25 pares de consultas cortas francés-inglés proporcionadas oficialmente (CL1-CL25). La selección de este conjunto de datos se debe al hecho de que la longitud promedio de las consultas es de 3.3 palabras, lo cual coincide con los registros de consultas web que utilizamos para entrenar CLQS. El rendimiento de la Sugerencia de Consultas Cruzadas (CLQS) se mide mediante el error cuadrático medio (MSE) y se define de la siguiente manera: ( )2 ),(),( 1 ∑ −= i eiqMLeifiCL qTsimqqsim l MSE fi donde l es el número total de pares de consultas cruzadas en los datos de prueba. Como se describe en la Sección 3.4, se aprende un umbral de relevancia utilizando los datos de desarrollo, y solo los CLQS con un valor de similitud por encima del umbral se consideran verdaderamente relevantes para la consulta de entrada. De esta manera, CLQS también puede ser evaluado como una tarea de clasificación utilizando la precisión (P) y la exhaustividad (R), que se definen de la siguiente manera: CLQS MLQSCLQS P S SS I = , MLQS MLQSCLQS R S SS I = donde CLQSS es el conjunto de consultas relevantes sugeridas por CLQS, MLQSS es el conjunto de consultas relevantes sugeridas por MLQS (ver Sección 3.2). Los resultados de la comparación con diferentes configuraciones de características se muestran en la Tabla 1. Regresión Clasificación Características MSE P R DD 0.274 0.723 0.098 DD+PC 0.224 0.713 0.125 DD+PC+ Web 0.115 0.808 0.192 DD+PC+ Web+ML QS 0.174 0.796 0.421 Tabla 1. El rendimiento de CLQS con diferentes configuraciones de características (DD: solo diccionario; DD+PC: diccionario y corpus paralelo; DD+PC+Web: diccionario, corpus paralelo y minería web; DD+PC+Web+MLQS: diccionario, corpus paralelo, minería web y sugerencia de consulta monolingüe) La Tabla 1 muestra la comparación de rendimiento con varias configuraciones de características. El sistema base (DD) utiliza un enfoque convencional de traducción de consultas, es decir, un diccionario bilingüe con desambiguación de traducción basada en coocurrencia. El sistema base solo cubre menos del 10% de las sugerencias hechas por MLQS. El uso de características adicionales obviamente permite a CLQS generar consultas más relevantes. La mejora más significativa en la recuperación se logra al explotar MLQS. El sistema CLQS final es capaz de generar el 42% de las consultas sugeridas por MLQS. Entre todas las combinaciones de características, no hay un cambio significativo en la precisión. Esto indica que nuestros métodos pueden mejorar la recuperación al aprovechar de manera efectiva diversas fuentes de información sin perder la precisión de las sugerencias. Además de comparar la salida de CLQS con la salida de MLQS, se seleccionan aleatoriamente 200 consultas en francés del registro de consultas en francés. Estas consultas son verificadas dos veces para asegurarse de que no estén en el corpus de entrenamiento de CLQS. Entonces, el sistema CLQS se utiliza para sugerir consultas relevantes en inglés para ellos. En promedio, por cada consulta en francés, se sugieren 8.7 consultas relevantes en inglés. Luego, las 1,740 consultas en inglés sugeridas son verificadas manualmente por dos traductores profesionales de inglés/francés con validación cruzada. De las 1,747 consultas sugeridas, 1,407 consultas son reconocidas como relevantes a las originales, por lo tanto la precisión es del 80.9%. La Figura 1 muestra un ejemplo de CLQS de la consulta francesa terrorisme international (terrorismo internacional en inglés). 5.3 Rendimiento de CLIR En esta sección, CLQS se prueba con tareas de CLIR de francés a inglés. Realizamos experimentos de CLIR utilizando el conjunto de datos de CLIR TREC 6 descrito en la Sección 5.1. El CLIR se realiza utilizando un sistema de traducción de consultas seguido de un módulo de RI monolingüe basado en BM25. Los siguientes tres sistemas diferentes se han utilizado para realizar la traducción de consultas: (1) CLQS: nuestro sistema CLQS; (2) MT: sistema de traducción automática de Google de francés a inglés; (3) DT: un sistema de traducción de consultas basado en diccionario que utiliza estadísticas de coocurrencia para la desambiguación de la traducción. El algoritmo de desambiguación de traducción se presenta en la Sección 3.3.1. Además, el rendimiento de IR monolingüe también se informa como referencia. La precisión promedio de los cuatro sistemas de IR se reporta en la Tabla 2, y las curvas de precisión-recuperación de 11 puntos se muestran en la Figura 2. Tabla 2. Precisión promedio de CLIR en el Conjunto de Datos TREC 6 (Monolingual: sistema de IR monolingüe; MT: CLIR basado en traducción automática; DT: CLIR basado en traducción de diccionario; CLQS: CLIR basado en CLQS) Sistema de IR Precisión Promedio % de IR Monolingual Monolingual 0.266 100% MT 0.217 81.6% DT 0.186 69.9% CLQS 0.233 87.6% Figura 1. Un ejemplo de CLQS de la consulta francesa terrorisme international terrorismo internacional (0.991); qué es el terrorismo (0.943); lucha contra el terrorismo (0.920); terrorista (0.911); ataques terroristas (0.898); terrorista internacional (0.853); terrorismo mundial (0.845); terrorismo global (0.833); terrorismo transnacional (0.821); derechos humanos (0.811); grupos terroristas (0.777); patrones de terrorismo global (0.762) 11 de septiembre (0.734) curvas P-R de 11 puntos (TREC6) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recuperación Precisión MT Monolingüe DT CLQS El estudio de referencia muestra que el uso de CLQS como herramienta de traducción de consultas supera en un 7.4% a CLIR basado en traducción automática, supera en un 25.2% a CLIR basado en traducción de diccionario y alcanza el 87.6% del rendimiento de IR monolingüe. La efectividad de CLQS radica en su capacidad para sugerir consultas estrechamente relacionadas además de traducciones precisas. Por ejemplo, para la consulta CL14 terrorismo internacional, aunque la herramienta de traducción automática traduce la consulta correctamente, el sistema CLQS aún logra una puntuación más alta al recomendar muchos términos relacionados adicionales como terrorismo global, terrorismo mundial, etc. (como se muestra en la Figura 1). Otro ejemplo es la consulta La pollution causée par lautomobile (contaminación del aire causada por automóviles) de CL6. La herramienta MT proporciona la traducción de la contaminación causada por el automóvil, mientras que el sistema CLQS enumera todos los posibles sinónimos de automóvil y sugiere las siguientes consultas: contaminación por automóvil, contaminación por auto, contaminación por automóvil. Además, también se sugieren otras consultas relacionadas como el calentamiento global. Para la consulta CL12 La culture écologique (agricultura orgánica), la herramienta de traducción automática no logra generar la traducción correcta. Aunque la traducción correcta no se encuentra en nuestro diccionario francés-inglés, el sistema CLQS genera "granja orgánica" como una consulta relevante debido a la exitosa minería web. El experimento anterior demuestra la efectividad de usar CLQS para sugerir consultas relevantes para mejorar la recuperación de información en lenguaje cruzado. Una investigación relacionada es realizar una expansión de consultas para mejorar la Recuperación de Información en Lenguaje Cruzado (CLIR) [2, 18]. Por lo tanto, es muy interesante comparar el enfoque CLQS con los enfoques convencionales de expansión de consultas. Siguiendo [18], se realiza una expansión post-traducción basada en técnicas de retroalimentación de pseudo relevancia (PRF). Primero realizamos CLIR de la misma manera que antes. Luego utilizamos el algoritmo PRF tradicional descrito en [24] para seleccionar términos de expansión. En nuestros experimentos, se seleccionan los 10 términos principales para expandir la consulta original, y la nueva consulta se utiliza para buscar en la colección por segunda vez. El rendimiento CLIR nuevo en términos de precisión promedio se muestra en la Tabla 3. Las curvas P-R de 11 puntos están dibujadas en la Figura 3. Aunque se ve mejorado por la retroalimentación de pseudo-relevancia, el RICL utilizando traducción automática o traducción de consultas basada en diccionarios aún no tiene un rendimiento tan bueno como el enfoque basado en CLQS. Se realiza una prueba t estadística [13] para indicar si el CLIR basado en CLQS funciona significativamente mejor. Los valores de p por pares se muestran en la Tabla 4. Claramente, CLQS supera significativamente a MT y DT sin PRF, así como a DT+PRF, pero su superioridad sobre MT+PRF no es significativa. Sin embargo, cuando se combina con PRF, CLQS supera significativamente a todos los demás métodos. Esto indica la mayor efectividad de CLQS en la identificación de términos relacionados al aprovechar un amplio espectro de recursos. Además, la expansión post-traducción es capaz de mejorar la recuperación de información en lenguaje cruzado basada en consultas largas. Esto se debe al hecho de que CLQS y la retroalimentación de pseudo relevancia están aprovechando diferentes categorías de recursos, y ambos enfoques pueden ser complementarios. Sistema IR AP sin PRF AP con PRF Monolingüe 0.266 (100%) 0.288 (100%) MT 0.217 (81.6%) 0.222 (77.1%) DT 0.186 (69.9%) 0.220 (76.4%) CLQS 0.233 (87.6%) 0.259 (89.9%) Curvas P-R de 11 puntos con retroalimentación de relevancia pseudo (TREC6) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Precisión Monolingüe MT DT CLQS MT DT MT+PRF DT+PRF CLQS 0.0298 3.84e-05 0.1472 0.0282 CLQS+PRF 0.0026 2.63e-05 0.0094 0.0016 CONCLUSIONES En este artículo, propusimos un nuevo enfoque para la sugerencia de consultas entre idiomas mediante la extracción de consultas relevantes en diferentes idiomas de los registros de consultas. La solución clave a este problema es aprender una medida de similitud de consultas entre idiomas mediante un modelo discriminativo que aproveche múltiples recursos monolingües y bilingües. El modelo se entrena basado en el principio de que la similitud entre lenguas cruzadas debe ajustarse mejor a la similitud monolingüe entre una consulta y la traducción de la otra consulta. Figura 2. Precisión-recall de 11 puntos en el conjunto de datos CLIR de TREC6. Figura 3. Precisión-recall de 11 puntos en el conjunto de datos CLIR de TREC6 con retroalimentación de relevancia pseudo. Tabla 3. Comparación de la precisión promedio (AP) en TREC 6 sin y con expansión post-traducción. (%) son los porcentajes relativos sobre el rendimiento de recuperación de información monolingüe en la Tabla 4. Los resultados de la prueba t de significancia de pares. Aquí, un valor de p < 0.05 se considera estadísticamente significativo. El sistema CLQS de referencia aplica un enfoque típico de traducción de consultas, utilizando un diccionario bilingüe con desambiguación de traducción basada en co-ocurrencia. Este enfoque solo cubre el 10% de las consultas relevantes sugeridas por un sistema MLQS (cuando se proporciona la traducción exacta de la consulta original). Al aprovechar recursos adicionales como corpora paralelos, minería web y expansión de consultas monolingües basadas en registros, el sistema final es capaz de cubrir el 42% de las consultas relevantes sugeridas por un sistema MLQS con una precisión tan alta como el 79.6%. Para poner a prueba la calidad de las consultas sugeridas, se utiliza el sistema CLQS como sistema de traducción de consultas en tareas de recuperación de información multilingüe. Benchmarked utilizando la tarea CLIR francés-inglés de TREC 6, CLQS demuestra una mayor efectividad que los métodos tradicionales de traducción de consultas utilizando un diccionario bilingüe o herramientas comerciales de traducción automática. La mejora en la tarea de CLIR de francés a inglés de TREC al usar CLQS demuestra la alta calidad de las consultas sugeridas. Esto también muestra la fuerte correspondencia entre las consultas en francés de entrada y las consultas en inglés en el registro. En el futuro, construiremos un sistema CLQS entre idiomas que pueden estar menos correlacionados, por ejemplo, inglés y chino, y estudiaremos el cambio en el rendimiento de CLQS debido a la correspondencia menos fuerte entre las consultas en dichos idiomas. 7. REFERENCIAS [1] Ambati, V. y Rohini., U. Utilizando datos de clics monolingües para construir sistemas de búsqueda multilingües. En Actas del Taller de Nuevas Direcciones en Acceso a la Información Multilingüe de SIGIR 2006. [2] Ballesteros, L. A. y Croft, W. B. Técnicas de Traducción Frasal y Expansión de Consultas para la Recuperación de Información entre Idiomas. En Proc. SIGIR 1997, pp. 84-91. [3] Ballesteros, L. A. y Croft, W. B. Resolviendo la ambigüedad para la recuperación de información entre idiomas. En Proc. SIGIR 1998, pp. 64-71. [4] Brown, P. F., Pietra, D. S. A., Pietra, D. V. J., y Mercer, R. L. Las matemáticas de la traducción automática estadística: Estimación de parámetros. Lingüística Computacional, 19(2):263-311, 1993. [5] Chang, C. C. y Lin, C. LIBSVM: una biblioteca para máquinas de vectores de soporte (Versión 2.3). 2001. http://citeseer.ist.psu.edu/chang01libsvm.html [6] Chen, H.-H., Lin, M.-S. y Wei, Y.-C. Nuevas medidas de asociación utilizando búsqueda web con verificación doble. En Proc. COLING/ACL 2006, pp. 1009-1016. [7] Cheng, P.-J., Teng, J.-W., Chen, R.-C., Wang, J.-H., Lu, W.H., y Chien, L.-F. Traduciendo consultas desconocidas con corpus web para la recuperación de información entre idiomas. En Proc. SIGIR 2004, pp. 146-153. [8] Cui, H., Wen, J. R., Nie, J.-Y., y Ma, W. Y. Expansión de consultas mediante la minería de registros de usuario. IEEE Trans. on Knowledge and Data Engineering, 15(4):829-839, 2003. [9] Fujii A. y Ishikawa, T. Aplicando la Traducción Automática a la Recuperación de Información entre Idiomas en Dos Etapas. En Actas de la 4ta Conferencia de la Asociación para la Traducción Automática en las Américas, pp. 13-24, 2000. [10] Gao, J. F., Nie, J.-Y., Xun, E., Zhang, J., Zhou, M., y Huang, C. Mejorando la traducción de consultas para la Recuperación de Información en Lenguaje Cruzado utilizando Modelos Estadísticos. En Proc. SIGIR 2001, pp. 96-104. [11] Gao, J. F., Nie, J.-Y., He, H., Chen, W., y Zhou, M. Resolución de la ambigüedad en la traducción de consultas utilizando un modelo de co-ocurrencia en descomposición y relaciones de dependencia sintáctica. En Proc. SIGIR 2002, pp. 183-190. [12] Gleich, D., y Zhukov, L. Proyecciones de Subespacios SVD para la Clasificación y Agrupación de Sugerencias de Términos. En el Informe Técnico, Yahoo! Laboratorios de Investigación, 2004. [13] Hull, D. Utilizando pruebas estadísticas en la evaluación de experimentos de recuperación. En Proc. SIGIR 1993, pp. 329-338. [14] Jeon, J., Croft, W. B., y Lee, J. Encontrando preguntas similares en grandes archivos de preguntas y respuestas. En Proc. CIKM 2005, pp. 84-90. [15] Joachims, T. Optimizando motores de búsqueda utilizando datos de clics. En Proc. SIGKDD 2002, pp. 133-142. [16] Lavrenko, V., Choquette, M., y Croft, W. B. Modelos de relevancia interlingüística. En Proc. SIGIR 2002, pp. 175-182. [17] Lu, W.-H., Chien, L.-F., y Lee, H.-J. Minería de texto ancla para la extracción de términos de consulta. En Proc. SIGIR 2001, pp. 388-389. [18] McNamee, P. y Mayfield, J. Comparando técnicas de expansión de consultas entre idiomas mediante la degradación de recursos de traducción. En Proc. SIGIR 2002, pp. 159-166. [19] Monz, C. y Dorr, B. J. Desambiguación de traducción iterativa para la recuperación de información entre idiomas. En Proc. SIGIR 2005, pp. 520-527. [20] Nie, J.-Y., Simard, M., Isabelle, P., y Durand, R. Recuperación de información entre idiomas basada en texto paralelo y extracción automática de texto paralelo de la web. En Proc. SIGIR 1999, pp. 74-81. [21] Och, F. J. y Ney, H. Una comparación sistemática de varios modelos de alineación estadística. Lingüística Computacional, 29(1):19-51, 2003. [22] Pirkola, A., Hedlund, T., Keshusalo, H., y Järvelin, K. Recuperación de Información Basada en Diccionarios entre Idiomas: Problemas, Métodos y Resultados de Investigación. Recuperación de información, 4(3/4):209-230, 2001. [23] Robertson, S. E., Walker, S., Hancock-Beaulieu, M. M., y Gatford, M. OKAPI en TREC-3. En Proc.TREC-3, pp. 200-225, 1995. [24] Robertson, S. E. y Jones, K. S. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27(3):129-146, 1976. [25] Smola, A. J. y Schölkopf, B. Tutorial sobre Regresión de Vectores de Soporte. Estadísticas y Computación, 14(3):199-222, 2004. [26] Wen, J. R., Nie, J.-Y., y Zhang, H. J. Agrupación de consultas utilizando registros de usuario. ACM Trans. Sistemas de Información, 20(1):59-81, 2002. [27] Zhang, Y. y Vines, P. Utilizando la Web para la Extracción Automatizada de Traducciones en la Recuperación de Información entre Idiomas. En Proc. SIGIR 2004, pp. 162-169.