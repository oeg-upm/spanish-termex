Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, "en construcción" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general. Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día. La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web. También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página. Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc. Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14]. Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica. Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7. CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de recuperación de información actuales. Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank. Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo. Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean. El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la clasificación adversarial. Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales. AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets. También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank como una función del factor de amortiguamiento. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de grafos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy. Impacto de los motores de búsqueda en la popularidad de las páginas. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10]J. Cho, S. Roy, R. Adams. Calidad de la página: En busca de una clasificación web imparcial. En las Actas de la Conferencia ACM SIGMOD 2005. Baltimore, Maryland. Junio de 2005. N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Clasificación adversarial. En Actas de la Décima Conferencia Internacional sobre Descubrimiento de Conocimiento y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning y Y. Cantante. Modelos log-lineales para clasificación de etiquetas. En Avances en Sistemas de Procesamiento de Información Neural 16. Cambridge, MA: MIT Press, 2003. [14] S. Fox, K. S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005). Evaluando medidas implícitas para mejorar las experiencias de búsqueda. En la revista ACM Transactions on Information Systems, 23(2), pp. 147-168. Abril de 2005. [15] T. Haveliwala. Cálculo eficiente de PageRank. Informe técnico de la Universidad de Stanford, 1999. [16] T. Haveliwala. PageRank sensible al tema. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] D. Hawking y N. Craswell. Recuperación a gran escala y búsqueda en la web. En D. Harman y E. Voorhees (eds), El Libro de TREC. MIT Press. [18] R. Herbrich, T. Graepel y K. Obermayer. Aprendizaje de vectores de soporte para regresión ordinal. En Actas de la Novena Conferencia Internacional sobre Redes Neuronales Artificiales, pp. 97-102. 1999. [19] M. Ivory y M. Hearst. Perfiles estadísticos de sitios web altamente valorados. En Actas de la Conferencia ACM SIGCHI sobre Factores Humanos en Sistemas Informáticos, 2002. [20]T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (KDD), 2002. [21] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay. Interpretación precisa de los datos de clics como retroalimentación implícita. En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22]J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM 46:5, pp. 604-32. 1999. [23]A. Langville y C. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet 1(3):335-380, 2004. [24] F. Matthieu y M. Bouklit. El efecto del botón de retroceso en un paseo aleatorio: aplicación para PageRank. En los trabajos y pósters de la pista alternativa de la Decimotercera Conferencia Internacional de la World Wide Web, 2004. [25]F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] Y. Minamide. Aproximación estática de páginas web generadas dinámicamente. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] S. Pandey y C. Olston. Rastreo web centrado en el usuario. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de la información de enlaces y contenido en PageRank. En Advances in Neural Information Processing Systems 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30]C. Sherman.
Cambridge, MA: MIT Press, 2002. [30]C. Sherman. Teoma vs. Google, Ronda 2. Disponible en World Wide Web (http://dc.internet.com/news/article.php/1002061), 2002. [31] T. Upstill, N. Craswell y D. Hawking. Prediciendo fama y fortuna: ¿PageRank o grado de entrada? En el Octavo Simposio de Computación de Documentos Australasiano. 2003. [32] T. Upstill, N. Craswell y D. Hawking. Evidencia independiente de la consulta en la búsqueda de la página de inicio. En ACM Transactions on Information Systems. 2003. 715