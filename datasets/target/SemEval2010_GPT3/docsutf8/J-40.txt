Estudios sobre redes que preservan equilibrios evolutivos y el poder de la aleatorización Michael Kearns mkearns@cis.upenn.edu Siddharth Suri ssuri@cis.upenn.edu Departamento de Ciencias de la Computación e Información Universidad de Pensilvania Filadelfia, PA 19104 RESUMEN Investigamos una extensión natural de la teoría clásica de juegos evolutivos a un entorno en el que las interacciones por pares están restringidas a los bordes de un grafo o red no dirigida. Generalizamos la definición de una estrategia evolutivamente estable (ESS) y mostramos un par de resultados complementarios que exhiben el poder de la aleatorización en nuestro entorno: sujeto a condiciones de grado o densidad de aristas, las ESS clásicas de cualquier juego se conservan cuando el grafo se elige al azar y el conjunto de mutaciones se elige adversarialmente, o cuando el grafo se elige adversarialmente y el conjunto de mutaciones se elige al azar. Examinamos fortalecimientos naturales de nuestra definición generalizada de ESS, y demostramos que resultados igualmente sólidos no son posibles para ellos. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía Términos Generales Economía, Teoría 1. En este artículo, presentamos y examinamos una extensión natural de la teoría clásica de juegos evolutivos (EGT) a un entorno en el que las interacciones por pares están restringidas a los bordes de un grafo o red no dirigida. Esta extensión generaliza el escenario clásico, en el cual todos los pares de organismos en una población infinita tienen la misma probabilidad de interactuar. El entorno clásico se puede ver como el caso especial en el que la red subyacente es un clique. Hay muchas razones obvias por las que a uno le gustaría examinar grafos más generales, siendo la principal que en muchos escenarios considerados en la teoría de juegos evolutiva, todas las interacciones de hecho no son posibles. Por ejemplo, las restricciones geográficas pueden limitar las interacciones a pares de organismos físicamente próximos. Más generalmente, dado que la teoría evolutiva de juegos se ha convertido en un modelo plausible no solo para la interacción biológica, sino también para la interacción económica y otros tipos de interacción en los que ciertas dinámicas son más imitativas que optimizadoras (ver [2, 16] y el capítulo 4 de [19]), las restricciones de red pueden provenir de fuentes igualmente más generales. La teoría de juegos evolutiva en redes ha sido considerada anteriormente, pero no en la generalidad en la que lo haremos aquí (ver Sección 4). Generalizamos la definición de una estrategia evolutivamente estable (ESS) a redes, y mostramos un par de resultados complementarios que exhiben el poder de la aleatorización en nuestro entorno: sujeto a condiciones de grado o densidad de aristas, las ESS clásicas de cualquier juego se conservan cuando el grafo se elige al azar y el conjunto de mutaciones se elige adversarialmente, o cuando el grafo se elige adversarialmente y el conjunto de mutaciones se elige al azar. Examinamos fortalecimientos naturales de nuestra definición generalizada de ESS, y demostramos que resultados igualmente sólidos no son posibles para ellos. El trabajo descrito aquí forma parte de los esfuerzos recientes que examinan la relación entre la topología o estructura de un grafo y las propiedades de los resultados de equilibrio. Trabajos previos en esta línea incluyen estudios de la relación de la topología con las propiedades de los equilibrios correlacionados en juegos gráficos [11], y estudios de la variación de precios en modelos de intercambio de mercado de teoría de grafos [12]. Más generalmente, este trabajo contribuye a la línea de modelos de teoría de juegos basados en teoría de grafos investigados tanto en informática [13] como en economía [10]. 2. La idea fundamental de la teoría evolutiva de juegos clásica es la estrategia evolutivamente estable (ESS). De manera intuitiva, un ESS es una estrategia tal que si todos los miembros de una población la adoptan, entonces ninguna estrategia mutante podría invadir la población [17]. Para hacer esto más preciso, describimos el modelo básico de la teoría de juegos evolutiva, en el cual reside la noción de una ESS. El modelo estándar de la teoría evolutiva de juegos considera una población infinita de organismos, cada uno de los cuales juega una estrategia en un juego fijo, simétrico de 2 jugadores. El juego está definido por una función de aptitud F. Todas las parejas de miembros de la población infinita tienen la misma probabilidad de interactuar entre sí. Si dos organismos interactúan, uno jugando la estrategia s 200 y el otro jugando la estrategia t, el jugador s gana una aptitud de F(s|t) mientras que el jugador t gana una aptitud de F(t|s). En esta población infinita de organismos, supongamos que hay una fracción de 1 − que juega la estrategia s, y llamemos a estos organismos incumbentes; y supongamos que hay una fracción que juega t, y llamemos a estos organismos mutantes. Suponga que dos organismos son elegidos de forma aleatoria para jugar entre sí. La estrategia s es un ESS si el fitness esperado de un organismo que juega s es mayor que el de un organismo que juega t, para todo t = s y todo lo suficientemente pequeño . Dado que un titular se encontrará con otro titular con probabilidad 1 − y se encontrará con un mutante con probabilidad , podemos calcular el fitness esperado de un titular, que es simplemente (1 − )F(s|s) + F(s|t). De manera similar, la aptitud esperada de un mutante es (1 − )F(t|s) + F(t|t). Así llegamos a la definición formal de un ESS [19]. Definición 2.1. Una estrategia s es una estrategia evolutivamente estable (ESS) para el juego simétrico de 2 jugadores, dado por la función de aptitud F, si para cada estrategia t = s, existe una t tal que para todo 0 < < t, (1 − )F(s|s) + F(s|t) > (1 − )F(t|s) + F(t|t). Una consecuencia de esta definición es que para que s sea un ESS, debe ser el caso que F(s|s) ≥ F(t|s), para todas las estrategias t. Esta desigualdad significa que s debe ser una mejor respuesta para sí misma, y por lo tanto cualquier estrategia ESS s también debe ser un equilibrio de Nash. En general, la noción de ESS es más restrictiva que el equilibrio de Nash, y no todos los juegos simétricos de 2 jugadores tienen un ESS. En este artículo nuestro interés es examinar qué tipos de estructura de red preservan las estrategias ESS para aquellos juegos que tienen un ESS estándar. Primero debemos, por supuesto, generalizar la definición de ESS a un entorno de red. 3. En nuestros gráficos, ya no asumiremos que dos organismos son elegidos de forma uniforme al azar para interactuar. En cambio, asumimos que los organismos interactúan solo con aquellos en su vecindario local, definido por un grafo o red no dirigida. En el entorno clásico (que puede considerarse como el caso especial de la red completa o clique), asumiremos una población infinita, lo que significa que examinamos el comportamiento límite en una familia de grafos de tamaño creciente. Antes de dar definiciones formales, es necesario hacer algunos comentarios sobre qué esperar al pasar del enfoque clásico al enfoque de teoría de grafos. En el entorno clásico (grafo completo), existen muchas simetrías que pueden romperse al pasar al entorno de red, tanto a nivel de grupo como a nivel individual. De hecho, tales asimetrías son el principal interés al examinar una generalización teórica de grafos. Por ejemplo, a nivel de grupo, en la definición estándar de ESS, no es necesario discutir ningún conjunto particular de mutantes de fracción poblacional. Dado que todos los organismos tienen la misma probabilidad de interactuar, la supervivencia o destino de cualquier conjunto de mutantes específico es idéntico al de cualquier otro. En el entorno de la red, esto puede no ser cierto: algunos conjuntos mutantes pueden tener una mayor capacidad para sobrevivir que otros debido a las topologías específicas de sus interacciones en la red. Por ejemplo, anticipando parte de nuestro análisis, si s es un ESS pero F(t|t) es mucho mayor que F(s|s) y F(s|t), un conjunto mutante con una gran cantidad de interacción interna (es decir, conexiones entre mutantes) puede ser capaz de sobrevivir, mientras que uno sin esto puede sufrir. A nivel de individuos, en el contexto clásico, la afirmación de que un mutante muere implica que todos los mutantes mueren, nuevamente por simetría. En el entorno de red, los destinos individuales pueden diferir dentro de un grupo que juega una estrategia común. Estas observaciones implican que al examinar la ESS en redes nos enfrentamos a elecciones definicionales que estaban oscurecidas en el modelo clásico. Si G es un grafo que representa las interacciones permitidas entre organismos (vértices), y u es un vértice de G que juega la estrategia su, entonces la aptitud de u está dada por F(u) = P v∈Γ(u) F(su|sv) |Γ(u)|. Aquí sv es la estrategia que está siendo jugada por el vecino v, y Γ(u) = {v ∈ V : (u, v) ∈ E}. Se puede ver la aptitud de u como la aptitud promedio que u obtendría si jugara con cada uno de sus vecinos, o la aptitud esperada que u obtendría si se le asignara jugar con uno de sus vecinos elegido de forma uniforme al azar. La teoría evolutiva de juegos clásica examina una población infinita y simétrica. Los gráficos o redes son objetos inherentemente finitos, y estamos específicamente interesados en sus asimetrías, como se discutió anteriormente. Por lo tanto, todas nuestras definiciones girarán en torno a una familia infinita G = {Gn}∞ n=0 de grafos finitos Gn con n vértices, pero examinaremos propiedades asintóticas (para n grande) de tales familias. Primero damos una definición para una familia de conjuntos de vértices mutantes en tal familia de grafos infinitos para contraer. Definición 3.1. Sea G = {Gn}∞ n=0 una familia infinita de grafos, donde Gn tiene n vértices. Sea M = {Mn}∞ n=0 cualquier familia de subconjuntos de vértices de Gn tal que |Mn| ≥ n para alguna constante > 0. Supongamos que todos los vértices de Mn juegan una estrategia común (mutante) t, y supongamos que los vértices restantes en Gn juegan una estrategia común (incumbente) s. Decimos que Mn se contrae si para n suficientemente grande, para todos menos o(n) de los j ∈ Mn, j tiene un vecino incumbente i tal que F(j) < F(i). Una alternativa razonable sería pedir que la condición anterior se cumpla para todos los mutantes en lugar de todos menos o(n). También hay que tener en cuenta que solo requerimos que un mutante tenga un vecino vigente de mayor aptitud para morir; se podría considerar requerir más. En las Secciones 6.1 y 6.2 consideramos estas condiciones más fuertes y demostramos que nuestros resultados ya no pueden sostenerse. Para definir adecuadamente un ESS para una familia infinita de grafos finitos de manera que recupere la definición clásica asintóticamente en el caso de la familia de grafos completos, primero debemos dar una definición que restrinja la atención a familias de vértices mutantes que son más pequeños que algún umbral de invasión n, pero que siguen siendo una fracción constante de la población. Esto evita invasiones que sobreviven simplemente al constituir una fracción desaparecida de la población. Definición 3.2. Sea > 0, y sea G = {Gn}∞ n=0 una familia infinita de grafos, donde Gn tiene n vértices. Sea M = {Mn}∞ n=0 cualquier familia de vértices (mutantes) en Gn. Decimos que M es -lineal si existe un , > > 0, tal que para todo n suficientemente grande, n > |Mn| > n. Ahora podemos dar nuestra definición para una estrategia que sea evolutivamente estable cuando es empleada por organismos que interactúan con su vecindario en un grafo. Definición 3.3. Sea G = {Gn}∞ n=0 una familia infinita de grafos, donde Gn tiene n vértices. Sea F cualquier juego simétrico de 2 jugadores para el cual s sea una estrategia. Decimos que s es una ESS con respecto a F y G si para todas las estrategias mutantes t = s, existe un t > 0 tal que para cualquier familia t-lineal de vértices mutantes M = {Mn}∞ n=0 que juegan todos con t, para n suficientemente grande, Mn se contrae. Por lo tanto, para violar la propiedad ESS para G, uno debe presenciar una familia de mutaciones M en la que cada Mn sea una fracción constante arbitrariamente pequeña pero distinta de cero de la población de Gn, pero no se contrae (es decir, cada conjunto de mutantes tiene un subconjunto de tamaño lineal que sobrevive a todas sus interacciones vigentes). En la Sección A.1 mostramos que la definición dada coincide con la clásica en el caso en que G es la familia de grafos completos, en el límite de n grande. Observamos que incluso en el modelo clásico, se permitía que conjuntos pequeños de mutantes tuvieran una aptitud mayor que los incumbentes, siempre y cuando el tamaño del conjunto fuera o(n) [18]. En la definición anterior hay tres parámetros: el juego F, la familia de grafos G y la familia de mutaciones M. Nuestros principales resultados se mantendrán para cualquier juego F simétrico de 2 jugadores. También estudiaremos dos configuraciones bastante generales para G y M: aquella en la que G es una familia de grafos aleatorios y M es arbitrario, y aquella en la que G es casi arbitrario y M se elige al azar. En ambos casos, veremos que, sujeto a condiciones sobre el grado o la densidad de los bordes (forzando esencialmente la conectividad de G pero no mucho más), para cualquier juego simétrico de 2 jugadores, las ESS de las configuraciones clásicas, y solo esas estrategias, siempre se conservan. Por lo tanto, un tema común de estos resultados es el poder de la aleatorización: siempre y cuando la red misma sea elegida al azar, o el conjunto de mutaciones sea elegido al azar, los ESS clásicos se conservan. 4. TRABAJO RELACIONADO Ha habido trabajos previos que analizan qué estrategias son resilientes a invasiones de mutantes con respecto a varios tipos de grafos. Lo que distingue nuestro trabajo es que el modelo que consideramos abarca una clase de juegos y topologías de grafos significativamente más generales. Revisaremos brevemente esta literatura y señalaremos las diferencias entre los modelos anteriores y el nuestro. En [8], [3] y [4], los autores consideran familias específicas de grafos, como ciclos y retículas, donde los jugadores participan en juegos específicos, como juegos de 2 × 2 o juegos de coordinación k × k. En estos documentos, los autores especifican una dinámica simple y local para que los jugadores mejoren sus ganancias cambiando estrategias, y analizan qué tipo de estrategias crecerán para dominar la población. El modelo que proponemos es más general que ambos, ya que abarca una clase más amplia de grafos y un conjunto más rico de juegos. También relacionado con nuestro trabajo está el de [14], donde los autores proponen dos modelos. El primero asume que los organismos interactúan de acuerdo a un grafo ponderado y no dirigido. Sin embargo, la aptitud de cada organismo se asigna simplemente y no depende de las acciones del vecindario de cada organismo. El segundo modelo tiene organismos dispuestos alrededor de un ciclo dirigido, donde los vecinos juegan un juego 2 × 2. Con una probabilidad proporcional a su aptitud, se elige a un organismo para reproducirse colocando una réplica de sí mismo en la posición de su vecino, matando así al vecino. Consideramos juegos más generales que el primer modelo y grafos más generales que el segundo. Finalmente, los trabajos más relacionados con el nuestro son [7], [15] y [6]. Los autores consideran juegos de coordinación de 2 acciones jugados por jugadores en un grafo no dirigido general. En estos tres trabajos, los autores especifican una dinámica para una estrategia de reproducción, y analizan las propiedades del grafo que permiten que una estrategia supere a la población. Aquí nuevamente, se puede ver que nuestro modelo es más general que estos, ya que permite a los organismos jugar cualquier juego simétrico de 2 jugadores. 5. Ahora procedemos a enunciar y demostrar dos resultados complementarios en el modelo de red ESS definido en la Sección 3. Primero, consideramos un escenario donde los grafos son generados a través del modelo Gn,p de Erd˝os y R´enyi [5]. En este modelo, cada par de vértices está unido por un borde de forma independiente y con una probabilidad p (donde p puede depender de n). El conjunto mutante, sin embargo, se construirá de manera adversarial (sujeto a la restricción de tamaño lineal dada por la Definición 3.3). Para estas configuraciones, demostramos que para cualquier juego simétrico de 2 jugadores, s es un ESS clásico de ese juego, si y solo si s es un ESS para {Gn,p}∞ n=0, donde p = Ω(1/nc) y 0 ≤ c < 1, y cualquier familia de mutantes {Mn}∞ n=0, donde cada Mn tiene un tamaño lineal. Observamos que bajo esta configuración, si dejamos que c = 1 − γ para γ pequeño y positivo, el número esperado de aristas en Gn es n1+γ o mayor, es decir, solo superlineal en el número de vértices y potencialmente mucho menor que O(n2). Es fácil convencerse de que una vez que los gráficos tienen solo un número lineal de aristas, estamos coqueteando con la desconexión, y simplemente puede haber conjuntos mutantes grandes que pueden sobrevivir en aislamiento debido a la falta de interacciones existentes en ciertos juegos. Así, en cierto sentido examinamos la densidad mínima plausible de los bordes. El segundo resultado es una especie de dualidad del primero, considerando un escenario donde los grafos son elegidos arbitrariamente (sujeto a condiciones) pero los conjuntos mutantes son elegidos al azar. Se establece que para cualquier juego simétrico de 2 jugadores, s es una ESS clásica para ese juego, si y solo si s es una ESS para cualquier {Gn = (Vn, En)}∞ n=0 en el que para todo v ∈ Vn, deg(v) = Ω(nγ) (para cualquier constante γ > 0), y una familia de conjuntos de mutantes {Mn}∞ n=0, que se elige al azar (es decir, en la que cada organismo se etiqueta como mutante con una probabilidad constante > 0). Por lo tanto, en este escenario nuevamente encontramos que las ESS clásicas se conservan sujeto a restricciones de densidad de bordes. Dado que la suposición del grado es algo fuerte, también demostramos otro resultado que solo asume que |En| ≥ n1+γ, y muestra que debe existir al menos 1 mutante con un vecino titular de mayor aptitud (en lugar de mostrar que todos menos o(n) mutantes tienen un vecino titular de mayor aptitud). Como se discutirá, esto descarta las invasiones mutantes estacionarias. 5.1 Grafos Aleatorios, Mutaciones Adversarias Ahora enunciamos y demostramos un teorema que muestra que si s es un ESS clásico, entonces s será un ESS para grafos aleatorios, donde un conjunto de mutantes de tamaño lineal es elegido por un adversario. Teorema 5.1. Sea F cualquier juego simétrico de 2 jugadores, y supongamos que s es una ESS clásica de F. Deje que la familia de grafos infinitos {Gn}∞ n=0 se dibuje de acuerdo a Gn,p, donde p = Ω(1/nc) y 0 ≤ c < 1. Entonces, con probabilidad 1, s es una ESS. La idea principal de la prueba es dividir a los mutantes en 2 categorías, aquellos con aptitud normal y aquellos con aptitud anormal ab202. Primero, mostramos que todos menos o(n) de la población (incumbente o mutante) tienen un vecino incumbente de aptitud normal. Esto implicará que todos menos o(n) de los mutantes de aptitud normal tienen un vecino dominante de mayor aptitud. El vehículo para demostrar esto es el Teorema 2.15 de [5], que proporciona una cota superior sobre el número de vértices no conectados a un conjunto lo suficientemente grande. Este teorema asume que el tamaño de este conjunto grande se conoce con igualdad, lo que requiere el argumento del límite de unión que se presenta a continuación. En segundo lugar, demostramos que puede haber como máximo o(n) mutantes con aptitud anormal. Dado que hay tan pocos de ellos, incluso si ninguno de ellos tiene un vecino incumbente de mayor aptitud, s seguirá siendo un ESS con respecto a F y G. Prueba. (Bosquejo) Sea t = s la estrategia mutante. Dado que s es un ESS clásico, existe un t tal que (1− )F(s|s)+ F(s|t) > (1 − )F(t|s) + F(t|t), para todo 0 < < t. Sea M cualquier familia de mutantes que sea t-lineal. Por lo tanto, para cualquier valor fijo de n que sea suficientemente grande, existe un n tal que |Mn| = n y t > > 0. Además, sea In = Vn \ Mn y sea I ⊆ In el conjunto de los titulares que tienen aptitud en el rango (1 ± τ)[(1 − )F(s|s) + F(s|t)] para algún τ constante, 0 < τ < 1/6. El lema 5.1 a continuación muestra (1 − )n ≥ |I | ≥ (1 − )n − 24 log n τ2p. Finalmente, dejemos que TI = {x ∈ V \ I : Γ(x) ∩ I = ∅}. (Para mayor claridad, omitimos el subíndice n en los conjuntos I y T.) La unión acotada nos da Pr(|TI | ≥ δn) ≤ (1− )n X i=(1− )n− 24 log n τ2p Pr(|TI | ≥ δn y |I | = i) (1) Tomando δ = n−γ para algún γ > 0, obtenemos que δn = o(n). Aplicaremos el Teorema 2.15 de [5] al sumando del lado derecho de la Ecuación 1. Si dejamos que γ = (1−c)/2, y combinamos esto con el hecho de que 0 ≤ c < 1, se cumplirán todos los requisitos de este teorema (detalles omitidos). Ahora, al aplicar este teorema a la Ecuación 1, obtenemos Pr(|TI | ≥ δn) ≤ (1− )n X i=(1− )n− 24 log n τ2p exp „ − 1 6 Cδn « (2) = o(1). Esto se debe a que la ecuación 2 tiene solo 24 log n τ2p términos, y el Teorema 2.15 de [5] nos dice que C ≥ (1 − )n1−c − 24 log n τ2. Por lo tanto, hemos demostrado, con una probabilidad que tiende a 1 a medida que n → ∞, que como máximo o(n) individuos no están vinculados a un titular que tiene aptitud en el rango (1 ± τ)[(1 − )F(s|s) + F(s|t)]. Esto implica que el número de mutantes de aptitud aproximadamente normal, no vinculados a un titular de aptitud aproximadamente normal, también es de orden o(n). Ahora esos mutantes de aproximadamente normal aptitud que están unidos a un titular de aproximadamente normal aptitud tienen una aptitud en el rango (1±τ)[(1− )F(t|s)+ F(t|t)]. Los titulares a los que están adjuntos tienen aptitud en el rango (1±τ)[(1− )F(s|s)+ F(s|t)]. Dado que s es un ESS de F, sabemos que (1− )F(s|s)+ F(s|t) > (1− )F(t|s)+ F(t|t), por lo tanto, si elegimos τ lo suficientemente pequeño, podemos asegurarnos de que todos menos o(n) mutantes de aptitud normal tengan un titular vecino de mayor aptitud. Finalmente, por el Lema 5.1, sabemos que hay como máximo o(n) mutantes con aptitud anormal. Por lo tanto, aunque todos ellos son más aptos que sus respectivos vecinos titulares, hemos demostrado que todos menos o(n) de los mutantes tienen un vecino titular de mayor aptitud. Ahora enunciamos y demostramos el lema utilizado en la demostración anterior. Lema 5.1. Para casi todos los gráficos Gn,p con (1 − )n incumbentes, todos menos 24 log n δ2p incumbentes tienen aptitud en el rango (1±δ)[(1− )F(s|s)+ F(s|t)], donde p = Ω(1/nc ) y , δ y c son constantes que satisfacen 0 < < 1, 0 < δ < 1/6, 0 ≤ c < 1. De manera similar, bajo las mismas suposiciones, todos menos 24 mutantes log n δ2p tienen aptitud en el rango (1 ± δ)[(1 − )F(t|s) + F(t|t)]. Prueba. Definimos el grado mutante de un vértice como el número de vecinos mutantes de ese vértice, y el grado de titularidad de manera análoga. Observa que la única forma en que un titular pueda tener una aptitud muy alejada de su valor esperado de (1− )F(s|s)+ F(s|t) es si tiene una fracción de vecinos mutantes mucho más alta o mucho más baja que . El Teorema 2.14 de [5] nos da un límite en el número de tales titulares. Indica que el número de titulares con un grado mutante fuera del rango (1 ± δ)p|M| es a lo sumo 12 log n δ2p. Según el mismo teorema, el número de titulares con un grado de titular fuera del rango (1 ± δ)p|I| es a lo sumo 12 log n δ2p. A partir de la linealidad de la aptitud como función de la fracción de vecinos mutantes o incumbentes, se puede demostrar que para aquellos incumbentes con grado mutante e incumbente en el rango esperado, su aptitud está dentro de un factor constante de (1 − )F(s|s) + F(s|t), donde esa constante tiende a 1 a medida que n tiende a infinito y δ tiende a 0. La prueba para el caso del mutante es análoga. Observamos que si en la afirmación del Teorema 5.1 dejamos que c = 0, entonces p = 1. Esto, a su vez, hace que G = {Kn}∞ n=0, donde Kn es una clique de n vértices. Entonces, para cualquier Kn, todos los titulares tendrán un nivel de aptitud idéntico y todos los mutantes tendrán un nivel de aptitud idéntico. Además, dado que s era una ESS para G, la aptitud del titular será mayor que la aptitud del mutante. Finalmente, se puede demostrar que a medida que n → ∞, la aptitud del individuo incumbente converge a (1 − )F(s|s) + F(s|t), y la aptitud del mutante converge a (1 − )F(t|s) + F(t|t). En otras palabras, s debe ser un ESS clásico, proporcionando un contrapunto al Teorema 5.1. Presentamos rigurosamente este argumento en la Sección A.1. 5.2 Grafos Adversarios, Mutaciones Aleatorias. Ahora pasamos a nuestro segundo resultado principal. Aquí mostramos que si la familia de grafos, en lugar de ser elegida al azar, es arbitraria sujeta a un requisito de grado mínimo, y los conjuntos de mutaciones son elegidos al azar, los ESS clásicos se conservan nuevamente. Una noción modificada de ESS nos permite debilitar considerablemente el requisito de grado a un requisito mínimo de densidad de aristas. Teorema 5.2. Sea G = {Gn = (Vn, En)}∞ n=0 una familia infinita de grafos en la que para todo v ∈ Vn, deg(v) = Ω(nγ) (para cualquier constante γ > 0). Sea F cualquier juego simétrico de 2 jugadores, y supongamos que s es una ESS clásica de F. Sea t cualquier estrategia mutante, y sea la familia de mutantes M = {Mn}∞ n=0 elegida al azar etiquetando cada vértice como mutante con una probabilidad constante, donde t > > 0. Entonces, con probabilidad 1, s es una ESS con respecto a F, G y M. 203 Prueba. Sea t = s la estrategia mutante y sea X el evento de que cada titular tenga una aptitud dentro del rango (1 ± τ)[(1 − )F(s|s) + F(s|t)], para algún valor constante τ > 0 que se especificará más adelante. De manera similar, sea Y el evento en el que cada mutante tiene una aptitud dentro del rango (1 ± τ)[(1 − )F(t|s) + F(t|t)]. Dado que Pr(X ∩ Y ) = 1 − Pr(¬X ∪ ¬Y ), procedemos mostrando que Pr(¬X ∪ ¬Y ) = o(1). ¬X es el evento de que exista un titular con aptitud fuera del rango (1±τ)[(1− )F(s|s)+ F(s|t)]. Si degM (v) denota el número de vecinos mutantes de v, de manera similar, degI (v) denota el número de vecinos titulares de v, entonces un titular i tiene aptitud degI (i) deg(i) F(s|s) + degM (i) deg(i) F(s|t). Dado que F(s|s) y F(s|t) son cantidades fijas, la única variación en la aptitud de un titular puede provenir de la variación en los términos degI (i) y degM (i). Se puede utilizar el límite de Chernoff seguido del límite de unión para demostrar que para cualquier titular i, Pr(F(i) /∈ (1 ± τ)[(1 − )F(s|s) + F(s|t)]) < 4 exp „ − deg(i)τ2 3 «. A continuación, se puede utilizar el límite de unión nuevamente para acotar la probabilidad del evento ¬X, Pr(¬X) ≤ 4n exp „ − diτ2 3 « donde di = mini∈V \M deg(i), 0 < ≤ 1/2. Un argumento análogo se puede hacer para mostrar que Pr(¬Y) < 4n exp(− dj τ2 3), donde dj = minj∈M deg(j) y 0 < ≤ 1/2. Por lo tanto, mediante la unión acotada, Pr(¬X ∪ ¬Y ) < 8n exp „ − dτ2 3 « donde d = minv∈V deg(v), 0 < ≤ 1/2. Dado que deg(v) = Ω(nγ), para todo v ∈ V, y τ y γ son constantes mayores que 0, lim n→∞ 8n exp (dτ2/3) = 0, por lo que Pr(¬X∪¬Y) = o(1). Por lo tanto, podemos elegir τ lo suficientemente pequeño para que (1 + τ)[(1 − )F(t|s) + F(t|t)] < (1 − τ)[(1 − )F(s|s)+ F(s|t)], y luego elegir n lo suficientemente grande para que con probabilidad 1 − o(1), cada titular tenga aptitud en el rango (1±τ)[(1− )F(s|s)+F(s|t)], y cada mutante tenga aptitud en el rango (1 ± τ)[(1 − )F(t|s) + F(t|t)]. Por lo tanto, con alta probabilidad, cada individuo existente tendrá una aptitud mayor que cada mutante. Por argumentos similares a los que siguen la demostración del Teorema 5.1, si dejamos que G = {Kn}∞ n=0, cada titular tendrá la misma aptitud y cada mutante tendrá la misma aptitud. Además, dado que s es una ESS para G, la aptitud del titular debe ser mayor que la aptitud del mutante. Aquí nuevamente, uno tiene que demostrar que a medida que n → ∞, la aptitud del individuo incumbente converge a (1 − )F(s|s) + F(s|t), y la aptitud del mutante converge a (1 − )F(t|s) + F(t|t). Observe que la fracción exacta de mutantes de Vn es ahora una variable aleatoria. Para demostrar esta convergencia, utilizamos un argumento similar al que se usa para demostrar que una secuencia de variables aleatorias que converge en probabilidad también converge en distribución (detalles omitidos). Esto a su vez establece que s debe ser una ESS clásica, y así obtenemos un converso al Teorema 5.2. Este argumento se hace riguroso en la Sección A.2. La suposición sobre el grado de cada vértice del Teorema 5.2 es bastante fuerte. El siguiente teorema relaja este requisito y solo requiere que cada grafo tenga n1+γ aristas, para alguna constante γ > 0, en cuyo caso muestra que siempre habrá al menos 1 mutante con un vecino incumbente de mayor aptitud. Una estrategia que es un ESS en este sentido debilitado esencialmente descartará conjuntos estables y estáticos de invasiones mutantes, pero no invasiones más complejas. Un ejemplo de invasiones más complejas son conjuntos mutantes que sobreviven, pero solo al migrar perpetuamente a través del grafo bajo alguna dinámica evolutiva natural, similar a los planeadores en el conocido Juego de la Vida [1]. Teorema 5.3. Sea F cualquier juego, y sea s una ESS clásica de F, y sea t = s una estrategia mutante. Para cualquier familia de grafos G = {Gn = (Vn, En)}∞ n=0 en la que |En| ≥ n1+γ (para cualquier constante γ > 0), y cualquier familia de mutantes M = {Mn}∞ n=0 que está determinada por etiquetar cada vértice como mutante con probabilidad , donde t > > 0, la probabilidad de que exista un mutante con un vecino incumbente de mayor aptitud tiende a 1 a medida que n → ∞. Prueba. (Bosquejo) La idea principal detrás de la prueba es demostrar que con alta probabilidad, solo con la elección de mutantes, habrá un borde entre el incumbente y el mutante en el que ambos vértices tengan un alto grado. Si su grado es lo suficientemente alto, podemos demostrar que cerca de una fracción de sus vecinos son mutantes, y por lo tanto, sus aptitudes son muy cercanas a lo que esperamos que sean en el caso clásico. Dado que s es un ESS, la aptitud del titular será mayor que la del mutante. Llamamos a un borde (i, j) ∈ En una g(n)-barra si deg(i) ≥ g(n) y deg(j) ≥ g(n). Supongamos que Gn tiene a lo sumo h(n) aristas que son g(n)-mancuernas. Esto significa que hay al menos |En| − h(n) aristas en las cuales al menos un vértice tiene un grado de a lo sumo g(n). Llamamos a estos vértices vértices de luz. Sea (n) el número de vértices ligeros en Gn. Observa que |En|−h(n) ≤ (n)g(n). Esto se debe a que cada vértice de luz incide en un máximo de g(n) aristas. Esto nos da que |En| ≤ h(n) + (n)g(n) ≤ h(n) + ng(n). Entonces, si elegimos h(n) y g(n) de manera que h(n) + ng(n) = o(n1+γ), entonces |En| = o(n1+γ). Esto contradice la suposición de que |En| = Ω(n1+γ). Por lo tanto, sujeto a la restricción anterior en h(n) y g(n), Gn debe contener al menos h(n) aristas que son g(n)-barbells. Ahora dejemos que Hn denote el subgrafo inducido por las aristas de barra de Gn. Ten en cuenta que, independientemente de la estructura de Gn, no hay razón para que Hn esté conectado. Por lo tanto, sea m el número de componentes conectadas de Hn, y sean c1, c2, . . . , cm el número de vértices en cada una de estas componentes conectadas. Ten en cuenta que dado que Hn es un subgrafo inducido por aristas, tenemos ck ≥ 2 para todos los componentes k. Elijamos el conjunto de mutantes comenzando por voltear únicamente los vértices en Hn. Ahora demostramos que la probabilidad, con respecto al conjunto mutante aleatorio, de que ninguno de los componentes de Hn tenga un borde mutante-incumbente es exponencialmente pequeña en n. Sea An el evento de que cada componente de Hn contenga solo mutantes o solo incumbentes. Entonces, las manipulaciones algebraicas pueden establecer que Pr[An] = Πm k=1( ck + (1 − )ck ) ≤ (1 − )(1− β2 2 ) Pm k=1 ck 204 donde β es una constante. Por lo tanto, para suficientemente pequeño, el límite disminuye exponencialmente con Pm k=1 ck. Además, dado que ∑ desde k=1 hasta m de ck^2 ≥ h(n) (con igualdad lograda al hacer que cada componente sea un clique), se puede demostrar que ∑ desde k=1 hasta m de ck ≥ p h(n). Por lo tanto, siempre y cuando h(n) → ∞ con n, la probabilidad de que todos los componentes estén etiquetados de forma uniforme tiende a 0. Ahora, suponiendo que existe un componente etiquetado de forma no uniforme, por construcción ese componente contiene un borde (i, j) donde i es un titular y j es un mutante, es decir, una barra g(n). También asumimos que los vértices h(n) ya etiquetados han sido etiquetados de manera arbitraria, pero que los restantes g(n) - h(n) vértices vecinos de i y j están etiquetados como mutantes de forma independiente con una probabilidad de . Luego, a través de un argumento estándar de límite de Chernoff, se puede demostrar que con alta probabilidad, la fracción de mutantes vecinos de i y la fracción de mutantes vecinos de j están en el rango (1 ± τ)(g(n)−h(n)) g(n). De manera similar, se puede demostrar que la fracción de titulares vecinos de i y la fracción de mutantes vecinos de j se encuentran en el rango 1 − (1 ± τ)(g(n)−h(n)) g(n). Dado que s es un ESS, existe un ζ > 0 tal que (1 − )F(s|s) + F(s|t) = (1 − )F(t|s) + F(t|t) + ζ. Si elegimos g(n) = nγ, y h(n) = o(g(n)), podemos elegir un n lo suficientemente grande y un τ lo suficientemente pequeño para forzar que F(i) > F(j), como se desee. 6. LIMITACIONES DE MODELOS MÁS FUERTES En esta sección mostramos que si uno intentara fortalecer el modelo descrito en la Sección 3 de dos maneras naturales, no se podría demostrar resultados tan sólidos como los Teoremas 5.1 y 5.2, que se aplican a cada juego simétrico de 2 jugadores. 6.1 Contracción más fuerte para el conjunto de mutantes En la Sección 3 aludimos al hecho de que tomamos ciertas decisiones de diseño al llegar a las Definiciones 3.1, 3.2 y 3.3. Una de esas decisiones fue requerir que todos los mutantes, excepto o(n), tengan vecinos incumbentes de mayor aptitud. En cambio, podríamos haber requerido que todos los mutantes tengan un vecino actual de mayor aptitud. Los dos teoremas de esta subsección muestran que si se fortaleciera nuestra noción de contracción para el conjunto mutante, dada por la Definición 3.1, de esta manera, sería imposible demostrar teoremas análogos a los Teoremas 5.1 y 5.3. Recuerde que la Definición 3.1 dio la noción de contracción para un subconjunto de mutantes de tamaño lineal. En lo que sigue, diremos que un borde (i, j) se contrae si i es un titular, j es un mutante, y F(i) > F(j). Además, recuerda que el Teorema 5.1 estableció que si s es un ESS clásico, entonces es un ESS para grafos aleatorios con mutaciones adversariales. A continuación, demostramos que si en su lugar requerimos que cada borde entre un individuo y un mutante en ejercicio se contraiga, esto no necesariamente debe ser así. Teorema 6.1. Sea F un juego simétrico de 2 jugadores que tiene un ESS clásico s para el cual existe una estrategia mutante t = s con F(t|t) > F(s|s) y F(t|t) > F(s|t). Sea G = {Gn}∞ n=0 una familia infinita de grafos aleatorios dibujados de acuerdo a Gn,p, donde p = Ω(1/nc) para cualquier constante 0 ≤ c < 1. Entonces, con probabilidad que tiende a 1 a medida que n → ∞, existe una familia de mutantes M = {Mn}∞ n=0, donde tn > |Mn| > n y t, > 0, en la que hay una arista que no se contrae. Prueba. (Bosquejo) Con probabilidad que tiende a 1 a medida que n → ∞, existe un vértice j donde deg(j) está arbitrariamente cerca de n. Por lo tanto, etiqueta j como mutante, etiqueta a uno de sus vecinos como titular, denotado como i, y etiqueta al resto del vecindario de j como mutante. Además, etiquete a todos sus vecinos como incumbentes, con la excepción de los vecinos de j y js (que ya fueron etiquetados como mutantes). En este contexto, se puede demostrar que F(j) estará arbitrariamente cerca de F(t|t) y F(i) será una combinación convexa de F(s|s) y F(s|t), las cuales son estrictamente menores que F(t|t). El Teorema 5.3 estableció que si s es una ESS clásica, entonces para grafos donde |En| ≥ n1+γ, para algún γ > 0, y donde cada organismo está etiquetado como mutante con probabilidad p, un borde debe contraerse. A continuación demostramos que, para ciertos grafos y ciertos juegos, siempre existirá una arista que no se contraerá. Teorema 6.2. Sea F un juego simétrico de 2 jugadores que tiene un ESS clásico s, tal que existe una estrategia mutante t = s donde F(t|s) > F(s|t). Existe una familia infinita de grafos {Gn = (Vn, En)}∞ n=0, donde |En| = Θ(n2), tal que para una familia de mutantes M = {Mn}∞ n=0, que se determina etiquetando cada vértice como mutante con probabilidad > 0, la probabilidad de que exista una arista en En que no se contraiga tiende a 1 a medida que n → ∞. Prueba. (Bosquejo) Construye Gn de la siguiente manera. Selecciona n/4 vértices u1, u2, . . . , un/4 y agrega aristas de manera que formen una clique. Luego, para cada ui, i ∈ [n/4], agregar aristas (ui, vi), (vi, wi) y (wi, xi). Con probabilidad 1 a medida que n → ∞, existe un i tal que ui y wi son mutantes y vi y xi son incumbentes. Observa que F(vi) = F(xi) = F(s|t) y F(wi) = F(t|s). 6.2 Contracción más fuerte para individuos. El modelo de la Sección 3 requiere que para que un borde (i, j) se contraiga, la aptitud de i debe ser mayor que la aptitud de j. Una forma de fortalecer esta noción de contracción sería requerir que el máximo nivel de aptitud presente en el vecindario de j sea más alto que el máximo nivel de aptitud del mutante en el vecindario de j. Esto modela la idea de que cada organismo intenta apoderarse de cada lugar en su vecindario, pero solo el organismo más apto en el vecindario de un vértice tiene el privilegio de hacerlo. Si asumimos que adoptamos esta noción de contracción para mutantes individuales, y requerimos que todos los bordes entre incumbentes y mutantes se contraigan, a continuación mostraremos que los Teoremas 6.1 y 6.2 siguen siendo válidos, y por lo tanto sigue siendo imposible obtener resultados como los Teoremas 5.1 y 5.3 que son válidos para cada juego simétrico de 2 jugadores. En la demostración del Teorema 6.1 demostramos que F(i) es estrictamente menor que F(j). Observa que el mutante con máxima aptitud en el vecindario de j debe tener una aptitud de al menos F(j). También observa que solo hay 1 titular en el vecindario de j, es decir, i. Por lo tanto, bajo esta noción más fuerte de contracción, el borde (i, j) no se contraerá. De manera similar, en la demostración del Teorema 6.2, observe que el único mutante en el vecindario de wi es wi mismo, que tiene una aptitud de F(t|s). Además, los únicos ocupantes en el vecindario de wi son vi y xi, ambos con una aptitud de F(s|t). Por suposición, F(t|s) > F(s|t), por lo tanto, bajo esta noción más fuerte de contracción, ninguno de los bordes mutantes del titular, (vi, wi) y (xi, wi), se contraerá. 7. REFERENCIAS [1] Elwyn R. Berlekamp, John Horton Conway y Richard K. Guy. Formas ganadoras para tus 205 juegos matemáticos, volumen 4. AK Peters, Ltd, marzo de 2004. [2] Jonas Björnerstedt y Karl H. Schlag. Sobre la evolución del comportamiento imitativo. Documento de discusión B-378, Universidad de Bonn, 1996. [3] L. E. Blume. La mecánica estadística de la interacción estratégica. Juegos y Comportamiento Económico, 5:387-424, 1993. [4] L. E. Blume. La mecánica estadística de la revisión de estrategias de mejor respuesta. Juegos y Comportamiento Económico, 11(2):111-145, noviembre de 1995. [5] B. Bollobás. Gráficos aleatorios. Cambridge University Press, 2001. [6] Michael Suk-Young Chwe.
Cambridge University Press, 2001. [6] Michael Suk-Young Chwe. Comunicación y coordinación en redes sociales. Revisión de Estudios Económicos, 67:1-16, 2000. [7] Glenn Ellison. Aprendizaje, interacción local y coordinación. Econometrica, 61(5):1047-1071, septiembre de 1993. [8] I. Eshel, L. Samuelson y A. Shaked. Altruistas, egoístas y gamberros en un modelo de interacción local. La American Economic Review, 88(1), 1998. [9] Geoffrey R. Grimmett y David R. Stirzaker. Probabilidad y Procesos Aleatorios. Editorial de la Universidad de Oxford, 3ra edición, 2001. [10] M. Jackson. Una encuesta de modelos de formación de redes: Estabilidad y eficiencia. En la formación de grupos en economía; redes, clubes y coaliciones. Cambridge University Press, 2004. [11] S. Kakade, M. Kearns, J. Langford, y L. Ortiz. Equilibrios correlacionados en juegos gráficos. Conferencia ACM sobre Comercio Electrónico, 2003. [12] S. Kakade, M. Kearns, L. Ortiz, R. Pemantle y S. Suri. Propiedades económicas de las redes sociales. Sistemas de Procesamiento de Información Neural, 2004. [13] M. Kearns, M. Littman y S. Singh. Modelos gráficos para teoría de juegos. Conferencia sobre Incertidumbre en Inteligencia Artificial, páginas 253-260, 2001. [14] E. Lieberman, C. Hauert y M. A. Nowak. Dinámica evolutiva en grafos. Naturaleza, 433:312-316, 2005. [15] S. Morris. Contagio. Revisión de Estudios Económicos, 67(1):57-78, 2000. [16] Karl H. Schlag. ¿Por qué imitar y, en caso afirmativo, cómo? Revista de Teoría Económica, 78:130-156, 1998. [17] J. M. Smith. Evolución y la Teoría de Juegos. Cambridge University Press, 1982. [18] William L. Vickery.
Editorial de la Universidad de Cambridge, 1982. [18] William L. Vickery. Cómo hacer trampa contra una estrategia mixta ESS simple. Revista de Biología Teórica, 127:133-139, 1987. [19] Jörgen W. Weibull. Teoría de juegos evolutiva. El MIT Press, 1995. APÉNDICE A. ESS GRÁFICO Y CLÁSICO En esta sección exploramos las condiciones bajo las cuales un ESS gráfico también es un ESS clásico. Para hacerlo, enunciamos y demostramos dos teoremas que proporcionan las conversas de cada uno de los teoremas principales en la Sección 3. El Teorema 5.2 de Grafos Aleatorios, Mutaciones Adversariales establece que si s es un ESS clásico y G = {Gn,p}, donde p = Ω(1/nc) y 0 ≤ c < 1, entonces con probabilidad 1 a medida que n → ∞, s es un ESS con respecto a G. Aquí mostramos que si s es un ESS con respecto a G, entonces s es un ESS clásico. Para demostrar este teorema, no necesitamos la plena generalidad de que s sea un ESS para G cuando p = Ω(1/nc) donde 0 ≤ c < 1. Todo lo que necesitamos es que s sea un ESS para G cuando p = 1. En este caso no hay más eventos probabilísticos en la declaración del teorema. Además, dado que p = 1, cada gráfico en G es un clique, por lo que si un titular tiene un mayor nivel de aptitud que un mutante, entonces todos los titulares tienen un nivel de aptitud mayor que todos los mutantes. Esto da lugar al siguiente teorema. Teorema A.1. Sea F cualquier juego simétrico de 2 jugadores, y supongamos que s es una estrategia para F y t = s es una estrategia mutante. Sea G = {Kn}∞ n=0. Si, a medida que n → ∞, para cualquier familia t-lineal de mutantes M = {Mn}∞ n=0, existe un titular i y un mutante j tal que F(i) > F(j), entonces s es un SEE clásico de F. La prueba de este teorema analiza el comportamiento límite de la población mutante a medida que el tamaño de los cliques en G tiende a infinito. También muestra cómo la definición de ESS dada en la Sección 5 recupera la definición clásica de ESS. Prueba. Dado que cada gráfico en G es un clique, cada titular tendrá el mismo número de vecinos titulares y mutantes, y cada mutante tendrá el mismo número de vecinos titulares y mutantes. Por lo tanto, todos los titulares tendrán una aptitud idéntica y todos los mutantes tendrán una aptitud idéntica. A continuación, se puede construir una familia mutante t-lineal M, donde la fracción de mutantes converge a para cualquier , donde t > > 0. Entonces, para n suficientemente grande, el número de mutantes en Kn estará arbitrariamente cerca de n. Por lo tanto, cualquier subconjunto mutante de tamaño n resultará en que todos los titulares tengan una aptitud de (1 − n n−1 )F(s|s) + n n−1 F(s|t), y todos los mutantes tengan una aptitud de (1 − n−1 n−1 )F(t|s) + n−1 n−1 F(t|t). Además, según la suposición, la aptitud del organismo original debe ser mayor que la aptitud del mutante. Esto implica que, lim n→∞ „ (1 − n n − 1 )F(s|s) + n n − 1 F(s|t) > (1 − n − 1 n − 1 )F(t|s) + n − 1 n − 1 F(t|t) « = 1. Esto implica que (1− )F(s|s)+ F(s|t) > (1− )F(t|s)+ F(t|t), para todo , donde t > > 0. El Teorema 5.2 de Grafos Adversarios, Mutaciones Aleatorias A.2 establece que si s es una ESS clásica para un juego simétrico de 2 jugadores F, donde G es elegido adversarialmente sujeto a la restricción de que el grado de cada vértice es Ω(nγ) (para cualquier constante γ > 0), y los mutantes son elegidos con probabilidad , entonces s es una ESS con respecto a F, G y M. Aquí mostramos que si s es una ESS con respecto a F, G y M, entonces s es una ESS clásica. Todo lo que necesitaremos para demostrar esto es que s sea un ESS con respecto a G = {Kn}∞ n=0, es decir, cuando cada vértice tiene grado n − 1. Como en el Teorema A.1, dado que los grafos son cliques, si un titular tiene mayor aptitud que un mutante, entonces todos los titulares tienen mayor aptitud que todos los mutantes. Por lo tanto, el teorema a continuación también es una conversión del Teorema 5.3. (Recuerde que el Teorema 5.3 utiliza una noción más débil de contracción que requiere que solo un titular tenga una aptitud más alta que un mutante). Teorema A.2. Sea F cualquier juego simétrico de 2 jugadores, y supongamos que s es una estrategia incumbente para F y t = s es una estrategia mutante. Sea G = {Kn}∞ n=0. Si con probabilidad 1 cuando n → ∞, s es una ESS para G y una familia de mutantes M = {Mn}∞ n=0, que está determinada etiquetando cada vértice como mutante con probabilidad , donde t > > 0, entonces s es una ESS clásica de F. Esta prueba también analiza el comportamiento límite de la población de mutantes a medida que el tamaño de los cliques en G tiende a infinito. Dado que los mutantes son elegidos al azar, utilizaremos un argumento similar a la demostración de que una secuencia de variables aleatorias que converge en probabilidad también converge en distribución. En este caso, la secuencia de variables aleatorias será la fracción real de mutantes en cada Kn. Prueba. Fije cualquier valor de n, donde n >> 0, y construya cada Mn etiquetando un vértice como mutante con probabilidad p. Por el mismo argumento que en la demostración del Teorema A.1, si el número real de mutantes en Kn se denota por nn, cualquier subconjunto de mutantes de tamaño nn resultará en que todos los titulares tengan una aptitud de (1 − nn n−1 )F(s|s) + nn n−1 F(s|t), y que todos los mutantes tengan una aptitud de (1 − nn−1 n−1 )F(t|s) + nn−1 n−1 F(t|t). Esto implica lim n→∞ Pr(s es un ESS para Gn con respecto a nn mutantes) = 1 ⇒ lim n→∞ Pr „ (1 − nn n − 1 )F(s|s) + nn n − 1 F(s|t) > (1 − nn − 1 n − 1 )F(t|s) + nn − 1 n − 1 F(t|t) « = 1 ⇔ lim n→∞ Pr „ n > F(t|s) − F(s|s) F(s|t) − F(s|s) − F(t|t) + F(t|s) + F(s|s) − F(t|t) n « = 1 (3) Mediante dos simples aplicaciones del límite de Chernoff y una aplicación del límite de unión, se puede demostrar que la secuencia de variables aleatorias { n}∞ n=0 converge en probabilidad. A continuación, si dejamos que Xn = − n, X = − , b = −F(s|s) + F(t|t), y a = − F (t|s)−F (s|s) F (s|t)−F (s|s)−F (t|t)+F (t|s), por el Teorema A.3 a continuación, obtenemos que limn→∞ Pr(Xn < a + b/n) = Pr(X < a). Combinando esto con la ecuación 3, Pr( > −a) = 1. La demostración del siguiente teorema es muy similar a la demostración de que una secuencia de variables aleatorias que converge en probabilidad, también converge en distribución. Una buena explicación de esto se puede encontrar en [9], que es la base del argumento a continuación. Teorema A.3. Si {Xn}∞ n=0 es una secuencia de variables aleatorias que convergen en probabilidad a la variable aleatoria X, y a y b son constantes, entonces limn→∞ Pr(Xn < a+b/n) = Pr(X < a). Prueba. Por el Lema A.1 (ver abajo) tenemos las siguientes dos desigualdades, Pr(X < a + b/n − τ) ≤ Pr(Xn < a + b/n) + Pr(|X − Xn| > τ), Pr(Xn < a + b/n) ≤ Pr(X < a + b/n + τ) + Pr(|X − Xn| > τ). Al combinar estos se obtiene, Pr(X < a + b/n − τ) − Pr(|X − Xn| > τ) ≤ Pr(Xn < a + b/n) ≤ Pr(X < a + b/n + τ) + Pr(|X − Xn| > τ). Existe un n0 tal que para todo n > n0, |b/n| < τ, por lo que la siguiente afirmación se cumple para todo n > n0. Pr(X < a − 2τ) − Pr(|X − Xn| > τ) ≤ Pr(Xn < a + b/n) ≤ Pr(X < a + 2τ) + Pr(|X − Xn| > τ). Toma el límite cuando n tiende a infinito de ambos lados de ambas desigualdades, y dado que Xn converge en probabilidad a X, Pr(X < a − 2τ) ≤ lim n→∞ Pr(Xn < a + b/n) (4) ≤ Pr(X < a + 2τ). (5) Recuerda que X es una variable aleatoria continua que representa la fracción de mutantes en un grafo de tamaño infinito. Entonces, si dejamos que FX (a) = Pr(X < a), vemos que FX (a) es una función de distribución acumulativa de una variable aleatoria continua, y por lo tanto es continua por la derecha. Entonces lim τ↓0 FX (a − τ) = lim τ↓0 FX (a + τ) = FX (a). Por lo tanto, si tomamos el límite cuando τ tiende a 0 de las desigualdades 4 y 5, obtenemos Pr(X < a) = lim n→∞ Pr(Xn < a + b/n). El siguiente lema es bastante útil, ya que expresa la distribución acumulada de una variable aleatoria Y en términos de la distribución acumulada de otra variable aleatoria X y la diferencia entre X e Y. Lema A.1. Si X e Y son variables aleatorias, c ∈ y τ > 0, entonces Pr(Y < c) ≤ Pr(X < c + τ) + Pr(|Y − X| > τ). Prueba. Pr(Y < c) = Pr(Y < c, X < c + τ) + Pr(Y < c, X ≥ c + τ) ≤ Pr(Y < c | X < c + τ) Pr(X < c + τ) + Pr(|Y − X| > τ) ≤ Pr(X < c + τ) + Pr(|Y − X| > τ) 207