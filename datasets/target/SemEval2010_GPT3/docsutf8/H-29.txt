Estimación y Uso de la Incertidumbre en la Retroalimentación de Pseudo-Relevancia Kevyn Collins-Thompson y Jamie Callan Instituto de Tecnologías del Lenguaje Escuela de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA 15213-8213 EE. UU. {kct | callan}@cs.cmu.edu RESUMEN Los métodos existentes de retroalimentación de pseudo-relevancia suelen realizar un promedio de los documentos mejor clasificados, pero ignoran una dimensión estadística importante: el riesgo o la varianza asociada tanto a los modelos de documentos individuales como a su combinación. Tratando el método de retroalimentación de línea base como una caja negra, y el modelo de retroalimentación de salida como una variable aleatoria, estimamos una distribución posterior para el modelo de retroalimentación mediante el remuestreo de los documentos mejor recuperados de una consulta dada, utilizando la media o la moda posterior como el modelo de retroalimentación mejorado. Luego realizamos la combinación de modelos sobre varios modelos mejorados, cada uno basado en una consulta ligeramente modificada muestreada de la consulta original. Observamos que el remuestreo de documentos ayuda a aumentar la precisión del modelo de retroalimentación individual al eliminar términos de ruido, mientras que el muestreo de la consulta mejora la robustez (rendimiento en el peor de los casos) al enfatizar términos relacionados con múltiples aspectos de la consulta. El resultado es un algoritmo de meta-retroalimentación que es tanto más robusto como más preciso que el método de referencia original. Categorías y Descriptores de Asignaturas: H.3.3 [Recuperación de Información]: Modelos de Recuperación Términos Generales: Algoritmos, Experimentación 1. INTRODUCCIÓN La incertidumbre es una característica inherente de la recuperación de información. No solo no sabemos las consultas que se presentarán a nuestro algoritmo de recuperación con anticipación, sino que la necesidad de información de los usuarios puede ser vaga o estar incompletamente especificada por estas consultas. Incluso si la consulta estuviera perfectamente especificada, el lenguaje en los documentos de la colección es inherentemente complejo y ambiguo, y hacer coincidir dicho lenguaje de manera efectiva es un problema formidable por sí mismo. Con esto en mente, deseamos tratar muchas cantidades importantes calculadas por el sistema de recuperación, ya sea un puntaje de relevancia para un documento, o un peso para un término de expansión de consulta, como variables aleatorias cuyo valor real es incierto pero donde la incertidumbre sobre el valor real puede ser cuantificada reemplazando el valor fijo con una distribución de probabilidad sobre posibles valores. De esta manera, los algoritmos de recuperación pueden intentar cuantificar el riesgo o la incertidumbre asociados con sus clasificaciones de salida, o mejorar la estabilidad o precisión de sus cálculos internos. Los algoritmos actuales para la retroalimentación de pseudo relevancia (PRF) tienden a seguir el mismo método básico ya sea que utilicemos algoritmos basados en espacio vectorial como la fórmula de Rocchio [16], o enfoques más recientes de modelado de lenguaje como Modelos de Relevancia [10]. Primero, se obtiene un conjunto de documentos recuperados en la parte superior a partir de una consulta inicial y se asume que aproxima un conjunto de documentos relevantes. A continuación, se calcula un vector de modelo de retroalimentación único según algún tipo de promedio, centroide o expectativa sobre el conjunto de modelos de documentos posiblemente relevantes. Por ejemplo, los vectores de documentos pueden combinarse con igual ponderación, como en Rocchio, o por probabilidad de consulta, como se puede hacer utilizando el Modelo de Relevancia. El uso de una expectativa es razonable por razones prácticas y teóricas, pero por sí sola ignora información potencialmente valiosa sobre el riesgo del modelo de retroalimentación. Nuestra hipótesis principal en este artículo es que estimar la incertidumbre en la retroalimentación es útil y conduce a modelos de retroalimentación individual más efectivos y a modelos combinados más robustos. Por lo tanto, proponemos un método para estimar la incertidumbre asociada con un modelo de retroalimentación individual en términos de una distribución posterior sobre modelos de lenguaje. Para hacer esto, variamos sistemáticamente las entradas al método de retroalimentación base y ajustamos una distribución de Dirichlet a la salida. Utilizamos la media posterior o el modo como la estimación mejorada del modelo de retroalimentación. Este proceso se muestra en la Figura 1. Como mostraremos más adelante, la media y la moda pueden variar significativamente del modelo de retroalimentación única propuesto por el método de referencia. También realizamos la combinación de modelos utilizando varios modelos de lenguaje de retroalimentación mejorados obtenidos a partir de un pequeño número de nuevas consultas muestreadas de la consulta original. El peso de un modelo combina dos factores complementarios: la probabilidad del modelo de generar la consulta y la varianza del modelo, siendo los modelos con alta varianza los que obtienen un peso menor. Por ejemplo, un vector de parámetros esperado condicionado a la observación de la consulta se forma a partir de los documentos recuperados en la parte superior, que se tratan como cadenas de entrenamiento (ver [10], p. 62). Figura 1: Estimación de la incertidumbre del modelo de retroalimentación para una sola consulta. 2. En las Secciones 2.1-2.5 describimos un método general para estimar una distribución de probabilidad sobre el conjunto de posibles modelos de lenguaje basado en muestreo. En las Secciones 2.6 y 2.7 resumimos cómo se utilizan diferentes muestras de consultas para generar múltiples modelos de retroalimentación, que luego se combinan. 2.1 Modelado de la Incertidumbre de la Retroalimentación Dado una consulta Q y una colección C, asumimos un sistema de recuperación probabilístico que asigna un puntaje de documento de valor real f(D, Q) a cada documento D en C, de manera que el puntaje sea proporcional a la probabilidad estimada de relevancia. No hacemos ninguna otra suposición sobre f(D, Q). La naturaleza de f(D, Q) puede ser compleja: por ejemplo, si el sistema de recuperación admite lenguajes de consulta estructurados [12], entonces f(D, Q) puede representar la salida de una red de inferencia arbitrariamente compleja definida por los operadores de consulta estructurados. En teoría, la función de puntuación puede variar de una consulta a otra, aunque en este estudio por simplicidad mantenemos la misma función de puntuación para todas las consultas. Nuestro método de consulta específico se encuentra en la Sección 3. Tratamos el algoritmo de retroalimentación como una caja negra y asumimos que los insumos del algoritmo de retroalimentación son la consulta original y los documentos recuperados principales correspondientes, a los cuales se les asigna una puntuación a cada documento. Suponemos que la salida del algoritmo de retroalimentación es un vector de pesos de términos que se utilizarán para agregar o reponderar los términos en la representación de la consulta original, con el vector normalizado para formar una distribución de probabilidad. Consideramos las entradas a la caja negra de retroalimentación como variables aleatorias, y analizamos el modelo de retroalimentación como una variable aleatoria que cambia en respuesta a cambios en las entradas. Al igual que la función de puntuación del documento f(D, Q), el algoritmo de retroalimentación puede implementar una fórmula de puntuación compleja y no lineal, por lo que, a medida que sus entradas varían, los modelos de retroalimentación resultantes pueden tener una distribución compleja en el espacio de modelos de retroalimentación (el espacio muestral). Debido a esta complejidad potencial, no intentamos derivar una distribución posterior de forma cerrada, sino que en su lugar utilizamos simulación. Llamamos a esta distribución sobre posibles modelos de retroalimentación la distribución de modelos de retroalimentación. Nuestro objetivo en esta sección es estimar una aproximación útil a la distribución del modelo de retroalimentación. Para un marco específico de experimentos, utilizamos el enfoque de modelado de lenguaje (LM) para la recuperación de información [15]. El puntaje de un documento D con respecto a una consulta Q y una colección C se da por p(Q|D) con respecto a los modelos de lenguaje ˆθQ y ˆθD estimados para la consulta y el documento respectivamente. Denotamos el conjunto de los k documentos mejor recuperados de la colección C en respuesta a Q como DQ(k, C). Para simplificar, asumimos que las consultas y documentos son generados por distribuciones multinomiales cuyos parámetros están representados por modelos de lenguaje unigram. Para incorporar retroalimentación en el enfoque de LM, asumimos un esquema basado en modelos en el que nuestro objetivo es tomar la consulta y los documentos clasificados resultantes DQ(k, C) como entrada, y producir un modelo de lenguaje expandido ˆθE, que luego se interpola con el modelo de consulta original ˆθQ: ˆθNew = (1 − α) · ˆθQ + α · ˆθE (1). Esto incluye la posibilidad de α = 1 donde el modelo de consulta original es completamente reemplazado por el modelo de retroalimentación. Nuestro espacio muestral es el conjunto de todos los posibles modelos de lenguaje LF que pueden ser generados como modelos de retroalimentación. Nuestro enfoque es tomar muestras de este espacio y luego ajustar una distribución a las muestras utilizando máxima verosimilitud. Para simplificar, comenzamos asumiendo que la distribución de retroalimentación latente tiene la forma de una distribución de Dirichlet. Aunque la distribución de Dirichlet es unimodal y en general bastante limitada en su expresividad en el espacio muestral, es una coincidencia natural para el modelo de lenguaje multinomial, puede ser estimada rápidamente y capturar las características más relevantes de los modelos de retroalimentación confiada e incierta, como la dispersión general de la distribución. 2.2 Re-muestreo de modelos de documentos. Nos gustaría una aproximación a la distribución posterior del modelo de retroalimentación LF. Para lograr esto, aplicamos una técnica de simulación ampliamente utilizada llamada muestreo bootstrap ([7], p. 474) en los parámetros de entrada, es decir, el conjunto de documentos recuperados en la parte superior. El muestreo de arranque nos permite simular el efecto aproximado de perturbar los parámetros dentro del algoritmo de retroalimentación de la caja negra al perturbar los insumos de ese algoritmo de manera sistemática, sin hacer suposiciones sobre la naturaleza del algoritmo de retroalimentación. Específicamente, muestreamos k documentos con reemplazo de DQ(k, C), y calculamos un modelo de lenguaje de expansión θb utilizando el método de retroalimentación de caja negra. Repetimos este proceso B veces para obtener un conjunto de B modelos de lenguaje de retroalimentación, a los cuales luego ajustamos una distribución de Dirichlet. Normalmente, B se encuentra en el rango de 20 a 50 muestras, con un rendimiento relativamente estable en este rango. Ten en cuenta que en lugar de tratar cada documento superior como igualmente probable, muestreamos de acuerdo con las probabilidades estimadas de relevancia de cada documento en DQ(k, C). Por lo tanto, es más probable que un documento sea elegido cuanto más alto esté en la clasificación. 2.3 Justificación de un enfoque de muestreo La justificación de nuestro enfoque de muestreo tiene dos partes. Primero, queremos mejorar la calidad de los modelos de retroalimentación individual al suavizar la variación cuando el modelo de retroalimentación base es inestable. En este sentido, nuestro enfoque se asemeja al bagging [4], un enfoque de conjunto que genera múltiples versiones de un predictor haciendo copias de arranque del conjunto de entrenamiento, y luego promedia los predictores (numéricos). En nuestra aplicación, los documentos recuperados en la parte superior pueden ser vistos como una especie de conjunto de entrenamiento ruidoso para la relevancia. Segundo, el muestreo es una forma efectiva de estimar propiedades básicas de la distribución posterior de retroalimentación, las cuales pueden ser utilizadas para mejorar la combinación de modelos. Por ejemplo, un modelo puede ser ponderado por su confianza de predicción, estimada como una función de la variabilidad del posterior alrededor del modelo. foo2-401.map-Dim:5434,Size:12*12units, vecindario gaussiano (a) Tema 401 Minorías extranjeras, Alemania foo2-402.map-Dim:5698,Size:12*12units, vecindario gaussiano (b) Tema 402 Genética del comportamiento foo2-459.map-Dim:8969,Size:12*12units, vecindario gaussiano (c) Tema 459 ¿Cuándo puede un prestamista ejecutar una hipoteca sobre una propiedad? Figura 2: Visualización de la varianza del modelo de lenguaje de expansión utilizando mapas autoorganizados, mostrando la distribución de modelos de lenguaje que resulta de remuestrear las entradas al método de expansión de referencia. El modelo de lenguaje que habría sido elegido por la expansión de la línea base se encuentra en el centro de cada mapa. La función de similitud es la divergencia JensenShannon. 2.4 Visualización de distribuciones de retroalimentación Antes de describir cómo ajustamos y utilizamos la distribución de Dirichlet sobre modelos de retroalimentación, es instructivo ver algunos ejemplos de distribuciones de modelos de retroalimentación reales que resultan de muestrear por bootstrap los documentos más recuperados de diferentes temas de TREC. Cada punto en nuestro espacio muestral es un modelo de lenguaje, que típicamente tiene varias miles de dimensiones. Para ayudar a analizar el comportamiento de nuestro método, utilizamos un Mapa Auto-organizado (a través del paquete SOM-PAK [9]), para aplanar y visualizar la función de densidad de alta dimensión. Los mapas de densidad para tres temas de TREC se muestran en la Figura 2 arriba. Las áreas oscuras representan regiones de alta similitud entre los modelos de lenguaje. Las áreas claras representan regiones de baja similitud, los valles entre los grupos. Cada diagrama está centrado en el modelo de lenguaje que habría sido elegido por la expansión de referencia. Un solo pico (modo) es evidente en algunos ejemplos, pero en otros aparece una estructura más compleja. Además, aunque la distribución suele estar cerca del modelo de retroalimentación de referencia, para algunos temas están a una distancia significativa (según la divergencia de JensenShannon), como se muestra en la Subfigura 2c. En tales casos, la moda o la media de la distribución de retroalimentación a menudo funcionan significativamente mejor que el valor base (y en una proporción menor de casos, significativamente peor). 2.5 Ajuste de una distribución de retroalimentación posterior Después de obtener muestras del modelo de retroalimentación mediante el remuestreo de las entradas del modelo de retroalimentación, estimamos la distribución de retroalimentación. Suponemos que los modelos de retroalimentación multinomial {ˆθ1, . . . , ˆθB} fueron generados por una distribución de Dirichlet latente con parámetros {α1, . . . , αN}. Para estimar los {α1, . . . , αN }, ajustamos los parámetros de Dirichlet a las muestras del modelo de lenguaje B según la máxima verosimilitud utilizando un procedimiento de Newton generalizado, cuyos detalles se encuentran en Minka [13]. Suponemos una distribución de Dirichlet simple sobre los {α1, . . . , αN}, estableciendo cada uno como αi = μ · p(wi | C), donde μ es un parámetro y p(· | C) es el modelo de lenguaje de colección estimado a partir de un conjunto de documentos de la colección C. El ajuste de parámetros converge muy rápidamente, generalmente en solo 2 o 3 iteraciones. Dado que nuestros puntos son modelos de lenguaje en el simplex multinomial, extendimos SOM-PAK para admitir la divergencia de Jensen-Shannon, una medida de similitud ampliamente utilizada entre distribuciones de probabilidad. 3 iteraciones son suficientes, por lo que es práctico aplicarlo en tiempo de consulta cuando la sobrecarga computacional debe ser pequeña. En la práctica, podemos restringir el cálculo al vocabulario de los documentos recuperados en la parte superior, en lugar de toda la colección. Ten en cuenta que para este paso estamos reutilizando los documentos recuperados existentes y no realizando consultas adicionales. Dado los parámetros de una distribución de Dirichlet N-dimensional Dir(α), los vectores de media μ y moda x son fáciles de calcular y se dan respectivamente por μi = αiP αi (2) y xi = αi−1P αi−N . (3) Luego podemos elegir el modelo de lenguaje en la media o en la moda del posterior como el modelo de retroalimentación mejorado final. (Encontramos que la moda proporciona un rendimiento ligeramente mejor). Para la recuperación de información, es probable que el número de muestras disponibles sea bastante pequeño por razones de rendimiento, generalmente menos de diez. Además, si bien el muestreo aleatorio es útil en ciertos casos, es perfectamente aceptable permitir distribuciones de muestreo determinísticas, pero estas deben diseñarse cuidadosamente para aproximar una varianza de salida precisa. Dejamos esto para estudios futuros. 2.6 Variantes de consulta Utilizamos los siguientes métodos para generar variantes de la consulta original. Cada variante corresponde a una suposición diferente sobre qué aspectos de la consulta original pueden ser importantes. Esta es una forma de muestreo determinístico. Seleccionamos tres métodos simples que cubren suposiciones complementarias sobre la consulta. Uso sin expansión. La suposición es que los términos dados son una descripción completa de la necesidad de información. Deja uno fuera. Se deja fuera un término del query original. La suposición es que uno de los términos de la consulta es un término de ruido. Se elige un término único de la consulta original. Esto asume que solo un aspecto de la consulta, es decir, el representado por el término, es el más importante. Después de generar una variante de la consulta original, la combinamos con la consulta original utilizando un peso αSUB para no alejarnos demasiado. En este estudio, establecimos αSUB = 0.5. Por ejemplo, utilizando el lenguaje de consulta Indri [12], una variante de dejar uno fuera de la consulta inicial que omite el término "ireland" para el tema TREC 404 es: #weight(0.5 #combine(ireland peace talks) 0.5 #combine(peace talks)) 2.7 Combinando modelos de retroalimentación mejorados de múltiples variantes de consulta. Cuando se utilizan múltiples variantes de consulta, los modelos de retroalimentación mejorados resultantes se combinan utilizando la combinación de modelos bayesianos. Para hacer esto, tratamos cada palabra como un elemento a clasificar como perteneciente a una clase relevante o no relevante, y derivamos una probabilidad de clase para cada palabra combinando las puntuaciones de cada variante de consulta. Cada puntuación es dada por la probabilidad de ese término en la distribución de Dirichlet. Las puntuaciones de los términos se ponderan por el inverso de la varianza del término en los modelos de retroalimentación mejorada de la distribución de Dirichlet. La probabilidad previa de pertenencia de una palabra a la clase relevante se da por la probabilidad de la consulta original en todo el modelo de expansión mejorado. 3. EVALUACIÓN En esta sección presentamos resultados que confirman la utilidad de estimar una distribución del modelo de retroalimentación a partir del remuestreo ponderado de documentos mejor clasificados, y de combinar los modelos de retroalimentación obtenidos a partir de diferentes pequeños cambios en la consulta original. 3.1 Método general Evaluamos el rendimiento en un total de 350 consultas derivadas de cuatro conjuntos de temas de TREC: 51-200 (TREC-1&2), 351-400 (TREC-7), 401-450 (TREC-8) y 451-550 (wt10g, TREC-9&10). Elegimos estos por su contenido variado y propiedades del documento. Por ejemplo, los documentos wt10g son páginas web con una amplia variedad de temas y estilos, mientras que los documentos TREC-1&2 son artículos de noticias más homogéneos. La indexación y recuperación se realizó utilizando el sistema Indri en el kit de herramientas Lemur [12] [1]. Nuestras consultas se derivaron de las palabras en el campo del título de los temas de TREC. Las frases no fueron utilizadas. Para generar las consultas base que se pasaron a Indri, envolvimos los términos de la consulta con el operador #combine de Indri. Por ejemplo, la consulta inicial para el tema 404 es: #combine(ireland peace talks) Realizamos el stemming de Krovetz para todos los experimentos. Debido a que encontramos que el método de expansión de la base (Indri) funcionó mejor utilizando una lista de palabras vacías con el modelo de retroalimentación, todos los experimentos utilizaron una lista de 419 palabras comunes en inglés. Sin embargo, un efecto secundario interesante de nuestro enfoque de remuestreo es que tiende a eliminar muchas palabras vacías del modelo de retroalimentación, lo que hace que una lista de paradas sea menos crítica. Esto se discute más a fondo en la Sección 3.6. Método de retroalimentación de línea base 3.2 Para nuestro método de expansión de línea base, utilizamos un algoritmo incluido en Indri 1.0 como el método de expansión predeterminado. Este método primero selecciona términos utilizando un cálculo de logaritmo de probabilidades descrito por Ponte [14], pero asigna pesos finales a los términos utilizando el modelo de relevancia de Lavrenko [10]. Elegimos el método Indri porque proporciona una línea base consistentemente sólida, se basa en un enfoque de modelado del lenguaje y es fácil de experimentar con él. En una evaluación de TREC utilizando el corpus GOV2, el método fue uno de los mejores resultados, logrando un aumento del 19.8% en el MAP en comparación con el uso de consultas no expandidas. En este estudio, se logra una ganancia promedio en MAP del 17.25% en las cuatro colecciones. El método de expansión de Indri primero calcula una razón de logaritmos de probabilidades o(v) para cada término de expansión potencial v dado por o(v) = X D log p(v|D) p(v|C) (4) sobre todos los documentos D que contienen v, en la colección C. Luego, los candidatos a términos de expansión se ordenan por o(v) descendente, y se eligen los primeros m. Finalmente, los pesos de término r(v) utilizados en la consulta ampliada se calculan en base al modelo de relevancia r(v) = X D p(q|D)p(v|D) p(v) p(D) (5). La cantidad p(q|D) es la puntuación de probabilidad asignada al documento en la recuperación inicial. Utilizamos suavizado de Dirichlet de p(v|D) con μ = 1000. Este modelo de relevancia se combina luego con la consulta original utilizando interpolación lineal, ponderada por un parámetro α. Por defecto, utilizamos los 50 documentos principales para la retroalimentación y los 20 términos de expansión, con el parámetro de interpolación de retroalimentación α = 0.5 a menos que se indique lo contrario. Por ejemplo, la consulta expandida base para el tema 404 es: #weight(0.5 #combine(ireland peace talks) 0.5 #weight(0.10 ireland 0.08 peace 0.08 northern ...) 3.3 Rendimiento de la expansión. Medimos la efectividad de nuestros algoritmos de retroalimentación mediante dos criterios principales: precisión y robustez. La robustez, y el equilibrio entre precisión y robustez, se analiza en la Sección 3.4. En esta sección, examinamos la precisión promedio y la precisión en los 10 documentos principales (P10). También incluimos la recuperación de 1,000 documentos. Para cada consulta, obtuvimos un conjunto de B modelos de retroalimentación utilizando la línea base de Indri. Cada modelo de retroalimentación se obtuvo a partir de una muestra aleatoria de los k documentos principales tomados con reemplazo. Para estos experimentos, B = 30 y k = 50. Cada modelo de retroalimentación contenía 20 términos. En el lado de la consulta, utilizamos muestreo de dejar uno fuera (LOO) para crear las variantes de consulta. El muestreo de consulta de un solo término tuvo un rendimiento consistentemente peor en todas las colecciones, por lo que nuestros resultados se centran en el muestreo de LOO aquí. Utilizamos los métodos descritos en la Sección 2 para estimar un modelo de retroalimentación mejorado a partir de la distribución posterior de Dirichlet para cada variante de consulta, y para combinar los modelos de retroalimentación de todas las variantes de consulta. Llamamos a nuestro método expansión de remuestreo y lo denotamos como RS-FB aquí. Denominamos al método de retroalimentación de línea base Indri como Base-FB. Los resultados de aplicar tanto el método de expansión de línea base (Base-FB) como la expansión de remuestreo (RS-FB) se muestran en la Tabla 1. Observamos varias tendencias en esta tabla. Primero, la precisión promedio de RS-FB fue comparable a Base-FB, logrando una ganancia promedio del 17.6% en comparación con no utilizar expansión en las cuatro colecciones. La ganancia de expansión de la línea base de Indri fue del 17.25%. Además, el método RS-FB logró mejoras consistentes en P10 sobre Base-FB para cada conjunto de temas, con una mejora promedio del 6.89% sobre Base-FB para los 350 temas. La ganancia P10 más baja sobre Base-FB fue del +3.82% para TREC-7 y la más alta fue del +11.95% para wt10g. Finalmente, tanto Base-FB como RS-FB también mejoraron consistentemente la recuperación en comparación con no utilizar expansión, siendo Base-FB el que logró una mejor recuperación que RS-FB para todos los conjuntos de temas. 3.4 Robustez de recuperación. Utilizamos el término robustez para referirnos al rendimiento de precisión promedio en el peor de los casos de un algoritmo de retroalimentación. Idealmente, un método de retroalimentación sólido nunca debería funcionar peor que usar la consulta original, mientras que a menudo funciona mejor utilizando la expansión. Para evaluar la robustez en este estudio, utilizamos una medida muy simple llamada índice de robustez (RI). Para un conjunto de consultas Q, la medida de RI se define como: RI(Q) = n+ − n− |Q| (6) donde n+ es el número de consultas ayudadas por el método de retroalimentación y n− es el número de consultas perjudicadas. Aquí, por "ayudar" nos referimos a obtener una precisión promedio más alta como resultado de la retroalimentación. El valor de RI varía desde un mínimo de 3. A veces también se le llama índice de confiabilidad de mejora y fue utilizado en Sakai et al. [17]. Colección NoExp Base-FB RS-FB TREC 1&2 AvgP 0.1818 0.2419 (+33.04%) 0.2406 (+32.24%) P10 0.4443 0.4913 (+10.57%) 0.5363 (+17.83%) Recall 15084/37393 19172/37393 15396/37393 TREC 7 AvgP 0.1890 0.2175 (+15.07%) 0.2169 (+14.75%) P10 0.4200 0.4320 (+2.85%) 0.4480 (+6.67%) Recall 2179/4674 2608/4674 2487/4674 TREC 8 AvgP 0.2031 0.2361 (+16.25%) 0.2268 (+11.70%) P10 0.3960 0.4160 (+5.05%) 0.4340 (+9.59%) Recall 2144/4728 2642/4728 2485/4728 wt10g AvgP 0.1741 0.1829 (+5.06%) 0.1946 (+11.78%) P10 0.2760 0.2630 (-4.71%) 0.2960 (+7.24%) Recall 3361/5980 3725/5980 3664/5980 Tabla 1: Comparación de la retroalimentación base (Base-FB) y la retroalimentación utilizando re-muestreo (RS-FB). La mejora mostrada para BaseFB y RS-FB es relativa al uso de ninguna expansión. (a) TREC 1&2 (curva superior); TREC 8 (curva inferior) (b) TREC 7 (curva superior); wt10g (curva inferior) Figura 3: La compensación entre robustez y precisión promedio para diferentes corpora. El eje x muestra el cambio en la MAP al utilizar la expansión de la línea base con α = 0.5. El eje y muestra el Índice de Robustez (RI). Cada curva a través de los puntos no circulados muestra el compromiso entre RI/MAP utilizando la estrategia simple de pequeño α (ver texto) a medida que α disminuye de 0.5 a cero en la dirección de la flecha. Los puntos circulados representan los compromisos obtenidos al volver a muestrear la retroalimentación para α = 0.5. Colección N Base-FB RS-FB n− RI n− RI TREC 1&2 103 26 +0.495 15 +0.709 TREC 7 46 14 +0.391 10 +0.565 TREC 8 44 12 +0.455 12 +0.455 wt10g 91 48 -0.055 39 +0.143 Combinado 284 100 +0.296 76 +0.465 Tabla 2: Comparación del índice de robustez (RI) para retroalimentación de línea base (Base-FB) vs. retroalimentación de remuestreo (RS-FB). También se muestran el número real de consultas perjudicadas por la retroalimentación (n−) para cada método y colección. Las consultas para las cuales la precisión promedio inicial era insignificante (≤ 0.01) fueron ignoradas, dando como resultado el recuento de consultas restantes en la columna N, de -1.0, cuando todas las consultas son perjudicadas por el método de retroalimentación, a +1.0 cuando todas las consultas son ayudadas. La medida de RI no tiene en cuenta la magnitud o distribución de la cantidad de cambio en el conjunto Q. Sin embargo, es fácil de entender como una indicación general de robustez. Una forma obvia de mejorar el rendimiento en el peor de los casos de la retroalimentación es simplemente utilizar un parámetro de interpolación α fijo más pequeño, como α = 0.3, otorgando menos peso al modelo de retroalimentación (posiblemente arriesgado) y más al cuestionario original. Llamamos a esto la estrategia de pequeña α. Dado que también estamos reduciendo las ganancias potenciales cuando el modelo de retroalimentación es correcto, sin embargo, esperaríamos algún tipo de compensación entre la precisión promedio y la robustez. Por lo tanto, comparamos el equilibrio entre precisión y robustez entre nuestro algoritmo de retroalimentación de remuestreo y el método simple de pequeño α. Los resultados se resumen en la Figura 3. En la figura, la curva para cada conjunto de temas interpola entre los puntos de compensación, comenzando en x=0, donde α = 0.5, y continuando en la dirección de la flecha a medida que α disminuye y la consulta original recibe cada vez más peso. Como era de esperar, la robustez aumenta continuamente a medida que avanzamos a lo largo de la curva, pero la precisión media promedio generalmente disminuye a medida que se eliminan las ganancias del feedback. Para la comparación, se muestra el rendimiento del re-muestreo con retroalimentación en α = 0.5 para cada colección como el punto marcado con un círculo. Más alto y a la derecha es mejor. Esta figura muestra que el re-muestreo de retroalimentación ofrece un compromiso algo mejor que el enfoque de pequeño α para 3 de las 4 colecciones. Figura 4: Histograma que muestra la mayor robustez del re-muestreo de retroalimentación (RS-FB) sobre la retroalimentación base (Base-FB) para todos los conjuntos de datos combinados. Las consultas se agrupan por el % de cambio en AP en comparación con la consulta no expandida. Colección DS + QV DS + No QV TREC 1&2 AvgP 0.2406 0.2547 (+5.86%) P10 0.5263 0.5362 (+1.88%) RI 0.7087 0.6515 (-0.0572) TREC 7 AvgP 0.2169 0.2200 (+1.43%) P10 0.4480 0.4300 (-4.02%) RI 0.5652 0.2609 (-0.3043) TREC 8 AvgP 0.2268 0.2257 (-0.49%) P10 0.4340 0.4200 (-3.23%) RI 0.4545 0.4091 (-0.0454) wt10g AvgP 0.1946 0.1865 (-4.16%) P10 0.2960 0.2680 (-9.46%) RI 0.1429 0.0220 (-0.1209) Tabla 3: Comparación de la retroalimentación de remuestreo utilizando muestreo de documentos (DS) con (QV) y sin (No QV) combinar modelos de retroalimentación de múltiples variantes de consulta. La Tabla 2 muestra los puntajes del Índice de Robustez para Base-FB y RS-FB. El método de retroalimentación RS-FB obtuvo una mayor robustez que Base-FB en tres de los cuatro conjuntos de temas, con solo un rendimiento ligeramente peor en TREC-8. Una vista más detallada que muestra la distribución de los cambios relativos en AP se presenta en el histograma de la Figura 4. En comparación con Base-FB, el método RS-FB logra una reducción notable en el número de consultas significativamente afectadas por la expansión (es decir, donde AP se ve afectado en un 25% o más), al tiempo que conserva ganancias positivas en AP. 3.5 Efecto de los métodos de muestreo de consultas y documentos Dada la mayor robustez de nuestros algoritmos observada en la Sección 3.4, una pregunta importante es qué componente de nuestro sistema es responsable. ¿Es el uso de la re-muestreo de documentos, el uso de múltiples variantes de consulta, o algún otro factor? Los resultados en la Tabla 3 sugieren que la combinación de modelos basada en variantes de consulta puede ser en gran medida responsable de la mayor robustez. Cuando se desactivan las variantes de consulta y se utiliza la consulta original por sí sola con muestreo de documentos, hay poco cambio neto en la precisión promedio, una pequeña disminución en P10 para 3 de los 4 conjuntos de temas, pero una caída significativa en la robustez para todos los conjuntos de temas. En dos casos, la medida de RI disminuye en más del 50%. También examinamos el efecto del método de muestreo de documentos en la efectividad de la recuperación, utilizando dos estrategias diferentes. La estrategia de ponderación uniforme ignoró las puntuaciones de relevancia de la recuperación inicial y otorgó a cada documento en los primeros k la misma probabilidad de selección. Por el contrario, la estrategia de ponderación de puntajes de relevancia seleccionó documentos con una probabilidad proporcional a sus puntajes de relevancia. De esta manera, los documentos que tenían una clasificación más alta tenían más probabilidades de ser seleccionados. Los resultados se muestran en la Tabla 4. La estrategia de ponderación de la puntuación de relevancia tiene un mejor rendimiento en general, con puntajes de RI y P10 significativamente más altos en 3 de los 4 conjuntos de temas. La diferencia en la precisión promedio entre los métodos, sin embargo, es menos marcada. Esto sugiere que el peso uniforme actúa para aumentar la varianza en los resultados de recuperación: cuando la precisión promedio inicial es alta, hay muchos documentos relevantes en los primeros k y el muestreo uniforme puede proporcionar un modelo de relevancia más representativo que centrarse en los elementos altamente clasificados. Por otro lado, cuando la precisión inicial es baja, hay pocos documentos relevantes en las posiciones inferiores y el muestreo uniforme mezcla más de los documentos no relevantes. Por razones de espacio, solo resumimos nuestros hallazgos sobre el tamaño de la muestra aquí. El número de muestras tiene cierto efecto en la precisión cuando es menor a 10, pero el rendimiento se estabiliza alrededor de 15 a 20 muestras. Utilizamos 30 muestras para nuestros experimentos. Mucho más allá de este nivel, los beneficios adicionales de más muestras disminuyen a medida que la distribución inicial de puntajes se ajusta más estrechamente y aumenta el tiempo de procesamiento. 3.6 El efecto del remuestreo en la calidad del término de expansión Idealmente, un modelo de recuperación no debería requerir una lista de palabras vacías al estimar un modelo de relevancia: un modelo estadístico robusto debería reducir automáticamente el peso de las palabras vacías dependiendo del contexto. Las palabras vacías pueden perjudicar la retroalimentación si se seleccionan como términos de retroalimentación, ya que suelen ser malos discriminadores y desperdician espacios de términos valiosos. En la práctica, sin embargo, debido a que la mayoría de los métodos de selección de términos se asemejan a un tipo de ponderación tf · idf, a veces se pueden seleccionar términos con un idf bajo pero un tf muy alto como candidatos de términos de expansión. Esto sucede, por ejemplo, incluso con el enfoque del Modelo de Relevancia que forma parte de nuestra retroalimentación base. Para garantizar una línea base lo más sólida posible, utilizamos una lista de paradas para todos los experimentos reportados aquí. Si desactivamos la lista de palabras vacías, sin embargo, obtenemos resultados como los mostrados en la Tabla 5 donde cuatro de los diez términos de retroalimentación básica principales para el tema 60 de TREC (dijo, pero, su, no) son palabras vacías utilizando el método BaseFB. (Se seleccionaron los 100 términos de expansión principales para generar este ejemplo). El método Indris intenta abordar el problema de las palabras vacías aplicando un paso inicial basado en Ponte [14] para seleccionar términos menos comunes que tienen altas probabilidades logarítmicas de estar en los documentos mejor clasificados en comparación con toda la colección. Sin embargo, esto no resuelve completamente el problema de las palabras vacías, especialmente a medida que aumenta el número de términos de retroalimentación. Sin embargo, el uso de retroalimentación de remuestreo parece mitigar la ponderación de la colección QV + QV uniforme + ponderación de puntaje de relevancia TREC 1&2 AvgP 0.2545 0.2406 (-5.46%) P10 0.5369 0.5263 (-1.97%) RI 0.6212 0.7087 (+14.09%) TREC 7 AvgP 0.2174 0.2169 (-0.23%) P10 0.4320 0.4480 (+3.70%) RI 0.4783 0.5652 (+18.17%) TREC 8 AvgP 0.2267 0.2268 (+0.04%) P10 0.4120 0.4340 (+5.34%) RI 0.4545 0.4545 (+0.00%) wt10g AvgP 0.1808 0.1946 (+7.63%) P10 0.2680 0.2960 (+10.45%) RI 0.0220 0.1099 (+399.5%) Tabla 4: Comparación de muestreo de documentos uniforme y ponderado por relevancia. El cambio porcentual en comparación con el muestreo uniforme se muestra entre paréntesis. QV indica que se utilizaron variantes de consulta en ambas ejecuciones. FB de línea base p(wi|R) FB de remuestreo p(wi|R) dijo 0.055 corte 0.026 corte 0.055 pagar 0.018 pagar 0.034 federal 0.012 pero 0.026 educación 0.011 empleados 0.024 maestros 0.010 sus 0.024 empleados 0.010 no 0.023 caso 0.010 federal 0.021 sus 0.009 trabajadores 0.020 apelaciones 0.008 educación 0.020 sindicato 0.007 Tabla 5: Calidad del término de retroalimentación cuando no se utiliza una lista de paradas. Términos de retroalimentación para el tema 60 de TREC: pago por mérito vs antigüedad. el efecto de las palabras vacías automáticamente. En el ejemplo de la Tabla 5, la retroalimentación de remuestreo deja solo una palabra vacía (su) en las diez primeras posiciones. Observamos un comportamiento similar del término de retroalimentación en muchos otros temas. La razón de este efecto parece ser la interacción de la puntuación de selección de términos con el límite superior de términos m. Si bien la presencia e incluso la proporción de palabras vacías particulares es bastante estable en diferentes muestras de documentos, su posición relativa en la lista de los primeros m elementos no lo es, ya que se examinan conjuntos de documentos con diferentes números de candidatos de términos mejores y de menor frecuencia para cada muestra. Como resultado, si bien algunos stopwords pueden aparecer en cada conjunto de documentos muestreados, tiende a ocurrir que cualquier stopword dado caiga por debajo del umbral para múltiples muestras, lo que lleva a su clasificación como una característica de alta varianza y bajo peso. 4. TRABAJO RELACIONADO Nuestro enfoque está relacionado con trabajos previos de varias áreas de recuperación de información y aprendizaje automático. Nuestro uso de la variación de consultas fue inspirado por el trabajo de YomTov et al. [20], Carpineto et al. [5] y Amati et al. [2], entre otros. Estos estudios utilizan la idea de crear múltiples subconsultas y luego examinar la naturaleza de la superposición en los documentos y/o términos de expansión que resultan de cada subconsulta. La combinación de modelos se realiza utilizando heurísticas. En particular, los estudios de Amati et al. y Carpineto et al. investigaron la combinación de términos de métodos de distribución individuales utilizando una heurística de combinación de reordenamiento de términos. En un conjunto de temas de TREC encontraron una amplia variación promedio en la distancia de rango de los términos de diferentes métodos de expansión. Su método de combinación proporcionó modestas mejoras positivas en la precisión promedio. La idea de examinar la superposición entre listas de términos sugeridos también ha sido utilizada en enfoques tempranos de expansión de consultas. El método de Análisis de Contexto Local (LCA) de Xu y Crofts [19] incluye un factor en la fórmula de ponderación derivada empíricamente que hace que se prefieran los términos de expansión que tienen conexiones con múltiples términos de consulta. En el lado del documento, el trabajo reciente de Zhou & Croft [21] exploró la idea de agregar ruido a los documentos, volver a puntuarlos y utilizar la estabilidad de las clasificaciones resultantes como una estimación de la dificultad de la consulta. Esto está relacionado con nuestro uso de muestreo de documentos para estimar el riesgo del modelo de retroalimentación construido a partir de los diferentes conjuntos de documentos recuperados en la parte superior. Sakai et al. [17] propusieron un enfoque para mejorar la robustez de la retroalimentación de relevancia pseudo utilizando un método que llaman muestreo selectivo. La esencia de su método es que permiten omitir algunos documentos de alta clasificación, basándose en un criterio de agrupación, para seleccionar un conjunto de documentos más variado e innovador más adelante en la clasificación para su uso por un método tradicional de retroalimentación pseudo. Su estudio no encontró mejoras significativas ni en robustez (RI) ni en MAP en sus corpora. Greiff, Morgan y Ponte [8] exploraron el papel de la varianza en la ponderación de términos. En una serie de simulaciones que simplificaron el problema a documentos de 2 características, encontraron que la precisión promedio disminuye a medida que la varianza de la frecuencia de términos - ruido alto - aumenta. La reducción del peso de los términos con alta varianza resultó en una mejora de la precisión promedio. Esto parece estar en concordancia con nuestros propios hallazgos para los modelos de retroalimentación individual. Las estimaciones de la varianza de la producción han sido utilizadas recientemente para mejorar la clasificación de textos. Lee et al. [11] utilizaron estimaciones de varianza específicas de la consulta de las salidas del clasificador para realizar una combinación de modelos mejorada. En lugar de utilizar muestreo, pudieron derivar expresiones en forma cerrada para la varianza del clasificador asumiendo clasificadores base utilizando tipos simples de redes de inferencia. Ando y Zhang propusieron un método que ellos llaman retroalimentación estructural [3] y mostraron cómo aplicarlo a la expansión de consultas para la pista de Genómica de TREC. Utilizaron variaciones de consultas r para obtener R conjuntos diferentes Sr de documentos mejor clasificados que se han intersectado con los documentos mejor clasificados obtenidos de la consulta original qorig. Para cada Si, se calcula el vector centróide normalizado ˆwi de los documentos. El análisis de componentes principales (PCA) se aplica luego a los ˆwi para obtener la matriz Φ de los vectores singulares izquierdos φh que se utilizan para obtener la nueva consulta expandida qexp = qorig + ΦT Φqorig. (7) En el caso de H = 1, tenemos un único vector singular izquierdo φ: qexp = qorig + (φT qorig)φ, de modo que el producto punto φT qorig es un tipo de peso dinámico en la consulta expandida que se basa en la similitud de la consulta original con la consulta expandida. El uso de la varianza como medida de calidad del modelo de retroalimentación ocurre de forma indirecta a través de la aplicación de PCA. Sería interesante estudiar las conexiones entre este enfoque y nuestro propio método de ajuste de modelos. Finalmente, en los enfoques de modelado del lenguaje para retroalimentación, Tao y Zhai [18] describen un método para una retroalimentación más robusta que permite que cada documento tenga un α de retroalimentación diferente. Los pesos de retroalimentación se derivan automáticamente utilizando EM regularizado. La condición de parada de EM implica un equilibrio aproximadamente igual entre el modelo de consulta y expansión. Proponen adaptar el parámetro de parada η basado en una función de alguna medida de calidad de los documentos de retroalimentación. CONCLUSIONES Hemos presentado un nuevo enfoque para la retroalimentación de relevancia pseudo basado en el muestreo de documentos y consultas. El uso del muestreo es un dispositivo muy flexible y poderoso, motivado por nuestro deseo general de ampliar los modelos actuales de recuperación mediante la estimación del riesgo o la varianza asociada con los parámetros o la salida de los procesos de recuperación. Tales estimaciones de varianza, por ejemplo, pueden ser utilizadas de forma natural en un marco bayesiano para una mejor estimación y combinación de modelos. Aplicaciones como la expansión selectiva pueden ser implementadas de manera fundamentada. Si bien nuestro estudio utiliza el enfoque de modelado del lenguaje como marco para experimentos, hacemos pocas suposiciones sobre el funcionamiento real del algoritmo de retroalimentación. Creemos que es probable que cualquier algoritmo de retroalimentación de línea base razonablemente efectivo se beneficiaría de nuestro enfoque. Nuestros resultados en colecciones estándar de TREC muestran que nuestro marco mejora la robustez de un método de retroalimentación de referencia sólido en una variedad de colecciones, sin sacrificar la precisión promedio. También proporciona pequeñas pero consistentes mejoras en la precisión del top 10. En trabajos futuros, visualizamos una investigación sobre cómo variar el conjunto de métodos de muestreo utilizados y el número de muestras controla el equilibrio entre robustez, precisión y eficiencia. Agradecimientos Agradecemos a Paul Bennett por las valiosas discusiones relacionadas con este trabajo, el cual fue apoyado por las becas de la NSF #IIS-0534345 y #CNS-0454018, y la beca del Departamento de Educación de los EE. UU. #R305G03123. Cualquier opinión, hallazgo, conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las de los patrocinadores. REFERENCIAS [1] El kit de herramientas Lemur para modelado de lenguaje y recuperación. http://www.lemurproject.org. [2] G. Amati, C. Carpineto y G. Romano. Dificultad de la consulta, robustez y aplicación selectiva de la expansión de consultas. En Actas de la 25ª Conferencia Europea sobre Recuperación de Información (ECIR 2004), páginas 127-137. [3] R. K. Ando y T. Zhang. Un método de aprendizaje semisupervisado de alto rendimiento para segmentación de texto. En Actas de la 43ª Reunión Anual de la ACL, páginas 1-9, junio de 2005. [4] L. Breiman. Empaquetando predictores. Aprendizaje automático, 24(2):123-140, 1996. [5] C. Carpineto, G. Romano y V. Giannini. Mejorando la retroalimentación de recuperación con la combinación de múltiples funciones de clasificación de términos. ACM Trans. Información. Sistemas, 20(3):259 - 290. [6] K. Collins-Thompson, P. Ogilvie y J. Callan. Resultados iniciales con consultas estructuradas y modelos de lenguaje en medio terabyte de texto. En Actas de la Conferencia de Recuperación de Información de Texto de 2005. Publicación Especial del NIST. [7] R. O. Duda, P. E. Hart y D. G. Stork. Clasificación de patrones. Wiley and Sons, 2da edición, 2001. [8] W. R. Greiff, W. T. Morgan y J. M. Ponte. El papel de la varianza en la ponderación de términos para la recuperación de información probabilística. En Actas de la 11ª Conferencia Internacional. Conf. sobre Gestión de Información y Conocimiento (CIKM 2002), páginas 252-259. [9] T. Kohonen, J. Hynninen, J. Kangas y J. Laaksonen. SOMPAK: El paquete de programas de mapas autoorganizados. Informe técnico A31, Universidad de Tecnología de Helsinki, 1996. http://www.cis.hut.fi/research/papers/som tr96.ps.Z. [10] V. Lavrenko. Una teoría generativa de relevancia. Tesis doctoral, Universidad de Massachusetts, Amherst, 2004. [11] C.-H. Lee, R. Greiner y S. Wang. Utilizando estimaciones de varianza específicas de la consulta para combinar clasificadores bayesianos. En Actas del 23º Congreso Internacional. Conf. sobre Aprendizaje Automático (ICML 2006), páginas 529-536. [12] D. Metzler y W. B. Croft. Combinando el modelo de lenguaje y los enfoques de red de inferencia para la recuperación. Información. Procesamiento y Gestión, 40(5):735-750, 2004. [13] T. Minka. Estimando una distribución de Dirichlet. Informe técnico, 2000. http://research.microsoft.com/minka/papers/dirichlet. [14] J. Ponte. Avances en la Recuperación de Información, capítulo Modelos de lenguaje para retroalimentación de relevancia, páginas 73-96. 2000. W.B. Croft, ed. [15] J. M. Ponte y W. B. Croft. Un enfoque de modelado del lenguaje para la recuperación de información. En Actas de la Conferencia ACM SIGIR de 1998 sobre Investigación y Desarrollo en Recuperación de Información, páginas 275-281. [16] J. Rocchio. El Sistema de Recuperación SMART, capítulo Retroalimentación de Relevancia en la Recuperación de Información, páginas 313-323. Prentice-Hall, 1971. G. Salton, ed. [17] T. Sakai, T. Manabe y M. Koyama. Retroalimentación de pseudo-relevancia flexible a través de muestreo selectivo. ACM Transactions on Asian Language Information Processing (TALIP), 4(2):111-135, 2005. [18] T. Tao y C. Zhai. Estimación regularizada de modelos de mezcla para retroalimentación de pseudo relevancia robusta. En Actas de la Conferencia ACM SIGIR 2006 sobre Investigación y Desarrollo en Recuperación de Información, páginas 162-169. [19] J. Xu y W. B. Croft. Mejorando la efectividad de la recuperación de información con análisis de contexto local. ACM Trans. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Syst., 18(1):79-112, 2000. [20] E. YomTov, S. Fine, D. Carmel, y A. Darlow. Aprendiendo a estimar la dificultad de la consulta. En Actas de la Conferencia ACM SIGIR 2005 sobre Investigación y Desarrollo en Recuperación de Información, páginas 512-519. [21] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En Actas de la 15ª Conferencia Internacional de la ACM. Conferencia sobre Gestión de Información y Conocimiento (CIKM 2006), páginas 567-574.