Políticas de poda para índice invertido de dos niveles con garantía de corrección Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. antoulas@microsoft.com Junghoo Cho† Depto. de Ciencias de la Computación de la UCLA. El Hall Boelter, Los Ángeles, CA 90095, EE. UU. cho@cs.ucla.edu RESUMEN Los motores de búsqueda en la web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por usuarios ansiosos de información. Para hacer frente a las grandes cantidades de consultas, los motores de búsqueda podan su índice para mantener documentos que probablemente serán devueltos como resultados principales, y utilizan este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los mejores resultados solo a partir del índice podado, podríamos notar una degradación significativa en la calidad de los resultados: si un documento debería estar entre los mejores resultados pero no fue incluido en el índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Nuestra contribución consiste en una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas con mejores coincidencias siempre se coloquen en los primeros resultados de búsqueda, aunque la mayoría de las veces estemos calculando el primer lote a partir del índice podado. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y Descriptores de Asignaturas H.3.1 [Almacenamiento y Recuperación de Información]: Análisis de Contenido e Indexación; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación Términos Generales Algoritmos, Medición, Rendimiento, Diseño, Experimentación 1. INTRODUCCIÓN La cantidad de información en la web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la Web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios están volviéndose cada vez más dependientes de los motores de búsqueda en la Web para localizar información relevante en Internet. Normalmente, los motores de búsqueda web, al igual que otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada índice invertido. Un índice invertido permite la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que emite el usuario puede tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. El usuario luego revisa el primer lote de resultados y, si no encuentra la respuesta que busca, puede potencialmente solicitar ver el siguiente lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo las primeras 3 tandas de resultados. Es decir, el 80% de los usuarios suele ver como máximo de 30 a 60 resultados por cada consulta que realizan en un motor de búsqueda. Al mismo tiempo, dado el tamaño de la Web, el índice invertido que mantienen los motores de búsqueda puede crecer muy grande. Dado que los usuarios están interesados en un pequeño número de resultados (y por lo tanto están visualizando una pequeña porción del índice para cada consulta que realizan), utilizar un índice capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo en términos de tiempo, espacio de almacenamiento y recursos computacionales, lo cual está destinado a empeorar a medida que la Web crezca en tamaño con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devolverán como los principales resultados (utilizando, por ejemplo, las técnicas de poda en [7, 20]) y calcular el primer lote de respuestas utilizando el índice podado. Si bien se ha demostrado que este enfoque proporciona una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, ya que las respuestas principales se calculan solo a partir del índice podado. Es decir, aunque una página deba ser colocada como la página con mejor coincidencia según la métrica de clasificación de los motores de búsqueda, la página puede ser colocada detrás de las que se encuentran en el índice podado si la página no formó parte del índice podado por diversas razones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy en día, esta degradación es claramente indeseable y debe ser abordada si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización de rendimiento mencionada anteriormente, al mismo tiempo que seguimos obteniendo la mayor parte de sus beneficios. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas con mejor coincidencia (según la métrica de clasificación de los motores de búsqueda) siempre se coloquen en la parte superior de los resultados de búsqueda, aunque estemos calculando la primera tanda de respuestas a partir del índice podado la mayor parte del tiempo. Estas técnicas mejoradas de poda y algoritmos de cálculo de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleada por los motores de búsqueda de hoy en día. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas mientras proporcionan resultados de búsqueda de alta calidad. SI SI SI SI SI SI SI Ip Ip Ip Ip Ip Ip 5000 consultas/seg 5000 consultas/seg : 1000 consultas/seg : 1000 consultas/seg 2da capa 1ra capa (a) (b) Figura 1: (a) El motor de búsqueda replica su índice completo IF para aumentar la capacidad de respuesta a consultas. (b) En la 1ra capa, los pequeños píndices IP manejan la mayoría de las consultas. Cuando la IP no puede responder a una consulta, se redirige a la segunda capa, donde se utiliza el índice completo IF para calcular la respuesta. 2. ARQUITECTURA DE CLÚSTER Y AHORRO DE COSTOS DE UN ÍNDICE PODADO Por lo general, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Supongamos que hemos recopilado un conjunto de documentos D = {D1, . . . , DM} y que hemos extraído todos los términos T = {t1, . . . , tn} de los documentos. Para cada término ti ∈ T, mantenemos una lista I(ti) de identificadores de documentos que contienen ti. Cada entrada en I(ti) se llama un posting y puede ser ampliada para incluir información adicional, como cuántas veces ti aparece en un documento, las posiciones de ti en el documento, si ti está en negrita/cursiva, etc. El conjunto de todas las listas I = {I(t1), . . . , I(tn)} es nuestro índice invertido. Arquitectura de índice de dos niveles. Los motores de búsqueda están recibiendo un enorme número de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde a más de 250 millones de consultas de usuarios al día. Para hacer frente a esta gran carga de consultas, los motores de búsqueda suelen replicar su índice en un gran clúster de máquinas como ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1(a). El tamaño de su índice invertido completo IF es mayor de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consultas de 1000 consultas por segundo. Suponiendo que el motor de búsqueda recibe 5000 consultas por segundo, necesita replicarse CINCO veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster. Si bien replicar completamente todo el índice varias veces es una forma directa de escalar a un gran número de consultas, las cargas de consultas típicas en los motores de búsqueda muestran ciertas localidades, lo que permite una reducción significativa en costos al replicar solo una pequeña parte del índice completo. En principio, esto se suele hacer mediante la poda de un índice completo IF para crear un índice más pequeño y podado (o p-índice) IP, que contiene un subconjunto de los documentos que probablemente se devolverán como resultados principales. Dado el índice p, los motores de búsqueda operan empleando una arquitectura de índice de dos niveles como mostramos en la Figura 1(b): Todas las consultas entrantes son dirigidas primero a uno de los índices p mantenidos en el primer nivel. En los casos en los que un índice p no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para devolver al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo SI. El siguiente ejemplo ilustra la reducción potencial en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2. Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda recibe una carga de consulta de 5000 consultas/segundo. Algoritmo 2.1 Cálculo de la respuesta con garantía de corrección. Entrada q = ({t1, . . . , tn}, [i, i + k]) donde {t1, . . . , tn}: palabras clave en la consulta [i, i + k]: rango de la respuesta a devolver Procedimiento (1) (A, C) = CalcularRespuesta(q, IP) (2) Si (C = 1) Entonces (3) Devolver A (4) Sino (5) A = CalcularRespuesta(q, IF) (6) Devolver A Figura 2: Cálculo de la respuesta bajo la arquitectura de dos niveles con la garantía de corrección del resultado. Y cada copia de un índice (tanto el índice completo IF como el índice p IP) puede manejar hasta 1000 consultas/segundo. También se asume que el tamaño de IP es una cuarta parte de IF y, por lo tanto, puede almacenarse en una sola máquina. Finalmente, supongamos que los p-índices pueden manejar el 80% de las consultas de los usuarios por sí mismos y solo reenvían el 20% restante de las consultas a IF. Bajo esta configuración, dado que todas las consultas de usuario de 5000 por segundo se dirigen primero a un p-índice, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que el 20% (o 1000 consultas/segundo) se reenvían, necesitamos mantener una copia de IF para manejar la carga. En total necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). Comparado con el Ejemplo 1, esto representa una reducción de más del 50% en el número de máquinas. El ejemplo anterior demuestra el ahorro potencial de costos logrado al utilizar un índice de p. Sin embargo, la arquitectura de dos niveles puede tener una desventaja significativa en cuanto a la calidad de sus resultados en comparación con la replicación completa de IF; dado que el índice p contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice p no contenga el documento mejor clasificado según los criterios de clasificación particulares utilizados por el motor de búsqueda y no lo devuelva como la página principal, lo que conduce a una degradación notable en la calidad de los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de la búsqueda para maximizar la satisfacción del usuario. 2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la posible degradación de la calidad de la búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: solo utilizamos el resultado top-k del índice p si estamos seguros de que es el mismo que el resultado top-k del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado a partir de IP (Paso 1), no solo calculamos el resultado top-k A, sino también la función indicadora de corrección C definida de la siguiente manera: Definición 1 (Función indicadora de corrección) Dada una consulta q, el índice p IP devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntico (es decir, mismos resultados en el mismo orden) al resultado calculado a partir del índice completo IF. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (Paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el Paso 2). De lo contrario, el algoritmo vuelve a calcular y devuelve el resultado del índice completo SI (Paso 5). Por lo tanto, el algoritmo está garantizado de devolver el mismo resultado que la replicación completa SIEMPRE. Ahora, el verdadero desafío es descubrir (1) cómo podemos calcular la función indicadora de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función indicadora de corrección C? Una forma sencilla de calcular C es calcular la respuesta top-k tanto desde IP como desde IF y compararlos. Sin embargo, esta solución ingenua incurre en un costo aún mayor que la replicación completa de IF porque las respuestas se calculan dos veces: una vez desde IP y otra vez desde IF. ¿Existe alguna forma de calcular la función indicadora de corrección C solo a partir de IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar IF a IP para lograr el máximo ahorro de costos? La efectividad del Algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función indicadora de corrección C y se obtiene el valor 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar IF a IP, de manera que C = 1 para una gran fracción de consultas? En las próximas secciones, intentaremos abordar estas preguntas. 3. TAMAÑO ÓPTIMO DEL ÍNDICE P: De manera intuitiva, existe un claro equilibrio entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando IP es grande y tiene más información, podrá manejar más consultas, pero el costo de mantener y buscar en IP será mayor. Cuando IP es pequeño, por otro lado, el costo para IP será menor, pero se enviarán más consultas a IF, lo que requerirá que mantengamos más copias de IF. Dado este compromiso, ¿cómo deberíamos determinar el tamaño óptimo de la propiedad intelectual para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo sencillo. Ejemplo 3 Nuevamente, considera un escenario similar al Ejemplo 1, donde la carga de consultas es de 5000 consultas por segundo, cada copia de un índice puede manejar 1000 consultas por segundo, y el índice completo abarca 4 máquinas. Pero ahora, supongamos que si podamos IF en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% de las consultas). También supongamos que si IF se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de los IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos la IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consultas de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (que requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5×1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que el IP 1 puede manejar el 40% de las consultas, la segunda capa debe manejar 3000 consultas/seg (el 60% de las 5000 consultas/seg), por lo que necesitamos un total de 3×4 = 12 máquinas para la segunda capa (3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos realizar un análisis similar cuando utilizamos la IP 2 y observamos que se necesitan un total de 14 máquinas cuando se utiliza la IP 2. Dado este resultado, podemos concluir que es preferible utilizar IP 2. El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice p y la fracción de las consultas que pueden ser manejadas únicamente por el índice del primer nivel. Utilizamos s para denotar el tamaño del índice p en relación con IF (es decir, si s = 0.2, por ejemplo, el índice p es el 20% del tamaño de IF). Usamos f(s) para denotar la fracción de las consultas que un p-índice de tamaño s puede manejar (es decir, si f(s) = 0.3, el 30% de las consultas devuelven el valor C = 1 de IP). En general, podemos esperar que f(s) aumente a medida que s se hace más grande porque IP puede manejar más consultas a medida que su tamaño crece. En la Figura 3, mostramos un ejemplo de gráfica de f(s) sobre s. Dada la notación, podemos plantear el problema de optimización del tamaño del índice p de la siguiente manera. Al formular el problema, asumimos que el número de máquinas necesarias para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fracción de consultas garantizadas-f(s) Fracción de índice - s Fracción de consultas garantizadas por fracción de índice Tamaño óptimo s=0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas f(s) en un tamaño dado s del p-índice, es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consultas. Problema 1 (Tamaño óptimo del índice) Dada una carga de consulta Q y la función f(s), encontrar el tamaño óptimo del índice p s que minimiza el tamaño total de los índices necesarios para manejar la carga Q. El siguiente teorema muestra cómo podemos determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consultas Q es mínimo cuando el tamaño del p-índice, s, satisface d f(s) d s = 1. 2 Prueba La demostración de este y los siguientes teoremas se omite debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva f(s) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando s = 0.16. Ten en cuenta que la forma exacta del gráfico de f(s) puede variar dependiendo de la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice de p, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice de p, disminuyendo (o aumentando) f(s). De manera similar, si utilizamos una política de poda efectiva, más consultas serán manejadas por IP que cuando utilizamos una política de poda ineficaz, aumentando f(s). Por lo tanto, la función f(s) y el tamaño óptimo del índice pueden cambiar significativamente dependiendo de la carga de consultas y la política de poda. En nuestros experimentos posteriores, sin embargo, encontramos que aunque la forma del gráfico f(s) cambia notablemente entre experimentos, el tamaño óptimo del índice se sitúa consistentemente entre el 10% y el 30% en la mayoría de los experimentos. 4. En esta sección, mostramos cómo debemos podar el índice completo IF a IP, de modo que (1) podamos calcular la función indicadora de corrección C a partir de IP misma y (2) podamos manejar una gran cantidad de consultas mediante IP. Al diseñar las políticas de poda, tomamos nota de las siguientes dos localidades en el comportamiento de búsqueda de los usuarios: 1. Localidad de palabras clave: Aunque hay muchas palabras diferentes en la colección de documentos que el motor de búsqueda indexa, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder a una fracción significativa de las consultas de los usuarios incluso si solo puede manejar estas pocas palabras clave populares. 2. Localización del documento: Aunque una consulta tenga millones de documentos coincidentes, los usuarios suelen mirar solo los primeros resultados [16]. Por lo tanto, siempre y cuando los motores de búsqueda puedan calcular correctamente las primeras respuestas principales k, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Basándonos en las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar la lista invertida completa I(ti) para palabras clave impopulares tis y (2) una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo algunas publicaciones en cada lista I(ti), que probablemente se incluirán en los resultados principales k. Como discutimos anteriormente, necesitamos ser capaces de calcular la función indicadora de corrección solo a partir del índice podado para poder ofrecer la garantía de corrección. Dado que el cálculo de la función indicadora de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestras suposiciones sobre la función de clasificación. 4.1 Suposiciones sobre la función de clasificación Consideremos una consulta q = {t1, t2, . . . , tw} que contiene un subconjunto de los términos del índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos de la consulta. Segundo, una vez que tenemos los documentos relevantes, calculamos la clasificación (o puntuación) de cada uno de los documentos con respecto a la consulta y devolvemos al usuario los documentos que obtienen la clasificación más alta. La mayoría de los motores de búsqueda principales hoy en día devuelven documentos que contienen todos los términos de la consulta (es decir, utilizan semántica AND). Para que nuestras discusiones sean más concisas, también asumiremos la popular semántica AND al responder una consulta. Es sencillo extender nuestros resultados también a la semántica OR. La función de clasificación exacta que emplean los motores de búsqueda es un secreto muy bien guardado. Lo que se sabe, sin embargo, es que los factores que determinan la clasificación del documento pueden ser aproximadamente categorizados en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura qué tan relevante es la consulta para cada documento. A un nivel alto, dado un documento D, para cada término ti un motor de búsqueda asigna un puntaje de relevancia de término tr(D, ti) a D. Dados los puntajes tr(D, ti) para cada ti, entonces la relevancia dependiente de la consulta de D a la consulta, notada como tr(D, q), puede ser calculada combinando los valores de relevancia de término individuales. Una forma popular de calcular la relevancia dependiente de la consulta es representar tanto el documento D como la consulta q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de tr(D, ti) y tr(D, q) difiere dependiendo del motor de búsqueda, no nos restringiremos a ninguna forma particular; en su lugar, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula como una función de los valores de relevancia de los términos individuales en la consulta: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independientemente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], HITS [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos pr(D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. La puntuación de clasificación final r(D, q) de un documento dependerá tanto de las partes dependientes de la consulta como de las partes independientes de la función de clasificación. La combinación exacta de estas partes puede hacerse de varias maneras. En general, podemos asumir que la puntuación final de clasificación de un documento es una función de sus puntuaciones de relevancia dependientes de la consulta y de relevancia independientes de la consulta. Más formalmente: r(D, q) = fr(tr(D, q), pr(D)) (2). Por ejemplo, fr(tr(D, q), pr(D)) puede tomar la forma fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), asignando así un peso α a la parte dependiente de la consulta y el peso 1 − α a la parte independiente de la consulta. En las Ecuaciones 1 y 2, la forma exacta de fr y ftr puede variar dependiendo del motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento solo haremos la suposición genérica de que la función de clasificación r(D, q) es monótona en sus parámetros tr(D, t1), . . . , tr(D, tw) y pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figura 4: Poda de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el Procedimiento de poda de palabras clave (1) C = 1 (2) Para cada ti ∈ q (3) Si (I(ti) /∈ IP) Entonces C = 0 (4) Devolver C Figura 5: Garantía de resultado en la poda de palabras clave. Definición 2 Una función f(α, β, . . . , ω) es monótona si ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 se cumple que: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Rudamente, la monotonía de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una relevancia dependiente de la consulta más alta que D2 y también una puntuación independiente de la consulta más alta que D2, entonces D1 debería clasificarse por encima de D2, lo cual creemos es una suposición razonable en la mayoría de los entornos prácticos. 4.2 Recorte de palabras clave Dadas nuestras suposiciones sobre la función de clasificación, ahora investigamos la política de recorte de palabras clave, que recorta el índice invertido IF horizontalmente al eliminar todos los I(ti) correspondientes a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para t3 y t5, asumiendo que no aparecen con frecuencia en la carga de consultas. Ten en cuenta que después de la poda de palabras clave, si todas las palabras clave {t1, . . . , tn} en la consulta q aparecen en IP, el índice p tiene la misma información que IF en lo que respecta a q. En otras palabras, si todas las palabras clave en q aparecen en IP, la respuesta calculada a partir de IP está garantizada de ser la misma que la respuesta calculada a partir de IF. La Figura 5 formaliza esta observación y calcula la función indicadora de corrección C para un índice IP con palabras clave podadas. Es sencillo demostrar que la respuesta de IP es idéntica a la de IF si C = 1 en el algoritmo anterior. Ahora consideramos el tema de optimizar el IP de manera que pueda manejar la mayor fracción de consultas. Este problema puede ser formulado formalmente de la siguiente manera: Problema 2 (Poda óptima de palabras clave) Dada la carga de consultas Q y un tamaño de índice objetivo s · |IF | para el índice podado, seleccionar las listas invertidas IP = {I(t1), . . . , I(th)} de manera que |IP | ≤ s · |IF | y se maximice la fracción de consultas que IP puede responder (expresada por f(s)). Lamentablemente, la solución óptima al problema anterior es intratable, como podemos demostrar reduciendo desde el problema de la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda óptima de palabras clave es NP-duro. Dado lo intratable de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política voraz al mantener los elementos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I(ti) es la cantidad de consultas que pueden ser respondidas por IP cuando I(ti) está incluida en IP. Aproximamos este número por la fracción de consultas en la carga de consultas Q que incluyen el término ti y lo representamos como P(ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, el Procedimiento HS de Poda de Palabras Clave Codicioso del Algoritmo 4.2 (1) Para cada ti, calcular HS(ti) = P(ti) |I(ti)|. (2) Incluir las listas invertidas con los valores de HS(ti) más altos de manera que |IP| ≤ s · |IF|. Figura 6: Algoritmo de aproximación para la poda óptima de palabras clave. Algoritmo 4.3 Poda global de documentos V SG Procedimiento (1) Ordenar todos los documentos Di basados en pr(Di) (2) Encontrar el valor umbral τp, de manera que solo una fracción s de los documentos tengan pr(Di) > τp (4) Mantener Di en las listas invertidas si pr(Di) > τp Figura 7: Poda global de documentos basada en pr. luego P(computadora) = 0.1. El costo de incluir I(ti) en el índice p es su tamaño |I(ti)|. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I(ti)s en orden decreciente de P(ti)/|I(ti)| siempre y cuando |IP | ≤ s · |IF |. Más adelante en nuestra sección de experimentos, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política de poda de palabras clave codiciosa. 4.3 Poda de documentos En un nivel alto, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las primeras respuestas a una consulta. Dado esto, no es necesario mantener todas las publicaciones en una lista invertida I(ti), ya que de todos modos los usuarios no mirarán la mayoría de los documentos en la lista. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de t1 y D8 de t3, asumiendo que es poco probable que estos documentos formen parte de las respuestas principales a las consultas de los usuarios. Nuestro objetivo es desarrollar una política de poda de manera que (1) podamos calcular la función indicadora de corrección C solo a partir de la IP y (2) podamos manejar la mayor fracción de consultas con la IP. En las próximas secciones, discutiremos algunos enfoques alternativos para la poda de documentos. 4.3.1 Poda basada en PR global. Primero investigamos la política de poda que comúnmente se utiliza en los motores de búsqueda existentes. La idea básica de esta política de poda es que la puntuación de calidad independiente de la consulta pr(D) es un factor muy importante en el cálculo de la clasificación final del documento (por ejemplo, PageRank se sabe que es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda, por lo que construimos el índice p manteniendo solo aquellos documentos cuyos valores de pr son altos (es decir, pr(D) > τp para un valor umbral τp). La esperanza es que la mayoría de los resultados mejor clasificados probablemente tengan valores altos de pr(D), por lo que es probable que la respuesta calculada a partir de este p-índice sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos Dis por sus respectivos valores pr(Di) y mantenemos un Di en el índice p cuando su Algoritmo 4.4 Poda de documentos locales V SL N: tamaño máximo de una lista de publicaciones individuales Procedimiento (1) Para cada I(ti) ∈ IF (2) Ordenar Dis en I(ti) basado en pr(Di) (3) Si |I(ti)| ≤ N entonces mantener todos los Dis (4) De lo contrario, mantener los N mejores Dis con el pr(Di) más alto Figura 8: Poda de documentos locales basada en pr. Algoritmo 4.5 Procedimiento de poda de documentos específicos de palabras clave extendidas (1) Para cada I(ti) (2) Mantener D ∈ I(ti) si pr(D) > τpi o tr(D, ti) > τti Figura 9: Poda de documentos específicos de palabras clave extendida basada en pr y tr. El valor pr(Di) es mayor que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas globales (GPR). Variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I(ti), de modo que mantengamos al menos un cierto número de entradas para cada lista invertida I(ti). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda basada en PR local (LPR). Desafortunadamente, la mayor deficiencia de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo a partir de la PI cuando la PI está construida de esta manera. Teorema 3 Ninguna poda de documentos basada en PR puede garantizar el resultado. 2 Prueba Supongamos que creamos IP basado en la política GPR (generalizar la prueba a LPR es directo) y que cada documento D con pr(D) > τp está incluido en IP. Suponga que la entrada k-ésima en los resultados principales k, tiene un puntaje de clasificación de r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Ahora considera otro documento Dj que fue podado de IP porque pr(Dj) < τp. Aun así, es posible que el valor tr(Dj, q) de los documentos sea muy alto, de tal manera que r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada desde IP puede ser significativamente peor que la de IF y no es posible detectar esta degradación sin calcular la respuesta desde IF. En la siguiente sección, proponemos cambios simples pero esenciales a esta política de poda que nos permiten calcular la función de corrección C solo a partir de IP. 4.3.2 Poda específica de palabras clave extendida El problema principal de las políticas de poda de documentos basadas en PR global es que no conocemos la puntuación de relevancia de términos tr(D, ti) de los documentos podados, por lo que un documento que no está en IP puede tener una puntuación de clasificación más alta que los devueltos por IP debido a sus altas puntuaciones de tr. Aquí proponemos una nueva política de poda, llamada poda de documentos específicos de palabras clave extendida (EKS), que evita este problema al podar no solo basándose en la puntuación pr(D) independiente de la consulta, sino también en la puntuación de relevancia de términos tr(D, ti). Es decir, para cada lista invertida I(ti), seleccionamos dos valores de umbral, τpi para pr y τti para tr, de modo que si un documento D ∈ I(ti) cumple pr(D) > τpi o tr(D, ti) > τti, lo incluimos en I(ti) de IP. De lo contrario, lo eliminamos de la IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden ser seleccionados de varias maneras diferentes. Por ejemplo, si pr y tr tienen el mismo peso en la clasificación final y si queremos mantener como máximo N publicaciones en cada lista invertida I(ti), es posible que deseemos establecer los dos valores umbral iguales a τi (τpi = τti = τi) y ajustar τi de manera que permanezcan N publicaciones en I(ti). Esta nueva política de poda, cuando se combina con una función de puntuación monótona, nos permite calcular la función indicadora de corrección C a partir del índice podado. Utilizamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {t1, t2} y una función de clasificación monótona, f(pr(D), tr(D, t1), tr(D, t2)). Hay tres posibles escenarios sobre cómo un documento D aparece en el índice podado IP. 1. D aparece tanto en I(t1) como en I(t2) de IP: Dado que la información completa de D aparece en IP, podemos calcular el Algoritmo exacto 4.6 Computando la Respuesta de la Consulta de Entrada de IP q = {t1, . . . , tw} Salida A: resultado top-k, C: función indicadora de corrección Procedimiento (1) Para cada Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) Para cada tm ∈ q (3) Si Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) De lo contrario (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis con los valores más altos de f(Di) (9) C = j 1 si todos los Di ∈ A aparecen en todos los I(ti), ti ∈ q 0 de lo contrario Figura 10: Clasificación basada en umbrales trτ (ti) y prτ (ti). puntaje de D basado en los valores de pr(D), tr(D, t1) y tr(D, t2) en IP: f(pr(D), tr(D, t1), tr(D, t2)). D aparece solo en I(t1) pero no en I(t2): Dado que D no aparece en I(t2), no conocemos tr(D, t2), por lo que no podemos calcular su puntaje de ranking exacto. Sin embargo, a partir de nuestros criterios de poda, sabemos que tr(D, t2) no puede ser mayor que el valor umbral τt2. Por lo tanto, a partir de la monotonía de f (Definición 2), sabemos que la puntuación de clasificación de D, f(pr(D), tr(D, t1), tr(D, t2)), no puede ser mayor que f(pr(D), tr(D, t1), τt2). 3. D no aparece en ninguna lista: Dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores de pr(D), tr(D, t1), tr(D, t2). Sin embargo, a partir de nuestros criterios de poda, sabemos que pr(D) ≤ τp1 y ≤ τp2 y que tr(D, t1) ≤ τt1 y tr(D, t2) ≤ τt2. Por lo tanto, a partir de la monotonía de f, sabemos que la puntuación de clasificación de D no puede ser mayor que f(min(τp1, τp2), τt1, τt2). El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I(ti) con ti ∈ q, no podemos calcular su puntuación exacta de clasificación, pero aún podemos calcular su puntuación límite superior utilizando el valor umbral τti para los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado superior-k A a partir de IP junto con la función indicadora de corrección C. En el algoritmo, la función indicadora de corrección C se establece en uno solo si todos los documentos en el resultado superior-k A aparecen en todas las listas invertidas I(ti) con ti ∈ q, por lo que conocemos su puntuación exacta. En este caso, dado que estos documentos tienen puntuaciones superiores a las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en el top-k. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., proporciona una prueba similar en el contexto de middleware multimedia. Teorema 4 Dado un índice invertido IP podado por el algoritmo en la Figura 9, una consulta q = {t1, . . . , tw} y una función de clasificación monótona, el resultado top-k de IP calculado por el Algoritmo 4.6 es el mismo que el resultado top-k de IF si C = 1. 2 Prueba Supongamos que Dk es el documento clasificado en la posición k calculado a partir de IP según el Algoritmo 4.6. Para cada documento Di ∈ IF que no esté en el resultado top-k de IP, hay dos posibles escenarios: Primero, Di no está en la respuesta final porque fue eliminado de todas las listas invertidas I(tj), 1 ≤ j ≤ w, en IP. En este caso, sabemos que pr(Di) ≤ min1≤j≤wτpj < pr(Dk) y que tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. A partir de la suposición de monotonía, se deduce que la puntuación de clasificación de Di es r(Di) < r(Dk). Es decir, la puntuación de Dis nunca puede ser mayor que la de Dk. Segundo, Di no está en la respuesta porque Di se elimina de algunas listas invertidas, digamos, I(t1), . . . , I(tm), en IP. Supongamos que ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Entonces, a partir de tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) y la suposición de monotonía, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas − f(s) Fracción de índice − s Fracción de consultas garantizadas por fracción de índice consultas garantizadas Figura 11: Fracción de consultas garantizadas f(s) respondidas en un p-índice podado de tamaño s. sabemos que r(Di) ≤ ¯r(Di). Además, el Algoritmo 4.6 establece C = 1 solo cuando los documentos principales tienen puntajes mayores que ¯r(Di). Por lo tanto, r(Di) no puede ser mayor que r(Dk). 5. EVALUACIÓN EXPERIMENTAL Para realizar pruebas realistas de nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este artículo, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, recopiladas de la Web durante marzo de 2004. El rastreo comenzó desde la página de inicio del Directorio Abierto [10] y continuó de manera horizontal en primer lugar. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es aproximadamente de 1.9 TB, lo que resulta en un índice invertido completo IF de aproximadamente 1.2 TB. Para los experimentos reportados en esta sección, utilizamos un conjunto real de consultas emitidas a Looksmart [22] diariamente durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que utilicemos una función de clasificación particular. Para esto, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación r(D, q) es r(D, q) = prnorm(D) + trnorm(D, q) (3) donde prnorm(D) es el PageRank normalizado de D calculado a partir de las páginas descargadas y trnorm(D, q) es la distancia coseno TF.IDF normalizada de D a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda. 5.1 Poda de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo IF y creamos un índice p podado de palabras clave IP de tamaño s. Para la construcción de nuestro índice p podado de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga restante de consultas de 20 días, medimos f(s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, una consulta puede ser manejada por IP (es decir, C = 1) si IP incluye las listas invertidas de todas las palabras clave de la consulta. Hemos repetido el experimento para valores variables de s, seleccionando las palabras clave de forma codiciosa como se discute en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño s del índice p como una fracción del tamaño de IF. El eje vertical muestra la fracción f(s) de las consultas que el índice p de tamaño s puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder a una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas se pueden responder utilizando el 30% del índice original. Además, encontramos que cuando usamos solo la política de poda de palabras clave, el tamaño óptimo del índice es s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Fracción de índice - s Fracción de consultas garantizadas para las 20 mejores por fracción de índice Fracción de consultas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas f(s) respondidas en un índice p podado de tamaño s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas respondidas - tamaño del índice s Fracción de consultas respondidas para las 20 mejores por fracción de índice GPR LPR EKS Figura 13: Fracción de consultas respondidas en un índice p podado de tamaño s. 5.2 Poda de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos de poda de documentos reportados aquí, trabajamos con una muestra del 5.5% del conjunto completo de consultas. La razón detrás de esto es meramente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos llevaría aproximadamente un año de cálculos procesar todas las 462 millones de consultas. Para nuestro primer experimento, generamos un índice-p podado de documentos de tamaño s utilizando el podado específico de palabras clave extendido (EKS) en la Sección 4. Dentro del índice p medimos la fracción de consultas que se pueden garantizar (según el Teorema 4) que sean correctas. Hemos realizado el experimento para diferentes tamaños de índice s y el resultado se muestra en la Figura 12. Basándonos en esta figura, podemos ver que nuestro algoritmo de poda de documentos funciona bien en función de la escala de tamaños de índice s: para todos los tamaños de índice mayores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los 20 resultados principales para el 70% de las consultas utilizando al menos el 40% del tamaño total del índice. Desde la figura, podemos ver que el tamaño óptimo del índice s = 0.20 cuando utilizamos EKS como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las Figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños de índice p ≤ 20%. Para los tamaños de índice p mayores al 20%, la poda de palabras clave hace un trabajo mucho mejor al proporcionar un mayor número de garantías en cualquier tamaño de índice dado. Más adelante, en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en PR descritas en la Sección 4.3. Con este fin, además de EKS, también generamos píndices podados por documento para las políticas de poda basadas en PR global (GPR) y local (LPR). Para cada una de las políticas que creamos, generamos índices p podados de documentos de diferentes tamaños s. Dado que GPR y LPR no pueden garantizar la corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados principales calculados a partir del índice completo. Aquí informaremos nuestros resultados para k = 20; los resultados son similares para otros valores de k. Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción promedio de documentos en el índice de respuesta - s Fracción promedio de documentos en la respuesta para los 20 principales por fracción del índice GPR LPR EKS Figura 14: Fracción promedio de los 20 principales resultados del índice p con tamaño s contenidos en los 20 principales resultados del índice completo. Fracción de consultas garantizadas para los 20 mejores por fracción de índice, utilizando palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de palabra clave - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de índice de documento - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - f(s) Figura 15: Combinando poda de palabra clave y documento. El eje horizontal muestra el tamaño s del índice p; el eje vertical muestra la fracción f(s) de las consultas cuyos 20 mejores resultados son idénticos a los 20 mejores resultados del índice completo, para un tamaño s dado. Al observar la Figura 13, podemos ver que GPR es el peor de los tres métodos. Por otro lado, EKS responde tempranamente, contestando una gran fracción de consultas (aproximadamente el 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder sigue siendo inferior a la de EKS hasta aproximadamente s = 37%. Para cualquier tamaño de índice mayor al 37%, LPR tiene el mejor rendimiento. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice p deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de orden. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un p-índice que están contenidos dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño s del índice p; el eje vertical muestra la fracción promedio de los 20 mejores resultados comunes con los 20 mejores resultados del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican aproximadamente la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos detrás. 5.3 Combinando la poda de palabras clave y documentos En las Secciones 5.1 y 5.2 estudiamos el rendimiento individual de nuestros esquemas de poda de palabras clave y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la poda de palabras clave como la poda de documentos en nuestro índice completo IF? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo IF y aplicamos la poda de palabras clave para crear un índice Ih P de tamaño sh · 100% de IF. Después de eso, aplicamos un proceso de poda de documentos a Ih P y creamos nuestro índice final IP de tamaño sv ·100% de Ih P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de sh y sv. El resultado se muestra en la Figura 15. El eje x muestra el tamaño del índice sh después de aplicar la poda de palabras clave; el eje y muestra el tamaño del índice sv después de aplicar la poda de documentos; el eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante aplicamos la poda de documentos manteniendo el 30% (creando así un píndice de tamaño 20%·30% = 6% de IF), podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para tamaños de índice-p inferiores al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de poda de palabras clave y un 40% de poda de documentos (lo que se traduce en un índice podado con s = 0.16) podemos garantizar aproximadamente el 60% de las consultas. En la Figura 15, también observamos un plateau para sh > 0.5 y sv > 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en s = 0.13, con sh = 0.46 y sv = 0.29. 6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas de recuperación de información. Se presentan estudios experimentales y análisis de varios esquemas de particionamiento para un índice invertido en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este artículo son independientes del esquema de particionamiento utilizado. Los trabajos en [1, 5, 7, 20, 27] son los más relacionados con el nuestro, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación. [32] presenta un marco genérico para calcular respuestas aproximadas de los primeros k con algunos límites probabilísticos sobre la calidad de los resultados. Nuestro trabajo extiende esencialmente [1, 2, 4, 7, 20, 27, 31] proponiendo mecanismos para garantizar la corrección de los resultados top-k calculados. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Esta línea de trabajo también es ortogonal a la nuestra, ya que un esquema de almacenamiento en caché puede operar sobre nuestro índice p para minimizar el costo de cálculo de respuestas. Las funciones de clasificación exactas utilizadas por los motores de búsqueda actuales son secretos muy bien guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y en la calidad del documento independiente de la consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de trabajos que miden la calidad de los documentos, generalmente a través de análisis basados en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este conjunto de trabajos. Ha habido una gran cantidad de trabajos sobre el cálculo de los mejores k resultados. La idea principal es detener la travesía de las listas invertidas temprano, o reducir las listas eliminando entradas de las listas [14, 4, 11, 8]. Nuestra prueba para la función indicadora de corrección fue principalmente inspirada por [12]. 7. CONCLUSIONES Los motores de búsqueda web suelen podar sus índices invertidos a gran escala para poder manejar cargas de consultas enormes. Si bien este enfoque puede mejorar el rendimiento, al calcular los mejores resultados de un índice podado, podríamos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para nuevas técnicas de poda y algoritmos de cálculo de respuestas que garantizan que las páginas con las mejores coincidencias siempre se coloquen en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y la poda basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden ser utilizados de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice con poda de palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice con poda de documentos puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y eficientes, y así proporcionar una mejor experiencia de búsqueda para los usuarios en la web. REFERENCIAS [1] V. N. Anh, O. de Kretser y A. Moffat. Clasificación en el espacio vectorial con terminación temprana efectiva. En SIGIR, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas de modo mixto. En CIKM, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas top-k sobre bases de datos accesibles a través de la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índices estáticos en sistemas de recuperación de texto. En CIKM, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluando el rendimiento de arquitecturas distribuidas para la recuperación de información utilizando una variedad de cargas de trabajo. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En SIGIR, 2001. [8] S. Chaudhuri y L. Gravano. Optimizando consultas en repositorios multimedia. En SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los Algoritmos, 2da Edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto. http://www.dmoz.org. [11] R. Fagin. Combinando información difusa: una visión general. En SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para middleware. En PODS, 2001. [13] A. Gulli y A. Signorini. La web indexable tiene más de 11.5 mil millones de páginas. En WWW, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas eficientes de múltiples características en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina y J. Pedersen. Combatiendo el spam web con trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y visualizados. En la Conferencia Internacional sobre Computación en Internet, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM, 46(5):604-632, septiembre de 1999. [18] R. Lempel y S. Moran. Caché predictivo y precarga de resultados de consultas en motores de búsqueda. En WWW, 2003. [19] R. Lempel y S. Moran. Optimización de la precarga de resultados en motores de búsqueda web con índices segmentados. ACM Trans. "Inter" does not have a meaning on its own in English. Could you please provide more context or a complete sentence for me to translate to Spanish? Tecnología, 4(1), 2004. [20] X. Largo y T. Suel. Ejecución optimizada de consultas en motores de búsqueda grandes con ordenación global de páginas. En VLDB, 2003. [21] X. Largo y T. Suel. Caché de tres niveles para un procesamiento eficiente de consultas en motores de búsqueda web de gran tamaño. En WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang y H. Garcia-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. 

ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde la perspectiva de un motor de búsqueda. En WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detectando páginas web de spam a través del análisis de contenido. En WWW, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas de PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford. [27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices ordenados por frecuencia. Revista de la Sociedad Americana de Ciencia de la Información, 47(10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: Combinación probabilística de la información de enlaces y contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Spärck-Jones. Ponderación de relevancia de términos de búsqueda. Revista de la Sociedad Americana de Ciencia de la Información, 27:129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. Caché de dos niveles que preserva el orden para motores de búsqueda escalables. En SIGIR, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas Top-k con garantías probabilísticas. En VLDB, 2004. [33] A. Tomasic y H. Garcia-Molina. Rendimiento de índices invertidos en sistemas distribuidos de recuperación de información de documentos de texto sin compartición de recursos. En Sistemas de Información Paralelos y Distribuidos, 1993.