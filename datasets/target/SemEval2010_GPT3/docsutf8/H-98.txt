Utilizando distribuciones asimétricas para mejorar las estimaciones de probabilidad del clasificador de texto Paul N. Bennett Departamento de Ciencias de la Computación. Universidad Carnegie Mellon Pittsburgh, PA 15213 pbennett+@cs.cmu.edu RESUMEN Los clasificadores de texto que proporcionan estimaciones de probabilidad son más fácilmente aplicables en una variedad de escenarios. Por ejemplo, en lugar de elegir un umbral de decisión fijo, se pueden utilizar en un modelo de riesgo bayesiano para emitir una decisión en tiempo de ejecución que minimice una función de costo especificada por el usuario, elegida dinámicamente en el momento de la predicción. Sin embargo, la calidad de las estimaciones de probabilidad es crucial. Revisamos una variedad de enfoques estándar para convertir puntuaciones (y malas estimaciones de probabilidad) de clasificadores de texto en estimaciones de alta calidad e introducimos nuevos modelos motivados por la intuición de que la distribución empírica de puntuaciones para los elementos extremadamente irrelevantes, difíciles de discriminar y obviamente relevantes a menudo es significativamente diferente. Finalmente, analizamos el rendimiento experimental de estos modelos sobre las salidas de dos clasificadores de texto. El análisis demuestra que uno de estos modelos es teóricamente atractivo (introduciendo pocos parámetros nuevos mientras aumenta la flexibilidad), computacionalmente eficiente y preferible empíricamente. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; I.2.6 [Inteligencia Artificial]: Aprendizaje; I.5.2 [Reconocimiento de Patrones]: Metodología de Diseño Términos Generales Algoritmos, Experimentación, Confiabilidad. 1. Los clasificadores de texto que proporcionan estimaciones de probabilidad son más flexibles en la práctica que aquellos que solo ofrecen una clasificación simple o incluso un ranking. Por ejemplo, en lugar de elegir un umbral de decisión fijo, se pueden utilizar en un modelo de riesgo bayesiano [8] para emitir una decisión en tiempo de ejecución que minimice el costo esperado de una función de costo especificada por el usuario, elegida dinámicamente en el momento de la predicción. Esto se puede utilizar para minimizar una función de costo de utilidad lineal para tareas de filtrado donde los costos preespecificados de relevante/no relevante no están disponibles durante el entrenamiento, pero se especifican en el momento de la predicción. Además, los costos pueden cambiarse sin necesidad de volver a entrenar el modelo. Además, las estimaciones de probabilidad se utilizan frecuentemente como base para decidir qué etiqueta de documentos solicitar a continuación durante el aprendizaje activo [17, 23]. El aprendizaje activo efectivo puede ser clave en muchas tareas de recuperación de información donde obtener datos etiquetados puede ser costoso, reduciendo significativamente la cantidad de datos etiquetados necesarios para alcanzar el mismo rendimiento que cuando se solicitan nuevas etiquetas al azar [17]. Finalmente, también están dispuestos a tomar otros tipos de decisiones sensibles al costo [26] y a combinar decisiones [3]. Sin embargo, en todas estas tareas, la calidad de las estimaciones de probabilidad es crucial. Los modelos paramétricos generalmente utilizan suposiciones de que los datos se ajustan al modelo para equilibrar la flexibilidad con la capacidad de estimar con precisión los parámetros del modelo con poca cantidad de datos de entrenamiento. Dado que muchas tareas de clasificación de texto a menudo tienen muy pocos datos de entrenamiento, nos enfocamos en métodos paramétricos. Sin embargo, la mayoría de los métodos paramétricos existentes que se han aplicado a esta tarea tienen una suposición que consideramos indeseable. Si bien algunos de estos métodos permiten que las distribuciones de los documentos relevantes e irrelevantes al tema tengan diferentes varianzas, típicamente imponen la restricción innecesaria de que los documentos estén distribuidos simétricamente alrededor de sus respectivos modos. Introducimos varios modelos paramétricos asimétricos que nos permiten relajar esta suposición sin aumentar significativamente el número de parámetros y demostramos cómo podemos ajustar eficientemente los modelos. Además, estos modelos pueden interpretarse como asumiendo que las puntuaciones producidas por el clasificador de texto tienen tres tipos básicos de comportamiento empírico, uno correspondiente a cada uno de los elementos extremadamente irrelevantes, difíciles de discriminar y obviamente relevantes. Primero revisamos trabajos relacionados sobre la mejora de estimaciones de probabilidad y modelado de puntuaciones en la recuperación de información. Luego, discutimos con más detalle la necesidad de modelos asimétricos. Después de esto, describimos dos modelos asimétricos específicos y, utilizando dos clasificadores de texto estándar, Bayes ingenuo y SVMs, demostramos cómo pueden ser utilizados eficientemente para recalibrar estimaciones de probabilidad pobres o producir estimaciones de probabilidad de alta calidad a partir de puntajes brutos. Luego revisamos experimentos utilizando métodos previamente propuestos y los métodos asimétricos en varios corpus de clasificación de texto para demostrar las fortalezas y debilidades de los diferentes métodos. Finalmente, resumimos nuestras contribuciones y discutimos las direcciones futuras. TRABAJO RELACIONADO Se han empleado modelos paramétricos para obtener estimaciones de probabilidad en varias áreas de recuperación de información. Lewis & Gale [17] utilizan regresión logística para recalibrar el clasificador Bayesiano ingenuo aunque la calidad de las estimaciones de probabilidad no se evalúa directamente; simplemente se realiza como un paso intermedio en el aprendizaje activo. Manmatha et al. [20] introdujeron modelos apropiados para producir estimaciones de probabilidad a partir de puntuaciones de relevancia devueltas por motores de búsqueda y demostraron cómo las estimaciones de probabilidad resultantes podrían ser posteriormente empleadas para combinar las salidas de varios motores de búsqueda. Utilizan una distribución paramétrica diferente para las clases relevantes e irrelevantes, pero no persiguen distribuciones asimétricas de dos lados para una sola clase como se describe aquí. También investigan la larga historia de modelar las puntuaciones de relevancia de los motores de búsqueda. Nuestro trabajo es similar en enfoque a estos intentos previos de modelar las puntuaciones de los motores de búsqueda, pero nos enfocamos en las salidas de clasificadores de texto que hemos encontrado que demuestran un tipo diferente de comportamiento en la distribución de puntuaciones debido al papel de los datos de entrenamiento. El enfoque en mejorar las estimaciones de probabilidad ha estado creciendo últimamente. Zadrozny & Elkan [26] proporcionan una medida correctiva para árboles de decisión (llamada recorte) y un método no paramétrico para recalibrar el Bayes ingenuo. En un trabajo más reciente [27], investigan el uso de un método semiparamétrico que utiliza un ajuste monótono de piezas constantes a los datos y aplican el método al Bayes ingenuo y a una SVM lineal. Aunque compararon sus métodos con otros métodos paramétricos basados en simetría, no lograron proporcionar resultados de pruebas de significancia. Nuestro trabajo proporciona métodos paramétricos asimétricos que complementan los métodos no paramétricos y semiparamétricos que proponen cuando la escasez de datos es un problema. Además, sus métodos reducen la resolución de las puntuaciones generadas por el clasificador (el número de valores distintos generados), pero los métodos aquí no tienen tal debilidad ya que son funciones continuas. Hay una variedad de otros trabajos a los que este documento se extiende. Platt [22] utiliza un marco de regresión logística que modela etiquetas de clase ruidosas para producir probabilidades a partir de la salida cruda de un SVM. Su trabajo demostró que este método de post-procesamiento no solo puede producir estimaciones de probabilidad de calidad similar a las SVM entrenadas directamente para producir probabilidades (métodos de núcleo de verosimilitud regularizados), sino que también tiende a producir núcleos más dispersos (que generalizan mejor). Finalmente, Bennett [1] obtuvo ganancias moderadas al aplicar el método de Platts para la recalibración del Naïve Bayes, pero encontró que había más áreas problemáticas que cuando se aplicaba a las SVM. Reajustar clasificadores mal calibrados no es un problema nuevo. Lindley et al. [19] propusieron por primera vez la idea de recalibrar clasificadores, y DeGroot & Fienberg [5, 6] proporcionaron la formalización estándar aceptada actualmente para el problema de evaluar la calibración iniciado por otros [4, 24]. 3. DEFINICIÓN DEL PROBLEMA Y ENFOQUE Nuestro trabajo difiere de enfoques anteriores principalmente en tres puntos: (1) Proporcionamos modelos paramétricos asimétricos adecuados para su uso cuando hay pocos datos de entrenamiento disponibles; (2) Analizamos explícitamente la calidad de las estimaciones de probabilidad que estos y otros métodos producen y proporcionamos pruebas de significancia para estos resultados; (3) Nos enfocamos en las salidas de clasificadores de texto, mientras que la mayoría de la literatura anterior se centró en las salidas de motores de búsqueda. 3.1 Definición del Problema El problema general con el que nos preocupamos se destaca en la Figura 1. Un clasificador de texto produce una predicción sobre un documento y proporciona una puntuación s(d) que indica la fuerza de su decisión de que el documento pertenece a la clase positiva (relacionada con el tema). Suponemos en todo momento que solo hay dos clases: la clase positiva y la clase negativa (o irrelevante) (+ y - respectivamente). Hay dos tipos generales de enfoques paramétricos. El primero de estos intenta ajustar directamente la función posterior, es decir, hay una regla de Bayes p(s|+) p(s|−) P(+) P(−) Clasificador P(+| s(d)) Predecir clase, c(d)={+,−} confianza s(d) de que c(d)=+ Documento, d y dar la Figura 1 sin normalizar: Nos preocupa cómo realizar el recuadro resaltado en gris. Los componentes internos son para un tipo de enfoque. estimador de función que realiza un mapeo directo de la puntuación s a la probabilidad P(+|s(d)). El segundo tipo de enfoque descompone el problema tal como se muestra en el recuadro gris de la Figura 1. Se produce un estimador para cada una de las densidades condicionales de clase (es decir, p(s|+) y p(s|−)), luego se utiliza la regla de Bayes y las probabilidades a priori de clase para obtener la estimación de P(+|s(d)). 3.2 Motivación para Distribuciones Asimétricas La mayoría de los enfoques paramétricos anteriores a este problema corresponden, ya sea directa o indirectamente (cuando se ajusta solo el posterior), a ajustar gaussianas a las densidades condicionales de clase; difieren solo en el criterio utilizado para estimar los parámetros. Podemos visualizar esto tal como se muestra en la Figura 2. Dado que un aumento en s generalmente indica una mayor probabilidad de pertenecer a la clase positiva, entonces la distribución más a la derecha generalmente corresponde a p(s|+). Sin embargo, el uso de gaussianas estándar no aprovecha una característica básica comúnmente observada. Es decir, si tenemos un puntaje de salida en bruto que se puede utilizar para la discriminación, entonces el comportamiento empírico entre los modos (etiqueta B en la Figura 2) suele ser muy diferente al que se encuentra fuera de los modos (etiquetas A y C en la Figura 2). De manera intuitiva, el área entre los modos corresponde a los ejemplos difíciles, que son difíciles de distinguir para este clasificador, mientras que las áreas fuera de los modos son los ejemplos extremos que generalmente son fácilmente distinguibles. Esto sugiere que quizás queramos desacoplar la escala de los segmentos externo e interno de la distribución (como se muestra en la curva denominada A-Gaussiana en la Figura 3). Como resultado, una distribución asimétrica puede ser una elección más apropiada para aplicarla a la puntuación de salida en bruto de un clasificador. Idealmente (es decir, clasificación perfecta) existirán puntuaciones θ− y θ+ tales que todos los ejemplos con puntuación mayor que θ+ son relevantes y todos los ejemplos con puntuaciones menores que θ− son irrelevantes. Además, no hay ejemplos que caigan entre θ- y θ+. La distancia | θ− − θ+ | corresponde al margen en algunos clasificadores, y a menudo se intenta maximizar esta cantidad. Debido a que los clasificadores de texto tienen datos de entrenamiento para separar las clases, el comportamiento final de las distribuciones de puntajes es principalmente un factor de la cantidad de datos de entrenamiento y la separación consiguiente en las clases lograda. Esto contrasta con la recuperación de motores de búsqueda, donde la distribución de puntajes es más un factor de la distribución del lenguaje en los documentos, la función de similitud, y la longitud y tipo de consulta. La clasificación perfecta corresponde al uso de dos distribuciones muy asimétricas, pero en este caso, las probabilidades son en realidad uno y cero y muchos métodos funcionarán para propósitos típicos. Prácticamente, algunos ejemplos caerán entre θ− y θ+, y a menudo es importante estimar bien las probabilidades de estos ejemplos (ya que corresponden a los ejemplos difíciles). Se pueden dar justificaciones tanto para por qué podrías encontrar más y menos ejemplos entre θ− y θ+ que fuera de ellos, pero hay pocas razones empíricas para creer que las distribuciones deberían ser simétricas. Un primer candidato natural para una distribución asimétrica es generalizar una distribución simétrica común, por ejemplo, la Laplace o la Gaussiana. Una distribución asimétrica de Laplace se puede lograr colocando dos exponenciales alrededor de la moda de la siguiente manera: p(x | θ, β, γ) =    βγ β+γ exp [−β (θ − x)] x ≤ θ (β, γ > 0) βγ β+γ exp [−γ (x − θ)] x > θ (1) donde θ, β y γ son los parámetros del modelo. θ es la moda de la distribución, β es la escala inversa de la exponencial a la izquierda de la moda, y γ es la escala inversa de la exponencial a la derecha. Utilizaremos la notación Λ(X | θ, β, γ) para referirnos a esta distribución. 0 0.002 0.004 0.006 0.008 0.01 -300 -200 -100 0 100 200 p(s|Clase={+,-}) Puntuación de Confianza No Normalizada s Gaussiana A-Gaussiana Figura 3: Gaussianas vs. Gaussianas Asimétricas. Una limitación de las distribuciones simétricas: las líneas verticales muestran los modos estimados de forma no paramétrica. Podemos crear una Gaussiana asimétrica de la misma manera: p(x | θ, σl, σr) =    2√ 2π(σl+σr) exp −(x−θ)2 2σ2 l x ≤ θ (σl, σr > 0) 2√ 2π(σl+σr) exp −(x−θ)2 2σ2 r x > θ (2) donde θ, σl y σr son los parámetros del modelo. Para referirnos a esta Gaussiana asimétrica, usamos la notación Γ(X | θ, σl, σr). Si bien estas distribuciones están compuestas por mitades, la función resultante es una única distribución continua. Estas distribuciones nos permiten ajustar nuestros datos con mucha mayor flexibilidad a cambio de solo ajustar seis parámetros. Podríamos intentar en su lugar modelos de mezcla para cada componente u otras extensiones, pero la mayoría de las otras extensiones requieren al menos la misma cantidad de parámetros (y a menudo pueden ser más costosas computacionalmente). Además, la motivación anterior debería proporcionar una causa significativa para creer que las distribuciones subyacentes realmente se comportan de esta manera. Además, esta familia de distribuciones aún puede ajustarse a una distribución simétrica, y finalmente, en la evaluación empírica, se presenta evidencia que demuestra este comportamiento asimétrico (ver Figura 4). Hasta donde sabemos, ninguna de las dos familias de distribuciones ha sido utilizada previamente en aprendizaje automático o recuperación de información. Ambos se denominan generalizaciones de una Laplace Asimétrica en [14], pero nos referimos a ellos como se describe arriba para reflejar la forma en que los derivamos para esta tarea. 3.3 Estimación de los parámetros de las distribuciones asimétricas. Esta sección desarrolla el método para encontrar estimaciones de máxima verosimilitud (MLE) de los parámetros para las distribuciones asimétricas mencionadas anteriormente. Para encontrar los EMV, tenemos dos opciones: (1) utilizar estimación numérica para estimar los tres parámetros a la vez, (2) fijar el valor de θ y estimar los otros dos (β y γ o σl y σr) dados nuestra elección de θ, luego considerar valores alternativos de θ. Debido a la simplicidad del análisis en la última alternativa, elegimos este método. 3.3.1 Estimaciones MLE de Laplace asimétricas Para D = {x1, x2, . . . , xN } donde los xi son i.i.d. y X ∼ Λ(X | θ, β, γ), la verosimilitud es N i Λ(X | θ, β, γ). Ahora, fijamos θ y calculamos la máxima verosimilitud para esa elección de θ. Entonces, simplemente podemos considerar todas las opciones de θ y elegir aquella con la máxima verosimilitud entre todas las opciones de θ. La derivación completa se omite debido al espacio pero está disponible en [2]. Definimos los siguientes valores: Nl = | {x ∈ D | x ≤ θ} | Nr = | {x ∈ D | x > θ} | Sl = x∈D|x≤θ x Sr = x∈D|x>θ x Dl = Nlθ − Sl Dr = Sr − Nrθ. Ten en cuenta que Dl y Dr son la suma de las diferencias absolutas entre las x pertenecientes a las mitades izquierda y derecha de la distribución (respectivamente) y θ. Finalmente, los EMV para β y γ para un θ fijo son: βEMV = N Dl + √ DrDl γEMV = N Dr + √ DrDl. Estas estimaciones no son del todo inesperadas ya que obtendríamos Nl Dl si estimáramos β de forma independiente de γ. La elegancia de las fórmulas radica en que las estimaciones tienden a ser simétricas solo en la medida en que los datos lo dicten (es decir, cuanto más cercanos sean Dl y Dr a ser iguales, más cercanas serán las escalas inversas resultantes). Por argumentos de continuidad, cuando N = 0, asignamos β = γ = 0 donde 0 es una constante pequeña que actúa para dispersar la distribución a una uniforme. De manera similar, cuando N = 0 y Dl = 0, asignamos β = inf donde inf es una constante muy grande que corresponde a una distribución extremadamente aguda (es decir, casi toda la masa en θ para esa mitad). Dr = 0 se maneja de manera similar. Suponiendo que θ cae en algún rango [φ, ψ] dependiendo solo de los documentos observados, entonces esta alternativa también es fácilmente computable. Dado Nl, Sl, Nr, Sr, podemos calcular el posterior y los MLEs en tiempo constante. Además, si los puntajes están ordenados, entonces podemos realizar todo el proceso de manera bastante eficiente. Comenzando con el mínimo θ = φ que nos gustaría probar, recorremos los puntajes una vez y establecemos Nl, Sl, Nr, Sr apropiadamente. Luego aumentamos θ y simplemente pasamos por encima de las puntuaciones que se han desplazado del lado derecho de la distribución al lado izquierdo. Suponiendo que el número de candidatos θ es O(n), este proceso es O(n), y el proceso general está dominado por la clasificación de las puntuaciones, O(n log n) (o tiempo lineal esperado). 3.3.2 MLEs Gaussianos Asimétricos Para D = {x1, x2, . . . , xN } donde los xi son i.i.d. y X ∼ Γ(X | θ, σl, σr), la verosimilitud es N i Γ(X | θ, β, γ). Los EMV pueden ser calculados de manera similar a lo anterior. Suponemos las mismas definiciones que arriba (la derivación completa omitida por espacio está disponible en [2]), y además, dejemos: Sl2 = x∈D|x≤θ x2 Sr2 = x∈D|x>θ x2 Dl2 = Sl2 − Slθ + θ2 Nl Dr2 = Sr2 − Srθ + θ2 Nr. La solución analítica para los MLEs para un θ fijo es: σl,MLE = Dl2 + D 2/3 l2 D 1/3 r2 N (4) σr,MLE = Dr2 + D 2/3 r2 D 1/3 l2 N . (5) Por argumentos de continuidad, cuando N = 0, asignamos σr = σl = inf , y cuando N = 0 y Dl2 = 0 (resp. Cuando Dr2 = 0, asignamos σl = 0 (o σr = 0). Nuevamente, el mismo análisis de complejidad computacional se aplica para estimar estos parámetros. 4. ANÁLISIS EXPERIMENTAL 4.1 Métodos Para cada uno de los métodos que utilizan una clase previa, utilizamos una estimación suavizada de uno adicional, es decir, P(c) = |c|+1 N+2 donde N es el número de documentos. Para los métodos que se ajustan a las densidades condicionales de clase, p(s|+) y p(s|−), las densidades resultantes se invierten utilizando la regla de Bayes como se describe arriba. Todos los métodos a continuación se ajustan utilizando estimaciones de máxima verosimilitud. Para recalibrar un clasificador (es decir, corregir las malas estimaciones de probabilidad generadas por el clasificador), es habitual utilizar el logaritmo de las probabilidades de los estimados del clasificador como s(d). Los logaritmos de las probabilidades son definidos como log P (+|d) P (−|d). El umbral de decisión normal (minimizando el error) en términos de logaritmos de probabilidades está en cero (es decir, P(+|d) = P(−|d) = 0.5. Dado que escala las salidas a un espacio [−∞, ∞], las logaritmos de probabilidades hacen que las distribuciones normales (y similares) sean aplicables [19]. Lewis & Gale [17] ofrecen un punto de vista más motivador que ajustar los logaritmos de las probabilidades es un efecto amortiguador para la suposición inexacta de independencia y una corrección de sesgo para estimaciones inexactas de las probabilidades a priori. En general, ajustar los logaritmos de las probabilidades puede servir para potenciar o disminuir la señal del clasificador original según lo dicten los datos. Se ajusta una distribución gaussiana a cada una de las densidades condicionales de clase, utilizando las estimaciones habituales de máxima verosimilitud. Este método está designado en las tablas a continuación como Gauss. Gaussianas asimétricas Se ajusta una Gaussiana asimétrica a cada una de las densidades condicionales de clase utilizando el procedimiento de estimación de máxima verosimilitud descrito anteriormente. Los intervalos entre las puntuaciones adyacentes se dividen por 10 al probar candidatos θ, es decir, se prueban 8 puntos entre las puntuaciones reales que ocurren en el conjunto de datos. Este método se denota como A. Gauss. Aunque las distribuciones de Laplace no suelen aplicarse a esta tarea, también probamos este método para aislar por qué se obtiene un beneficio de la forma asimétrica. Se utilizaron los estimadores MLE habituales para estimar la ubicación y la escala de una distribución Laplace simétrica clásica, tal como se describe en [14]. Denominamos a este método como Laplace a continuación. Se ajusta una distribución Laplace asimétrica a cada una de las densidades condicionales de clase utilizando el procedimiento de estimación de máxima verosimilitud descrito anteriormente. Al igual que con la Gaussiana asimétrica, los intervalos entre puntuaciones adyacentes se dividen por 10 al probar candidatos de θ. Este método se denota como A. Laplace abajo. Regresión Logística Este método es el primero de los dos métodos que evaluamos que ajustan directamente el posterior, P(+|s(d)). Ambos métodos restringen el conjunto de familias a una familia sigmoidea de dos parámetros; difieren principalmente en su modelo de etiquetas de clase. A diferencia de los métodos anteriores, se puede argumentar que una ventaja adicional de estos métodos es que preservan por completo la clasificación dada por el clasificador. Cuando se desee, estos métodos pueden ser más apropiados. Los métodos anteriores en su mayoría conservarán los rankings, pero pueden desviarse si los datos lo dictan. Por lo tanto, pueden modelar mejor el comportamiento de los datos a costa de alejarse de una restricción de monotonía en la salida del clasificador. Lewis & Gale [17] utilizan regresión logística para recalibrar el clasificador Bayesiano ingenuo para su posterior uso en aprendizaje activo. El modelo que utilizan es: P(+|s(d)) = exp(a + b s(d)) 1 + exp(a + b s(d)) . En lugar de utilizar directamente las probabilidades generadas por el clasificador, utilizan el logaritmo de la razón de verosimilitud de las probabilidades, log P (d|+) P (d|−) , como la puntuación s(d). En lugar de usar esto de abajo, utilizaremos la razón de logaritmos de probabilidades. Esto no afecta al modelo, ya que simplemente desplaza todas las puntuaciones por una constante determinada por las probabilidades a priori. Nos referimos a este método como LogReg a continuación. Regresión Logística con Etiquetas de Clase Ruidosas. Platt [22] propone un marco que extiende el modelo de regresión logística mencionado anteriormente para incorporar etiquetas de clase ruidosas y lo utiliza para producir estimaciones de probabilidad a partir de la salida cruda de un SVM. Este modelo difiere del modelo LogReg solo en cómo se estiman los parámetros. Los parámetros siguen siendo ajustados utilizando la estimación de máxima verosimilitud, pero se utiliza un modelo de etiquetas de clase ruidosas además, para permitir la posibilidad de que la clase haya sido etiquetada incorrectamente. El ruido se modela asumiendo que hay una probabilidad finita de etiquetar incorrectamente un ejemplo positivo y de etiquetar incorrectamente un ejemplo negativo; estas dos estimaciones de ruido se determinan por el número de ejemplos positivos y el número de ejemplos negativos (usando la regla de Bayes para inferir la probabilidad de etiqueta incorrecta). Aunque no se esperaría que el rendimiento de este modelo difiera mucho del de LogReg, lo evaluamos para asegurar su completitud. Nos referimos a este método como LR+Ruido. 4.2 Datos Examinamos varios corpus, incluyendo el Directorio Web de MSN, Reuters y TREC-AP. El Directorio Web de MSN es una gran colección de páginas web heterogéneas (de una instantánea web de mayo de 1999) que han sido clasificadas jerárquicamente. Utilizamos la misma división de documentos de entrenamiento/prueba de 50078/10024 que se reportó en [9]. La jerarquía web de MSN es una jerarquía de siete niveles; utilizamos las 13 categorías de nivel superior. Las proporciones de clase en el conjunto de entrenamiento varían del 1.15% al 22.29%. En el conjunto de pruebas, van desde el 1.14% hasta el 21.54%. Las clases son materias generales como Salud y Fitness y Viajes y Vacaciones. Los indexadores humanos asignaron los documentos a cero o más categorías. Para los experimentos a continuación, utilizamos solo las 1000 palabras principales con mayor información mutua para cada clase; aproximadamente 195 mil palabras aparecen en al menos tres documentos de entrenamiento. El corpus Reuters 21578 contiene artículos de noticias de Reuters del año 1987. Para este conjunto de datos, utilizamos la división estándar de entrenamiento/prueba de ModApte de 9603/3299 documentos (8676 documentos no utilizados). Las clases son temas económicos (por ejemplo, acq para adquisiciones, earn para ganancias, etc.) que los etiquetadores humanos aplicaron al documento; un documento puede tener varios temas. De hecho, hay 135 clases en este dominio (solo 90 de las cuales aparecen en el conjunto de entrenamiento y prueba); sin embargo, solo examinamos las diez clases más frecuentes, ya que los números pequeños de ejemplos de prueba dificultan la interpretación de algunas medidas de rendimiento debido a la alta varianza. Limitar a las diez clases más grandes nos permite comparar nuestros resultados con resultados previamente publicados [10, 13, 21, 22]. Las proporciones de clase en el conjunto de entrenamiento varían del 1.88% al 29.96%. En el conjunto de pruebas, van desde el 1.7% hasta el 32.95%. Para los experimentos a continuación, utilizamos solo las 300 palabras principales con mayor información mutua para cada clase; aproximadamente 15 000 palabras aparecen en al menos tres documentos de entrenamiento. El corpus TREC-AP es una colección de noticias de AP de 1988 a 1990. Utilizamos la misma división de documentos de entrenamiento/prueba de 142791/66992 que se utilizó en [18]. Como se describe en [17] (ver también [15]), las categorías están definidas por palabras clave en un campo de palabras clave. Los campos de título y cuerpo se utilizan en los experimentos a continuación. Hay veinte categorías en total. Las proporciones de clase en el conjunto de entrenamiento varían del 0.06% al 2.03%. En el conjunto de pruebas, van desde el 0.03% hasta el 4.32%. Para los experimentos descritos a continuación, utilizamos solo las 1000 palabras principales con la información mutua más alta para cada clase; aproximadamente 123 mil palabras aparecen en al menos 3 documentos de entrenamiento. 4.3 Clasificadores Seleccionamos dos clasificadores para la evaluación. Un clasificador SVM lineal, que es un clasificador discriminativo que normalmente no produce valores de probabilidad, y un clasificador de Bayes ingenuo cuyas salidas de probabilidad suelen ser deficientes [1, 7] pero pueden mejorarse [1, 26, 27]. También se realizó una comparación separada solo entre LogReg, LR+Noise y A. Laplace en las 90 categorías de Reuters. Después de tener en cuenta la varianza, esa evaluación también respaldó las afirmaciones hechas aquí. Para SVM lineales, utilizamos la herramienta Smox que se basa en el algoritmo de Optimización Secuencial Mínima de Platts. Las características fueron representadas como valores continuos. Utilizamos la puntuación de salida en bruto del SVM como s(d) ya que se ha demostrado que es apropiada anteriormente [22]. El umbral de decisión normal (suponiendo que buscamos minimizar errores) para este clasificador es cero. El modelo de clasificador de Bayes ingenuo es un modelo multinomial [21]. Suavizamos las probabilidades de palabras y clases utilizando una estimación bayesiana (con la prioridad de palabras) y una estimación m de Laplace, respectivamente. Utilizamos los logaritmos de las probabilidades estimadas por el clasificador como s(d). El umbral de decisión normal está en cero. 4.4 Medidas de rendimiento Utilizamos la pérdida logarítmica [12] y el error cuadrático [4, 6] para evaluar la calidad de las estimaciones de probabilidad. Para un documento d con clase c(d) ∈ {+, −} (es decir, los datos tienen etiquetas conocidas y no probabilidades), la pérdida logarítmica se define como δ(c(d), +) log P(+|d) + δ(c(d), −) log P(−|d) donde δ(a, b) . = 1 si a = b y 0 en caso contrario. El error cuadrático es δ(c(d), +)(1 − P(+|d))2 + δ(c(d), −)(1 − P(−|d))2. Cuando la clase de un documento se predice correctamente con una probabilidad de uno, la pérdida logarítmica es cero y el error cuadrático es cero. Cuando la clase de un documento se predice incorrectamente con una probabilidad de uno, la pérdida logarítmica es −∞ y el error cuadrático es uno. Por lo tanto, ambas medidas evalúan qué tan cerca está una estimación de predecir correctamente la clase de los elementos, pero varían en la severidad con la que se penalizan las predicciones incorrectas. Informamos solo la suma de estas medidas y omitimos los promedios por cuestiones de espacio. Sus promedios, pérdida logarítmica promedio y error cuadrático medio (MSE) se pueden calcular a partir de estos totales dividiendo por el número de decisiones binarias en un corpus. Además, también comparamos el error de los clasificadores en sus umbrales predeterminados y con las probabilidades. Esto evalúa cómo han mejorado las estimaciones de probabilidad con respecto al umbral de decisión P(+|d) = 0.5. Por lo tanto, el error solo indica cómo se desempeñarían los métodos si un falso positivo fuera penalizado de la misma manera que un falso negativo y no la calidad general de las estimaciones de probabilidad. Se presenta simplemente para proporcionar al lector una comprensión más completa de las tendencias empíricas de los métodos. Utilizamos una prueba de signo de micro emparejado estándar [25] para determinar la significancia estadística en la diferencia de todas las medidas. Solo se utilizan los pares en los que los métodos no están de acuerdo en la prueba de signos. Este test compara pares de puntuaciones de dos sistemas con la hipótesis nula de que el número de elementos en los que discrepan sigue una distribución binomial. Utilizamos un nivel de significancia de p = 0.01. 4.5 Metodología Experimental Dado que las categorías consideradas en los experimentos no son mutuamente excluyentes, la clasificación se realizó entrenando n clasificadores binarios, donde n es el número de clases. Para generar las puntuaciones que cada método utiliza para ajustar sus estimaciones de probabilidad, utilizamos validación cruzada de cinco pliegues en los datos de entrenamiento. Observamos que, aunque es computacionalmente eficiente realizar validación cruzada de dejar uno fuera para el clasificador de Bayes ingenuo, esto puede no ser deseable ya que la distribución de puntajes puede verse sesgada como resultado. Por supuesto, al igual que con cualquier aplicación de validación cruzada n-fold, también es posible sesgar los resultados al mantener n demasiado bajo y subestimar el rendimiento del clasificador final. 4.6 Resultados y Discusión Los resultados para recalibrar el Bayes ingenuo se muestran en la Tabla 1a. La Tabla 1b muestra los resultados para la producción de salidas probabilísticas para las SVM. Error de pérdida logarítmica2 Errores MSN Web Gauss -60656.41 10503.30 10754 A.Gauss -57262.26 8727.47 9675 Laplace -45363.84 8617.59 10927 A.Laplace -36765.88 6407.84† 8350 LogReg -36470.99 6525.47 8540 LR+Ruido -36468.18 6534.61 8563 Bayes ingenuo -1098900.83 17117.50 17834 Reuters Gauss -5523.14 1124.17 1654 A.Gauss -4929.12 652.67 888 Laplace -5677.68 1157.33 1416 A.Laplace -3106.95‡ 554.37‡ 726 LogReg -3375.63 603.20 786 LR+Ruido -3374.15 604.80 785 Bayes ingenuo -52184.52 1969.41 2121 TREC-AP Gauss -57872.57 8431.89 9705 A.Gauss -66009.43 7826.99 8865 Laplace -61548.42 9571.29 11442 A.Laplace -48711.55 7251.87‡ 8642 LogReg -48250.81 7540.60 8797 LR+Ruido -48251.51 7544.84 8801 Bayes ingenuo -1903487.10 41770.21 43661 Error de pérdida logarítmica2 Errores MSN Web Gauss -54463.32 9090.57 10555 A.Gauss -44363.70 6907.79 8375 Laplace -42429.25 7669.75 10201 A.Laplace -31133.83 5003.32 6170 LogReg -30209.36 5158.74 6480 LR+Ruido -30294.01 5209.80 6551 SVM Lineal N/A N/A 6602 Reuters Gauss -3955.33 589.25 735 A.Gauss -4580.46 428.21 532 Laplace -3569.36 640.19 770 A.Laplace -2599.28 412.75 505 LogReg -2575.85 407.48 509 LR+Ruido -2567.68 408.82 516 SVM Lineal N/A N/A 516 TREC-AP Gauss -54620.94 6525.71 7321 A.Gauss -77729.49 6062.64 6639 Laplace -54543.19 7508.37 9033 A.Laplace -48414.39 5761.25‡ 6572‡ LogReg -48285.56 5914.04 6791 LR+Ruido -48214.96 5919.25 6794 SVM Lineal N/A N/A 6718 Tabla 1: (a) Resultados para Bayes ingenuo (izquierda) y (b) SVM (derecha). La mejor entrada para un corpus está en negrita. Las entradas que son estadísticamente significativamente mejores que todas las demás entradas están subrayadas. Un † indica que el método es significativamente mejor que todos los demás métodos, excepto por el método de Bayes ingenuo. Un ‡ indica que la entrada es significativamente mejor que todos los demás métodos excepto por A. Gauss (y Bayes ingenuo para la tabla de la izquierda). La razón de esta distinción en las pruebas de significancia está descrita en el texto. Comenzamos con observaciones generales que resultan de examinar el rendimiento de estos métodos en los diversos corpus. El primero es que A. Laplace, LR+Noise y LogReg claramente superan a los otros métodos. Por lo general, hay poca diferencia entre el rendimiento de LR+Noise y LogReg (tanto como se muestra aquí como en una base de decisión por decisión), pero esto no es sorprendente ya que LR+Noise simplemente agrega etiquetas de clase ruidosas al modelo LogReg. Con respecto a las tres medidas diferentes, LR+Noise y LogReg tienden a tener un rendimiento ligeramente mejor (pero nunca significativamente) que A. Laplace en algunas tareas en relación con la pérdida logarítmica y el error cuadrático. Sin embargo, A. Laplace siempre produce la menor cantidad de errores para todas las tareas, aunque a veces el grado de mejora no es significativo. Para darle al lector una mejor idea del comportamiento de estos métodos, las Figuras 4-5 muestran los ajustes producidos por el método más competitivo en comparación con el comportamiento real de los datos (estimado de forma no paramétrica mediante agrupación) para la clase Earn en Reuters. La Figura 4 muestra las densidades condicionales de clase, por lo que solo se muestra A. Laplace ya que LogReg ajusta directamente el posterior. La Figura 5 muestra las estimaciones de los logaritmos de las probabilidades, es decir, log P (Ganar|s(d)) P (¬Ganar|s(d)). Visualizar los logaritmos de las probabilidades a posteriori (en lugar de las probabilidades a posteriori) generalmente permite detectar errores en la estimación de manera más fácil a simple vista. Podemos desglosar las cosas como lo hace la prueba de signos y simplemente observar las victorias y derrotas en los elementos en los que los métodos no están de acuerdo. Vistos de esta manera, solo dos métodos (naïve Bayes y A. Gauss) tienen más victorias en pares que A. Laplace; esos dos a veces tienen más victorias en pares en pérdida logarítmica y error cuadrático, aunque nunca ganan en total (es decir, son arrastrados por penalizaciones severas). Además, esta comparación de victorias por pares significa que para aquellos casos en los que LogReg y LR+Noise tienen puntajes mejores que A. Laplace, no se consideraría significativo por la prueba de signos en ningún nivel, ya que no tienen más victorias. Por ejemplo, de las 130,000 decisiones binarias sobre el conjunto de datos web de MSN, A. Laplace tuvo aproximadamente 101,000 victorias en pares frente a LogReg y LR+Noise. Ningún método tiene más victorias en pares que A. Laplace para la comparación de errores, ni ningún método logra un total mejor. La observación básica hecha sobre el método de Bayes ingenuo en trabajos anteriores es que tiende a producir estimaciones muy cercanas a cero y uno [1, 17]. Esto significa que si tiende a ser correcto la mayor parte del tiempo, producirá resultados que no parecen significativos en una prueba de signos que ignora el tamaño de la diferencia (como la que se muestra aquí). Las sumas del error cuadrático y la pérdida logarítmica confirman la observación previa de que cuando está mal, está realmente mal. Hay varios puntos interesantes sobre el rendimiento de las distribuciones asimétricas también. Primero, A. Gauss tiene un rendimiento deficiente porque (similar al Bayes ingenuo) hay algunos ejemplos donde se le penaliza en gran medida. Este comportamiento resulta de una tendencia general a comportarse como la imagen mostrada en la Figura 3 (nota el cruce en las colas). Si bien la distribución gaussiana asimétrica tiende a colocar el modo de manera mucho más precisa que una gaussiana simétrica, su flexibilidad asimétrica combinada con su función de distancia hace que distribuya demasiada masa en las colas exteriores, sin ajustarse lo suficientemente alrededor del modo para compensar. La Figura 3 es en realidad el resultado de ajustar las dos distribuciones a datos reales. Como resultado, en las colas puede haber una gran discrepancia entre la probabilidad de pertenecer a cada clase. Por lo tanto, cuando no hay valores atípicos, A. Gauss puede desempeñarse bastante competitivamente, pero cuando hay un 0 0.002 0.004 0.006 0.008 0.01 0.012 -600 -400 -200 0 200 400 p(s(d)|Clase={+,-}) s(d) = Bayes ingenuo logaritmo de probabilidades Entrenamiento Prueba A.Laplace 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 -15 -10 -5 0 5 10 15 p(s(d)|Clase={+,-}) s(d) = SVM lineal puntuación bruta Entrenamiento Prueba A.Laplace Figura 4: La distribución empírica de las puntuaciones del clasificador para documentos en el conjunto de entrenamiento y el conjunto de prueba para la clase Earn en Reuters. También se muestra el ajuste de la distribución Laplace asimétrica a la distribución de puntuaciones de entrenamiento. La clase positiva (es decir, La clase positiva (es decir, Earn) es la distribución a la derecha en cada gráfico, y la clase negativa (es decir, ¬Earn) es la de la izquierda en cada gráfico. Hay suficientes casos de este tipo en general que parece claramente inferior a los tres métodos principales. Sin embargo, la distribución asimétrica de Laplace pone mucho más énfasis alrededor del modo (Figura 4) debido a la función de distancia diferente (piensa en el pico agudo de una exponencial). Como resultado, la mayor parte de la masa se mantiene centrada alrededor del modo, mientras que los parámetros asimétricos aún permiten más flexibilidad que la Laplace estándar. Dado que el Laplace estándar también corresponde a un ajuste por tramos en el espacio de logaritmos de probabilidades, esto resalta que parte del poder de los métodos asimétricos radica en su sensibilidad para colocar los puntos de inflexión en los modos reales, en lugar de la suposición simétrica de que las medias corresponden a los modos. Además, los métodos asimétricos tienen una mayor flexibilidad para ajustar las pendientes de los segmentos de línea también. Incluso en casos donde la distribución de prueba difiere de la distribución de entrenamiento (Figura 4), A. Laplace sigue proporcionando una solución que se ajusta mejor que LogReg (Figura 5), el siguiente mejor competidor. Finalmente, podemos hacer algunas observaciones sobre la utilidad de las diferentes métricas de rendimiento. Primero, la pérdida logarítmica solo otorga una cantidad finita de crédito a medida que mejora el grado de corrección de algo (es decir, hay rendimientos decrecientes a medida que se acerca a cero), pero puede penalizar infinitamente por una estimación incorrecta. Por lo tanto, es posible que un valor atípico sesgue los totales, pero clasificar erróneamente este ejemplo puede no importar para ninguna otra función de utilidad real utilizada en la práctica. En segundo lugar, el error cuadrático tiene una debilidad en la otra dirección. Es decir, su penalización y recompensa están limitadas en [0, 1], pero si el número de errores es lo suficientemente pequeño, es posible que un método parezca mejor cuando está produciendo lo que generalmente consideramos estimaciones de probabilidad poco útiles. Por ejemplo, considera un método que solo estima probabilidades como cero o uno (a lo que tiende el Bayes ingenuo pero no alcanza completamente si se utiliza suavizado). Este método podría ganar según el error cuadrático, pero con solo un error nunca superaría en pérdida logarítmica a cualquier método que asigne alguna probabilidad no nula a cada resultado. Por estas razones, recomendamos que ninguno de estos se utilice de forma aislada, ya que cada uno proporciona perspectivas ligeramente diferentes sobre la calidad de las estimaciones producidas. Estas observaciones son directas a partir de las definiciones, pero están subrayadas por la evaluación. 5. TRABAJO FUTURO Una extensión prometedora al trabajo presentado aquí es una distribución híbrida de una Gaussiana (en las pendientes exteriores) y exponenciales (en las pendientes interiores). A partir de la evidencia empírica presentada en [22], la expectativa es que dicha distribución pueda permitir más énfasis de la masa de probabilidad alrededor de los modos (como en el caso de la exponencial) al tiempo que proporciona estimaciones más precisas hacia las colas. Así como la regresión logística permite ajustar directamente el logaritmo de las probabilidades a posteriori con una línea, podríamos ajustar directamente el logaritmo de las probabilidades a posteriori con una línea de tres piezas (un spline) en lugar de hacer lo mismo indirectamente ajustando la distribución asimétrica de Laplace. Este enfoque puede proporcionar más potencia ya que conserva la suposición de asimetría pero no la suposición de que las densidades condicionales de clase provienen de una distribución Laplace asimétrica. Finalmente, extender estos métodos a las salidas de otros clasificadores discriminativos es un área abierta. Actualmente estamos evaluando la adecuación de estos métodos para la salida de un perceptrón votado [11]. Por analogía con las probabilidades logarítmicas, la puntuación operativa que parece prometedora es la suma de los votos de los perceptrones con peso logarítmico y los votos de los perceptrones con peso. - 0.6. RESUMEN Y CONCLUSIONES Hemos revisado una amplia variedad de métodos paramétricos para producir estimaciones de probabilidad a partir de las puntuaciones crudas de un clasificador discriminativo y para recalibrar un clasificador probabilístico no calibrado. Además, hemos introducido dos nuevas familias que intentan capitalizar el comportamiento asimétrico que tiende a surgir al aprender una función de discriminación. Hemos proporcionado una forma eficiente de estimar los parámetros de estas distribuciones. Si bien estas distribuciones intentan lograr un equilibrio entre el poder de generalización de las distribuciones paramétricas y la flexibilidad que otorgan los parámetros asimétricos añadidos, la Gaussiana asimétrica parece tener un énfasis excesivo lejos de los modos. En marcado contraste, la distribución asimétrica de Laplace parece ser preferible sobre varios dominios de texto grandes y una variedad de medidas de rendimiento en comparación con los principales métodos paramétricos competidores, aunque a veces se logra un rendimiento comparable con una de las dos variedades de regresión logística. Dada la facilidad de estimar los parámetros de esta distribución, es una buena primera opción para producir estimaciones de probabilidad de calidad. Agradecimientos Agradecemos a Francisco Pereira por el código del test de signos, a Anton Likhodedov por el código de regresión logística y a John Platt por el soporte del código para la herramienta de clasificación SVM lineal Smox. También agradecemos sinceramente a Chris Meek y John Platt por los consejos muy útiles proporcionados en las primeras etapas de este trabajo. Gracias también a Jaime Carbonell y John Lafferty por sus útiles comentarios sobre las versiones finales de este artículo. 7. REFERENCIAS [1] P. N. Bennett. Evaluando la calibración de las estimaciones posteriores de Naive Bayes. Informe técnico CMU-CS-00-155, Carnegie Mellon, Escuela de Ciencias de la Computación, 2000. [2] P. N. Bennett. Utilizando distribuciones asimétricas para mejorar las probabilidades del clasificador: Una comparación de métodos paramétricos nuevos y estándar. Informe técnico CMU-CS-02-126, Carnegie Mellon, Escuela de Ciencias de la Computación, 2002. [3] H. Bourlard y N. Morgan. Un sistema de reconocimiento continuo del habla que incorpora mlp en hmm. En NIPS 89, 1989. [4] G. Brier. Verificación de pronósticos expresados en términos de probabilidad. Revista Mensual del Clima, 78:1-3, 1950. [5] M. H. DeGroot y S. E. Fienberg. La comparación y evaluación de pronosticadores. Estadístico, 32:12-22, 1983. [6] M. H. DeGroot y S. E. Fienberg. Comparación de pronosticadores de probabilidad: Conceptos binarios básicos y extensiones multivariadas. En P. Goel y A. Zellner, editores, Inferencia Bayesiana y Técnicas de Decisión. Elsevier Science Publishers B.V., 1986. [7] P. Domingos y M. Pazzani. Más allá de la independencia: Condiciones para la optimalidad del clasificador bayesiano simple. En ICML 96, 1996. [8] R. Duda, P. Hart y D. Stork. Clasificación de patrones. John Wiley & Sons, Inc., 2001. [9] S. T. Dumais y H. Chen. Clasificación jerárquica de contenido web. En SIGIR 00, 2000. [10] S. T. Dumais, J. Platt, D. Heckerman y M. Sahami. Algoritmos de aprendizaje inductivo y representaciones para la categorización de texto. En CIKM 98, 1998. [11] Y. Freund y R. Schapire. Clasificación de márgen amplio utilizando el algoritmo del perceptrón. Aprendizaje automático, 37(3):277-296, 1999. [12] I. Bien. Decisiones racionales. Revista de la Real Sociedad Estadística, Serie B, 1952. [13] T. Joachims. Categorización de texto con máquinas de vectores de soporte: Aprendizaje con muchas características relevantes. En ECML 98, 1998. [14] S. Kotz, T. J. Kozubowski y K. Podgorski. La Distribución de Laplace y sus Generalizaciones: Una Revisión con Aplicaciones a Comunicaciones, Economía, Ingeniería y Finanzas. Birkhäuser, 2001. [15] D. D. Lewis. 

Birkhäuser, 2001. [15] D. D. Lewis. Un algoritmo secuencial para entrenar clasificadores de texto: Corrección y datos adicionales. SIGIR Forum, 29(2):13-19, Otoño 1995. [16] D. D. Lewis. Reuters-21578, distribución 1.0. http://www.daviddlewis.com/resources/testcollections/reuters21578, enero de 1997. [17] D. D. Lewis y W. A. Gale. Un algoritmo secuencial para entrenar clasificadores de texto. En SIGIR 94, 1994. [18] D. D. Lewis, R. E. Schapire, J. P. Callan y R. Papka. Entrenando algoritmos para clasificadores de texto lineales. En SIGIR 96, 1996. [19] D. Lindley, A. Tversky y R. Brown. Sobre la conciliación de evaluaciones de probabilidad. Revista de la Real Sociedad Estadística, 1979. [20] R. Manmatha, T. Rath y F. Feng. Modelando las distribuciones de puntuaciones para combinar las salidas de los motores de búsqueda. En SIGIR 01, 2001. [21] A. McCallum y K. Nigam. Una comparación de modelos de eventos para la clasificación de texto con Naive Bayes. En AAAI 98, Taller sobre Aprendizaje para la Categorización de Textos, 1998. [22] J. C. Platt. Salidas probabilísticas para máquinas de vectores de soporte y comparaciones con métodos de verosimilitud regularizados. En A. J. Smola, P. Bartlett, B. Scholkopf y D. Schuurmans, editores, Avances en Clasificadores de Márgenes Amplios. MIT Press, 1999. [23] M. Saar-Tsechansky y F. Provost. Aprendizaje activo para la estimación de probabilidades y clasificación en clase. En IJCAI 01, 2001. [24] R. L. Winkler. Reglas de puntuación y la evaluación de los evaluadores de probabilidad. Revista de la Asociación Estadística Americana, 1969. [25] Y. Yang y X. Liu. Una reevaluación de los métodos de categorización de texto. En SIGIR 99, 1999. [26] B. Zadrozny y C. Elkan. Obteniendo estimaciones de probabilidad calibradas a partir de árboles de decisión y clasificadores bayesianos ingenuos. En ICML 01, 2001. [27] B. Zadrozny y C. Elkan. Reducir la clasificación multiclase a binaria mediante el acoplamiento de estimaciones de probabilidad. En KDD 02, 2002.