La privacidad en el comercio electrónico y la economía de la gratificación inmediata. Alessandro Acquisti. Escuela de Política Pública y Gestión H. John Heinz III de la Universidad Carnegie Mellon. acquisti@andrew.cmu.edu. RESUMEN Se han observado dicotomías entre las actitudes y el comportamiento en relación con la privacidad en la literatura, pero aún no han sido completamente explicadas. Aplicamos lecciones de la investigación en economía conductual para comprender el proceso de toma de decisiones individuales con respecto a la privacidad en el comercio electrónico. Mostramos que es irrealista esperar racionalidad individual en este contexto. Los modelos de problemas de autocontrol y gratificación inmediata ofrecen descripciones más realistas del proceso de toma de decisiones y son más consistentes con los datos actualmente disponibles. En particular, demostramos por qué individuos que genuinamente desean proteger su privacidad podrían no hacerlo debido a distorsiones psicológicas bien documentadas en la literatura conductual; demostramos que estas distorsiones pueden afectar no solo a individuos ingenuos sino también a los sofisticados; y demostramos que esto puede ocurrir incluso cuando los individuos perciben los riesgos de no proteger su privacidad como significativos. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.1 [Temas de Política Pública]: Privacidad Términos Generales Economía, Seguridad, Factores Humanos 1. PRIVACIDAD Y COMERCIO ELECTRÓNICO La privacidad sigue siendo un tema importante para el comercio electrónico. Un estudio de PriceWaterhouseCoopers en 2000 mostró que casi dos tercios de los consumidores encuestados comprarían más en línea si supieran que los sitios minoristas no harían nada con su información personal [15]. Un estudio de la Comisión Federal de Comercio informó en 2000 que el sesenta y siete por ciento de los consumidores estaban muy preocupados por la privacidad de la información personal proporcionada en línea [11]. Más recientemente, una encuesta de Harris Interactive de febrero de 2002 encontró que las tres mayores preocupaciones de los consumidores en el área de la seguridad de la información personal en línea eran: empresas que intercambian datos personales sin permiso, las consecuencias de transacciones inseguras y el robo de datos personales [19]. Según un estudio de Jupiter Research en 2002, se perderán $24.5 mil millones en ventas en línea para el año 2006, en comparación con los $5.5 mil millones en 2001. Las ventas minoristas en línea serían aproximadamente un veinticuatro por ciento más altas en 2006 si se abordaran de manera efectiva los temores de los consumidores sobre la privacidad y la seguridad [21]. Aunque la publicidad exagerada en los medios de comunicación ha disminuido en cierta medida, los riesgos y costos no lo han hecho, como lo demuestran los crecientes volúmenes de correo no deseado electrónico y robo de identidad [16]. Las encuestas en este campo, sin embargo, así como los experimentos y la evidencia anecdótica, también han pintado un panorama diferente. [36, 10, 18, 21] han encontrado evidencia de que incluso las personas preocupadas por la privacidad están dispuestas a sacrificar la privacidad por conveniencia, o negociar la divulgación de información muy personal a cambio de recompensas relativamente pequeñas. El fracaso de varios servicios en línea destinados a proporcionar anonimato a los usuarios de Internet [6] ofrece evidencia indirecta adicional de la renuencia de la mayoría de las personas a invertir esfuerzo alguno en proteger su información personal. La dicotomía entre las actitudes de privacidad y el comportamiento ha sido resaltada en la literatura. Se han proporcionado interpretaciones preliminares de este fenómeno [2, 38, 33, 40]. Todavía faltan: una explicación fundamentada en teorías económicas o psicológicas; una validación empírica de la explicación propuesta; y, por supuesto, la respuesta a la pregunta más recurrente: ¿deberían preocuparse las personas en absoluto por la privacidad? En este artículo nos enfocamos en la primera pregunta: analizamos formalmente el proceso de toma de decisiones individuales con respecto a la privacidad y sus posibles deficiencias. Nos enfocamos en las (in)concepciones individuales sobre cómo manejan los riesgos que enfrentan al revelar información privada. No abordamos la cuestión de si las personas realmente deberían protegerse. Comentaremos sobre eso en la Sección 5, donde también discutiremos estrategias para validar empíricamente nuestra teoría. Aplicamos lecciones de economía conductual. La economía tradicional postula que las personas son previsoras y actualizan sus creencias de manera bayesiana: tienen en cuenta cómo el comportamiento actual influirá en su bienestar y preferencias futuras. Por ejemplo, el estudio [5] analiza modelos racionales de adicción. Este enfoque se puede comparar con aquellos que ven en la decisión 21 de no proteger su privacidad una elección racional dada la (supuesta) baja probabilidad de riesgos en juego. Sin embargo, los avances en el área de la economía conductual han destacado diversas formas de inconsistencias psicológicas (problemas de autocontrol, descuento hiperbólico, sesgos hacia el presente, etc.) que chocan con la visión completamente racional del agente económico. En este documento nos basamos en estos avances para llegar a las siguientes conclusiones: • Mostramos que es poco probable que los individuos puedan actuar racionalmente en el sentido económico cuando se enfrentan a decisiones sensibles a la privacidad. • Mostramos que modelos alternativos de comportamiento personal y preferencias inconsistentes en el tiempo son compatibles con la dicotomía entre actitudes y comportamiento y pueden ajustarse mejor a los datos actuales. Por ejemplo, pueden explicar los resultados presentados por [36] en la conferencia ACM EC 01. En su experimento, se descubrió que los defensores autoproclamados de la privacidad estaban dispuestos a revelar cantidades variables de información personal a cambio de pequeñas recompensas. • En particular, mostramos que los individuos pueden tener una tendencia a subprotegerse contra los riesgos de privacidad que perciben, y a proporcionar en exceso información personal incluso cuando están alerta de los riesgos (percibidos) involucrados. • Mostramos que la magnitud de los costos percibidos de la privacidad en ciertas condiciones no actuará como un disuasivo contra el comportamiento que el individuo admite como riesgoso. • Mostramos, siguiendo estudios similares en la economía de la gratificación inmediata [31], que incluso individuos sofisticados pueden, en ciertas condiciones, volverse miope en cuanto a la privacidad. Nuestra conclusión es que simplemente proporcionar más información y conciencia en un entorno autorregulativo no es suficiente para proteger la privacidad individual. Las tecnologías mejoradas, al reducir los costos de adopción y protección, ciertamente pueden ayudar. Sin embargo, también deben abordarse respuestas conductuales humanas más fundamentales si se pretende proteger la privacidad. En la siguiente sección proponemos un modelo de agentes racionales enfrentando decisiones sensibles a la privacidad. En la Sección 3 mostramos las dificultades que obstaculizan cualquier modelo de toma de decisiones sobre privacidad basado en la plena racionalidad. En la Sección 4 mostramos cómo los modelos conductuales basados en el sesgo de gratificación inmediata pueden explicar mejor la dicotomía actitudes-comportamiento y coincidir con los datos disponibles. En la Sección 5 resumimos y discutimos nuestras conclusiones. 2. Un MODELO DE RACIONALIDAD EN LA TOMA DE DECISIONES DE PRIVACIDAD Algunos han utilizado la dicotomía entre actitudes y comportamientos de privacidad para afirmar que los individuos actúan de manera racional cuando se trata de privacidad. Bajo esta perspectiva, los individuos pueden aceptar pequeñas recompensas por proporcionar información porque esperan que los daños futuros sean aún menores (cuando se descuentan en el tiempo y con su probabilidad de ocurrencia). Aquí queremos investigar qué suposiciones subyacentes sobre el comportamiento personal respaldarían la hipótesis de plena racionalidad en la toma de decisiones sobre privacidad. Desde [28, 37, 29] los economistas se han interesado en la privacidad, pero solo recientemente han comenzado a aparecer modelos formales [3, 7, 39, 40]. Si bien estos estudios se centran en las interacciones de mercado entre un agente y otras partes, aquí estamos interesados en formalizar el proceso de toma de decisiones del individuo único. Queremos ver si los individuos pueden ser económicamente racionales (mirando hacia adelante, actualizando según Bayes, maximizando la utilidad, y así sucesivamente) cuando se trata de proteger su propia información personal. El concepto de privacidad, antes entendido como el derecho a ser dejado en paz [41], ha evolucionado a medida que nuestra sociedad se ha vuelto más orientada a la información. En una sociedad de la información, el yo se expresa, se define y se ve afectado a través de la información y la tecnología de la información. Las fronteras entre lo privado y lo público se vuelven borrosas. Por lo tanto, la privacidad se ha convertido en una clase de intereses multifacéticos en lugar de un concepto único y ambiguo. Por lo tanto, su valor puede ser discutido (si no determinado) solo una vez que su contexto también haya sido especificado. Esto requiere principalmente el estudio de una red de relaciones entre un sujeto, cierta información (relacionada con el sujeto), otras partes (que pueden tener varios vínculos de interés o asociación con esa información o ese sujeto) y el contexto en el que se producen dichos vínculos. Para comprender cómo un agente racional podría navegar a través de esas complejas relaciones, en la Ecuación 1 abstraemos el proceso de decisión de un agente económico racional idealizado que enfrenta compensaciones de privacidad al completar una cierta transacción. max d Ut = δ vE (a) , pd (a) + γ vE (t) , pd (t) − cd t (1) En la Ecuación 1, δ y γ son formas funcionales no especificadas que describen relaciones ponderadas entre los beneficios esperados de un conjunto de eventos v y las probabilidades asociadas de ocurrencia de esos eventos p. Más precisamente, la utilidad U de completar una transacción t (la transacción siendo cualquier acción - no necesariamente una operación monetaria - posiblemente involucrando la exposición de información personal) es igual a alguna función del beneficio esperado vE (a) de mantener (o no) cierta información privada durante esa transacción, y la probabilidad de mantener [o no mantener] esa información privada al usar la tecnología d, pd (a) [1 − pd (a)]; más alguna función del beneficio esperado vE (t) de completar (o no completar) la transacción (posiblemente revelando información personal), y la probabilidad de completar [o no completar] esa transacción con una cierta tecnología d, pd (t) [1 − pd (t)]; menos el costo de usar la tecnología t: cd t.1 La tecnología d puede o no ser de mejora de privacidad. Dado que las recompensas en la Ecuación 1 pueden ser tanto positivas como negativas, la Ecuación 1 encarna la dualidad implícita en los problemas de privacidad: existen tanto costos como beneficios derivados de revelar o proteger información personal, y los costos y beneficios de completar una transacción, vE (t), podrían ser distintos de los costos y beneficios de mantener la información asociada privada, vE (a). Por ejemplo, revelar la identidad a una librería en línea puede resultar en un descuento. Viceversa, también puede resultar en una factura más alta, debido a la discriminación de precios. Proteger la privacidad financiera al no divulgar información de tarjetas de crédito en línea puede proteger contra futuras pérdidas y problemas relacionados con el robo de identidad. Pero puede hacer que la experiencia de compras en línea sea más engorrosa y, por lo tanto, más costosa. Los parámetros funcionales δ y γ representan los pesos variables y actitudes que un individuo puede tener hacia mantener su información privada (por ejemplo, su sensibilidad a la privacidad, o su creencia de que la privacidad es un derecho cuyo respeto debería ser garantizado por el gobierno) y completar ciertas transacciones. Ten en cuenta que vE y p podrían referirse a conjuntos de pagos y las probabilidades asociadas de ocurrencia. Los pagos en sí mismos solo se esperan porque, independientemente de la probabilidad de que se complete la transacción o la información permanezca privada, pueden depender de otros conjuntos de eventos y sus probabilidades asociadas. vE() y pd(), en otras palabras, pueden ser interpretados como parámetros multivariados dentro de los cuales están ocultas varias otras variables, expectativas y funciones debido a la complejidad de la red de privacidad descrita anteriormente. Con el tiempo, la probabilidad de mantener cierta información privada, por ejemplo, no solo dependerá de la tecnología elegida, sino también de los esfuerzos de otras partes para apropiarse de esa información. Estos esfuerzos pueden depender, entre otras cosas, del valor esperado de esa información para esas partes. La probabilidad de mantener la información privada también dependerá del entorno en el que se esté llevando a cabo la transacción. Del mismo modo, el beneficio esperado de mantener la información privada también será una recopilación a lo largo del tiempo de distribuciones de probabilidad dependientes de varios parámetros. Imagina que la probabilidad de mantener privadas tus transacciones financieras es muy alta cuando utilizas un banco en Bermudas: sin embargo, el valor esperado de mantener confidencial tu información financiera dependerá de una serie de otros factores. Un agente racional, en teoría, elegiría la tecnología d que maximiza su ganancia esperada en la Ecuación 1. Quizás ella elegiría completar la transacción bajo la protección de una tecnología que mejora la privacidad. Quizás ella completaría la transacción sin protección. Tal vez ella no completaría la transacción en absoluto (d = 0). Por ejemplo, el agente puede considerar los costos y beneficios de enviar un correo electrónico a través de un sistema MIX-net anónimo [8] y compararlos con los costos y beneficios de enviar ese correo electrónico a través de un canal convencional no anónimo. Las magnitudes de los parámetros en la Ecuación 1 cambiarán con la tecnología elegida. Los sistemas MIX-net pueden disminuir las pérdidas esperadas por intrusiones a la privacidad. Los sistemas de correo electrónico no anónimos pueden prometer una confiabilidad comparativamente mayor y (posiblemente) costos reducidos de operaciones. La RACIONALIDAD Y LAS DISTORSIONES PSICOLÓGICAS EN LA PRIVACIDAD La Ecuación 1 es una guía completa (aunque intencionalmente genérica) para navegar a través de los compromisos de privacidad que ningún agente humano sería capaz de utilizar en realidad. Insinuamos algunas dificultades al notar que varias capas de complejidades están ocultas dentro de conceptos como el valor esperado de mantener cierta información privada y la probabilidad de tener éxito al hacerlo. Más precisamente, un agente enfrentará tres problemas al comparar los compromisos implícitos en la Ecuación 1: información incompleta sobre todos los parámetros; poder limitado para procesar toda la información disponible; ninguna desviación del camino racional hacia la maximización de la utilidad. Esos tres problemas son exactamente los mismos problemas con los que las personas reales tienen que lidiar a diario al enfrentarse a decisiones sensibles sobre la privacidad. Discutimos cada problema en detalle. Información incompleta. ¿A qué información tiene acceso la persona mientras se prepara para tomar decisiones sensibles sobre privacidad? ¿Por ejemplo, está consciente de las invasiones a la privacidad y los riesgos asociados? ¿Cuál es su conocimiento sobre la existencia y características de las tecnologías de protección? Las transacciones económicas suelen caracterizarse por información incompleta o asimétrica. Las diferentes partes involucradas pueden no tener la misma cantidad de información sobre la transacción y pueden estar inseguras acerca de algunos aspectos importantes de la misma [4]. La información incompleta afectará casi todos los parámetros en la Ecuación 1, y en particular la estimación de costos y beneficios. Los costos y beneficios asociados con la protección de la privacidad y las intrusiones a la privacidad son tanto monetarios como inmateriales. Los costos monetarios pueden incluir, por ejemplo, los costos de adopción (que probablemente sean fijos) y los costos de uso (que son variables) de tecnologías de protección, si la persona decide protegerse a sí misma. O pueden incluir los costos financieros asociados al robo de identidad, si resulta que la información de la persona no fue protegida adecuadamente. Los costos inmateriales pueden incluir los costos de aprendizaje de una tecnología protectora, los costos de cambio entre diferentes aplicaciones, o el estigma social al utilizar tecnologías de anonimato, entre otros. Asimismo, los beneficios de proteger (o no proteger) la información personal también pueden ser fáciles de cuantificar en términos monetarios (el descuento que recibes por revelar datos personales) o ser intangibles (la sensación de protección al enviar correos electrónicos encriptados). Es difícil para un individuo estimar todos estos valores. A través de la tecnología de la información, las invasiones de privacidad pueden ser ubicuas e invisibles. Muchos de los beneficios asociados con la protección de la privacidad o la intrusión pueden ser descubiertos o determinados solo ex post a través de la experiencia real. Consideremos, por ejemplo, las dificultades en el uso de tecnologías de privacidad y cifrado descritas en [43]. Además, los cálculos implícitos en la Ecuación 1 dependen de información incompleta sobre la distribución de probabilidad de eventos futuros. Algunas de esas distribuciones pueden predecirse después de datos comparables, por ejemplo, la probabilidad de que una determinada transacción con tarjeta de crédito resulte en fraude hoy podría calcularse utilizando estadísticas existentes. Las distribuciones de probabilidad de otros eventos pueden ser muy difíciles de estimar porque el entorno es demasiado dinámico, por ejemplo, la probabilidad de ser víctima de robo de identidad dentro de 5 años debido a ciertos datos que estás revelando ahora. Y las distribuciones de algunos otros eventos pueden ser casi completamente subjetivas, por ejemplo, la probabilidad de que una nueva y práctica forma de ataque a un criptosistema seguro actualmente exponga todas tus comunicaciones personales encriptadas dentro de unos años. Esto conduce a un problema relacionado: racionalidad limitada. Racionalidad limitada. ¿La persona es capaz de calcular todos los parámetros relevantes para su elección? ¿O está limitada por la racionalidad limitada? En nuestro contexto, la racionalidad limitada se refiere a la incapacidad de calcular y comparar las magnitudes de las recompensas asociadas con diversas estrategias que el individuo puede elegir en situaciones sensibles a la privacidad. También se refiere a la incapacidad de procesar toda la información estocástica relacionada con los riesgos y probabilidades de eventos que conducen a costos y beneficios de privacidad. En la teoría económica tradicional, se asume que el agente tiene tanto racionalidad como poder computacional ilimitado para procesar información. Pero los agentes humanos son incapaces de procesar toda la información en sus manos y sacar conclusiones precisas de ella [34]. En el escenario que consideramos, una vez que un individuo proporciona información personal a otras partes, literalmente pierde el control de esa información. Esa pérdida de control se propaga a otras partes y persiste durante períodos de tiempo impredecibles. Al estar en una posición de asimetría de información con respecto a la parte con la que está realizando la transacción, las decisiones deben basarse en evaluaciones estocásticas, y las magnitudes de los factores que pueden afectar al individuo se vuelven muy difíciles de agregar, calcular y comparar. La racionalidad limitada afectará el cálculo de los parámetros en la Ecuación 1, y en particular δ, γ, vE() y pt(). Los costos cognitivos involucrados en tratar de calcular la mejor estrategia podrían ser tan altos que el individuo simplemente recurra a heurísticas simples. Distorsiones psicológicas. Eventualmente, incluso si un individuo tuviera acceso a información completa y pudiera calcularla adecuadamente, aún podría encontrar difícil seguir la estrategia racional presentada en la Ecuación 1. Un vasto cuerpo de literatura económica y psicológica ha confirmado hasta ahora el impacto de varias formas de distorsiones psicológicas en la toma de decisiones individuales. La privacidad parece ser un estudio de caso que abarca muchas de esas distorsiones: descuento hiperbólico, subseguro, problemas de autocontrol, gratificación inmediata y otros. La dicotomía tradicional entre actitud y comportamiento, observada en varios aspectos de la psicología humana y estudiada en la literatura de psicología social desde [24] y [13], también puede aparecer en el ámbito de la privacidad debido a estas distorsiones. Por ejemplo, los individuos tienden a descontar de forma hiperbólica los costos o beneficios futuros [31, 27]. En economía, el descuento hiperbólico implica una inconsistencia de las preferencias personales a lo largo del tiempo: los eventos futuros pueden ser descontados a tasas de descuento diferentes que los eventos a corto plazo. El descuento hiperbólico puede afectar las decisiones de privacidad, por ejemplo, cuando descontamos en gran medida la (baja) probabilidad de (altos) riesgos futuros como el robo de identidad. Relacionado con el descuento hiperbólico está la tendencia a subasegurarse contra ciertos riesgos. En general, los individuos pueden imponer restricciones en su comportamiento futuro que limiten su propio logro de utilidad máxima: las personas pueden querer protegerse genuinamente, pero debido al sesgo de autocontrol, en realidad no tomarán esas medidas y optarán por la gratificación inmediata en su lugar. Las personas tienden a subestimar los efectos de los cambios en sus estados, y por lo tanto proyectan falsamente sus preferencias actuales sobre el consumo en sus preferencias futuras. Mucho más que simplemente sugerir que las personas hacen predicciones erróneas sobre gustos futuros, este sesgo de proyección postula un patrón sistemático en estas predicciones erróneas que puede llevar a errores sistemáticos en entornos de elección dinámica [25, p. 2]. La utilidad negativa proveniente de posibles malos usos futuros de la información personal de alguien podría ser un shock aleatorio cuya probabilidad y alcance son extremadamente variables. Por ejemplo, un pequeño y aparentemente inofensivo pedazo de información podría convertirse en un activo crucial o en una responsabilidad peligrosa en el contexto adecuado. Una descripción y aplicación más rigurosa del descuento hiperbólico se proporciona en la Sección 4. Además, las personas sufren de sesgo optimista [42], la percepción errónea de que sus riesgos son menores que los de otras personas en condiciones similares. El sesgo optimista puede llevarnos a creer que no seremos objeto de intrusiones a nuestra privacidad. Los individuos enfrentan dificultades al lidiar con los riesgos acumulativos. Por ejemplo, [35] muestra que aunque los jóvenes fumadores aprecian los riesgos a largo plazo del tabaquismo, no se dan cuenta completamente de la relación acumulativa entre los bajos riesgos de cada cigarrillo adicional y la lenta acumulación de un peligro grave. Las dificultades para lidiar con los riesgos acumulativos se aplican a la privacidad, ya que nuestra información personal, una vez divulgada, puede permanecer disponible durante largos períodos de tiempo. Y dado que puede correlacionarse con otros datos, los conjuntos de anonimato [32, 14] en los que deseamos permanecer ocultos se hacen más pequeños. Como resultado, el riesgo total asociado con revelar diferentes piezas de información personal es mayor que la suma de los riesgos individuales asociados con cada dato. Además, es más fácil lidiar con acciones y efectos que están más cerca en el tiempo. Las acciones y efectos que están en el futuro lejano son difíciles de enfocar dada nuestra limitada perspectiva de previsión. A medida que la previsión cambia, también lo hace el comportamiento, incluso cuando las preferencias permanecen iguales [20]. Este fenómeno también puede afectar las decisiones de privacidad, ya que los costos de protección de la privacidad pueden ser inmediatos, pero las recompensas pueden ser invisibles (ausencia de intrusiones) y distribuirse a lo largo de períodos futuros de tiempo. Para resumir: cada vez que nos enfrentamos a decisiones sensibles sobre la privacidad, rara vez tenemos todos los datos necesarios para tomar una elección informada. Pero incluso si lo tuviéramos, es probable que no pudiéramos procesarlo. E incluso si pudiéramos procesarlo, aún podríamos terminar actuando en contra de nuestro propio juicio. En lo que sigue, presentamos un modelo de actitudes y comportamientos de privacidad basado en algunos de estos hallazgos, y en particular en la lucha por la gratificación inmediata. 4. PRIVACIDAD Y LA ECONOMÍA DE LA GRATIFICACIÓN INMEDIATA El problema de la gratificación inmediata (que está relacionado con los conceptos de inconsistencia temporal, descuento hiperbólico y sesgo de autocontrol) es descrito de la siguiente manera por O'Donoghue y Rabin [27, p. 4]: La preferencia relativa de una persona por el bienestar en una fecha anterior en lugar de en una fecha posterior se hace más fuerte a medida que la fecha anterior se acerca. [...] [L]as personas tienen problemas de autocontrol causados por una tendencia a buscar la gratificación inmediata de una manera que su yo a largo plazo no aprecia. Por ejemplo, si solo te dieran dos alternativas, el lunes podrías decir que prefieres trabajar 5 horas el sábado en lugar de 5 horas y media el domingo. Pero a medida que llegue el sábado, es más probable que prefieras posponer el trabajo hasta el domingo. Esta simple observación tiene consecuencias bastante importantes en la teoría económica, donde la consistencia temporal de las preferencias es el modelo dominante. Considera primero el modelo tradicional de utilidad que los agentes obtienen del consumo: el modelo establece que la utilidad se descuenta exponencialmente con el tiempo: Ut = T τ=t δτ uτ (2) En la Ecuación 2, la utilidad acumulada U en el tiempo t es la suma descontada de todas las utilidades desde el tiempo t (el presente) hasta el tiempo T (el futuro). δ es el factor de descuento, con un valor entre 0 y 1. Un valor de 0 implicaría que el individuo aplica descuentos tan fuertes que la utilidad de los periodos futuros no vale nada hoy. Un valor de 1 implicaría que la persona es tan paciente que no descuenta las utilidades futuras. El factor de descuento se utiliza en economía para capturar el hecho de que tener (digamos) un dólar dentro de un año es valioso, pero no tanto como tener ese dólar ahora. En la Ecuación 2, si todos los uτ fueran constantes, por ejemplo, 10, y δ fuera 0.9, entonces en el tiempo t = 0 (es decir, ahora) u0 valdría 10, pero u1 valdría 9. Modificando el modelo tradicional de descuento de utilidad, [23] y luego [31] han propuesto un modelo que tiene en cuenta la posible inconsistencia temporal de las preferencias. Consideremos la Ecuación 3: Ut(ut, ut+1, ..., uT ) = δt ut + β T τ=t+1 δτ uτ (3). Supongamos que δ, β ∈ [0, 1]. δ es el factor de descuento para la utilidad intertemporal como en la Ecuación 2. β es el parámetro que captura la tendencia de un individuo a gratificarse inmediatamente (una forma de preferencias no consistentes en el tiempo). Cuando β es 1, el modelo mapea el modelo de utilidad tradicionalmente consistente en el tiempo, y la Ecuación 3 es idéntica a la Ecuación 2. Pero cuando β es cero, el individuo no se preocupa por nada más que por el día de hoy. De hecho, cualquier β menor que 1 representa sesgo de autocontrol. La literatura experimental ha demostrado de manera convincente que los seres humanos tienden a tener problemas de autocontrol incluso cuando afirman lo contrario: tendemos a evitar y posponer actividades no deseadas incluso cuando esto implicará más esfuerzo mañana; y tendemos a involucrarnos en exceso en actividades placenteras aunque esto pueda causar sufrimiento o una utilidad reducida en el futuro. Este marco analítico se puede aplicar al estudio de las actitudes y comportamientos sobre la privacidad. Proteger tu privacidad a veces significa protegerte de una molestia clara y presente (como los teleoperadores, o personas mirando por tu ventana y viendo cómo vives - ver [33]); pero a veces representa algo similar a obtener un seguro contra riesgos futuros y solo inciertos. En las encuestas completadas en el tiempo t = 0, los sujetos preguntados sobre su actitud hacia los riesgos de privacidad pueden considerar mentalmente algunos costos de protegerse en un momento posterior t = s y compararlos con los costos evitados de las intrusiones a la privacidad en un futuro aún más distante t = s + n. Sus alternativas en el momento de la encuesta 0 están representadas en la Ecuación 4. min con respecto a x DU0 = β[(E(cs,p)δs x) + (E(cs+n,i)δs+n (1 − x))] (4) x es una variable ficticia que puede tomar valores 0 o 1. Representa la elección del individuo: qué costos decide enfrentar el individuo, ya sea el costo esperado de protegerse a sí mismo en el tiempo s, E(cs,p) (en cuyo caso x = 1), o los costos esperados de ser objeto de intrusiones a la privacidad en un momento posterior s + n, E(cs+n,i). El individuo está tratando de minimizar la desutilidad DU de estos costos con respecto a x. Debido a que ella descuenta los dos eventos futuros con el mismo factor de descuento (aunque en momentos diferentes), para ciertos valores de los parámetros, la persona puede concluir que vale la pena pagar para protegerse a sí misma. En particular, esto sucederá cuando: E(cs,p)δs < E(cs+n,i)δs+n (5) Ahora, considera qué sucede cuando llega el momento t = s. Ahora debería pagarse un precio real para poder disfrutar de alguna forma de protección (por ejemplo, comenzar a cifrar todos tus correos electrónicos para protegerte de futuras intrusiones). Ahora el individuo percibirá una imagen diferente: min wrt x DUs = δE(cs,p)x + βE(cn,i)δn (1 − x)] (6) Nótese que nada ha cambiado en la ecuación (ciertamente no los riesgos percibidos por los individuos) excepto el tiempo. Si β (el parámetro que indica el grado de problemas de autocontrol) es menor que uno, es probable que la persona elija no protegerse en este momento. Esto ocurrirá de hecho cuando: δE(cs,p) > βE(cn,i)δn (7). Nótese que las Desigualdades 5 y 7 pueden cumplirse simultáneamente para ciertos β < 1. En el momento de la encuesta, la persona afirmó honestamente que quería protegerse en principio, es decir, en algún momento en el futuro. Pero aunque se le pide que haga un esfuerzo para protegerse en este momento, ella elige correr el riesgo de intrusión en su privacidad. Argumentos matemáticos similares se pueden hacer para la comparación entre costos inmediatos con beneficios inmediatos (suscribirse a una lista de no llamadas para evitar que los telemercadeadores lo molesten durante la cena), y costos inmediatos con solo recompensas futuras esperadas (asegurarse contra el robo de identidad, o protegerse de fraudes al no usar nunca su tarjeta de crédito en línea), especialmente cuando las recompensas futuras esperadas (o riesgos evitados) también son intangibles: las consecuencias inmateriales de vivir (o no) en una sociedad de expedientes, o los efectos intimidatorios (o la falta de ellos) de estar bajo vigilancia. El lector habrá notado que nos hemos centrado en los costos percibidos (esperados) E(c), en lugar de los costos reales. No conocemos los costos reales y no afirmamos que el individuo 25 lo haga. Pero podemos demostrar que bajo ciertas condiciones, incluso los costos percibidos como muy altos (como durante períodos de intenso debate sobre la privacidad) serán ignorados. Podemos proporcionar algunos ejemplos numéricos ficticios para hacer el análisis más concreto. Presentamos algunos escenarios inspirados en los cálculos en [31]. Imagina una economía con solo 4 períodos (Tabla 1). Cada individuo puede inscribirse en un programa de lealtad de supermercados revelando información personal. Si lo hace, el individuo obtiene un descuento de 2 durante el período de inscripción, solo para pagar una unidad cada vez después debido a la discriminación de precios basada en la información que reveló (no hacemos ningún intento de calibrar el realismo de este ejemplo claramente abstracto; el punto en el que nos estamos enfocando es cómo las inconsistencias temporales pueden afectar el comportamiento individual dadas las costos y beneficios esperados de ciertas acciones). Dependiendo de en qué período el individuo elija vender sus datos, tenemos los pagos no descontados representados en la Tabla 1. Imagina que el individuo está considerando estas opciones y descartándolas de acuerdo con la Ecuación 3. Supongamos que δ = 1 para todos los tipos de individuos (esto significa que, para simplificar, no consideramos el descuento intertemporal), pero β = 1/2 para los individuos inconsistentes en el tiempo y β = 1 para todos los demás. El individuo consistente en el tiempo elegirá unirse al programa en el último período y obtener un beneficio de 2-1=1. El individuo con problemas de gratificación inmediata, para quien β = 1/2, percibirá en cambio los beneficios de unirse ahora o en el período 3 como equivalentes (0.5), y se unirá al programa ahora, haciéndose realmente peor. [31] también sugiere que, además de la distinción entre individuos consistentes en el tiempo e individuos con preferencias inconsistentes en el tiempo, también deberíamos distinguir entre individuos inconsistentes en el tiempo que son ingenuos de aquellos que son sofisticados. Los individuos ingenuos y con falta de consistencia temporal no son conscientes de sus problemas de autocontrol, por ejemplo, son aquellos que siempre planean comenzar una dieta la próxima semana. Las personas sofisticadas con inconsistencia temporal sufren de sesgo hacia la gratificación inmediata, pero al menos son conscientes de sus inconsistencias. Las personas en esta categoría eligen su comportamiento hoy estimando correctamente su comportamiento futuro inconsistente en el tiempo. Ahora considera cómo esta diferencia afecta las decisiones en otro escenario, representado en la Tabla 2. Un individuo está considerando la adopción de una cierta tecnología que mejora la privacidad. Le costará dinero tanto protegerse como no protegerse. Si decide protegerse, el costo será la cantidad que pague, por ejemplo, por alguna tecnología que proteja su información personal. Si decide no protegerse, el costo serán las consecuencias esperadas de las intrusiones a su privacidad. Suponemos que ambos costos totales aumentan con el tiempo, aunque debido a dinámicas separadas. A medida que pasa el tiempo, se revela cada vez más información sobre el individuo, y se vuelve más costoso protegerse contra las intrusiones a la privacidad. Al mismo tiempo, sin embargo, las intrusiones se vuelven más frecuentes y peligrosas. Uno podría afirmar que las tarjetas de fidelidad siguen proporcionando beneficios con el tiempo. Aquí hacemos la suposición simplificadora de que tales beneficios no son mayores que los costos futuros incurridos después de haber revelado los propios gustos. También asumimos que la economía termina en el período 4 para todos los individuos, independientemente de cuándo eligieron unirse al programa de lealtad. En el periodo 1, la persona puede protegerse gastando 5, o puede optar por enfrentar un riesgo de intrusión en la privacidad en el siguiente periodo, con un costo esperado de 7. En el segundo período, suponiendo que aún no haya tenido lugar ninguna intrusión, ella puede protegerse nuevamente gastando un poco más, 6; o puede optar por enfrentar un riesgo de intrusión en la privacidad en el próximo (tercer) período, con un costo esperado de 9. En el tercer período, ella podría protegerse por 8 o enfrentar un costo esperado de 15 en el último período siguiente. Aquí tampoco intentamos calibrar los valores en la Tabla 2. Una vez más, nos enfocamos en el comportamiento diferente impulsado por la heterogeneidad en la consistencia temporal y sofisticación versus ingenuidad. Suponemos que β = 1 para las personas sin problemas de autocontrol y β = 1/2 para todos los demás. Suponemos, para simplificar, que δ = 1 para todos. Las personas coherentes en el tiempo obviamente elegirán protegerse tan pronto como sea posible. En el primer período, los individuos ingenuos e inconsistentes en el tiempo compararán los costos de protegerse en ese momento o enfrentar una intrusión a su privacidad en el segundo período. Dado que 5 > 7 ∗ (1/2), preferirán esperar hasta el siguiente período para protegerse. Pero en el segundo período estarán comparando 6 > 9 ∗ (1/2) - y así pospondrán nuevamente su protección. Seguirán haciéndolo, enfrentando riesgos cada vez mayores. Eventualmente, correrán el riesgo de incurrir en los costos percibidos más altos de intrusión a la privacidad (nótese nuevamente que simplemente estamos asumiendo que los individuos creen que existen riesgos para la privacidad y que estos aumentan con el tiempo; volveremos a este concepto más adelante). Los individuos sofisticados pero inconsistentes en el tiempo, por otro lado, adoptarán una tecnología protectora en el período 2 y pagarán 6. Para el período 2, de hecho, se darán cuenta (correctamente) de que si esperan hasta el período 3 (lo cual están tentados a hacer, porque 6 > 9 ∗ (1/2)), su sesgo de autocontrol los llevará a posponer la adopción de la tecnología una vez más (porque 8 > 15 ∗ (1/2)). Por lo tanto, predicen que incurrirían en el costo esperado de 15 ∗ (1/2), que es mayor que el costo de protegerse en el período 2. En el periodo 1, sin embargo, predicen correctamente que no esperarán para protegerse más allá del periodo 2. Por lo tanto, esperan hasta el período 2, ya que 5 > 6 ∗ (1/2), momento en el cual adoptarán una tecnología protectora (ver también [31]). Para resumir, las personas con inconsistencia temporal tienden a no apreciar completamente los riesgos futuros y, si son ingenuas, también su incapacidad para hacerles frente. Esto sucede incluso si son conscientes de esos riesgos y saben que esos riesgos están aumentando. Como aprendimos del segundo escenario, la inconsistencia temporal puede llevar a las personas a aceptar riesgos cada vez mayores. Los individuos pueden tender a minimizar el hecho de que acciones individuales presentan bajos riesgos, pero su repetición forma una gran responsabilidad: es un aspecto engañoso de la privacidad que su valor solo se aprecia realmente después de que la privacidad misma se pierde. Esta dinámica captura la esencia de la privacidad y los llamados conjuntos de anonimato [32, 14], donde cada bit de información que revelamos puede estar vinculado a otros, de modo que el todo es más que la suma de las partes. Además, [31] muestra que cuando los costos son inmediatos, las personas con inconsistencia temporal tienden a postergar; cuando los beneficios son inmediatos, tienden a anticiparse. En nuestro contexto, las cosas son aún más interesantes porque todas las decisiones sobre privacidad implican al mismo tiempo costos y beneficios. Por lo tanto, optamos por no utilizar eCash [9] para ahorrarnos los costos de cambiar de tarjetas de crédito. Pero aceptamos el riesgo de que nuestro número de tarjeta de crédito en Internet pueda ser utilizado. Los costos de protección son 5 en el Periodo 1, 6 en el Periodo 2, 8 en el Periodo 3 y 4. Costos esperados de intrusión. 7 9 15 Tabla 2: Costos (ficticios) de proteger la privacidad y costos esperados de intrusión a la privacidad a lo largo del tiempo. Y entregamos nuestra información personal a los supermercados para obtener descuentos inmediatos, que probablemente se convertirán en discriminación de precios con el tiempo [3, 26]. Hemos demostrado en el segundo escenario anterior cómo individuos sofisticados pero inconsistentes en el tiempo pueden optar por proteger su información solo en el período 2. Las personas sofisticadas con problemas de autocontrol pueden estar en apuros, a veces incluso en comparación con personas ingenuas con problemas de inconsistencia en el tiempo (¿cuántos defensores de la privacidad utilizan tecnologías de mejora de la privacidad todo el tiempo?). El razonamiento es que las personas sofisticadas son conscientes de sus problemas de autocontrol y, en lugar de ignorarlos, los incorporan en su proceso de toma de decisiones. Esto puede disminuir su propio incentivo para comportarse de la manera óptima ahora. Los defensores sofisticados de la privacidad podrían darse cuenta de que protegerse de cualquier posible intrusión en la privacidad es irrealista, por lo que podrían comenzar a comportarse mal ahora (y podrían acostumbrarse a eso, una forma de arbitrariedad coherente). Esto es consistente con los resultados presentados por [36] en la conferencia ACM EC 01. [36] encontró que los defensores de la privacidad también estaban dispuestos a revelar información personal a cambio de recompensas monetarias. También es interesante notar que estas inconsistencias no son causadas por desconocimiento de los riesgos existentes o confusión sobre las tecnologías disponibles. Las personas en los escenarios abstractos que describimos son conscientes de los riesgos y costos percibidos. Sin embargo, bajo ciertas condiciones, la magnitud de esas responsabilidades es casi irrelevante. El individuo asumirá riesgos cada vez mayores muy lentamente, los cuales se convierten en pasos hacia enormes responsabilidades. 5. DISCUSIÓN Aplicar modelos de sesgo de autocontrol y gratificación inmediata al estudio de la toma de decisiones sobre privacidad puede ofrecer una nueva perspectiva sobre el debate continuo sobre la privacidad. Hemos demostrado que un modelo de comportamiento de privacidad racional es irrealista, mientras que los modelos basados en distorsiones psicológicas ofrecen una representación más precisa del proceso de decisión. Hemos demostrado por qué las personas que realmente desean proteger su privacidad pueden no hacerlo debido a distorsiones psicológicas bien documentadas en la literatura de la economía conductual. Hemos resaltado que estas distorsiones pueden afectar no solo a individuos ingenuos sino también a los sofisticados. Sorprendentemente, también hemos descubierto que estas inconsistencias pueden ocurrir cuando las personas perciben los riesgos de no proteger su privacidad como significativos. Las incertidumbres adicionales, la aversión al riesgo y las actitudes variables hacia las pérdidas y ganancias pueden ser elementos confusos en nuestro análisis. La validación empírica es necesaria para calibrar los efectos de diferentes factores. Un análisis empírico puede comenzar con la comparación de los datos disponibles sobre la tasa de adopción de tecnologías de privacidad que ofrecen refugio inmediato ante preocupaciones de privacidad menores pero urgentes (por ejemplo, listas de marketing de no llamar), con datos sobre la adopción de tecnologías de privacidad que ofrecen una protección menos obviamente perceptible ante riesgos de privacidad más peligrosos pero también menos visibles (por ejemplo, seguros contra robo de identidad). Sin embargo, solo un enfoque experimental a lo largo de diferentes períodos de tiempo en un entorno controlado puede permitirnos desentrañar la influencia de varios factores. Las encuestas por sí solas no son suficientes, ya que hemos demostrado que las actitudes en el momento de la encuesta rara vez coincidirán con las acciones en el momento de la decisión. Una verificación experimental es parte de nuestra agenda de investigación en curso. Las distorsiones psicológicas que hemos discutido pueden ser consideradas en el debate en curso sobre cómo abordar el problema de la privacidad: autorregulación de la industria, protección personal de los usuarios (a través de la tecnología u otras estrategias) o intervención gubernamental. Las conclusiones a las que hemos llegado sugieren que no se puede confiar en que los individuos tomen decisiones en su mejor interés cuando se trata de privacidad. Esto no significa que las tecnologías de privacidad sean ineficaces. Por el contrario, nuestros resultados, al apuntar a ofrecer un modelo más realista del comportamiento del usuario, podrían ser de ayuda para los tecnólogos en el diseño de herramientas que mejoren la privacidad. Sin embargo, nuestros resultados también implican que la tecnología por sí sola o la conciencia por sí sola pueden no abordar el núcleo del problema de privacidad. Las tecnologías mejoradas (con menores costos de adopción y protección) y más información sobre riesgos y oportunidades ciertamente pueden ayudar. Sin embargo, también es necesario abordar mecanismos de comportamiento humano más fundamentales. La autorregulación, incluso en presencia de información completa y conciencia, puede no ser confiable para funcionar por las mismas razones. Una combinación de tecnología, conciencia y políticas regulatorias - calibradas para generar y hacer cumplir responsabilidades e incentivos para las partes apropiadas - puede ser necesaria para aumentar el bienestar relacionado con la privacidad (como en otras áreas de una economía: ver un análisis relacionado [25]). Observar que las personas no quieren pagar por privacidad o no les importa la privacidad, por lo tanto, es solo una verdad a medias. Las personas pueden no ser capaces de actuar como agentes económicamente racionales cuando se trata de la privacidad personal. ¿Y la pregunta de si a los consumidores les importa? es una pregunta diferente a ¿la privacidad importa? Desde un punto de vista económico, si la privacidad debe ser protegida o no, sigue siendo una pregunta abierta. Es una pregunta que implica definir contextos específicos en los que se invoca el concepto de privacidad. Pero el valor de la privacidad eventualmente va más allá de los ámbitos del razonamiento económico y el análisis de costos y beneficios, y termina relacionándose con las opiniones de uno sobre la sociedad y la libertad. Sin embargo, incluso desde una perspectiva puramente económica, la evidencia anecdótica sugiere que los costos de la privacidad (desde el spam hasta el robo de identidad, las ventas perdidas, las intrusiones y similares [30, 12, 17, 33, 26]) son altos y están aumentando. 6. AGRADECIMIENTOS El autor agradece sinceramente al Fondo de Desarrollo Berkman de la Universidad Carnegie Mellon, que apoyó parcialmente esta investigación. El autor también desea agradecer a Jens Grossklags, Charis Kaskiris y a tres árbitros anónimos por sus comentarios útiles. 27 7. REFERENCIAS [1] A. Acquisti, R. Dingledine y P. Syverson. Sobre la economía del anonimato. En Criptografía Financiera FC 03, páginas 84-102. Springer Verlag, LNCS 2742, 2003. [2] A. Acquisti y J. Grossklags. Pérdidas, ganancias y descuento hiperbólico: Un enfoque experimental sobre las actitudes y comportamientos de seguridad de la información. En el 2º Taller Anual sobre Economía y Seguridad de la Información - WEIS 03, 2003. [3] A. Acquisti y H. R. Varian. Precios condicionados según el historial de compras. Informe técnico, Universidad de California, Berkeley, 2001. Presentado en la Conferencia de la Asociación Europea de Economía, Venecia, Italia, agosto de 2002. http://www.heinz.cmu.edu/~acquisti/papers/privacy.pdf. [4] G. A. Akerlof. El mercado de limones: incertidumbre de calidad y el mecanismo de mercado. Revista Trimestral de Economía, 84:488-500, 1970. [5] G. S. Becker y K. M. Murphy. Una teoría de la adicción racional. Revista de Economía Política, 96:675-700, 1988. [6] B. D. Brunk. Comprendiendo el espacio de privacidad. Primer lunes, 7, 2002. http://firstmonday.org/issues/ issue7_10/brunk/index.html. [7] G. Calzolari y A. Pavan. Diseño óptimo de políticas de privacidad. Informe técnico, Gremaq, Universidad de Toulouse, 2001. [8] D. Chaum. Correo electrónico no rastreable, direcciones de retorno y seudónimos digitales. Comunicaciones de la ACM, 24(2):84-88, 1981. [9] D. Chaum. Firmas ciegas para pagos no rastreables. En Avances en Criptología - Crypto 82, páginas 199-203. Plenum Press, 1983. [10] R. K. Chellappa y R. Sin. Personalización versus privacidad: Un examen empírico del dilema de los consumidores en línea. En la reunión de Informs de 2002, 2002. [11] Comisión F. T. Privacidad en línea: Prácticas justas de información en el mercado electrónico, 2000. http://www.ftc.gov/reports/privacy2000/privacy2000.pdf. [12] Asociación de Banqueros Comunitarios de Indiana. Se espera que el fraude de identidad se triplique para el año 2005, 2001. http://www.cbai.org/Newsletter/December2001/identity_fraud_de2001.htm. [13] S. Corey. Actitudes profesionales y comportamiento real. Revista de Psicología Educativa, 28(1):271 - 280, 1937. [14] C. Díaz, S. Seys, J. Claessens y B. Preneel. Hacia la medición del anonimato. En P. Syverson y R. Dingledine, editores, Tecnologías de Mejora de la Privacidad - PET 02. Springer Verlag, 2482, 2002. [15] ebusinessforum.com. eMarketer: El gran debate sobre la privacidad en línea, 2000. http://www.ebusinessforum.com/index.asp?doc_id=1785&layout=rich_story. [16] Comisión Federal de Comercio. El robo de identidad encabeza la lista de las 10 quejas de fraude al consumidor de la FTC de 2001 y 2002. http://www.ftc.gov/opa/2002/01/idtheft.htm. [17] R. Gellman. Privacidad, consumidores y costos: Cómo la falta de privacidad afecta a los consumidores y por qué los estudios empresariales sobre los costos de la privacidad son sesgados e incompletos, 2002. http://www.epic.org/reports/dmfprivacy.html. [18] I.-H. Harn, K.-L. Hui, T. S. Lee e I. P. L. Png. Privacidad de la información en línea: Medición del equilibrio costo-beneficio. En la 23ª Conferencia Internacional sobre Sistemas de Información, 2002. [19] Harris Interactive. La primera encuesta importante sobre privacidad después del 11 de septiembre encuentra a los consumidores exigiendo que las empresas hagan más para proteger la privacidad; el público quiere que las políticas de privacidad de las empresas sean verificadas de forma independiente, 2002. http://www.harrisinteractive.com/news/allnewsbydate.asp?NewsID=429. [20] P. Jehiel y A. Lilico. Fumar hoy y dejar de fumar mañana: Una perspectiva de previsión limitada. Informe técnico, Departamento de Economía, UCLA, 2002. [21] Investigación Jupiter. El setenta por ciento de los consumidores estadounidenses se preocupan por la privacidad en línea, pero pocos toman medidas de protección, 2002. http://www.jmm.com/xp/jmm/press/2002/pr_060302.xml. [22] H. Kunreuther. Causas de la falta de seguro contra desastres naturales. Geneva Papers on Risk and Insurance, 1984. [23] D. Laibson.
Papeles de Ginebra sobre Riesgo y Seguros, 1984. [23] D. Laibson. Ensayos sobre el descuento hiperbólico. MIT, Departamento de Economía, Tesis de Doctorado, 1994. [24] R. LaPiere. Actitudes versus acciones. Fuerzas Sociales, 13:230-237, 1934. [25] G. Lowenstein, T. ODonoghue y M. Rabin. El sesgo de proyección en la predicción de la utilidad futura. Informe técnico, Universidad Carnegie Mellon, Universidad Cornell y Universidad de California, Berkeley, 2003. [26] A. Odlyzko. Privacidad, economía y discriminación de precios en Internet. En la Quinta Conferencia Internacional de Comercio Electrónico, páginas 355-366. ACM, 2003. [27] T. O'Donoghue y M. Rabin. Elección y procrastinación. Revista Trimestral de Economía, 116:121-160, 2001. La página referenciada en el texto se refiere a la versión de trabajo de 2000. [28] R. A. Posner. Una teoría económica de la privacidad. Regulación, páginas 19-26, 1978. [29] R. A. Posner. La economía de la privacidad. American Economic Review, 71(2):405-409, 1981. [30] Privacy Rights Clearinghouse.
Revisión Económica Americana, 71(2):405-409, 1981. [30] Privacy Rights Clearinghouse. Sin salida: las víctimas hablan sobre el robo de identidad, 2000. http://www.privacyrights.org/ar/idtheft2000.htm. [31] M. Rabin y T. O'Donoghue. La economía de la gratificación inmediata. Revista de Toma de Decisiones Conductuales, 13:233-250, 2000. [32] A. Serjantov y G. Danezis. Hacia una métrica de teoría de la información para el anonimato. En P. Syverson y R. Dingledine, editores, Tecnologías de Mejora de la Privacidad - PET 02. Springer Verlag, LNCS 2482, 2002. [33] A. Shostack. 

Springer Verlag, LNCS 2482, 2002. [33] A. Shostack. Pagando por privacidad: Consumidores e infraestructuras. En el 2º Taller Anual sobre Economía y Seguridad de la Información - WEIS 03, 2003. [34] H. A. Simon. Modelos de racionalidad limitada. La editorial MIT Press, Cambridge, MA, 1982. 28 [35] P. Slovic. ¿Qué significa conocer un riesgo acumulativo? Percepciones de los adolescentes sobre las consecuencias a corto y largo plazo del tabaquismo. Revista de Toma de Decisiones Conductuales, 13:259-266, 2000. [36] S. Spiekermann, J. Grossklags y B. Berendt. Privacidad electrónica en el comercio electrónico de segunda generación: Preferencias de privacidad versus comportamiento real. En la 3ra Conferencia ACM sobre Comercio Electrónico - EC 01, páginas 38-47, 2002. [37] G. J. Stigler. Una introducción a la privacidad en economía y política. Revista de Estudios Legales, 9:623-644, 1980. [38] P. Syverson. El valor paradójico de la privacidad. En el 2º Taller Anual sobre Economía y Seguridad de la Información - WEIS 03, 2003. [39] C. R. Taylor. Demandas privadas y demandas de privacidad: Precios dinámicos y el mercado de información del cliente. Departamento de Economía, Universidad de Duke, Documento de Trabajo de Economía de Duke 02-02, 2002. [40] T. Vila, R. Greenstadt y D. Molnar. Por qué no nos molestamos en leer las políticas de privacidad: Modelos de economía de la privacidad como un mercado de limones. En el 2º Taller Anual sobre Economía y Seguridad de la Información WEIS 03, 2003. [41] S. Warren y L. Brandeis. El derecho a la privacidad. Revista de Derecho de Harvard, 4:193-220, 1890. [42] N. D. Weinstein. Prejuicios optimistas sobre los riesgos personales. Ciencia, 24:1232-1233, 1989. [43] A. Whitten y J. D. Tygar. Por qué Johnny no puede cifrar: Una evaluación de usabilidad de PGP 5.0. En el 8º Simposio de Seguridad USENIX, 1999. 29