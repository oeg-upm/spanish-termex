Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento. Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas. Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones. Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10. AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11. REFERENCIAS [1] J. Aslam y V. Pavlu. Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación de sistemas utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de prueba mínimas para evaluación de recuperación. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press. [5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. Umass en tdt 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. I'm sorry, but the sentence "Inf." is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Rev., 9(6):723-755, 2006. [8] F. Diaz. Normalizando las puntuaciones de recuperación ad-hoc. En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press. [9] F. Diaz y R. Jones. Utilizando perfiles temporales de consultas para predecir la precisión. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press. [10] D. A. Griffith. 

ACM Press. [10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. 

Springer Verlag, 2003. [11] B. Él y yo. Ounis. Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación. En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de agrupamiento jerárquico en la recuperación de información. Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press. [15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para metabusqueda. En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen y W.-Y. I'm sorry, but "Ma." is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish? Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Sobre la clasificación de la efectividad de las búsquedas. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press. [19] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press.