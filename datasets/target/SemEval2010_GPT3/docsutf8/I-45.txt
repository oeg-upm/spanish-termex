Implementando Interacciones Basadas en Compromisos∗ Michael Winikoff Escuela de Ciencias de la Computación e Informática Universidad RMIT Melbourne, Australia michael.winikoff@rmit.edu.au RESUMEN Aunque la interacción entre agentes juega un papel vital en los Sistemas Multiagente, y los enfoques centrados en mensajes para la interacción entre agentes tienen sus inconvenientes, los lenguajes de programación orientados a agentes actuales no proporcionan soporte para implementar una interacción entre agentes que sea flexible y robusta. En cambio, los mensajes se proporcionan como un bloque de construcción primitivo. En este artículo consideramos un enfoque para modelar las interacciones entre agentes: el marco de las máquinas de compromiso. Este marco de trabajo soporta la modelización de interacciones a un nivel más alto (utilizando compromisos sociales), lo que resulta en interacciones más flexibles. Investigamos cómo las interacciones basadas en compromisos pueden ser implementadas en lenguajes de programación orientados a agentes convencionales. Las contribuciones de este artículo son: un mapeo de una máquina de compromiso a una colección de planes de estilo BDI; extensiones a la semántica de los lenguajes de programación BDI; y un examen de dos problemas que surgen al distribuir máquinas de compromiso (gestión de turnos y condiciones de carrera) y soluciones a estos problemas. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial DistribuidaSistemas Multiagente; I.2.5 [Inteligencia Artificial]: Lenguajes de Programación y Software Términos Generales de Diseño 1. Los agentes son sociales, y la interacción entre agentes juega un papel vital en los sistemas multiagente. Por consiguiente, el diseño e implementación de la interacción de agentes es un tema de investigación importante. El enfoque estándar para diseñar interacciones de agentes es centrado en mensajes: las interacciones se definen mediante protocolos de interacción que establecen las secuencias permitidas de mensajes, especificadas utilizando notaciones como máquinas de estados finitos, redes de Petri o Agent UML. Se ha argumentado que este enfoque centrado en el mensaje para el diseño de interacción no es adecuado para agentes inteligentes. Los agentes inteligentes deben mostrar la capacidad de persistir en la consecución de sus objetivos ante el fracaso (robustez) al intentar diferentes enfoques (flexibilidad). Por otro lado, al seguir un protocolo de interacción, un agente tiene una flexibilidad y robustez limitadas: la capacidad de intentar persistentemente medios alternativos para lograr el objetivo de la interacción está limitada a las opciones que el diseñador del protocolo proporcionó, y en la práctica, los procesos de diseño centrados en mensajes no suelen conducir a protocolos que sean flexibles o robustos. Reconociendo estas limitaciones del enfoque tradicional para diseñar interacciones entre agentes, en los últimos años se han propuesto varios enfoques que se alejan de los protocolos de interacción centrados en mensajes, y en su lugar consideran el diseño de interacciones entre agentes utilizando conceptos de nivel superior como compromisos sociales [8, 10, 18] o metas de interacción [2]. También se ha trabajado en formas más ricas de interacción en entornos específicos, como equipos de agentes cooperativos [5, 11]. Sin embargo, aunque ha habido trabajo en el diseño de interacciones de agentes flexibles y robustas, prácticamente no ha habido trabajo en proporcionar soporte de lenguaje de programación para implementar tales interacciones. Los lenguajes de programación orientados a agentes actuales (AOPLs) no proporcionan soporte para implementar interacciones de agentes flexibles y robustas utilizando conceptos de nivel superior que los mensajes. De hecho, los modernos AOPLs [1], prácticamente sin excepciones, solo proporcionan el envío de mensajes simples como base para implementar la interacción entre agentes. Este documento presenta lo que, según nuestro conocimiento, es el segundo AOPL que respalda la implementación de interacción de agentes de alto nivel, flexible y robusta. El primer lenguaje de este tipo, STAPLE, fue propuesto hace unos años [9], pero no está descrito en detalle y es discutiblemente impráctico para su uso por no especialistas, debido a su base lógica y su fuerte dependencia de la lógica temporal y modal. Este documento presenta un esquema para extender los AOPLs tipo BDI para soportar la implementación directa de interacciones entre agentes que están diseñadas utilizando el marco de trabajo de la máquina de compromisos (CM) de Yolum & Singh [19]. En el resto de este documento revisamos brevemente las máquinas de compromiso y presentamos una abstracción simple de los AOPLs BDI que se encuentra en el subconjunto común de lenguajes como Jason, 3APL y CAN. Luego presentamos un esquema para traducir máquinas de compromiso a este lenguaje, e indicamos cómo el lenguaje debe ser ampliado para soportar esto. Luego extendemos nuestro esquema para abordar una serie de problemas relacionados con la distribución, incluido el seguimiento de turnos [7] y las condiciones de carrera. 2. ANTECEDENTES 2.1 Máquinas de Compromiso El objetivo del marco de las máquinas de compromiso es permitir la definición de interacciones que sean más flexibles que los enfoques tradicionales centrados en mensajes. Una Máquina de Compromiso (CM) [19] especifica una interacción entre entidades (por ejemplo, agentes, servicios, procesos) en términos de acciones que cambian el estado de la interacción. Este estado interactivo consiste en fluents (predicados que cambian de valor con el tiempo), pero también en compromisos sociales, tanto a nivel base como condicionales. Un compromiso social de nivel base es un compromiso del deudor A con el acreedor B para lograr la condición p, denotado como C(A, B, p). Esto a veces se abrevia como C(p), cuando no es importante especificar las identidades de las entidades en cuestión. Por ejemplo, un compromiso del cliente C con el comerciante M para hacer que el pago sea verdadero se escribiría como C(C, M, pagado). Un compromiso social condicional es un compromiso del deudor A con el acreedor B que, en caso de que la condición q se cumpla, A se comprometerá a cumplir la condición p. Esto se denota como CC(A, B, q, p) y, cuando la identidad de las entidades involucradas no es importante (o es obvia), se abrevia como CC(q, p) donde la flecha es un recordatorio del vínculo causal entre q haciéndose realidad y la creación de un compromiso para hacer que p sea verdadero. Por ejemplo, un compromiso de hacer efectivo el pago una vez que se hayan recibido los bienes se escribiría CC(pago de bienes). La semántica de los compromisos (tanto a nivel base como condicional) se define con reglas que especifican cómo cambian los compromisos con el tiempo. Por ejemplo, el compromiso C(p) (o CC(q p)) se cumple cuando p se vuelve verdadero; y el compromiso CC(q p) es reemplazado por C(p) cuando q se vuelve verdadero. En este artículo utilizamos la semántica más simétrica propuesta por [15] y posteriormente reformulada por [14]. En resumen, esta semántica trata con una serie de casos más complejos, como cuando se crean compromisos cuando las condiciones ya se cumplen: si p se cumple cuando se supone que se debe crear CC(p q), entonces en lugar de crear CC(p q) se crea C(q). Una interacción se define especificando las entidades involucradas, los posibles contenidos del estado de interacción (tanto fluents como compromisos), y (lo más importante) las acciones que cada entidad puede realizar junto con las condiciones previas y efectos de cada acción, especificados como listas de adición y eliminación. Una máquina de compromiso (CM) define un rango de posibles interacciones que comienzan en un estado1, y realizan acciones hasta alcanzar un estado final. Un estado final es aquel que no tiene compromisos a nivel base. Una forma de visualizar las interacciones que son posibles con una máquina de compromiso dada es generar la máquina de estados finitos correspondiente a la CM. Por ejemplo, la figura 1 muestra el FSM2 correspondiente a la máquina de compromiso NetBill [18]: un CM simple donde un cliente (C) y un comerciante (M) intentan comerciar utilizando las siguientes acciones: 1 A diferencia de los protocolos de interacción estándar, o máquinas de estados finitos, no hay un estado inicial designado para la interacción. 2 La máquina de estados finitos es generada por software: los nodos y conexiones fueron calculados por una implementación de los axiomas (disponible en http://www.winikoff.net/CM) y luego se dispusieron con graphviz (http://www.graphviz.org). 3 Utilizamos la notación A(X) : P ⇒ E para indicar que la acción A es realizada por la entidad X, tiene una condición previa P (con : P omitido si está vacío) y un efecto E. • sendRequest(C) ⇒ solicitud • sendQuote(M) ⇒ oferta donde oferta ≡ promesaMercancías ∧ promesaRecibo y promesaMercancías ≡ CC(M, C, aceptar, mercancías) y promesaRecibo ≡ CC(M, C, pagar, recibo) • sendAccept(C) ⇒ aceptar donde aceptar ≡ CC(C, M, mercancías, pagar) • sendGoods(M) ⇒ promesaRecibo ∧ mercancías donde promesaRecibo ≡ CC(M, C, pagar, recibo) • sendEPO(C) : mercancías ⇒ pagar • sendReceipt(M) : pagar ⇒ recibo. El compromiso de aceptación es la promesa del cliente de pagar una vez que se hayan enviado los bienes, la promesa de bienes es la promesa del comerciante de enviar los bienes una vez que el cliente acepte, y la promesa de recibo es la promesa del comerciante de enviar un recibo una vez que se haya realizado el pago. Como se ve en la figura 1, las máquinas de compromiso pueden soportar una variedad de secuencias de interacción. 2.2 Un lenguaje de programación de agentes abstracto en la tradición BDI (por ejemplo, dMARS, JAM, PRS, UM-PRS, JACK, AgentSpeak(L), Jason, 3APL, CAN, Jadex) define el comportamiento del agente en términos de planes desencadenados por eventos, donde cada plan especifica por qué se desencadena, en qué situaciones se considera aplicable (definido usando una condición de contexto) y un cuerpo del plan: una secuencia de pasos que pueden incluir la publicación de eventos que a su vez desencadenan más planes. Dado un conjunto de planes y un evento e que ha sido publicado, el agente primero recopila todos los tipos de planes que son activados por ese evento (los planes relevantes), luego evalúa las condiciones de contexto de estos planes para obtener un conjunto de instancias de planes aplicables. Uno de ellos es elegido y es ejecutado. Ahora definimos brevemente la sintaxis formal y la semántica de un Lenguaje de Programación de Agentes Abstractos Simples (BDI) (SAAPL). Este lenguaje está destinado a ser una abstracción que se encuentra en el subconjunto común de lenguajes como Jason [1, Capítulo 1], 3APL [1, Capítulo 2] y CAN [16]. Por lo tanto, está intencionalmente incompleto en algunas áreas, por ejemplo, no se compromete con un mecanismo particular para tratar el fracaso del plan, ya que diferentes mecanismos son utilizados por diferentes AOPLs. Un programa de agente (denotado por Π) consiste en una colección de cláusulas de plan de la forma e : C ← P donde e es un evento, C es una condición de contexto (una fórmula lógica sobre las creencias de los agentes) y P es el cuerpo del plan. El cuerpo del plan se construye a partir de los siguientes elementos. Tenemos el paso vacío que siempre tiene éxito y no hace nada, operaciones para agregar (+b) y eliminar (−b) creencias, enviar un mensaje m al agente N (↑N m), y publicar un evento4 (e). Estos pueden ser secuenciados (P; P). La semántica formal para este lenguaje se da en la figura 2. Esta semántica se basa en la semántica para AgentSpeak dada por [12], la cual a su vez se basa en la semántica para CAN [16]. La semántica es al estilo de la Semántica Operacional Estructural de Plotkin, y asume que existen operaciones que verifican si una condición 4 Utilizamos ↓N m como abreviatura para el evento correspondiente a recibir el mensaje m del agente N. 874 El Sexto Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 1: Máquina de Estados Finitos para NetBill (sombras = estados finales) sigue de un conjunto de creencias, que añade una creencia a un conjunto de creencias, y que elimina una creencia de un conjunto de creencias. En el caso de que las creencias sean un conjunto de átomos fundamentales, estas operaciones son respectivamente verificación de consecuencias (B |= C), y adición de conjunto (B ∪ {b}) y eliminación (B \ {b}). Se pueden utilizar métodos más sofisticados de gestión de creencias, pero no se consideran aquí. Definimos una configuración básica S = Q, N, B, P donde Q es una cola de mensajes (global) (modelada como una secuencia donde los mensajes se agregan en un extremo y se eliminan en el otro extremo), N es el nombre del agente, B son las creencias del agente y P es el cuerpo del plan que se está ejecutando (es decir, la intención). También definimos una configuración de agente, donde en lugar de un único cuerpo de plan P hay un conjunto de instancias de plan, Γ. Finalmente, un MAS completo es un par Q, As de una cola de mensajes global Q y un conjunto de configuraciones de agentes (sin la cola, Q). La cola de mensajes global es una secuencia de tríos de la forma remitente:destinatario:mensaje. Una transición S0 −→ S1 especifica que ejecutar S0 en un solo paso produce S1. Anotamos la flecha con una indicación de si la configuración en cuestión es básica, una configuración de agente o una configuración de MAS. La relación de transición se define utilizando reglas de la forma S −→ S o de la forma S −→ Sr S −→ Sr; estas últimas son condicionales, donde el numerador es la premisa y el denominador es la conclusión. Ten en cuenta que hay no determinismo en SAAPL, por ejemplo, la elección del plan a ejecutar de un conjunto de planes aplicables. Esto se resuelve utilizando funciones de selección: SO selecciona una de las instancias de plan aplicables para manejar un evento dado, SI selecciona cuál de las instancias de plan que pueden ejecutarse debe ejecutarse a continuación, y SA selecciona qué agente debe ejecutar (un paso) a continuación. 3. IMPLEMENTANDO INTERACCIONES BASADAS EN COMPROMISOS En esta sección presentamos un mapeo de una máquina de compromisos a una colección de programas SAAPL (uno para cada rol). Comenzamos considerando el caso simple de dos agentes interactuantes, y el operador + se utiliza para denotar la concatenación de secuencias. Supongamos que los agentes actúan por turnos. En la sección 4 relajamos estas suposiciones. Cada acción A(X) : P ⇒ E se asigna a una serie de planes: hay un plan (para el agente X) con condición de contexto P que realiza la acción (es decir, aplica los efectos E a las creencias del agente) y envía un mensaje al otro agente, y un plan (para el otro agente) que actualiza su estado cuando recibe un mensaje de X. Por ejemplo, dado la acción sendAccept(C) ⇒ accept tenemos los siguientes planes, donde cada plan está precedido por M: o C: para indicar a qué agente pertenece ese plan. Ten en cuenta que cuando la identidad del remitente (o destinatario) es obvia, es decir, el otro agente, abreviamos ↑N m a ↑m (o ↓N m a ↓m). El intercambio de turnos se captura a través del evento ı (abreviatura de interactuar): el agente que está activo tiene un evento ı que está siendo manejado. Manejar el evento implica enviar un mensaje al otro agente y luego no hacer nada hasta recibir una respuesta. C: ı : verdadero ← +aceptar; ↑enviarAceptar. M: ↓sendAccept : true ← +accept; ı.
M: ↓enviarAceptar : verdadero ← +aceptar; ı. Si la acción tiene una condición previa no trivial, entonces hay dos planes en el receptor: uno para realizar la acción (si es posible) y otro para informar un error si la condición previa de la acción no se cumple (volvemos a esto en la sección 4). Por ejemplo, la acción sendReceipt(M) : pay ⇒ receipt genera los siguientes planes: M: ı : pay ← +receipt; ↑sendReceipt. C: ↓enviarRecibo : pagar ← +recibo; ı. C: ↓enviarRecibo : ¬pagar ← . . . informar error . . . . Además de estos planes, también necesitamos planes para empezar y terminar la interacción. Una interacción puede completarse cuando no hay compromisos a nivel base, por lo que ambos agentes tienen los siguientes planes: ı : ¬∃p.C(p) ← ↑hecho. ↓hecho : ¬∃p.C(p) ← . ↓hecho : ∃p.C(p) ← . . . informar error . . . . Una interacción se inicia configurando las creencias iniciales de un agente y luego haciéndolo comenzar a interactuar. Exactamente cómo hacer esto depende de la plataforma del agente: por ejemplo, la plataforma del agente en cuestión puede ofrecer una forma sencilla de cargar creencias desde un archivo. Un enfoque genérico que es un poco engorroso, pero es portátil, es enviar a cada uno de los agentes involucrados en la interacción una secuencia de mensajes de inicio, cada uno El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 875 Q, N, B, +b Básico −→ Q, N, B ∪ {b}, Q, N, B, −b Básico −→ Q, N, B \ {b}, Δ = {Piθ|(ti : ci ← Pi) ∈ Π ∧ tiθ = e ∧ B |= ciθ} Q, N, B, e Básico −→ Q, N, B, SO(Δ) Q, N, B, P1 Básico −→ Q, N, B, P Q, N, B, P1; P2 Básico −→ Q, N, B, P; P2 Q, N, B, ; P Básico −→ Q, N, B, P Q, N, B, ↑NB m Básico −→ Q + N:NB:m, N, B, Q = NA:N:m + Q Q, N, B, Γ Agente −→ Q, N, B, Γ ∪ {↓NA m} P = SI(Γ) Q, N, B, P Básico −→ Q, N, B, P Q, N, B, Γ Agente −→ Q, N, B, (Γ \ {P}) ∪ {P} P = SI(Γ) P = Q, N, B, Γ Agente −→ Q, N, B, (Γ \ {P}) N, B, Γ = SA(As) Q, N, B, Γ Agente −→ Q, N, B, Γ Q, As MAS −→ Q, (As ∪ {N, B, Γ}) \ {N, B, Γ} Figura 2: Semántica Operacional para SAAPL que contiene una creencia a añadir; y luego enviar a uno de los agentes un mensaje de inicio que comienza la interacción. Ambos agentes tienen los siguientes dos planes: ↓init(B) : verdadero ← +B. ↓start : verdadero ← ı. La Figura 3 muestra los programas SAAPL tanto para el comerciante como para el cliente que implementan el protocolo NetBill. Por concisión, se omiten los planes de informe de errores. Ahora pasamos a refinar las condiciones del contexto. Hay tres refinamientos que consideramos. En primer lugar, debemos evitar realizar acciones que no tengan efecto en el estado de interacción. En segundo lugar, un agente puede querer especificar que ciertas acciones que puede realizar no deben llevarse a cabo a menos que se cumplan condiciones adicionales. Por ejemplo, el cliente puede no querer aceptar la oferta del comerciante a menos que los bienes tengan un precio o propiedad específicos. En tercer lugar, las condiciones de contexto de los planes que finalizan la interacción deben ser refinadas para evitar finalizar la interacción prematuramente. Para cada plan de la forma ı : P ← +E; ↑m, reemplazamos la condición de contexto P con la condición mejorada P ∧ P ∧ ¬E donde P son cualquier condiciones adicionales que el agente desee imponer, y ¬E es la negación de los efectos de la acción. Por ejemplo, el plan de pago de los clientes se convierte en (asumiendo que no hay condiciones adicionales, es decir, no P): ı : bienes ∧ ¬pagar ← +pagar; ↑enviarEPO. Para cada plan de la forma ↓m : P ← +E; ı podríamos agregar ¬E a la precondición, pero esto es redundante, ya que ya es verificado por el ejecutor de la acción, y si la acción no tiene efecto entonces los planes de los clientes: ı : true ← +solicitud; ↑enviarSolicitud. ı : true ← +aceptar; ↑enviarAceptación. ı : mercancías ← +pagar; ↑enviarEPO. ↓enviarCotización : true ← +prometerMercancías; +prometerRecibo; ı. ↓enviarMercancías : true ← +prometerRecibo; +mercancías; ı. ↓enviarRecibo : pagar ← +recibo; ı. Planes de los comerciantes: ı : true ← +promesaMercancías; +promesaRecibo; ↑enviarCotización. ı : true ← +promesaRecibo; +mercancías; ↑enviarMercancías. ı : pagar ← +recibo; ↑enviarRecibo. ↓enviarSolicitud : true ← +solicitud; ı. ↓enviarAceptación : true ← +aceptar; ı. ↓enviarEPO : mercancías ← +pagar; ı. Planes compartidos (es decir, planes de ambos agentes): ı : ¬∃p.C(p) ← ↑hecho. ↓hecho : ¬∃p.C(p) ← . ↓init(B) : verdadero ← +B. ↓inicio : verdadero ← ı. Donde aceptar ≡ CC(bienes pagados) promesaBienes ≡ CC(aceptar bienes) promesaRecibo ≡ CC(pagar recibo) oferta ≡ promesaBienes ∧ promesaRecibo Figura 3: Implementación de SAAPL de NetBill el remitente no lo llevará a cabo y enviará el mensaje (ver también la discusión en la sección 4). Al especificar condiciones adicionales (P), es necesario tener cuidado para evitar situaciones en las que no se pueda avanzar porque la única(s) acción(es) posible(s) está(n) impedida(s) por las condiciones adicionales. Una forma de indicar preferencia entre acciones (en muchas plataformas de agentes) es reorganizar los planes de los agentes. Esto es claramente seguro, ya que las acciones no se impiden, simplemente se consideran en un orden diferente. La tercera refinación de las condiciones de contexto se refiere a los planes que terminan la interacción. En el marco de la Máquina de Compromiso, cualquier estado que no tenga un compromiso a nivel base es final, en el sentido de que la interacción puede terminar allí (o puede continuar). Sin embargo, solo algunos de estos estados finales son estados finales deseables. Qué estados finales se consideran deseables depende del dominio y del resultado de interacción deseado. En el ejemplo de NetBill, el estado final deseable es aquel en el que los bienes han sido enviados y pagados, y se ha emitido un recibo (es decir, bienes ∧ pago ∧ recibo). Para evitar que un agente termine la interacción demasiado pronto, agregamos esto como una condición previa al plan de terminación: ı : bienes ∧ pago ∧ recibo ∧ ¬∃p.C(p) ← ↑hecho. La figura 4 muestra los planes que han sido modificados respecto a la figura 3. Para apoyar la realización de los CM, necesitamos cambiar SAAPL de varias maneras. Estos cambios, que se discuten a continuación, pueden aplicarse a los lenguajes BDI existentes para hacerlos compatibles con máquinas de compromiso. Presentamos los tres cambios, explicamos en qué consisten y, para cada cambio, explicamos cómo se implementó el cambio utilizando el lenguaje de programación orientado a agentes 3APL. Las tres modificaciones son: 1. extender las creencias del agente para que puedan contener compromisos; 876 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Planes de los clientes: ı : ¬solicitud ← +solicitud; ↑enviarSolicitud. ı : ¬aceptar ← +aceptar; ↑enviarAceptación. ı : mercancías ∧ ¬pagar ← +pagar; ↑enviarEPO. Planes de los comerciantes: ı : ¬ofrecer ← +promesaMercancías; +promesaRecibo; ↑enviarCotización. ı : ¬(promesaRecibo ∧ mercancías) ← +promesaRecibo; +mercancías; ↑enviarMercancías. ı : pagar ∧ ¬recibo ← +recibo; ↑enviarRecibo. Donde aceptar ≡ CC(bienes pagados) promesaBienes ≡ CC(aceptar bienes) promesaRecibo ≡ CC(pagar recibo) oferta ≡ promesaBienes ∧ promesaRecibo Figura 4: Implementación de SAAPL de NetBill con condiciones de contexto refinadas (solo planes cambiados) 2. cambiando la definición de |= para abarcar compromisos implícitos; y 3. cada vez que se agrega una creencia, actualizando compromisos existentes, de acuerdo con las reglas de dinámica de compromisos. Extender la noción de creencias para abarcar compromisos de hecho no requiere ningún cambio en las plataformas de agentes que son similares a Prolog y admiten términos como creencias (por ejemplo, ...). Jason, 3APL, CAN. Sin embargo, otras plataformas de agentes sí requieren una extensión. Por ejemplo, JACK, que es una extensión de Java, requeriría cambios para admitir compromisos que pueden estar anidados. En el caso de 3APL no se necesita ningún cambio para respaldar esto. Cuando una condición de contexto contiene compromisos, determinar si la condición de contexto está implícita en las creencias de los agentes (B |= C) requiere tener en cuenta la noción de compromisos implícitos [15]. En resumen, se puede considerar que un compromiso sigue de un conjunto de creencias B si el compromiso está en el conjunto de creencias (C ∈ B), pero también bajo otras condiciones. Por ejemplo, un compromiso de pago C(pay) puede considerarse implícito en un conjunto de creencias que contenga pay porque el compromiso pudo haberse mantenido y cumplido cuando pay se hizo verdadero. Se aplican reglas similares para compromisos condicionales. Estas reglas, que fueron introducidas en [15], fueron posteriormente reformuladas en una forma más simple por [14], lo que resultó en las cuatro reglas de inferencia en la parte inferior de la figura 5. La modificación que se necesita hacer en SAAPL para respaldar las implementaciones de máquinas de compromiso es extender la definición de |= para incluir estas cuatro reglas. Para 3APL esto se logró al hacer que cada agente incluyera las siguientes cláusulas de Prolog: holds(X) :- clause(X,true). holds(c(P)) :- holds(P). holds(c(P)) :- clause(cc(Q,P),true), holds(Q). holds(cc(_,Q)) :- holds(Q). holds(cc(_,Q)) :- holds(c(Q)). La primera cláusula simplemente dice que cualquier cosa es válida si está en las creencias de los agentes (la cláusula(X, verdadero) es verdadera si X es un hecho). Las cuatro cláusulas restantes corresponden respectivamente a las reglas de inferencia C1, C2, CC1 y CC2. Para utilizar estas reglas, modificamos las condiciones de contexto en nuestro programa para que en lugar de escribir, por ejemplo, cc(m,c, pagar, recibo), escribamos holds(cc(m,c, pagar, recibo)). La última modificación es actualizar los compromisos cuando se agrega una creencia. Formalmente, esto se hace modificando la regla semántica para la adición de creencias de manera que aplique un algoritmo para actualizar compromisos. La regla y algoritmo modificados (que reflejan la definición de norma en [14]) se pueden encontrar en la parte superior de la figura 5. Para 3APL, este cambio final se logró insertando manualmente update() después de actualizar creencias, y definiendo las siguientes reglas para update(): update() <- c(P) Y holds(P) | {Deletec(P) ; update()}, update() <- cc(P,Q) Y holds(Q) | {Deletecc(P,Q) ; update()}, update() <- cc(P,Q) Y holds(P) | {Deletecc(P,Q) ; Addc(Q) ; update()}, update() <- cc(P,Q) Y holds(c(Q)) | {Deletecc(P,Q) ; update()}, update() <- true | Skip donde Deletec y Deletecc eliminan respectivamente un compromiso de nivel base y un compromiso condicional, y Addc agrega un compromiso de nivel base. Un aspecto que no requiere un cambio es vincular compromisos y acciones. Esto se debe a que los compromisos no activan acciones directamente: pueden activar acciones de forma indirecta, pero en general su efecto es prevenir la finalización de una interacción mientras existan compromisos pendientes (a nivel base). La Figura 6 muestra las secuencias de mensajes de varias ejecuciones de una implementación de 3APL de la máquina de compromiso NetBill. Para ilustrar las diferentes interacciones posibles, el código fue modificado para que cada agente seleccionara aleatoriamente entre las acciones que podía realizar, y se realizaron una serie de ejecuciones con el cliente como iniciador, y luego con el comerciante como iniciador. Hay otras posibles secuencias de mensajes, no mostradas, 6 El código fuente está disponible en http://www.winikoff.net/CM La Sexta Conferencia Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 877 Figura 6: Ejecuciones de muestra de la implementación de 3APL (turnos alternados) incluyendo la obvia: solicitud, cotización, aceptación, bienes, pago, recibo y luego finalizado. Una pequeña diferencia entre la implementación de 3APL y SAAPL concierne a la semántica de los mensajes. En la semántica de SAAPL (y de la mayoría de los AOPLs), recibir un mensaje se trata como un evento. Sin embargo, en 3APL, recibir un mensaje se modela como la adición a las creencias de los agentes de un hecho que indica que el mensaje fue recibido [6]. Por lo tanto, en la implementación de 3APL tenemos reglas de PG que son activadas por estas creencias, en lugar de por cualquier evento. Un problema con este enfoque es que la creencia permanece allí, por lo que necesitamos asegurarnos de que la creencia en cuestión sea eliminada una vez resuelta, o que modifiquemos las precondiciones de los planes para evitar manejarla más de una vez. En nuestra implementación eliminamos estas creencias recibidas una vez que son procesadas, para evitar el manejo duplicado de mensajes. 4. MÁS ALLÁ DE DOS PARTICIPANTES Generalizar a más de dos participantes en la interacción requiere volver a examinar cómo se gestiona el turno, ya que ya no es posible asumir turnos alternados [7]. De hecho, quizás sorprendentemente, ¡incluso en el escenario de dos participantes, un sistema de turnos alternados es una suposición poco razonable! Por ejemplo, considera el camino (en la figura 1) desde el estado 1 al 15 (enviarMercancía) y luego al estado 12 (enviarAceptación). El resultado, en una configuración de turno alternado, es un callejón sin salida: solo hay una acción posible en el estado 12, que es enviar EPO, pero esta acción la realiza el cliente, ¡y es el turno del comerciante de actuar! La Figura 7 muestra el MEF para NetBill con iniciativa alternante. Una solución a este problema que funciona en este ejemplo, pero no se generaliza, es debilitar el régimen de toma de turnos alternados al permitir que un agente actúe dos veces seguidas si su segunda acción está motivada por un compromiso. Una solución general es llevar un registro de quién debe actuar en cada turno. Esto se puede lograr al determinar qué agentes tienen acciones que pueden ser realizadas en el estado actual. Si solo hay un agente activo, entonces está claro que los agentes deben actuar. Sin embargo, si más de un agente está activo, de alguna manera los agentes deben determinar quién debe actuar a continuación. Resolver esto mediante negociación no es una solución especialmente buena por dos razones. En primer lugar, esta negociación debe realizarse en cada paso de la interacción en la que más de un agente esté activo (en NetBill, esto se aplica a siete de dieciséis estados), por lo que es altamente deseable contar con un mecanismo ligero para hacerlo. En segundo lugar, no está claro cómo la negociación puede evitar una situación de regresión infinita (tú primero, no, tú primero, ...) sin imponer alguna regla arbitraria. También es posible resolver quién debe actuar imponiendo una regla arbitraria, por ejemplo, que el cliente siempre actúe en preferencia al comerciante, o que cada agente tenga una prioridad numérica (quizás determinada por el orden en el que se unieron a la interacción) que determine quién actúa. Una solución alternativa, que explota las propiedades simétricas de las máquinas de compromiso, es no intentar gestionar el turno. Consideremos las acciones A1(C) ⇒ p, A2(C) ⇒ q y A3(M) : p ∧ q ⇒ r. En lugar de rastrear y controlar de quién es el turno, simplemente permitimos que los agentes actúen libremente y confiamos en las propiedades del espacio de interacción para garantizar que las cosas funcionen, una noción que precisaremos y demostraremos en el resto de esta sección. El problema de tener múltiples agentes activos simultáneamente es que en lugar de que todos los agentes estén de acuerdo en el estado de interacción actual, los agentes pueden estar en estados diferentes. Esto se puede visualizar como cada agente teniendo su propia copia de la MEF por la que navega, donde es posible que los agentes sigan diferentes caminos a través de la MEF. Los dos problemas específicos que deben abordarse son: 1. ¿Pueden los agentes terminar en diferentes estados finales? 2. ¿Puede un agente encontrarse en una posición en la que se produce un error porque no puede realizar una acción correspondiente a un mensaje recibido? Mostraremos que, debido a que las acciones conmutan bajo ciertas suposiciones, los agentes no pueden terminar en diferentes estados finales, y además, que los errores no pueden ocurrir (de nuevo, bajo ciertas suposiciones). Por acciones conmutativas nos referimos al estado resultante de realizar una secuencia de acciones A1... "Un es lo mismo, independientemente del orden en que se realicen las acciones." Esto significa que incluso si los agentes siguen diferentes caminos a través del FSM, aún terminan en el mismo estado resultante, porque una vez que todos los mensajes han sido procesados, todos los agentes habrán realizado el mismo conjunto de acciones. Esto aborda el problema de terminar en diferentes estados finales. Regresamos a la posibilidad de que ocurran errores pronto. Definición 1 (Monotonía): Una acción es monótona si no elimina ningún fluente o compromiso. Una Máquina de Compromisos es aquella que elimina directamente, está bien liberar compromisos agregando fluents/compromisos. 878 La Sexta Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es monótona si todas sus acciones son monótonas. (Adaptado de [14, Definición 6]) Teorema 1: Si A1 y A2 son acciones monótonas, entonces realizar A1 seguido de A2 tiene el mismo efecto en las creencias de los agentes que realizar A2 seguido de A1. (Adaptado de [14, Teorema 2]). Esto asume que ambas acciones pueden ser realizadas. Sin embargo, es posible que el rendimiento de A1 impida que se realice A2. Por ejemplo, si A1 tiene el efecto +p, y A2 tiene la precondición ¬p, entonces aunque ambas acciones pueden estar habilitadas en el estado inicial, no pueden realizarse en ningún orden. Podemos prevenir esto asegurándonos de que las condiciones previas de las acciones no contengan negaciones (o implicaciones), ya que una acción monótona no puede hacer que una condición previa libre de negaciones se vuelva falsa. Ten en cuenta que esta restricción solo se aplica a la precondición de acción original, P, no a cualquier precondición adicional impuesta por el agente (P ). Esto se debe a que solo P se utiliza para determinar si otro agente es capaz de realizar la acción. Por lo tanto, los CMs monótonos con precondiciones que no contienen negaciones tienen acciones que conmutan. Sin embargo, de hecho, la restricción a los CM monótonos es innecesariamente fuerte: todo lo que se necesita es que cuando haya una elección de agente que pueda actuar, entonces las acciones posibles sean monótonas. Si solo hay un agente que puede actuar, entonces no se necesita ninguna restricción en las acciones: pueden ser o no monótonas. Definición 2 (Localmente Monótona): Una máquina de compromiso es localmente monótona si, para cualquier estado S, o bien (a) solo un agente tiene acciones que pueden realizarse; o (b) todas las acciones que pueden realizarse en S son monótonas. Teorema 2 En un CM localmente monótono, una vez que todos los mensajes hayan sido procesados, todos los agentes estarán en el mismo estado. Además, no pueden ocurrir errores. Prueba: Una vez que todos los mensajes hayan sido procesados, tendremos que todos los agentes habrán realizado el mismo conjunto de acciones, quizás en un orden diferente. La esencia de la prueba es argumentar que mientras los agentes no hayan convergido al mismo estado, todas las acciones deben ser monótonas, por lo tanto, estas acciones son conmutativas y no pueden deshabilitar ninguna otra acción. Considera el primer punto de divergencia, donde un agente realiza la acción A y al mismo tiempo otro agente (llamémoslo XB) realiza la acción B. Claramente, este estado tiene acciones de más de un agente habilitadas, por lo tanto, dado que el CM es localmente monótono, las acciones relevantes deben ser monótonas. Por lo tanto, después de realizar A, la acción B aún debe estar habilitada, y así el mensaje para hacer B puede ser procesado actualizando las creencias de los agentes receptores con los efectos de B. Además, dado que las acciones monótonas conmutan, el resultado de hacer A antes que B es el mismo que hacer B antes que A: S A −−−−−→ SA ? ? yB B ? ? y SB −−−−−→ A SAB Sin embargo, ¿qué sucede si la siguiente acción después de A no es B, sino C? Dado que B está habilitado, y C no es realizado por el agente XB (ver abajo), debemos tener que C también es monótono, y por lo tanto (a) el resultado de hacer A y B y C es el mismo independientemente del orden en que se realicen las tres acciones; y (b) C no deshabilita a B, por lo que B aún puede hacerse después de C. La razón por la que C no puede ser realizado por XB es que los mensajes se procesan en el orden de su llegada. Desde la perspectiva de XB, la acción B se realizó antes que C, y por lo tanto, desde la perspectiva de cualquier otro agente, el mensaje que indica que B se realizó debe ser recibido (y procesado) antes que un mensaje que indique que C se ha completado. Este argumento se puede extender para demostrar que una vez que los agentes comienzan a tomar diferentes caminos a través del FSM, todas las acciones tomadas hasta el punto en el que convergen en un solo estado deben ser monótonas, y por lo tanto siempre es posible converger (porque las acciones no están deshabilitadas), por lo que la interacción es libre de errores; y el estado resultante una vez que ocurre la convergencia es el mismo (porque las acciones monótonas conmutan). Este teorema proporciona una garantía teórica sólida de que no gestionar los turnos no conducirá a un desastre. Esto es análogo a demostrar que deshabilitar todos los semáforos no provocaría ningún accidente, y solo es posible porque los axiomas refinados de CM son simétricos. Basándose en este teorema, la transformación genérica de CM a código debería permitir a los agentes actuar libremente, lo cual se logra simplemente cambiando ı : P ∧ P ∧ ¬E ← +E; ↑A a ı : P ∧ P ∧ ¬E ← +E; ↑A; ı. Por ejemplo, en lugar de ı : ¬request ← +request; ↑sendRequest tenemos ı : ¬request ← +request; ↑sendRequest; ı. Una consecuencia del teorema es que no es necesario asegurarse de que los agentes procesen los mensajes antes de continuar interactuando. Sin embargo, para evitar un paralelismo innecesario, que puede dificultar la depuración, aún puede ser deseable procesar los mensajes antes de realizar acciones. La Figura 8 muestra una serie de ejecuciones de la implementación de 3APL que ha sido modificada para permitir interacción libre, no alternante. 5. DISCUSIÓN Hemos presentado un esquema para mapear máquinas de compromiso a plataformas BDI (utilizando SAAPL como ejemplo), identificado tres cambios que debían hacerse en SAAPL para respaldar la interacción basada en CM, y demostrado que la gestión de turnos puede evitarse en la interacción basada en CM, siempre que el CM sea localmente monótono. Las tres modificaciones a SAAPL y el esquema de traducción de máquina de compromiso a planes BDI son aplicables a cualquier lenguaje BDI. Como hemos mencionado en la sección 1, ha habido cierto trabajo en el diseño de interacciones de agentes flexibles y robustas, pero prácticamente no hay trabajo en la implementación de interacciones flexibles y robustas. Ya hemos discutido STAPLE [9, 10]. Otra pieza de trabajo relevante es el trabajo de Cheong y Winikoff sobre su metodología Hermes [2]. Aunque el enfoque principal de su trabajo es una metodología de diseño pragmática, también proporcionan pautas para implementar diseños de Hermes utilizando plataformas BDI (específicamente Jadex) [3]. Sin embargo, dado que Hermes no produce un diseño formal, solo es posible generar un código esquelético que luego debe completarse. Además, no abordan el problema de tomar turnos: cómo decidir qué agente actúa cuando más de un agente puede actuar. También asumimos que el medio de comunicación no entrega mensajes fuera de orden, como es el caso de (por ejemplo). TCP. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 879 Figura 8: Ejecuciones de muestra de la implementación de 3APL (turnos no alternantes). El trabajo de Kremer y Flores (por ejemplo, [8]) también utiliza compromisos y aborda la implementación. Sin embargo, ofrecen soporte de infraestructura (CASA) en lugar de un lenguaje de programación, y no parecen brindar asistencia a un programador que busque implementar agentes. Aunque hemos implementado la interacción de NetBill utilizando 3APL, los cambios en la semántica se realizaron modificando nuestro programa de NetBill 3APL, en lugar de modificar la implementación de 3APL en sí misma. Claramente, sería deseable modificar la semántica de 3APL (o de otro lenguaje) directamente, cambiando la implementación. Además, aunque no lo hayamos hecho, debería quedar claro que la traducción de un CM a su implementación podría automatizarse fácilmente. Otra área para futuros trabajos es examinar cómo se pueden relajar las suposiciones necesarias para garantizar que las acciones conmuten. Finalmente, es necesario realizar una evaluación empírica. Ya se ha realizado algo de trabajo comparando Hermes con un enfoque convencional centrado en mensajes para diseñar interacciones, y esto ha demostrado que el uso de Hermes resulta en diseños significativamente más flexibles y robustos [4]. Sería interesante comparar las máquinas de compromiso con Hermes, pero, dado que las máquinas de compromiso son un marco de trabajo, no una metodología de diseño, necesitamos comparar Hermes con una metodología para diseñar interacciones que resulte en máquinas de compromiso [13, 17]. 6. REFERENCIAS [1] R. H. Bordini, M. Dastani, J. Dix y A. E. F. Seghrouchni, editores. Programación multiagente: lenguajes, plataformas y aplicaciones. Springer, 2005. [2] C. Cheong y M. Winikoff. Hermes: Diseñando interacciones de agentes orientadas a objetivos. En Actas del 6º Taller Internacional de Ingeniería de Software Orientada a Agentes (AOSE-2005), julio de 2005. [3] C. Cheong y M. Winikoff. Hermes: Implementando interacciones de agentes orientadas a objetivos. En Actas del Tercer Taller Internacional sobre Programación de Sistemas Multiagente (ProMAS), julio de 2005. [4] C. Cheong y M. Winikoff. Hermes versus Prometeo: Una evaluación comparativa de dos enfoques de diseño de interacción de agentes. Presentado para su publicación, 2007. [5] P. R. Cohen y H. J. Levesque. Trabajo en equipo. Nosotros, 25(4):487-512, 1991. [6] M. Dastani, J. van der Ham y F. Dignum. Comunicación para agentes dirigidos por objetivos. En Actas del Taller de Lenguajes de Comunicación de Agentes y Políticas de Conversación, 2002. [7] F. P. Dignum y G. A. Vreeswijk. Hacia un banco de pruebas para diálogos de múltiples partes. En Avances en Comunicación de Agentes, páginas 212-230. Springer, LNCS 2922, 2004. [8] R. Kremer y R. Flores. Utilizando una retícula de subsumición performativa para apoyar conversaciones basadas en compromisos. En F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. P. Singh y M. Wooldridge, editores, Agentes Autónomos y Sistemas Multiagente (AAMAS), páginas 114-121. ACM Press, 2005. [9] S. Kumar y P. R. Cohen. STAPLE: Un lenguaje de programación de agentes basado en la teoría de la intención conjunta. En Actas de la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 2004), páginas 1390-1391. ACM Press, julio de 2004. [10] S. Kumar, M. J. Huber y P. R. Cohen. Representando y ejecutando protocolos como acciones conjuntas. En Actas de la Primera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 543 - 550, Bolonia, Italia, 15 - 19 de julio de 2002. ACM Press. [11] M. Tambe y W. Zhang. Hacia un trabajo en equipo flexible en equipos persistentes: Informe ampliado. Revista de Agentes Autónomos y Sistemas Multiagente, 2000. Número especial sobre lo mejor de ICMAS 98. [12] M. Winikoff. Un meta-intérprete de AgentSpeak y sus aplicaciones. En el Tercer Taller Internacional sobre Programación de Sistemas Multiagente (ProMAS), páginas 123-138. Springer, LNCS 3862 (post-proceedings, 2006), 2005. [13] M. Winikoff.
Springer, LNCS 3862 (actas posteriores, 2006), 2005. [13] M. Winikoff. Diseñando interacciones de agentes basadas en compromisos. En Actas de la Conferencia Internacional de Tecnología de Agentes Inteligentes (IAT-06) de IEEE/WIC/ACM de 2006. [14] M. Winikoff. Implementando interacciones de agentes flexibles y robustas utilizando máquinas de compromiso distribuidas. Sistemas Multiagente y de Red, 2(4), 2006. [15] M. Winikoff, W. Liu y J. Harland. Mejorando máquinas de compromiso. En J. Leite, A. Omicini, P. Torroni y P. Yolum, editores, Declarative Agent Languages and Technologies II, número 3476 en las Notas de Conferencias en Inteligencia Artificial (LNAI), páginas 198-220. Springer, 2004. [16] M. Winikoff, L. Padgham, J. Harland y J. Thangarajah. Objetivos declarativos y procedimentales en sistemas de agentes inteligentes. En Actas de la Octava Conferencia Internacional sobre Principios de Representación del Conocimiento y Razonamiento (KR2002), Toulouse, Francia, 2002. [17] P. Yolum. Hacia herramientas de diseño para el desarrollo de protocolos. En F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. P. Singh y M. Wooldridge, editores, Agentes Autónomos y Sistemas Multiagente (AAMAS), páginas 99-105. ACM Press, 2005. [18] P. Yolum y M. P. Singh. Especificación y ejecución flexible del protocolo: Aplicación de la planificación del cálculo de eventos utilizando compromisos. En Actas de la 1ª Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), páginas 527-534, 2002. [19] P. Yolum y M. P. Singh. Razonamiento sobre compromisos en el cálculo de eventos: Un enfoque para especificar y ejecutar protocolos. Anales de Matemáticas e Inteligencia Artificial (AMAI), 2004. 880 El Sexto Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07)