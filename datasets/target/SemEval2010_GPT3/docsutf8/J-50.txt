Determinamos la complejidad de comunicación de las reglas de votación comunes. Las reglas (ordenadas por su complejidad de comunicación de baja a alta) son pluralidad, pluralidad con segunda vuelta, voto único transferible (STV), Condorcet, aprobación, Bucklin, taza, maximin, Borda, Copeland y pares clasificados. Para cada regla, primero proporcionamos un protocolo de comunicación determinista y un límite superior en la cantidad de bits comunicados en él; luego, damos un límite inferior en los requisitos de comunicación (incluso los no deterministas) de la regla de votación. Los límites coinciden para todas las reglas de votación excepto STV y maximin. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Teoría 1. INTRODUCCIÓN Un factor clave en la viabilidad de cualquier regla de agregación de preferencias es su carga de comunicación. Para agregar con éxito las preferencias de los agentes, generalmente no es necesario que todos los agentes informen toda su información de preferencias. Los protocolos inteligentes que obtienen parcial y secuencialmente las preferencias de los agentes tienen el potencial de reducir drásticamente la comunicación requerida. Esto tiene al menos las siguientes ventajas: • Puede hacer factible la agregación de preferencias en entornos donde la cantidad total de información de preferencias es demasiado grande para comunicar. • Incluso cuando comunicar toda la información de preferencias es factible, reducir los requisitos de comunicación disminuye la carga impuesta a los agentes. Esto es especialmente cierto cuando los agentes, en lugar de conocer todas sus preferencias de antemano, necesitan invertir esfuerzo (como cálculos o recopilación de información) para determinar sus preferencias. • Preserva (parte de) la privacidad de los agentes. La mayor parte del trabajo sobre la reducción de la carga de comunicación en la agregación de preferencias se ha centrado en entornos de asignación de recursos como subastas combinatorias, en las que un subastador subasta un número de artículos (posiblemente distintos) en un solo evento. Debido a que en una subasta combinatoria, los postores pueden tener valoraciones separadas para cada uno de un número exponencial de posibles paquetes de artículos, este es un escenario en el que reducir la carga de comunicación es especialmente crucial. Esto se puede lograr complementando al subastador con un provocador que elicitara incrementalmente partes de las preferencias de los postores según sea necesario, basándose en lo que los postores han revelado sobre sus preferencias hasta el momento, como sugieren Conen y Sandholm [5]. Por ejemplo, el solicitante puede preguntar por el valor de un postor para un paquete específico (consultas de valor), cuál de dos paquetes prefiere el postor (consultas de orden), qué paquete clasifica en la posición k o cuál es la posición de un paquete dado (consultas de clasificación), qué paquete compraría dado un vector particular de precios (consultas de demanda), etc., hasta que se pueda determinar (al menos) la asignación final. Experimentalmente, esto produce a drástico ahorro en la revelación de preferencias [11]. Además, si las funciones de valoración de los agentes provienen de ciertas subclases naturales, el problema de la obtención de información puede resolverse utilizando solo un número polinomial de consultas incluso en el peor de los casos [23, 4, 13, 18, 14]. Para una revisión de la obtención de preferencias en subastas combinatorias, consulte [17]. Las subastas combinatorias ascendentes son una forma especial conocida de obtención de preferencias, donde el encuestador realiza consultas de demanda con precios crecientes [15, 21, 1, 9]. Finalmente, los problemas de asignación de recursos 78 también han sido estudiados desde el punto de vista de la complejidad de la comunicación, derivando así límites inferiores sobre la comunicación requerida. Por ejemplo, Nisan y Segal muestran que se requiere comunicación exponencial incluso para obtener un excedente mayor al obtenido al subastar todos los objetos como un único paquete [14]. Segal también estudia reglas de elección social en general, y muestra que para una gran clase de reglas de elección social, los conjuntos de presupuesto de apoyo deben ser revelados de tal manera que si cada agente prefiere el mismo resultado en su conjunto de presupuesto, esto demuestra la optimalidad de ese resultado. Segal luego utiliza esta caracterización para demostrar límites en la comunicación requerida en la asignación de recursos, así como en entornos de emparejamiento [20]. En este documento, nos enfocaremos en los requisitos de comunicación de una subclase generalmente aplicable de reglas de elección social, comúnmente conocidas como reglas de votación. En un entorno de votación, hay un conjunto de resultados de candidatos sobre los cuales los votantes expresan sus preferencias al enviar un voto (normalmente, una clasificación de los candidatos), y el ganador (es decir, el resultado elegido) se determina en función de estos votos. La comunicación requerida por las reglas de votación puede ser grande ya sea porque el número de votantes es grande (como, por ejemplo, en elecciones nacionales), o porque el número de candidatos es grande (por ejemplo, los agentes pueden votar sobre asignaciones de un número de recursos), o ambos. El trabajo previo [8] ha estudiado la obtención de información en votaciones, analizando qué tan difícil es computacionalmente decidir si se puede determinar un ganador con la información obtenida hasta el momento, así como qué tan difícil es encontrar la secuencia óptima de preguntas dadas sospechas perfectas sobre las preferencias de los votantes. Además, ese artículo discute cuestiones estratégicas (teóricas de juegos) introducidas por la obtención de información. Por el contrario, en este artículo nos preocupamos por el número máximo de bits que deben comunicarse para ejecutar una regla de votación dada, cuando no se conoce de antemano las preferencias de los votantes. Determinamos la complejidad de comunicación de las reglas de votación comunes. Para cada regla, primero damos una cota superior en la complejidad de comunicación (determinística) proporcionando un protocolo de comunicación para ella y analizando cuántos bits necesitan ser transmitidos en este protocolo. (Los resultados de Segal [20] no se aplican a la mayoría de las reglas de votación porque la mayoría de las reglas de votación no son intersección-monótonas (o incluso monótonas).) Para muchas de las reglas de votación bajo estudio, resulta que no se puede hacer mejor que simplemente permitir que cada votante comunique inmediatamente toda su información (potencialmente relevante). Sin embargo, para algunas reglas (como la pluralidad con segunda vuelta, STV y taza) existe un protocolo de comunicación multietapa directo que, con un análisis detallado, se puede demostrar que supera significativamente la comunicación inmediata de toda la información (potencialmente relevante). Finalmente, para algunas reglas (como las reglas de Condorcet y Bucklin), necesitamos introducir un protocolo de comunicación más complejo para lograr el mejor límite superior posible. Para dos de las reglas que estudiamos que son intersección-monótonas, a saber, las reglas de aprobación y Condorcet, los resultados de Segal de hecho pueden ser utilizados para dar pruebas alternativas de nuestros límites inferiores. Solo proporcionamos pruebas directas para estas reglas aquí porque 1) estas pruebas directas son de las más fáciles en este documento, 2) las pruebas alternativas son no triviales incluso dados los resultados de Segal, y 3) se aplica una restricción de espacio. Sin embargo, esperamos incluir también las pruebas alternativas en una versión posterior. Después de obtener los límites superiores, demostramos que son ajustados al proporcionar límites inferiores coincidentes en la complejidad de comunicación (incluso la no determinista) de cada regla de votación. Hay dos excepciones: STV, para el cual nuestros límites superiores e inferiores difieren en un factor log m; y maximin, para el cual nuestro mejor límite superior determinístico también es un factor log m por encima del límite inferior (no determinístico), aunque proporcionamos un límite superior no determinístico que coincide con el límite inferior. 2. REVISIÓN DE LAS REGLAS DE VOTACIÓN En esta sección, revisamos las reglas de votación comunes que estudiamos en este documento. Una regla de votación es una función que asigna un vector de votos de los n votantes (es decir, preferencias sobre candidatos) a uno de los m candidatos (el ganador) en el conjunto de candidatos C. En algunos casos (como la regla de Condorcet), la regla también puede declarar que no existe un ganador. No nos preocupamos por lo que sucede en caso de un empate entre candidatos (nuestros límites inferiores se mantienen independientemente de cómo se resuelvan los empates, y los protocolos de comunicación utilizados para nuestros límites superiores no intentan romper los empates). Todas las reglas que estudiamos son reglas basadas en el rango, lo que significa que un voto se define como un ordenamiento de los candidatos (con la excepción de la regla de la pluralidad, para la cual un voto es un único candidato, y la regla de aprobación, para la cual un voto es un subconjunto de los candidatos). Consideraremos las siguientes reglas de votación. (Para reglas que definen una puntuación, el candidato con la puntuación más alta gana.) • reglas de puntuación. Sea α = α1, . . . , αm un vector de enteros tal que α1 ≥ α2 . . . ≥ αm. Para cada votante, un candidato recibe α1 puntos si es clasificado en primer lugar por el votante, α2 si es clasificado en segundo lugar, etc. La puntuación sα de un candidato es el número total de puntos que recibe el candidato. La regla de Borda es la regla de puntuación con α = m−1, m−2, . . . , 0. La regla de la pluralidad es la regla de puntuación con α = 1, 0, . . . , 0. • voto único transferible (STV). La regla avanza a través de una serie de m - 1 rondas. En cada ronda, el candidato con la puntuación de pluralidad más baja (es decir, el menor número de votantes que lo clasifican en primer lugar entre los candidatos restantes) es eliminado (y cada uno de los votos para ese candidato se transfieren al siguiente candidato restante en el orden dado en ese voto). El ganador es el último candidato restante. • mayoría con segunda vuelta. En esta regla, una primera ronda elimina a todos los candidatos excepto a los dos con las puntuaciones de pluralidad más altas. Los votos se transfieren a estos como en la regla de VST, y una segunda ronda determina al ganador de estos dos. • aprobación. Cada votante etiqueta a cada candidato como aprobado o desaprobado. El candidato aprobado por el mayor número de votantes gana. • Condorcet. Para cualquier par de candidatos i y j, sea N(i, j) el número de votantes que prefieren a i sobre j. Si hay un candidato i que es preferido por la mayoría de los votantes a cualquier otro candidato (es decir, N(i, j) > N(j, i) para todo j = i, es decir, i gana en cada elección por pares), entonces el candidato i gana. El término protocolo de votación se usa a menudo para describir el mismo concepto, pero buscamos hacer una distinción clara entre la regla que mapea las preferencias a los resultados y el protocolo de comunicación/obtención utilizado para implementar esta regla. (Simpson). El puntaje maximin de i es s(i) = minj=i N(i, j), es decir, su peor desempeño en una elección por pares. El candidato con la puntuación maximin más alta gana. • Copeland. Para cualquier par de candidatos distintos i y j, sea C(i, j) = 1 si N(i, j) > N(j, i), C(i, j) = 1/2 si N(i, j) = N(j, i) y C(i, j) = 0 si N(i, j) < N(j, i). El puntaje de Copeland del candidato i es s(i) = j=i C(i, j). • taza (comparaciones binarias secuenciales). La regla de la copa se define por un árbol binario equilibrado T con un hoja por candidato, y una asignación de candidatos a hojas (cada hoja recibe un candidato). Cada nodo no hoja se le asigna el ganador de la elección por pares de los nodos hijos; el candidato asignado a la raíz gana. • Bucklin. Para cualquier candidato i y entero l, sea B(i, l) el número de votantes que clasifican al candidato i entre los l primeros candidatos. El ganador es arg mini(min{l : B(i, l) > n/2}). Es decir, si decimos que un votante aprueba a sus l candidatos principales, entonces aumentamos repetidamente l en 1 hasta que algún candidato sea aprobado por más de la mitad de los votantes, y este candidato es el ganador. • pares clasificados. Esta regla determina un orden en todos los candidatos, y el ganador es el candidato en la parte superior de este orden. Ordena todos los pares ordenados de candidatos (i, j) por N(i, j), el número de votantes que prefieren a i sobre j. Comenzando con el par (i, j) con el mayor N(i, j), aseguramos el resultado de su elección en pareja (i j). Luego, pasamos al siguiente par y bloqueamos el resultado de su elección por pares. Continuamos bloqueando cada resultado en pares que no contradiga el orden establecido hasta el momento. Enfatizamos que estas definiciones de reglas de votación no se preocupan por cómo se obtienen los votos de los votantes; todas las reglas de votación, incluidas aquellas que se definen sugestivamente en términos de rondas, son en realidad solo funciones que asignan el vector de todos los votos de los votantes a un ganador. Sin embargo, siempre hay muchas formas diferentes de obtener los votos (o las partes relevantes de estos) de los votantes. Por ejemplo, en la regla de la pluralidad con segunda vuelta, una forma de obtener los votos es pedir a cada votante que declare su orden completo de los candidatos de antemano. Alternativamente, podemos primero pedir a cada votante que declare solo su candidato más preferido; luego, sabremos los dos candidatos en la segunda vuelta, y podemos preguntar a cada votante cuál de estos dos candidatos prefiere. Por lo tanto, distinguimos entre la regla de votación (la asignación de vectores de votos a resultados) y el protocolo de comunicación (que determina cómo se obtienen realmente las partes relevantes de los votos de los votantes). El objetivo de este documento es proporcionar protocolos de comunicación eficientes para las reglas de votación recién definidas, y demostrar que no existen protocolos de comunicación más eficientes. Es interesante notar que la elección del protocolo de comunicación puede afectar el comportamiento estratégico de los votantes. Los protocolos de comunicación de múltiples etapas pueden revelar a los votantes cierta información sobre cómo están votando los demás votantes (por ejemplo, en el protocolo de comunicación de dos etapas recién dado para la pluralidad con segunda vuelta, en la segunda etapa los votantes sabrán qué dos candidatos tienen las puntuaciones de pluralidad más altas). En general, cuando los votantes reciben esa información, puede darles incentivos para votar de manera diferente a como lo harían en un protocolo de comunicación de una sola etapa en el que todos los votantes declaran sus votos completos simultáneamente. Por supuesto, incluso el protocolo de comunicación de una sola etapa no es a prueba de estrategias para ninguna regla de votación razonable, según el teorema de Gibbard-Satterthwaite [10, 19]. Sin embargo, esto no significa que no debamos preocuparnos por agregar aún más oportunidades para el voto estratégico. De hecho, muchos de los protocolos de comunicación introducidos en este documento sí presentan oportunidades adicionales para el voto estratégico, pero no tenemos espacio para discutirlo aquí. (En trabajos anteriores [8], sí proporcionamos un ejemplo donde un protocolo de obtención de información para la regla de votación por aprobación introduce el voto estratégico, y damos principios para diseñar protocolos de obtención de información que no introduzcan problemas estratégicos). Ahora que hemos revisado las reglas de votación, pasamos a una breve revisión de la teoría de la complejidad de la comunicación. 3. REVISIÓN DE ALGUNA TEORÍA DE LA COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, revisamos el modelo básico de un problema de comunicación y la técnica de límite inferior de construcción de un conjunto engañoso. (El modelo básico de un problema de comunicación se debe a Yao [22]; para obtener una visión general, consulte Kushilevitz y Nisan [12].) Cada jugador 1 ≤ i ≤ n conoce (solo) la entrada xi. Juntos, buscan calcular f(x1, x2, . . . , xn). En un protocolo determinista para calcular f, en cada etapa, uno de los jugadores anuncia (a todos los demás jugadores) un bit de información basado en su propia entrada y los bits anunciados hasta el momento. Finalmente, la comunicación termina y todos los jugadores conocen f(x1, x2, . . . , xn). El objetivo es minimizar el número de bits enviados en el peor caso (sobre todos los vectores de entrada). La complejidad de comunicación determinística de un problema es el número máximo de bits enviados en el peor caso en el mejor protocolo determinístico (correcto) para resolverlo. En un protocolo no determinista, el siguiente bit a enviar puede ser elegido de manera no determinista. Para los propósitos de este documento, consideraremos un protocolo no determinista como correcto si para cada vector de entrada, existe alguna secuencia de elecciones no deterministas que los jugadores pueden hacer para que los jugadores conozcan el valor de f cuando el protocolo termina. La complejidad de comunicación no determinista de un problema es el número máximo de bits enviados en el peor caso en el mejor protocolo no determinista (correcto) para él. Ahora estamos listos para dar la definición de un conjunto engañoso. Definición 1. Un conjunto engañoso es un conjunto de vectores de entrada {(x1 1, x1 2, . . . , x1 n), (x2 1, x2 2, . . . , x2 n), . . . , (xk 1 , xk 2 , . . . , xk n) tal que para cualquier i, f(xi 1, xi 2, . . . , xi n) = f0 para alguna constante f0, pero para cualquier i = j, existe algún vector (r1, r2, . . . , rn) ∈ {i, j}n tal que f(xr1 1 , xr2 2 , . . . , xrn n ) = f0. (Es decir, podemos mezclar las entradas de los dos vectores de entrada para obtener un vector con un valor de función diferente). Se sabe que si existe un conjunto engañoso de tamaño k, entonces log k es una cota inferior en la complejidad de la comunicación (incluso en la complejidad de la comunicación no determinista) [12]. Un protocolo a prueba de estrategias es aquel en el que es del mejor interés de los jugadores reportar sus preferencias de manera veraz. Para los propósitos de este documento, f es la regla de votación que asigna los votos al candidato ganador, y xi es el voto del votante (la información que la regla de votación requeriría del votante si no hubiera posibilidad de comunicación en múltiples etapas, es decir, el candidato más preferido (mayoría), los candidatos aprobados (aprobación), o la clasificación de todos los candidatos (todos los demás protocolos)). Sin embargo, cuando obtenemos nuestros límites inferiores, f solo significará si un candidato distinguido a gana. (Es decir, f es 1 si a gana, y 0 en caso contrario). Esto fortalecerá nuestros resultados de límite inferior (porque implica que incluso averiguar si un candidato dado gana es difícil). Por lo tanto, un conjunto engañoso en nuestro contexto es un conjunto de vectores de votos de manera que a gane (no gane) con cada uno de ellos; pero para cualquier par de vectores de votos diferentes en el conjunto, hay una forma de tomar los votos de algunos votantes del primer vector y los votos de los otros del segundo vector, de manera que a no gane (gane). Para simplificar las demostraciones de nuestros límites inferiores, hacemos suposiciones como que el número de votantes n es impar en muchas de estas demostraciones. Por lo tanto, técnicamente, no demostramos el límite inferior para los pares (número de candidatos, número de votantes) (m, n) que no cumplen con estas suposiciones (por ejemplo, si hacemos la suposición anterior, entonces técnicamente no demostramos el límite inferior para ningún par (m, n) en el que n sea par). Sin embargo, siempre demostramos el límite inferior para un conjunto representativo de pares (m, n). Por ejemplo, para cada uno de nuestros límites inferiores, sucede que para infinitos valores de m, hay infinitos valores de n tales que el límite inferior se demuestra para el par (m, n). RESULTADOS Estamos listos para presentar nuestros resultados. Para cada regla de votación, primero proporcionamos un protocolo de comunicación determinista para determinar al ganador y establecer un límite superior. Luego, damos un límite inferior en la complejidad de comunicación no determinista (incluso en la complejidad de decidir si un candidato dado gana, que es una pregunta más fácil). Los límites inferiores coinciden con los límites superiores en todos los casos excepto en dos: la regla STV (límite superior O(n(log m)2); límite inferior Ω(n log m)) y la regla maximin (límite superior O(nm log m), aunque proporcionamos un protocolo no determinista que es O(nm); límite inferior Ω(nm)). Cuando discutimos una regla de votación en la que los votantes clasifican a los candidatos, representaremos una clasificación en la que el candidato c1 está en primer lugar, c2 en segundo lugar, etc., como c1 c2 . . . cm. Una preocupación posible es que en el caso de que sean posibles los empates, puede requerir mucha comunicación verificar si un candidato específico a está entre los ganadores, pero poca comunicación para producir a uno de los ganadores. Sin embargo, todos los conjuntos de engaños que utilizamos en las demostraciones tienen la propiedad de que si a gana, entonces a es el único ganador. Por lo tanto, en estos conjuntos engañosos, si se conoce a alguno de los ganadores, entonces se sabe si a es un ganador. Por lo tanto, calcular uno de los ganadores requiere al menos tanta comunicación como verificar si a está entre los ganadores. En general, cuando un problema de comunicación permite múltiples respuestas correctas para un vector de entradas dado, esto se conoce como calcular una relación en lugar de una función [12]. Sin embargo, según lo anterior, podemos restringir nuestra atención a un subconjunto del dominio donde la regla de votación realmente es una función (de un solo valor), por lo que las técnicas de cota inferior para funciones en lugar de relaciones serán suficientes. A veces, para los propósitos de una demostración, el orden interno de un subconjunto de los candidatos no importa, y en este caso no lo especificaremos. Por ejemplo, si S = {c2, c3}, entonces c1 S c4 indica que se puede utilizar tanto la clasificación c1 c2 c3 c4 como la clasificación c1 c3 c2 c4 para la prueba. Primero damos un límite superior universal. Teorema 1. La complejidad de comunicación determinística de cualquier regla de votación basada en rangos es O(nm log m). Prueba. Este límite se logra simplemente haciendo que todos comuniquen su orden completo de los candidatos (indicar el rango de un candidato individual solo requiere O(log m) bits, por lo que cada uno de los n votantes puede simplemente indicar el rango de cada uno de los m candidatos). El siguiente lema será útil en algunas de nuestras demostraciones. Lema 1. Si m divide a n, entonces log(n!) - m log((n/m)!) ≥ n(log m - 1)/2. Prueba. Si n/m = 1 (es decir, n = m), entonces esta expresión se simplifica a log(n!). Tenemos log(n!) = n i=1 log i ≥ n x=1 log(i)dx, lo cual, utilizando integración por partes, es igual a n log n − (n − 1) > n(log n − 1) = n(log m − 1) > n(log m − 1)/2. Por lo tanto, podemos asumir que n/m ≥ 2. Observamos que log(n!) = n i=1 log i = n/m−1 i=0 m j=1 log(im+j) ≥ n/m−1 i=1 m j=1 log(im) = m n/m−1 i=1 log(im), y que m log((n/m)!) = m n/m i=1 log(i). Por lo tanto, log(n!) − m log((n/m)!) ≥ m n/m−1 i=1 log(im) − m n/m i=1 log(i) = m(( n/m−1 i=1 log(im/i))−log(n/m)) = m((n/m− 1) log m−log n+log m) = n log m−m log n. Ahora, usando el hecho de que n/m ≥ 2, tenemos m log n = n(m/n) log m(n/m) = n(m/n)(log m + log(n/m)) ≤ n(1/2)(log m + log 2). Por lo tanto, log(n!) − m log((n/m)!) ≥ n log m − m log n ≥ n log m − n(1/2)(log m + log 2) = n(log m − 1)/2. Teorema 2. La complejidad de comunicación determinística de la regla de la pluralidad es O(n log m). Prueba. Indicar a uno de los candidatos solo requiere O(log m) bits, por lo que cada votante puede simplemente indicar a su candidato más preferido. Teorema 3. La complejidad de comunicación no determinista de la regla de la pluralidad es Ω(n log m) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño n ! (( n m )! )m donde n = (n−1)/2. Tomar el logaritmo de esto da como resultado log(n ! )− m log((n /m)! ), por lo que el resultado se sigue del Lema 1. El conjunto de engaño estará formado por todos los vectores de votos que cumplan las siguientes restricciones: • Para cualquier 1 ≤ i ≤ n, los votantes 2i−1 y 2i votan lo mismo. • Cada candidato recibe la misma cantidad de votos de los primeros 2n = n − 1 votantes. • El último votante (votante n) vota por a. El candidato A gana con cada uno de estos vectores de votos debido al voto adicional por A del último votante. Dado que m divide a n, veamos cuántos vectores de voto hay en el conjunto engañoso. Necesitamos distribuir n pares de votantes de manera equitativa entre m candidatos, para un total de n /m pares de votantes por candidato; y hay precisamente n ! (( n m )! )m formas de hacer esto. Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto engañoso, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de manera que un candidato pierda. Sea i un número tal que los dos vectores de voto discrepan en el candidato por el cual votan los votantes 2i − 1 y 2i. Sin pérdida de generalidad, supongamos que en el primer vector de votos, estos votantes no votan por a (sino por algún otro candidato, b, en su lugar). Ahora, construye un nuevo vector de votos tomando los votos 2i − 1 y 2i del primer vector de votos, y los votos restantes del segundo vector de votos. Entonces, b recibe 2n /m + 2 votos en este vector de votación recién construido, mientras que a recibe como máximo 2n /m+1 votos. Por lo tanto, a no es el ganador en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 4. La complejidad de comunicación determinística de la regla de pluralidad con segunda vuelta es O(n log m). Prueba. Primero, permita que cada votante indique a su candidato más preferido usando log m bits. Después de esto, se conocen los dos candidatos en la segunda vuelta, y cada votante puede indicar cuál prefiere usando un solo bit adicional. Teorema 5. La complejidad de comunicación no determinista de la pluralidad con la regla de desempate es Ω(n log m) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño n ! (( n m )! )m donde m = m/2 y n = (n − 2)/4. Tomar el logaritmo de esto da como resultado log(n !) − m log((n /m )! ), por lo que el resultado se sigue del Lema 1. Divide a los candidatos en m pares: (c1, d1), (c2, d2), . . . , (cm , dm ) donde c1 = a y d1 = b. El conjunto de engaño estará formado por todos los vectores de votos que satisfacen las siguientes restricciones: • Para cualquier 1 ≤ i ≤ n, los votantes 4i − 3 y 4i − 2 clasifican a los candidatos ck(i) a C − {a, ck(i)}, para algún candidato ck(i). (Si ck(i) = a, entonces el voto es simplemente a C − {a}.) • Para cualquier 1 ≤ i ≤ n, los votantes 4i − 1 y 4i clasifican a los candidatos dk(i) a C − {a, dk(i)} (es decir, su candidato más preferido es el candidato que está emparejado con el candidato por el que votaron los dos votantes anteriores). Una prueba intuitiva de esto es la siguiente. Podemos contar el número de permutaciones de n elementos de la siguiente manera. Primero, divide los elementos en m cubetas de tamaño n / m, de modo que si x se coloca en una cubeta de índice inferior a y, entonces x se indexará más bajo en la permutación final. Luego, decide la permutación dentro de cada cubeta (para la cual hay (n / m)! opciones por cubeta). Se deduce que n! es igual al número de formas de dividir n elementos en m contenedores de tamaño n/m, multiplicado por ((n/m)!)^m. • Cada candidato está clasificado en la parte superior de igual cantidad de los primeros 4n = n − 2 votos. • El votante 4n + 1 = n−1 clasifica a los candidatos a C−{a}. • El votante 4n + 2 = n clasifica a los candidatos b C − {b}. El candidato a gana con cada uno de estos vectores de voto: debido a los dos últimos votos, los candidatos a y b están un voto por delante de todos los demás candidatos y avanzan a la segunda vuelta, y en este punto todos los votos que tenían a otro candidato clasificado en primer lugar se transfieren a a, de modo que a gana la segunda vuelta. Dado que m divide a n, veamos cuántos vectores de voto hay en el conjunto engañoso. Necesitamos distribuir n grupos de cuatro votantes de manera equitativa entre los m pares de candidatos, y (como en la demostración del Teorema 3) hay n ! (( n m )! )m formas de hacerlo. Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Sea i un número tal que ck(i) no sea el mismo en ambos de estos dos vectores de votos, es decir, c1 k(i) (ck(i) en el primer vector de votos) no es igual a c2 k(i) (ck(i) en el segundo vector de votos). Sin pérdida de generalidad, supongamos que c1 k(i) = a. Ahora, construye un nuevo vector de votos tomando los votos 4i − 3, 4i − 2, 4i − 1, 4i del primer vector de votos, y los votos restantes del segundo vector de votos. En este nuevo vector de voto construido, c1 k(i) y d1 k(i) reciben cada uno 4n /m+2 votos en la primera ronda, mientras que a recibe como máximo 4n /m+1 votos. Por lo tanto, a no continúa hasta la segunda vuelta en el nuevo vector de votación construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 6. La complejidad de comunicación no determinista de la regla de Borda es Ω(nm log m) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño (m ! )n donde m = m−2 y n = (n−2)/4. Esto demostrará el teorema porque m ! es Ω(m log m), por lo que log((m ! )n ) = n log(m !) es Ω(nm log m). Para cada vector (π1, π2, . . . , πn) que consiste en n ordenamientos de todos los candidatos excepto a y otro candidato fijo b (técnicamente, los ordenamientos toman la forma de una función biunívoca πi: {1, 2, . . . , m} → C − {a, b} con πi(j) = c indicando que el candidato c es el j-ésimo en el orden representado por πi), deja que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, deja que los votantes 4i − 3 y 4i − 2 clasifiquen a los candidatos a b πi(1) πi(2) . . . πi(m). • Para 1 ≤ i ≤ n, deja que los votantes 4i − 1 y 4i clasifiquen a los candidatos πi(m) πi(m − 1) . . . πi(1) b a. • Deja que el votante 4n + 1 = n − 1 clasifique a los candidatos a b π0(1) π0(2) . . . π0(m) (donde π0 es un orden arbitrario de los candidatos excepto a y b que es el mismo para cada elemento del conjunto engañoso). • Deja que el votante 4n + 2 = n clasifique a los candidatos π0(m) π0(m − 1) . . . π0(1) a b. Observamos que este conjunto engañoso tiene un tamaño de (m!)n, y que el candidato a gana en cada vector de votos en el conjunto engañoso (para ver por qué, observamos que para cualquier 1 ≤ i ≤ n, los votos 4i-3 y 4i-2 clasifican a los candidatos de manera exactamente opuesta a los votos 4i-1 y 4i, lo que bajo la regla de Borda significa que se cancelan entre sí; y los dos últimos votos dan un punto más a a que a cualquier otro candidato, además de b que recibe dos puntos menos que a). Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector (π1 1, π1 2, . . . , π1 n), y que el segundo vector de votos corresponda al vector (π2 1, π2 2, . . . , π2 n). Para algunos i, debemos tener π1 i = π2 i, de modo que para algún candidato c /∈ {a, b}, (π1 i )−1 (c) < (π2 i )−1 (c) (es decir, c está clasificado más alto en π1 i que en π2 i). Ahora, construye un nuevo vector de votos tomando los votos 4i−3 y 4i−2 del primer vector de votos, y los votos restantes del segundo vector de votos, ya que la puntuación de Borda permanece sin cambios. Sin embargo, debido a que c está clasificado más alto en π1 i que en π2 i , c recibe al menos 2 puntos más de los votos 4i−3 y 4i − 2 en el vector de votos recién construido que en el segundo vector de votos. Se deduce que c tiene una puntuación de Borda más alta que a en el vector de voto recién construido. Por lo tanto, a no es el ganador en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 7. La complejidad de comunicación no determinista de la regla de Copeland es Ω(nm log m) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño (m ! )n donde m = (m − 2)/2 y n = (n − 2)/2. Esto demostrará el teorema porque m ! es Ω(m log m), por lo que log((m ! )n ) = n log(m !) es Ω(nm log m). Escribimos el conjunto de candidatos como la siguiente unión disjunta: C = {a, b} ∪ L ∪ R donde L = {l1, l2, . . . , lm } y R = {r1, r2, . . . , rm }. Para cada vector (π1, π2, . . . , πn) que consiste en n permutaciones de los enteros del 1 al m (πi: {1, 2, . . . , m} → {1, 2, . . . , m}), deja que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, deja que el votante 2i − 1 clasifique a los candidatos a b lπi(1) rπi(1) lπi(2) rπi(2) . . . lπi(m) rπi(m). • Para 1 ≤ i ≤ n, deja que el votante 2i clasifique a los candidatos rπi(m) lπi(m) rπi(m −1) lπi(m −1) . . . rπi(1) lπi(1) b a. • Deja que el votante n − 1 = 2n + 1 clasifique a los candidatos a b l1 r1 l2 r2 . . . lm rm. • Deja que el votante n = 2n + 2 clasifique a los candidatos rm lm rm −1 lm −1 . . . r1 l1 a b. Observamos que este conjunto engañoso tiene tamaño (m ! )n, y que el candidato a gana en cada vector de votos en el conjunto engañoso (cada par de candidatos está empatado en su elección por pares, con la excepción de que a vence a b, de modo que a gana la elección por medio punto). Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector (π1 1, π1 2, . . . , π1 n), y que el segundo vector de votos corresponda al vector (π2 1, π2 2, . . . , π2 n). Para algunos i, debemos tener π1 i = π2 i, de modo que para algún j ∈ {1, 2, . . . , m}, tengamos (π1 i)−1 (j) < (π2 i)−1 (j). Ahora, construye un nuevo vector de votos tomando el voto 2i−1 del primer vector de votos, y los votos restantes del segundo vector de votos, ya que la puntuación de Copeland permanece sin cambios. Consideremos la puntuación de lj. Primero observamos que el rango de lj en el voto 2i − 1 en el vector de voto recién construido es al menos 2 más alto que en el segundo vector de voto, porque (π1 i )−1 (j) < (π2 i )−1 (j). Que D1 (lj) sea el conjunto de candidatos en L ∪ R que el votante 2i − 1 clasificó por debajo de lj en el primer vector de votos (D1 (lj) = {c ∈ L ∪ R : lj 1 2i−1 c}), y que D2 (lj) sea el conjunto de candidatos en L ∪ R que el votante 2i − 1 clasificó por debajo de lj en el segundo vector de votos (D2 (lj) = {c ∈ L ∪ R : lj 2 2i−1 c}). Entonces, se deduce que en el vector de voto recién construido, lj vence a todos los candidatos en D1 (lj) - D2 (lj) en sus elecciones de a pares (porque lj recibe un voto adicional en cada una de estas elecciones de a pares en comparación con el segundo vector de voto), y pierde contra todos los candidatos en D2 (lj) - D1 (lj) (porque lj pierde un voto en cada una de estas elecciones de a pares en comparación con el segundo vector de voto), y empata con todos los demás. Pero |D1 (lj)| − |D2 (lj)| ≥ 2, y por lo tanto |D1 (lj) − D2 (lj)| − |D2 (lj) − D1 (lj)| ≥ 2. Por lo tanto, en el vector de votos recién construido, lj tiene al menos dos victorias más en parejas que derrotas en parejas, y por lo tanto tiene al menos 1 punto más que si lj hubiera empatado todas sus elecciones en pareja. Por lo tanto, lj tiene una puntuación de Copeland más alta que a en el nuevo vector de voto construido. Por lo tanto, a no es el ganador en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 8. La complejidad de comunicación no determinística de la regla maximin es O(nm). Prueba. El protocolo no determinista adivinará cuál candidato w es el ganador, y, para cada otro candidato c, cuál es el candidato o(c) contra el cual c recibe su puntuación más baja en una elección por pares. Entonces, que cada votante comunique lo siguiente: • para cada candidato c = w, si prefiere a c sobre w; • para cada candidato c = w, si prefiere a c sobre o(c). Observamos que esto requiere la comunicación de 2n(m− 1) bits. Si las suposiciones fueran correctas, entonces, dejando que N(d, e) sea el número de votantes que prefieren al candidato d sobre el candidato e, deberíamos tener N(c, o(c)) < N(w, c) para cualquier c = w, c = w, lo cual demostrará que w gana la elección. Teorema 9. La complejidad de comunicación no determinista de la regla maximin es Ω(nm) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño 2n m donde m = m − 2 y n = (n − 1)/4. Que b sea un candidato distinto de a. Para cada vector (S1, S2, . . . , Sn) que consiste en n subconjuntos Si ⊆ C − {a, b}, deja que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, deja que los votantes 4i − 3 y 4i − 2 clasifiquen a los candidatos Si a C − (Si ∪ {a, b}) b. • Para 1 ≤ i ≤ n, deja que los votantes 4i − 1 y 4i clasifiquen a los candidatos b C − (Si ∪ {a, b}) a Si. • Deja que el votante 4n + 1 = n clasifique a los candidatos a b C − {a, b}. Observamos que este conjunto engañoso tiene un tamaño de (2m )n = 2n m, y que el candidato a gana en cada vector de votos en el conjunto engañoso (en cada una de las elecciones por pares, a es clasificado más alto que su oponente por 2n +1 = (n+1)/2 > n/2 votos). Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector (S1 1 , S1 2 , . . . , S1 n ), y que el segundo vector de votos corresponda al vector (S2 1 , S2 2 , . . . , S2 n ). Para algunos i, debemos tener S1 i = S2 i, de modo que ya sea S1 i S2 i o S2 i S1 i. Sin pérdida de generalidad, supongamos que S1 i S2 i , y sea c algún candidato en S1 i − S2 i. Ahora, construye un nuevo vector de votos tomando los votos 4i − 3 y 4i − 2 del primer vector de votos, y los votos restantes del segundo vector de votos. En este nuevo vector de votación construido, a es clasificado más alto que c por solo 2n - 1 votantes, por la siguiente razón. Mientras que los votantes 4i−3 y 4i − 2 no clasifican a c por encima de a en el segundo vector de votos (porque c /∈ S2 i ), los votantes 4i − 3 y 4i − 2 sí clasifican a c por encima de a en el primer vector de votos (porque c ∈ S1 i ). Además, en cada una de las elecciones por pares de b, b es clasificado más alto que su oponente por al menos 2n votantes. Entonces, a tiene una puntuación maximin más baja que b, por lo tanto a no es el ganador en el vector de voto recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 10. La complejidad de comunicación determinística de la regla STV es O(n(log m)2). Prueba. Considera el siguiente protocolo de comunicación. Que cada votante primero anuncie a su candidato más preferido (comunicación O(n log m)). En las rondas restantes, haremos un seguimiento del candidato más preferido de cada votante entre los candidatos restantes, lo cual será suficiente para implementar la regla. Cuando se elimina al candidato c, permita que cada uno de los votantes cuyo candidato más preferido entre los candidatos restantes era c anuncie su candidato más preferido entre los candidatos restantes después de la eliminación de c. Si el candidato c fue el candidato i-ésimo en ser eliminado (es decir, quedaban m − i + 1 candidatos antes de la eliminación de c), se sigue que como máximo n/(m − i + 1) votantes tenían al candidato c como su candidato más preferido entre los candidatos restantes, y por lo tanto, el número de bits a comunicar después de la eliminación del candidato i es O((n/(m−i+1)) log m). Así, la comunicación total en este protocolo de comunicación es O(n log m + m−1 i=1 (n/(m − i + 1)) log m). Por supuesto, m−1 i=1 1/(m − i + 1) = m i=2 1/i, lo cual es O(log m). Sustituyendo en la expresión anterior, encontramos que la complejidad de comunicación es O(n(log m)2). Teorema 11. La complejidad de comunicación no determinística de la regla STV es Ω(n log m) (incluso para decidir si un candidato dado a gana). Prueba. Omitimos esta prueba debido a la restricción de espacio. De hecho, O((n/(m − i + 1)) log(m − i + 1)) también es correcto, pero no mejorará el límite. Teorema 12. La complejidad de comunicación determinística de la regla de aprobación es O(nm). Prueba. Aprobar o desaprobar a un candidato solo requiere un bit de información, por lo que cada votante puede simplemente aprobar o desaprobar a cada candidato para una comunicación total de nm bits. Teorema 13. La complejidad de comunicación no determinista de la regla de aprobación es Ω(nm) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño 2n m donde m = m − 1 y n = (n − 1)/4. Para cada vector (S1, S2, . . . , Sn) que consiste en n subconjuntos Si ⊆ C - {a}, deja que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, deja que los votantes 4i - 3 y 4i - 2 aprueben Si ∪ {a}. • Para 1 ≤ i ≤ n, deja que los votantes 4i - 1 y 4i aprueben C - (Si ∪ {a}). • Deja que el votante 4n + 1 = n apruebe {a}. Observamos que este conjunto engañoso tiene un tamaño de (2m )n = 2n m, y que el candidato a gana en cada vector de votos en el conjunto engañoso (a es aprobado por 2n + 1 votantes, mientras que cada otro candidato es aprobado solo por 2n votantes). Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector (S1 1 , S1 2 , . . . , S1 n ), y que el segundo vector de votos corresponda al vector (S2 1 , S2 2 , . . . , S2 n ). Para algunos i, debemos tener S1 i = S2 i, de modo que ya sea S1 i S2 i o S2 i S1 i. Sin pérdida de generalidad, supongamos que S1 i S2 i , y sea b algún candidato en S1 i − S2 i. Ahora, construye un nuevo vector de votos tomando los votos 4i − 3 y 4i − 2 del primer vector de votos, y los votos restantes del segundo vector de votos. En este nuevo vector de votación construido, a sigue siendo aprobado por 2n + 1 votos. Sin embargo, b es aprobado por 2n + 2 votos, por la siguiente razón. Mientras que los votantes 4i−3 y 4i−2 no aprueban b en el segundo vector de votación (porque b /∈ S2 i), los votantes 4i−3 y 4i−2 sí aprueban b en el primer vector de votación (porque b ∈ S1 i). Se deduce que la puntuación bs en el vector de voto recién construido es la puntuación bs en el segundo vector de voto (2n), más dos. Por lo tanto, a no es el ganador en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Curiosamente, se puede obtener un límite inferior de Ω(m) incluso para el problema de encontrar un candidato que sea aprobado por más de un votante [20]. Teorema 14. La complejidad de comunicación determinística de la regla de Condorcet es O(nm). Prueba. Mantenemos un conjunto de candidatos activos S que se inicializa en C. En cada etapa, elegimos dos de los candidatos activos (digamos, los dos candidatos con los índices más bajos), y permitimos que cada votante comunique cuál de los dos candidatos prefiere. (Tal etapa requiere la comunicación de n bits, uno por votante). El candidato preferido por menos de 84 votantes (el perdedor de la elección por pares) es eliminado de S. (Si la elección por pares está empatada, ambos candidatos son eliminados). Después de un máximo de m - 1 iteraciones, solo queda un candidato (o no queda ningún candidato, en cuyo caso no hay un ganador de Condorcet). Que a sea el candidato restante. Para averiguar si el candidato a es el ganador de Condorcet, permita que cada votante comunique, para cada candidato c = a, si prefiere a a c. (Esto requiere la comunicación de como máximo n(m − 1) bits). Esto es suficiente para determinar si a ganó cada una de sus elecciones por pares (y por lo tanto, si a es el ganador de Condorcet). Teorema 15. La complejidad de comunicación no determinística de la regla de Condorcet es Ω(nm) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño 2n m donde m = m − 1 y n = (n − 1)/2. Para cada vector (S1, S2, . . . , Sn) que consiste en n subconjuntos Si ⊆ C − {a}, deja que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, deja que el votante 2i − 1 clasifique a los candidatos Si a C − Si. • Para 1 ≤ i ≤ n, deja que el votante 2i clasifique a los candidatos C − Si a Si. • Deja que el votante 2n + 1 = n clasifique a los candidatos a C − {a}. Observamos que este conjunto engañoso tiene tamaño (2m )n = 2n m , y que el candidato a gana en cada vector de votos en el conjunto engañoso (a gana cada una de sus elecciones por parejas por un solo voto). Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector (S1 1 , S1 2 , . . . , S1 n ), y que el segundo vector de votos corresponda al vector (S2 1 , S2 2 , . . . , S2 n ). Para algunos i, debemos tener S1 i = S2 i, de modo que ya sea S1 i S2 i o S2 i S1 i. Sin pérdida de generalidad, supongamos que S1 i S2 i , y sea b algún candidato en S1 i − S2 i. Ahora, construye un nuevo vector de votos tomando el voto 2i − 1 del primer vector de votos y los votos restantes del segundo vector de votos. En este nuevo vector de votos construido, b gana su elección por pares contra a por un voto (el voto 2i − 1 coloca a b por encima de a en el nuevo vector de votos construido porque b ∈ S1 i, mientras que en el segundo vector de votos el voto 2i − 1 colocó a a por encima de b porque b /∈ S2 i). Por lo tanto, a no es el ganador de Condorcet en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 16. La complejidad de comunicación determinística de la regla de la taza es O(nm). Prueba. Considera el siguiente protocolo de comunicación simple. Primero, permitamos que todos los votantes se comuniquen, para cada uno de los enfrentamientos en la primera ronda, cuál de los dos candidatos prefieren. Después de esto, se conocen los emparejamientos para la segunda ronda, así que permitan que todos los votantes comuniquen qué candidato prefieren en cada emparejamiento en la segunda ronda, etc. Dado que comunicar cuál de los dos candidatos es preferido solo requiere un bit por votante, y dado que solo hay m − 1 enfrentamientos en total, este protocolo de comunicación requiere O(nm) comunicación. Teorema 17. La complejidad de comunicación no determinista de la regla de la copa es Ω(nm) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto engañoso de tamaño 2n m donde m = (m − 1)/2 y n = (n − 7)/2. Dado que m + 1 es una potencia de 2, de modo que un candidato recibe un pase (es decir, no se enfrenta a un oponente) en la primera ronda, sea a el candidato con el pase. De los emparejamientos de la primera ronda, dejemos que lj denote al candidato de la izquierda en el j-ésimo enfrentamiento, y dejemos que rj sea el otro candidato de la derecha. Sea L = {lj : 1 ≤ j ≤ m} y R = {rj : 1 ≤ j ≤ m}, de modo que C = L ∪ R ∪ {a}. . . . . . . . . . l r l r l r a m1 1 2 2 m Figura 1: El horario para la regla de la copa utilizada en la demostración del Teorema 17. Para cada vector (S1, S2, . . . , Sn) que consiste en n subconjuntos Si ⊆ R, dejemos que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, dejemos que el votante 2i − 1 clasifique a los candidatos Si L a R − Si. • Para 1 ≤ i ≤ n, dejemos que el votante 2i clasifique a los candidatos R − Si L a Si. • Dejemos que los votantes 2n +1 = n−6, 2n +2 = n−5, 2n +3 = n−4 clasifiquen a los candidatos L a R. • Dejemos que los votantes 2n + 4 = n − 3, 2n + 5 = n − 2 clasifiquen a los candidatos a r1 l1 r2 l2 . . . rm lm. • Dejemos que los votantes 2n + 6 = n − 1, 2n + 7 = n clasifiquen a los candidatos rm lm rm −1 lm −1 . . . r1 l1 a. Observamos que este conjunto de engaño tiene tamaño (2m )n = 2n m. Además, el candidato a gana en cada vector de votos en el conjunto engañoso, por las siguientes razones. Cada candidato rj derrota a su oponente lj en la primera ronda. (Para cualquier 1 ≤ i ≤ n, el efecto neto de los votos 2i − 1 y 2i en la elección entre rj y lj es cero; los votos n − 6, n − 5, n − 4 prefieren a lj sobre rj, pero los votos n − 3, n − 2, n − 1, n prefieren a rj sobre lj). Además, a vence a cada rj en su elección por pares. (Para cualquier 1 ≤ i ≤ n, el efecto neto de los votos 2i − 1 y 2i en la elección por pares entre a y rj es cero; los votos n − 1, n prefieren a rj sobre a, pero los votos n − 6, n − 5, n − 4, n − 3, n − 2 todos prefieren a a rj.) Se deduce que una vencerá a todos los candidatos a los que se enfrente. Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector 85 (S1 1 , S1 2 , . . . , S1 n ), y que el segundo vector de votos corresponda al vector (S2 1 , S2 2 , . . . , S2 n ). Para algunos i, debemos tener S1 i = S2 i, de modo que sea S1 i S2 i o S2 i S1 i. Sin pérdida de generalidad, supongamos que S1 i S2 i , y dejemos que rj sea algún candidato en S1 i − S2 i. Ahora, construye un nuevo vector de votos tomando el voto 2i del primer vector de votos y los votos restantes del segundo vector de votos. Observamos que, mientras que en el segundo vector de votos el voto 2i prefirió a rj sobre lj (porque rj ∈ R−S2 i), en el nuevo vector de votos construido esto ya no es el caso (porque rj ∈ S1 i). Se deduce que, mientras que en el segundo vector de votos, rj venció a lj en la primera ronda por un voto, en el nuevo vector de votos construido, lj vence a rj en la primera ronda. Por lo tanto, al menos un lj avanza a la segunda ronda después de derrotar a su oponente rj. Ahora observamos que en el vector de votos recién construido, cualquier lk gana su elección de a pares contra cualquier rq con q = k. Esto se debe a que entre los primeros 2n votos, al menos n − 1 prefieren lk a rq; los votos n − 6, n − 5, n − 4 prefieren lk a rq; y, porque q = k, ya sea que los votos n − 3, n − 2 prefieran lk a rq (si k < q), o los votos n − 1, n prefieran lk a rq (si k > q). Por lo tanto, al menos n + 4 = (n + 1)/2 > n/2 votos prefieren lk a rq. Además, cualquier lk gana su elección de a uno a uno. Esto se debe a que solo los votos n − 3 y n − 2 prefieren a a lk. Se deduce que, después de la primera ronda, cualquier candidato superviviente lk solo puede perder un enfrentamiento contra otro candidato superviviente lk, por lo que uno de los lk debe ganar la elección. Por lo tanto, a no es el ganador en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 18. La complejidad de comunicación determinística de la regla de Bucklin es O(nm). Prueba. Sea l el entero mínimo para el cual hay un candidato que está clasificado entre los primeros l candidatos por más de la mitad de los votos. Realizaremos una búsqueda binaria para l. En cada punto, tendremos un límite inferior lL que es menor que l (inicializado en 0), y un límite superior lH que es al menos l (inicializado en m). Mientras que lH − lL > 1, continuamos averiguando si (lH − l)/2 es menor que l, después de lo cual podemos actualizar los límites. Para averiguar si un número k es menor que l, determinamos los candidatos más preferidos de cada votante k. Cada votante puede comunicar cuáles candidatos se encuentran entre sus k candidatos más preferidos usando m bits (para cada candidato, indicar si el candidato está entre los primeros k o no), pero debido a que la búsqueda binaria requiere log m iteraciones, esto nos da un límite superior de O((log m)nm), que no es lo suficientemente fuerte. Sin embargo, si lL < k < lH, y ya conocemos los candidatos más preferidos de un votante lL, así como sus candidatos más preferidos de lH, entonces el votante ya no necesita comunicar si los candidatos más preferidos de lL están entre sus k candidatos más preferidos (porque deben estarlo), y ya no necesita comunicar si los m−lH candidatos menos preferidos están entre sus k candidatos más preferidos (porque no pueden estarlo). Por lo tanto, el votante solo necesita comunicar lH −lL bits en cualquier etapa dada. Debido a que en cada etapa, lH − lL se reduce a la mitad (aproximadamente), cada votante en total comunica solo (aproximadamente) m + m/2 + m/4 + . . . ≤ 2m bits. Teorema 19. La complejidad de comunicación no determinista de la regla de Bucklin es Ω(nm) (incluso para decidir si un candidato dado a gana). Prueba. Exhibiremos un conjunto de engaño de tamaño 2n m donde m = (m−1)/2 y n = n/2. Escribimos el conjunto de candidatos como la siguiente unión disjunta: C = {a} ∪ L ∪ R donde L = {l1, l2, . . . , lm } y R = {r1, r2, . . . , rm }. Para cualquier subconjunto S ⊆ {1, 2, . . . , m}, sea L(S) = {li : i ∈ S} y sea R(S) = {ri : i ∈ S}. Para cada vector (S1, S2, . . . , Sn) que consiste en n conjuntos Si ⊆ {1, 2, . . . , m}, dejemos que el siguiente vector de votos sea un elemento del conjunto engañoso: • Para 1 ≤ i ≤ n, dejemos que el votante 2i − 1 clasifique a los candidatos L(Si) R − R(Si) a L − L(Si) R(Si). • Para 1 ≤ i ≤ n, dejemos que el votante 2i clasifique a los candidatos L − L(Si) R(Si) a L(Si) R − R(Si). Observamos que este conjunto engañoso tiene tamaño (2m )n = 2n m, y que el candidato a gana en cada vector de votos en el conjunto engañoso, por la siguiente razón. Cada candidato en C − {a} está clasificado entre los mejores m candidatos por exactamente la mitad de los votantes (lo cual no es suficiente para ganar). Por lo tanto, necesitamos analizar a los m +1 candidatos principales de los votantes, y a es clasificado en el puesto m +1 por todos los votantes. Todo lo que queda por demostrar es que para cualquier par de vectores de votos distintos en el conjunto de engaño, podemos hacer que cada uno de los votantes vote de acuerdo con uno de estos dos vectores de tal manera que a pierda. Que el primer vector de votos corresponda al vector (S1 1 , S1 2 , . . . , S1 n ), y que el segundo vector de votos corresponda al vector (S2 1 , S2 2 , . . . , S2 n ). Para algunos i, debemos tener S1 i = S2 i, de modo que sea S1 i S2 i o S2 i S1 i. Sin pérdida de generalidad, supongamos que S1 i S2 i , y sea j algún entero en S1 i − S2 i. Ahora, construye un nuevo vector de votos tomando el voto 2i − 1 del primer vector de votos, y los votos restantes del segundo vector de votos. En este nuevo vector de votos construido, a sigue siendo clasificado en el m + 1-ésimo lugar por todos los votos. Sin embargo, lj está clasificado entre los mejores m candidatos por n + 1 = n/2 + 1 votos. Esto se debe a que mientras que el voto 2i − 1 no clasifica a lj entre los m mejores candidatos en el segundo vector de votos (porque j /∈ S2 i , tenemos que lj /∈ L(S2 i )), el voto 2i − 1 sí clasifica a lj entre los m mejores candidatos en el primer vector de votos (porque j ∈ S1 i , tenemos que lj ∈ L(S1 i )). Por lo tanto, a no es el ganador en el vector de votación recién construido, y por lo tanto tenemos un conjunto de engaño correcto. Teorema 20. La complejidad de comunicación no determinista de la regla de pares clasificados es Ω(nm log m) (incluso para decidir si un candidato dado a gana). Prueba. Omitimos esta prueba debido a limitaciones de espacio. 5. DISCUSIÓN Un obstáculo clave para utilizar la votación como método de agregación de preferencias es la carga de comunicación que implica una elección para los votantes. Al reducir esta carga, puede ser factible llevar a cabo más elecciones sobre más temas. En última instancia, esto podría llevar a un cambio de un gobierno representativo a un sistema en el que la mayoría de los asuntos se decidan mediante referendos, una verdadera e-democracia. En este artículo, analizamos la complejidad de comunicación de las reglas de votación comunes. Conocer qué reglas de votación requieren poca comunicación es especialmente importante cuando el tema a votar es de tan poca importancia que se cumple lo siguiente: las partes involucradas están dispuestas a aceptar una regla que tiende a producir resultados ligeramente menos representativos de las preferencias de los votantes, si esta regla reduce significativamente la carga de comunicación para los votantes. La siguiente tabla resume los resultados que obtuvimos. Regla Límite inferior Límite superior pluralidad Ω(n log m) O(n log m) pluralidad con segunda vuelta Ω(n log m) O(n log m) Voto único transferible (STV) Ω(n log m) O(n(log m)2) Condorcet Ω(nm) O(nm) aprobación Ω(nm) O(nm) Bucklin Ω(nm) O(nm) taza Ω(nm) O(nm) maximin Ω(nm) O(nm) Borda Ω(nm log m) O(nm log m) Copeland Ω(nm log m) O(nm log m) pares clasificados Ω(nm log m) O(nm log m) Complejidad de comunicación de las reglas de votación, ordenadas de menor a mayor. Todos los límites superiores son deterministas (con la excepción de maximin, para el cual el mejor límite superior determinista que demostramos es O(nm log m)). Todos los límites inferiores se mantienen incluso para la comunicación no determinista y solo para determinar si un candidato dado a es el ganador. Una área de investigación futura es estudiar qué sucede cuando restringimos nuestra atención a protocolos de comunicación que no revelan información estratégicamente útil. Esta restricción puede invalidar algunos de los límites superiores que derivamos utilizando protocolos de comunicación multietapa. Además, todos nuestros límites son límites en el peor de los casos. Puede ser posible superar estos límites cuando la distribución de votos tiene una estructura adicional. Al decidir qué regla de votación utilizar para una elección, hay muchas consideraciones a tener en cuenta. Las reglas de votación que estudiamos en este documento son las más comunes que han resistido la prueba del tiempo. Una forma de seleccionar entre estas reglas es considerar los resultados recientes sobre complejidad. La tabla anterior muestra que desde una perspectiva de complejidad de comunicación, la pluralidad, la pluralidad con segunda vuelta y el voto único transferible son preferibles. Sin embargo, la pluralidad tiene la propiedad no deseada de que es fácil de manipular computacionalmente mediante votación estratégica [3, 7]. La pluralidad con segunda vuelta es NP-duro de manipular por una coalición de votantes ponderados, o por un individuo que enfrenta incertidumbre correlacionada sobre los votos de los demás [7, 6]. STV es NP-duro de manipular en esos escenarios también [7], pero también por un individuo con conocimiento perfecto de los votos de los demás (cuando el número de candidatos es ilimitado) [2]. Por lo tanto, STV es más robusto, aunque puede requerir ligeramente más comunicación en el peor de los casos según la tabla anterior. Sin embargo, otros criterios de selección son la complejidad computacional para determinar si se ha obtenido suficiente información para declarar un ganador, y la de determinar la secuencia óptima de consultas [8]. 6. REFERENCIAS [1] Lawrence Ausubel y Paul Milgrom. Subastas ascendentes con ofertas de paquetes. Fronteras de la Economía Teórica, 1, 2002. No. 1, Artículo 1. [2] John Bartholdi, III y James Orlin. El voto único transferible resiste el voto estratégico. Elección Social y Bienestar, 8(4):341-354, 1991. [3] John Bartholdi, III, Craig Tovey y Michael Trick. La dificultad computacional de manipular una elección. Elección Social y Bienestar, 6(3):227-241, 1989. [4] Avrim Blum, Jeffrey Jackson, Tuomas Sandholm y Martin Zinkevich. Elicitación de preferencias y aprendizaje de consultas. Revista de Investigación en Aprendizaje Automático, 5:649-667, 2004. [5] Wolfram Conen y Tuomas Sandholm. Elicitación de preferencias en subastas combinatorias: Resumen extendido. En Actas de la Conferencia ACM sobre Comercio Electrónico (ACM-EC), páginas 256-259, 2001. [6] Vincent Conitzer, Jerome Lang y Tuomas Sandholm. ¿Cuántos candidatos se necesitan para que las elecciones sean difíciles de manipular? En Aspectos Teóricos de la Racionalidad y el Conocimiento (TARK), páginas 201-214, 2003. [7] Vincent Conitzer y Tuomas Sandholm. Complejidad de manipular elecciones con pocos candidatos. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 314-319, 2002. [8] Vincent Conitzer y Tuomas Sandholm. Elicitación de votos: Complejidad y estrategia de prueba. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 392-397, 2002. [9] Sven de Vries, James Schummer y Rakesh V. Vohra. En subastas ascendentes de objetos heterogéneos, 2003. Borrador. [10] Allan Gibbard. Manipulación de esquemas de votación. Econometrica, 41:587-602, 1973. [11] Benoit Hudson y Tuomas Sandholm. Efectividad de tipos de consultas y políticas para la obtención de preferencias en subastas combinatorias. En la Conferencia Internacional sobre Agentes Autónomos y Sistemas Multiagente (AAMAS), páginas 386-393, 2004. [12] E Kushilevitz y N Nisan. Complejidad de la comunicación. Cambridge University Press, 1997. [13] Sebasti´en Lahaie y David Parkes. Aplicando algoritmos de aprendizaje a la obtención de preferencias. En Actas de la Conferencia de la ACM sobre Comercio Electrónico, 2004. [14] Noam Nisan e Ilya Segal. Los requisitos de comunicación de asignaciones eficientes y precios de apoyo. Revista de Teoría Económica, 2005. Próximamente. [15] David Parkes. iBundle: Una subasta de paquetes de precio ascendente eficiente. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 148-157, 1999. [16] Tuomas Sandholm. Una implementación del protocolo de red de contratos basada en cálculos de costos marginales. En Actas de la Conferencia Nacional de Inteligencia Artificial (AAAI), páginas 256-262, 1993. [17] Tuomas Sandholm y Craig Boutilier. Elicitación de preferencias en subastas combinatorias. En Peter Cramton, Yoav Shoham y Richard Steinberg, editores, Subastas Combinatorias, capítulo 10. MIT Press, 2005. [18] Paolo Santi, Vincent Conitzer y Tuomas Sandholm. Hacia una caracterización de la obtención de preferencias polinomiales con consultas de valor en subastas combinatorias. En la Conferencia sobre Teoría del Aprendizaje (COLT), páginas 1-16, 2004. [19] Mark Satterthwaite. In Spanish, the translation would be: "Inmutabilidad estratégica y condiciones de Arrow: teoremas de existencia y correspondencia para procedimientos de votación y funciones de bienestar social." Revista de Teoría Económica, 10:187-217, 1975. [20] Ilya Segal. Los requisitos de comunicación de las reglas de elección social y los conjuntos de presupuesto de apoyo, 2004. Borrador. Presentado en el Taller DIMACS sobre Problemas Computacionales en el Diseño de Subastas, Universidad de Rutgers, Nueva Jersey, EE. UU. [21] Peter Wurman y Michael Wellman. AkBA: Una subasta combinatoria progresiva y de precio anónimo. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 21-29, 2000. [22] A. C. Yao. Algunas preguntas de complejidad relacionadas con la computación distribuida. En Actas del 11º simposio de ACM sobre teoría de la computación (STOC), páginas 209-213, 1979. [23] Martin Zinkevich, Avrim Blum y Tuomas Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Actas de la Conferencia de la ACM sobre Comercio Electrónico (ACM-EC), páginas 176-185, 2003. 87