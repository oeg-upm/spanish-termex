Con el abrumador volumen de noticias en línea disponible hoy en día, hay una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se enfocaron únicamente en organizar historias de noticias por sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda rápidamente el tema. En este trabajo, intentamos capturar la rica estructura de eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocer eventos y sus dependencias como enhebrado de eventos. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una simple lista plana de historias relacionadas con el tema. Definimos formalmente el problema novedoso, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas como la localidad temporal de las historias para el reconocimiento de eventos y el orden temporal para capturar dependencias. Nuestros experimentos en conjuntos de datos etiquetados manualmente muestran que nuestros modelos identifican eficazmente los eventos y capturan las dependencias entre ellos. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Agrupamiento Términos Generales Algoritmos, Experimentación, Medición 1. INTRODUCCIÓN Las noticias constituyen una parte importante de la información difundida en el mundo todos los días. Tanto la gente común como los analistas de noticias están muy interesados en mantenerse al tanto de las novedades que ocurren en las noticias, pero se está volviendo muy difícil lidiar con los enormes volúmenes de información que llegan cada día. Por lo tanto, hay una creciente necesidad de técnicas automáticas para organizar historias de noticias de manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Detección y Seguimiento de Temas (TDT) [3] que lleva a cabo una competencia anual abierta sobre tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT consiste en organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una simple colección de historias: se caracteriza por una estructura definida de eventos interrelacionados. Esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas por algún evento seminal del mundo real, donde un evento se define como algo que sucede en un momento y lugar específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de los perpetradores, arrestos, juicios, entre otros. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de los intentos de rescate está influenciado por el evento del bombardeo y también lo está el evento de la búsqueda de los perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos no solo a identificar los eventos que conforman un tema, sino también a establecer dependencias, generalmente causales, entre ellos. Llamamos al proceso de reconocer eventos e identificar dependencias entre ellos enhebrado de eventos, una analogía al enhebrado de correos electrónicos que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura interconectada resultante de eventos como el modelo de eventos del tema. Aunque este documento se centra en enhebrar eventos dentro de un tema de noticias existente, esperamos que una estructura de dependencia basada en eventos refleje de manera más precisa la estructura de las noticias que lo hacen los temas estrictamente delimitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados les ayuda a obtener una visión general rápida del tema y también les permite navegar por el tema más rápidamente. El resto del documento está organizado de la siguiente manera. En la sección 2, discutimos el trabajo relacionado. En la sección 3, definimos el problema y utilizamos un ejemplo para ilustrar el enhebrado de eventos dentro de un tema de noticias. En la sección 4, describimos cómo construimos el corpus para nuestro problema. La sección 5 presenta nuestras técnicas de evaluación, mientras que la sección 6 describe las técnicas que utilizamos para modelar la estructura de eventos. En la sección 7 presentamos nuestros experimentos y resultados. La sección 8 concluye el artículo con algunas observaciones sobre nuestros resultados y comentarios sobre trabajos futuros. 446 2. TRABAJO RELACIONADO El proceso de enlazar eventos está relacionado con el enlace de correos electrónicos solo por el nombre en su mayor parte. El correo electrónico generalmente incorpora una estructura sólida de mensajes referenciados y encabezados de asunto consistentemente formateados, aunque las técnicas de recuperación de información son útiles cuando la estructura se descompone [7]. El enhebrado de correos electrónicos captura las dependencias de referencia entre los mensajes y no intenta reflejar ninguna estructura subyacente del mundo real del asunto en discusión. Otra área de investigación que examina la estructura dentro de un tema es la clasificación jerárquica de textos por temas [9, 6]. La jerarquía dentro de un tema impone una estructura en el tema, pero no conocemos ningún esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones subyacentes de los eventos. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del de ellos en que no restringimos la dependencia a ser lineal. También sus algoritmos están ajustados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras que esperamos que nuestros algoritmos se generalicen a cualquier tema. En TDT, los investigadores han considerado tradicionalmente los temas como clústeres planos [1]. Sin embargo, en TDT-2003 se propuso una estructura jerárquica de detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modelaba explícitamente ninguna dependencia entre eventos. En un trabajo más cercano al nuestro, Makkonen [8] sugirió modelar los temas de noticias en términos de sus eventos en evolución. Sin embargo, el artículo no llegó a proponer ningún modelo para el problema. Otro trabajo relacionado que abordó el análisis dentro de un tema de noticias incluye la sumarización temporal de temas de noticias [4]. 3. DEFINICIÓN DEL PROBLEMA Y NOTACIÓN En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (en letra normal) a continuación para mayor claridad. 1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se asume que una historia se refiere solo a un tema. En este trabajo, también asumimos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña en la jerarquía (tema evento historia). Claramente, ambas suposiciones no son necesariamente verdaderas en la realidad, pero las aceptamos por simplicidad en el modelado. 2. Evento: Un evento es algo que sucede en un momento y lugar específicos [10]. En nuestro trabajo, representamos un evento mediante un conjunto de historias que lo discuten. Siguiendo la suposición de la atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede ser representado por un conjunto de grupos no superpuestos de noticias. 3. Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada una representando un evento y un conjunto de aristas (dirigidas o no dirigidas) entre pares de estos grupos representando las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección. 4. Detección y seguimiento de temas (TDT): La detección de temas detecta grupos de historias que discuten el mismo tema; el seguimiento de temas detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se ocupa principalmente de agrupar historias en temas que las discuten. 5. Enhebrado de eventos: El enhebrado de eventos detecta eventos dentro de un tema y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y TDT es que enfocamos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más amplios. Además, el modelo de enhebrado de eventos representa la relación o dependencias entre pares de eventos en un tema, mientras que TDT modela los temas como grupos no relacionados de historias. Primero definimos formalmente nuestro problema y la representación de nuestro modelo, y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de historias de noticias sobre un tema dado y su hora de publicación. Definimos un conjunto de eventos ½ ¡ ¡ ¡ Ñ con las siguientes restricciones: ¾ ¾ Ë (1) × Ø (2) × ¾ × Ø × ¾ (3) Mientras que la primera restricción dice que cada evento es un elemento en el conjunto potencia de S, la segunda restricción asegura que cada historia puede pertenecer a lo sumo a un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en . De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´× µ si y solo si × ¾ (4). Además, también definimos un conjunto de aristas dirigidas ´ µ que denotan las dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: Si bien la existencia de un borde en sí mismo representa la relación entre dos eventos, la dirección podría implicar causalidad u orden temporal. Por dependencia causal nos referimos a que la ocurrencia del evento B está relacionada y es consecuencia de la ocurrencia del evento A. Por orden temporal, nos referimos a que el evento B ocurrió después del evento A y está relacionado con A, pero no necesariamente es una consecuencia de A. Por ejemplo, considera los siguientes dos eventos: el accidente de avión (evento A) y las investigaciones posteriores (evento B) en un tema sobre un incidente de accidente de avión. Claramente, las investigaciones son resultado del accidente. Por lo tanto, una flecha de A a B cae bajo la categoría de dependencia causal. Ahora considera el par de eventos: la llegada del Papa a Cuba (evento A) y el encuentro del Papa con Castro (evento B) en un tema que discute la visita del Papa a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en dicho escenario captura lo que llamamos orden temporal. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una opción más simple (y por lo tanto menos controvertida) sería ignorar por completo la dirección en las dependencias y considerar solo los bordes no dirigidos. Esta elección definitivamente tiene sentido como primer paso, pero elegimos la primera opción ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de diagrama de flujo sobre el tema. Para hacer la idea de enhebrado de eventos más concreta, considera el ejemplo del tema 30005 de TDT3, titulado Acusación de Osama bin Laden (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede ser representado como en la figura 1. Cada recuadro en la figura indica un evento en el tema del procesamiento de Osama. La ocurrencia del evento 2, es decir, el Juicio e Imputación de Osama, depende del evento de evidencia recopilada por la CIA, es decir, el evento 1. De manera similar, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, Amenazas de Militantes, Reacciones 447 del Mundo Musulmán y anuncio de recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo nuestra notación aún más, llamamos a un evento A padre de B y a B hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ como una tupla del conjunto de eventos y el conjunto de dependencias. El juicio y la CIA anuncian recompensa del mundo musulmán. Reacciones de militantes islámicos. Amenazas de Osama. Acusación de la CIA recopilada por evidencia. Figura 1: Un modelo de evento del tema de TDT, la acusación de Osama bin Laden. El enhebrado de eventos está fuertemente relacionado con la detección y seguimiento de temas, pero también es significativamente diferente de ello. Va más allá de los temas y modela las relaciones entre eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y seguimiento de temas y es más desafiante debido al menos a las siguientes dificultades. 1. El número de eventos es desconocido. 2. La granularidad de los eventos es difícil de definir. Las dependencias entre eventos son difíciles de modelar. 4. Dado que es un área de investigación completamente nueva, no hay métricas de evaluación estándar ni datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos para abordar estos problemas. 4. DATOS ETIQUETADOS Se seleccionaron 28 temas del corpus TDT2 y 25 temas del corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias relevantes de las noticias principales de CNN. Si el tema contenía más de 30 historias de CNN, seleccionamos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no suelen divagar o alejarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de abordar conjuntos de datos más complejos. Contratamos a un anotador para crear datos verídicos. La anotación incluye definir la pertenencia del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y los 25 temas de TDT3. Al identificar eventos en un tema, se pidió al anotador que siguiera ampliamente la definición de un evento de TDT, es decir, algo que sucede en un momento y lugar específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias menciona tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. Se alentó al anotador a evitar también los eventos únicos, eventos que contienen una única noticia, si es posible. Nos dimos cuenta a partir de nuestra propia experiencia de que las personas difieren en su percepción de un evento, especialmente cuando el número de relatos sobre ese evento es pequeño. Como parte de las pautas, instruimos al anotador a asignar títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no utilizamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del grafo. Cada evento podría tener uno, varios o ningún padre. Además, el gráfico podría tener ciclos o nodos huérfanos. Sin embargo, se instruyó al anotador asignar una dependencia de un evento A a un evento B solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A en el tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de prueba de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos aleatoriamente. La Tabla 1 muestra que los conjuntos de entrenamiento y prueba tienen estadísticas bastante similares. Conjunto de entrenamiento Conjunto de prueba Num. de temas 26 27 Prom. Número. Historias/Tema 28.69 26.74 Prom. "Doc." Len. 64.60 64.04 Prom. Número. Historias/Evento 5.65 6.22 Prom. Número. Eventos/Tema 5.07 4.29 Prom. Número. Dependencias/Tema 3.07 2.92 Prom. Número. Dependencias/Evento 0.61 0.68 Prom. Número. Días/Tema 30.65 34.48 Tabla 1: Estadísticas de los datos anotados 5. Un sistema puede generar un modelo de evento Å¼ ´ ¼ ¼µ utilizando ciertos algoritmos, que suele ser diferente del modelo real Å ´ µ (asumimos que el anotador no cometió ningún error). Comparar un modelo de evento del sistema Ż con el modelo real Ż requiere comparar los modelos de eventos completos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden generar una gran discrepancia entre Å¼ y Å. Sin duda, esto no es trivial, ya que ni siquiera probar si dos grafos son isomorfos tiene una solución conocida en tiempo polinómico. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas están de acuerdo en sus membresías de eventos y dependencias. Específicamente, comparamos dos tipos de pares de historias: pares de clúster (´Åµ): Estos son el conjunto completo de pares no ordenados ´× × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´Åµ ´× × µ × µ × ¾ Ë ´× µ ´× µ (5) donde es la función en Å que mapea historias a eventos como se define en la ecuación 4. ¯ Pares de dependencia ( ´Åµ): Estos son el conjunto de todos los pares ordenados de historias ´× × µ tales que hay una dependencia del evento de × al evento de × en el modelo Å. ´Åµ ´× × µ ´ ´× µ ´× µµ ¾ (6) Nota que el par de historias está ordenado aquí, por lo que ´× × µ no es equivalente a ´× × µ. En nuestra evaluación, un par correcto con el par incorrecto 448 (B->D) Pares de clúster (A,C) Pares de dependencia (A->B) (C->B) (B->D) D,E D,E (D,E) (D,E) (A->C) (A->E) (B->C) (B->E) (B->E) Precisión de clúster: 1/2 Recuperación de clúster: 1/2 Recuperación de dependencia: 2/6 Precisión de dependencia: 2/4 (A->D) Modelo de evento verdadero Modelo de evento del sistema A,B C A,C B Pares de clúster (A,B) Pares de dependencia Figura 2: Las medidas de evaluación considerarán una dirección incorrecta. Como mencionamos anteriormente en la sección 3, ignorar la dirección puede hacer que el problema sea más simple, pero perderemos la expresividad de nuestra representación. Dadas estas dos series de pares de historias correspondientes al modelo de evento verdadero Å y al modelo de evento del sistema Å¼, definimos la recuperación y precisión para cada categoría de la siguiente manera. Precisión de agrupación (CP): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. Donde ¼ es la función de mapeo de eventos de historia correspondiente al modelo Å¼. ¯ Recuerdo de Clúster (CR): Es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo evento verdadero. Precisión de Dependencia (DP): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo verdadero Å, dado que tienen una dependencia en el modelo del sistema Å¼. Ten en cuenta que la dirección de la dependencia es importante en la comparación. Recuerdo de Dependencia (DR): Es la probabilidad de que exista una dependencia entre los eventos de dos historias seleccionadas al azar × y × en el modelo del sistema Å¼ dado que tienen una dependencia en el modelo real Å. Nuevamente, se toma en consideración la dirección de la dependencia. Las medidas se ilustran con un ejemplo en la figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación. ¾ ¢ È ¢ Ê È · Ê ¾ ¢ È ¢ Ê È · Ê Â ¾ ¢ ¢ · (11) donde y son las medidas F1 de agrupación y dependencia respectivamente y Â es la medida F1 conjunta (Â ) que utilizamos para medir el rendimiento general. 6. TÉCNICAS La tarea de modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellos. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas sub tareas. 6.1 Agrupamiento Cada tema está compuesto por múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se asume que todas las historias sobre el mismo tema están disponibles al mismo tiempo, en lugar de llegar en un flujo de texto. Esta tarea es similar al agrupamiento tradicional, pero características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupamiento de textos, la similitud entre dos historias es el producto interno de sus vectores tf-idf, por lo tanto lo utilizamos como una de nuestras características. Las historias en el mismo evento tienden a seguir una localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades nombradas como nombres de personas y lugares son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con la misma(s) persona(s) y lugar(es). En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. En nuestros experimentos, sin embargo, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo. 6.1.1 Agrupamiento aglomerativo con decaimiento temporal (ACDT). Inicializamos nuestros eventos como eventos individuales (clusters), es decir, cada cluster contiene exactamente una historia. Por lo tanto, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud Û×ÙÑ´×½ ×¾µ entre dos historias ×½ y ×¾ se da por la siguiente fórmula: Û×ÙÑ´×½ ×¾µ ½ Ó×´×½ ×¾µ · ¾ÄÓ ´×½ ×¾µ · ¿È Ö´×½ ×¾µ (12) Aquí ½, ¾, ¿ son los pesos en diferentes características. En este trabajo, los determinamos de manera empírica, pero en el futuro, se pueden considerar técnicas de aprendizaje más sofisticadas para determinarlos. La similitud del coseno de los vectores de términos es Ó×´×½ ×¾µ. La variable ÄÓ ´×½ ×¾µ es 1 si hay alguna ubicación que aparezca en ambas historias, de lo contrario es 0. El término È Ö´×½ ×¾µ se define de manera similar para el nombre de la persona. Utilizamos la degradación temporal al calcular la similitud de pares de historias, es decir, a mayor diferencia de tiempo entre dos historias, menor será su similitud. El período de tiempo de cada tema difiere mucho, desde unos pocos días hasta unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando la duración completa de ese tema. La similitud ajustada por la degradación temporal 449 × Ñ´×½ ×¾µ se da por × Ñ´×½ ×¾µ Û×ÙÑ´×½ ×¾µ « Ø½ Ø¾ Ì (13) donde Ø½ y Ø¾ son las marcas de tiempo para la historia 1 y 2 respectivamente. T es la diferencia de tiempo entre la historia más temprana y la más reciente en el tema dado. « es el factor de decaimiento temporal. En cada iteración, encontramos el par de eventos más similar y los fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos Ù y Ú: ¯ Enlace promedio: En este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre Ù y Ú como se muestra a continuación: × Ñ´ Ù Ú µ È×Ù¾ Ù È×Ú¾ Ú × Ñ´×Ù ×Ú µ Ù Ú (14) ¯ Enlace completo: La similitud entre dos eventos se da por la menor de las similitudes de pares. × Ñ´ Ù Ú µ Ñ Ò ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (15) ¯ Enlace simple: Aquí la similitud se da por la mejor similitud entre todos los pares de historias. × Ñ´ Ù Ú µ Ñ Ü ×Ù¾ Ù ×Ú¾ Ú × Ñ´×Ù ×Ú µ (16) Este proceso continúa hasta que la similitud máxima caiga por debajo del umbral o el número de grupos sea menor que un número dado. 6.2 Modelado de dependencias Capturar dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide sobre las dependencias no solo basándose en la información de los eventos, sino también en su vasto repertorio de conocimiento del dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1 un ser humano sabe que el juicio y la acusación de Osama están influenciados por la evidencia recopilada por la CIA porque entiende el proceso legal en general. Creemos que un modelo sólido debería incorporar ese conocimiento del dominio para capturar las dependencias, pero en este trabajo, como primer paso, nos basaremos en características superficiales como el orden temporal de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que dichas características son realmente útiles para capturar dependencias en gran medida. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, asumimos que ya se nos ha dado el mapeo ¼ Ë y nos enfocamos únicamente en modelar las aristas ¼. Primero definimos un par de características que los modelos siguientes emplearán. Primero definimos una función de ordenación temporal 1-1 Ø Ë ½ ¡ ¡ ¡ Ò que ordena las historias en orden ascendente según su tiempo de publicación. Ahora, la función de ordenación de eventos en el tiempo Ø se define de la siguiente manera. En otras palabras, Ø ordena los eventos en función del orden temporal de sus respectivas primeras historias. También utilizaremos la similitud coseno promedio entre dos eventos como una característica y se define de la siguiente manera. En este modelo, asumimos que existen dependencias entre todos los pares de eventos. La dirección de la dependencia está determinada por el orden temporal de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera. ¼ ´ Ù Ú µ Ø ´ Ùµ Ø ´ Ú µ (19) donde Ø es la función de ordenamiento de eventos en el tiempo. En otras palabras, el borde de dependencia está dirigido desde el evento Ù hacia el evento Ú, si la primera historia en el evento Ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en agrupamiento. Aunque usemos los mismos nombres, quedará claro del contexto a cuál nos referimos. 6.2.2 Umbralización Simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos Ù y Ú solo si la similitud coseno promedio entre el evento Ù y el evento Ú es mayor que un umbral Ì. Formalmente, en este modelo asumimos que cada evento puede tener como máximo un padre. Definimos el conjunto de dependencias de la siguiente manera. Por lo tanto, para cada evento Ú, el modelo padre más cercano considera solo el evento que lo precede, definido por Ø, como un candidato potencial. El candidato se asigna como el padre solo si la similitud promedio supera un umbral predefinido Ì. 6.2.4 Mejor Modelo de Similitud Este modelo también asume que cada evento puede tener como máximo un padre. Un evento Ú se le asigna un padre Ù si y solo si Ù es el evento anterior más similar a Ú y la similitud supera un umbral Ì. Matemáticamente, esto se puede expresar como: ¼ ´ Ù Ú µ Ú Ë Ñ´ Ù Úµ Ì Ù Ö Ñ Ü Û Ø ´ Ûµ Ø ´ Úµ Ú Ë Ñ´ Û Ú µ (22) 6.2.5 Modelo de Árbol de Expansión Máxima En este modelo, primero construimos un árbol de expansión máxima (MST) utilizando un algoritmo voraz en el siguiente grafo ponderado, no dirigido y completamente conectado cuyos vértices son los eventos y cuyas aristas se definen de la siguiente manera: ´ Ù Ú µ Û´ Ù Ú µ Ú Ë Ñ´ Ù Úµ (23) Sea ÅËÌ´ µ el conjunto de aristas en el árbol de expansión máxima de ¼. Ahora, nuestras aristas de dependencia dirigida se definen de la siguiente manera. Por lo tanto, en este modelo, asignamos dependencias entre los eventos más similares en el tema. Nuestros experimentos consisten en tres partes. Primero modelamos solo la parte de agrupamiento de eventos (definiendo la función de asignación ¼) utilizando algoritmos de agrupamiento descritos en la sección 6.1. Luego modelamos solo las dependencias proporcionando al sistema los clústeres reales y ejecutando solo los algoritmos de dependencia de la sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupamiento y dependencia para producir el modelo completo de eventos. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación. 7.1 Agrupamiento Hemos probado varias variaciones del algoritmo Ì para estudiar los efectos de diversas características en el rendimiento del agrupamiento. Todos los parámetros se aprenden ajustando en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con los parámetros fijados en sus valores óptimos aprendidos durante el entrenamiento. Utilizamos el modelo de agrupamiento aglomerativo con los mejores parámetros T CP CR CF valor P cos+1-lnk 0.15 0.41 0.56 0.43 cos+all-lnk 0.00 0.40 0.62 0.45 cos+Loc+avg-lnk 0.07 0.37 0.74 0.45 cos+Per+avg-lnk 0.07 0.39 0.70 0.46 cos+TD+avg-lnk 0.04 0.45 0.70 0.53 2.9e-4* cos+N(T)+avg-lnk - 0.41 0.62 0.48 7.5e-2 cos+N(T)+T+avg-lnk 0.03 0.42 0.62 0.49 2.4e-2* cos+TD+N(T)+avg-lnk - 0.44 0.66 0.52 7.0e-3* cos+TD+N(T)+T+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Baseline(cos+avg-lnk) 0.05 0.39 0.67 0.46Tabla 2: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de entrenamiento) basado únicamente en la similitud coseno como nuestro punto de referencia para el agrupamiento. Los resultados en los conjuntos de entrenamiento y prueba están en las Tablas 2 y 3 respectivamente. Utilizamos la medida de F1 del clúster (CF) promediada sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF Valor P cos+1-lnk 0.43 0.49 0.39 cos+all-lnk 0.43 0.62 0.47 cos+Loc+avg-lnk 0.37 0.73 0.45 cos+Per+avg-lnk 0.44 0.62 0.45 cos+TD+avg-lnk 0.48 0.70 0.54 0.014* cos+N(T)+avg-lnk 0.41 0.71 0.51 0.31 cos+N(T)+T+avg-lnk 0.43 0.69* 0.52 0.14 cos+TD+N(T)+avg-lnk 0.43 0.76 0.54 0.025* cos+TD+N(T)+T+avg-lnk 0.47 0.69 0.54 0.0095* Baseline(cos+avg-lnk) 0.44 0.67 0.50Tabla 3: Comparación de algoritmos de agrupamiento aglomerativo (conjunto de prueba) El valor P marcado con un £ significa que es una mejora estadísticamente significativa sobre el valor base (nivel de confianza del 95%, prueba T de una cola). Los métodos mostrados en las tablas 2 y 3 son: ¯ Baseline: peso del vector tf-idf, similitud del coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿ ¼. Y « ¼ en la ecuación 13. Este valor F es el máximo obtenido al ajustar el umbral. ¯ cos+1-lnk: Se utiliza la comparación de enlace único (ver ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, las demás configuraciones son iguales a la ejecución base. ¯ cos+all-lnk: Se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único pero toma la similitud mínima de todos los pares de historias. ¯ cos+Loc+avg-lnk: Los nombres de ubicación se utilizan al calcular la similitud. ¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este utilizan el enlace promedio (ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora en el rendimiento. ¯ cos+Per+avg-lnk: ¿ ¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud. ¯ cos+TD+avg-lnk: El coeficiente de decaimiento temporal « ½ en la ecuación 13, lo que significa que la similitud entre dos historias se degradará a ½ si están en diferentes extremos del tema. ¯ cos+N(T)+avg-lnk: Utilice el número de eventos verdaderos para controlar el algoritmo de agrupamiento aglomerativo. Cuando el número de grupos es menor que el de eventos verdaderos, detén la fusión de grupos. ¯ cos+N(T)+T+avg-lnk: similar a N(T) pero también detén la aglomeración si la similitud máxima está por debajo del umbral Ì. ¯ cos+TD:+N(T)+avg-lnk: similar a N(T) pero las similitudes se decaen, « ½ en la ecuación 13. ¯ cos+TD+N(T)+T+avg-lnk: similar a TD+N(Truth) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral Ì. Nuestros experimentos demuestran que las similitudes de enlace único y enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de historias. Habíamos esperado que las ubicaciones y los nombres de personas mejoraran el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias relacionadas comparten los mismos lugares o personas, independientemente del evento al que pertenezcan, por lo que estas características pueden ser más útiles para identificar temas que eventos. La descomposición temporal es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a estar adyacentes en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía al algoritmo de agrupamiento para obtener la granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trampa para compararlo con otros algoritmos. En general, la decadencia temporal resultó ser la característica más poderosa además de la similitud coseno tanto en los conjuntos de entrenamiento como en los de prueba. 7.2 Dependencias En esta subsección, nuestro objetivo es modelar únicamente las dependencias. Utilizamos la función de mapeo verdadera y, por implicación, los eventos verdaderos Î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la sección 6.2. Primero entrenamos nuestros modelos en los 26 temas de entrenamiento. El entrenamiento implica aprender el mejor umbral Ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de Precisión de Dependencia (DP), Recuperación de Dependencia (DR) y Medida F de Dependencia (DF). Consideramos el modelo de enlace completo como nuestra línea base, ya que para cada evento, considera trivialmente que todos los eventos anteriores son padres. La tabla 4 enumera los resultados en el conjunto de entrenamiento. Observamos que, aunque todos los algoritmos excepto MST superan al algoritmo de enlace completo de referencia, el algoritmo del padre más cercano es estadísticamente significativo en comparación con el de referencia en términos de su valor de DF utilizando una prueba T pareada de una cola al 95% de nivel de confianza. El mejor modelo Ì DP DR DF Valor p Padre más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Umbral simple 0.045 0.45 0.76 0.52 0.14 Enlace completo - 0.36 0.93 0.48Tabla 4: Resultados en el conjunto de entrenamiento: Best Ì es el valor óptimo del umbral Ì. * indica que el modelo correspondiente es estadísticamente significativo en comparación con el valor base utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En la tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no utilizamos ningún ajuste, sino que establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo padre más cercano, que fue significativamente mejor que el valor base en el conjunto de entrenamiento, resulta ser peor que el valor base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que el modelo base, incluida la mejor similitud que es estadísticamente significativa. Observa que todos los modelos que tienen un mejor rendimiento que la línea base en términos de DF, en realidad sacrifican su rendimiento de recall en comparación con la línea base, pero mejoran sustancialmente su precisión, mejorando así su rendimiento en la medida de DF. Observamos que tanto el umbral simple como la mejor similitud son mejores que el valor base en ambos conjuntos de entrenamiento y prueba, aunque la mejora no es significativa. En general, observamos que las características a nivel de superficie que utilizamos capturan las dependencias a un nivel razonable, logrando un mejor valor de 0.72 DF en el conjunto de pruebas. Aunque hay mucho espacio para mejorar, creemos que este es un buen primer paso. Modelo DP DR DF Valor P-valor Padre más Cercano 0.61 0.60 0.60 Mejor Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Umbral Simple 0.57 0.75 0.64 0.24 Línea Base (Enlace Completo) 0.50 0.94 0.63Tabla 5: Resultados en el conjunto de prueba 7.3 Combinando Agrupamiento y Dependencias Ahora que hemos estudiado los algoritmos de agrupamiento y dependencia de forma aislada, combinamos los algoritmos con mejor rendimiento y construimos el modelo de evento completo. Dado que ninguno de los algoritmos de dependencia ha demostrado ser consistentemente y significativamente mejor que los demás, los utilizamos todos en nuestra experimentación. De las técnicas de agrupamiento, elegimos la mejor ejecutante Cos+TD. Como referencia, utilizamos una combinación de las líneas base en cada componente, es decir, cos para el agrupamiento y complete-link para las dependencias. Ten en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de entrenamiento porque nuestra función objetivo a optimizar es ahora JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupamiento como el umbral de dependencia. Lo hicimos empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la tabla 6, indican que cos+TD+Simple-Thresholding es significativamente mejor que el valor base en términos del valor F conjunto JF, utilizando una prueba T pareada de una cola al nivel de confianza del 95%. En general, observamos que si bien el rendimiento de agrupamiento es comparable a los experimentos en la sección 7.1, el rendimiento general se ve socavado por el bajo rendimiento de dependencia. A diferencia de nuestros experimentos en la sección 7.2 donde proporcionamos los grupos verdaderos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad de los grupos. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido considerablemente, lo que ha disminuido el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la mostrada en la tabla 7. También observamos una cantidad considerable de consistencia en el rendimiento de los algoritmos de combinación. cos+TD+Simple-Thresholding supera significativamente al valor de referencia. Los resultados del conjunto de pruebas también indican que el componente de agrupamiento sigue siendo un cuello de botella para lograr un rendimiento general óptimo. 8. DISCUSIÓN Y CONCLUSIONES En este artículo, hemos presentado una nueva perspectiva para modelar temas de noticias. A diferencia de la visión de los TDT sobre los temas como una colección plana de noticias, nosotros consideramos un tema de noticias como una estructura relacional de eventos interconectados por dependencias. En este artículo, también propusimos algunos enfoques para agrupar historias en eventos y construir dependencias entre ellas. Desarrollamos un enfoque de agrupamiento basado en la decaimiento temporal que aprovecha la localización temporal de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque base basado en la similitud del coseno. Nuestros experimentos también muestran que podemos tener un buen desempeño en dependencias utilizando solo características superficiales como la similitud del coseno y las marcas de tiempo de las noticias, siempre y cuando se proporcionen eventos reales al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí mismo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que los baselines. Nuestros resultados indican que modelar dependencias puede ser un problema muy difícil, especialmente cuando el rendimiento del agrupamiento está por debajo del nivel ideal. Los errores en el agrupamiento tienen un efecto amplificador en los errores en las dependencias, como hemos visto en nuestros experimentos. Por lo tanto, debemos enfocarnos no solo en mejorar las dependencias, sino también en agrupar al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a fondo los datos y descubrir nuevas características que influyan en la agrupación, así como las dependencias. Y para modelar dependencias, un marco probabilístico debería ser una mejor elección ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar alternativamente el rendimiento de agrupamiento y dependencia, como sugirió uno de los revisores. También esperamos expandir nuestro corpus etiquetado para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27 cos+TD+Mejor Similitud 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32 cos+TD+MST 0.04 0.00 0.45 0.70 0.53 0.22 0.35 0.25 0.33 cos+TD+Umbral Simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Baseline (cos+Enlace Completo) 0.10 - 0.58 0.31 0.38 0.20 0.67 0.30 0.33Tabla 6: Resultados combinados en el conjunto de entrenamiento Modelo CP CR CF DP DR DF JF Valor p cos+TD+Padre más Cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30 cos+TD+Mejor Similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35 cos+TD+MST 0.48 0.70 0.54 0.31 0.30 0.28 0.37 cos+TD+Umbral Simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* Baseline (cos+Enlace Completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Tabla 7: Resultados combinados en el conjunto de prueba para la Recuperación de Información Inteligente y en parte por la subvención SPAWARSYSCENSD número de concesión N66001-02-1-8903. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. REFERENCIAS [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron y Y. Yang. Estudio piloto de detección y seguimiento de temas: Informe final. En Actas del Taller de Transcripción y Comprensión de Noticias de Radiodifusión de DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolivar. Evaluación intrínseca flexible de agrupamiento jerárquico para tdt. Volumen en las Actas de la Duodécima Conferencia Internacional de la ACM sobre Información y Gestión del Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de la información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captando la idea: Modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y Capítulo Norteamericano de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubriendo y comparando jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Hilvanado de correos electrónicos: un estudio preliminar. I'm sorry, but the sentence "Inf." is not a complete sentence and cannot be translated without context. Could you please provide more information or a complete sentence for translation? Proceso. Manejo., 33(2):209-217, 1997. [8] Juha Makkonen. Investigaciones sobre la evolución de eventos en tdt. En Actas del Taller de Estudiantes de HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación jerárquica de texto y evaluación. En Actas de la Conferencia Internacional de Minería de Datos de IEEE de 2001, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En el número especial de IEEE Intelligent Systems sobre Aplicaciones de Recuperación de Información Inteligente, volumen 14 (4), páginas 32-43, 1999. 453