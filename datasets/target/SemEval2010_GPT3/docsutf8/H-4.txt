Hacia Evaluaciones de Gestión de Información Personal basadas en Tareas David Elsweiler Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Ciencias de la Computación e Información, Universidad de Strathclyde ir@cis.strath.ac.uk RESUMEN La Gestión de Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Una característica de la investigación de PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar información, pero muy pocos han sido evaluados. Esto ha sido señalado por varios académicos y explicado por las dificultades involucradas en realizar evaluaciones de PIM. Las dificultades incluyen que las personas vuelven a encontrar información dentro de colecciones personales únicas; los investigadores saben poco sobre las tareas que llevan a las personas a volver a encontrar información; y numerosos problemas de privacidad relacionados con la información personal. En este artículo buscamos facilitar las evaluaciones de PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y Descriptores de Asignaturas H3.3 [Búsqueda y Recuperación de Información]: Términos Generales Medición, Gestión, Experimentación, Factores Humanos 1. INTRODUCCIÓN La Gestión de la Información Personal (PIM) es un área de investigación en rápido crecimiento que se preocupa por cómo las personas almacenan, gestionan y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, categorizan y recuperan información en su día a día, están volviéndose cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como una consecuencia natural de completar otras tareas. Esto significa que las colecciones que las personas generan son únicas para ellas solas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales del propietario. Dado que las colecciones personales son únicas, no podemos crear tareas de evaluación que sean aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información que los participantes no se sienten cómodos compartiendo en una evaluación. La naturaleza precisa de esta información - qué información prefieren mantener privada las personas - varía entre individuos, lo que dificulta basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para llevar a cabo evaluaciones realistas pero controladas de PIM. Una característica particular de la investigación en PIM es que se han diseñado muchos sistemas para ayudar a los usuarios a gestionar y volver a encontrar su información, pero muy pocos han sido evaluados; una situación señalada por varios académicos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en formas de abordar el problema de la evaluación de PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los diversos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios de PIM basados en laboratorio y un conjunto común de tareas compartidas para hacer esto posible. Capra [6] también identifica la necesidad de evaluaciones de laboratorio de PIM controladas para complementar otras técnicas de evaluación, poniendo un énfasis específico en la necesidad de comprender el comportamiento de PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones controladas de PIM en laboratorio. En la primera parte de este artículo presentamos un estudio de diario sobre tareas de reencuentro de información. El estudio examina el tipo de tareas que requieren a los usuarios volver a encontrar información y produce una taxonomía de tareas de reencuentro para mensajes de correo electrónico y páginas web. También analizamos las características de las tareas que dificultan volver a encontrarlas. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este artículo ofrece dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. TRABAJO RELACIONADO Existen diversas aproximaciones disponibles para estudiar PIM. Los enfoques naturalistas estudian a los participantes realizando actividades de forma natural, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal de la PIM. Dado que las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimientos previos y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos pueden ser capturados de forma continua durante períodos de tiempo prolongados y las mediciones pueden ser tomadas en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas pueden aplicarse realizando trabajo de campo [17, 8], utilizando métodos etnográficos como sugiere [15] o a través del análisis de archivos de registro [9, 7]. Tanto los métodos etnográficos como los de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza el PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa; toma largos períodos de tiempo estudiar pequeños números de participantes y estas muestras pequeñas pueden no ser representativas del comportamiento de poblaciones más grandes. En segundo lugar, dado que los participantes no pueden ser observados continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los resultados. Una estrategia alternativa para llevar a cabo evaluaciones naturalísticas es utilizar el análisis de archivos de registro. Este enfoque hace uso de un software de registro que captura una amplia muestra de las actividades de los usuarios en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM para 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia distractora de un observador. Sin embargo, existen limitaciones a esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo desplegado debe ser algo que las personas usarían, es decir, tiene que ser una pieza de software completamente funcional que ofrezca mejoras en los sistemas normalmente disponibles para los participantes. Desarrollar un prototipo de investigación a este nivel está fuera del alcance de muchos investigadores. Además, se debe tener precaución al analizar los registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer afirmaciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador pueda relacionar el comportamiento de los participantes del estudio con los objetivos asociados a tareas de búsqueda conocidas. Los estudios basados en laboratorio simulan el entorno del mundo real de los usuarios en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas que están estrechamente definidos y son de alcance limitado. Una dificultad al realizar este tipo de evaluación es encontrar colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartida que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en llevar a cabo investigaciones sobre PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la recuperación de información convencional [13]. Sin embargo, una colección compartida sería inadecuada para estudios de usuarios porque no sería posible incorporar los aspectos personales de la gestión de información personal mientras se utiliza una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar el reencuentro de fotografías personales [11], mensajes de correo electrónico [20] y marcadores web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o acceder de forma remota. Otra solución es utilizar la web entera como una colección al estudiar la reencontrabilidad de páginas web [4]. Esto puede ser apropiado para estudiar la reencontrabilidad de páginas web, ya que estudios anteriores han demostrado que las personas a menudo utilizan motores de búsqueda web con este propósito [5]. Una segunda dificultad en realizar estudios de laboratorio de PIM es crear tareas para que los participantes las realicen y que puedan resolverse buscando en una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en la necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo una gran cantidad de trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas han sido categorizadas en términos de complejidad creciente [3] y se ha sugerido que la complejidad de la tarea afecta cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos previos han proporcionado metodologías que permiten la simulación de tareas al estudiar el comportamiento de búsqueda de información [2]. Sin embargo, se sabe poco sobre los tipos de tareas que llevan a las personas a buscar en sus almacenes personales o a reencontrar información que han visto antes. En consecuencia, es difícil idear situaciones simuladas de tareas laborales para PIM. La excepción es el estudio de la gestión de fotografías personales, donde el trabajo de Rodden sobre la categorización de las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas laborales simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas de PIM. Por ejemplo, [5] pidió a los participantes que clasificaran tareas según la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información buscada, y varios académicos han clasificado objetos de información según la frecuencia de su uso, por ejemplo [24]. Si bien estas son propiedades interesantes que pueden afectar cómo se realizará una tarea, no le dan a los experimentadores suficiente margen para diseñar tareas. Las colecciones personales son una de las razones por las que la creación de tareas es tan difícil. La taxonomía de tareas fotográficas de Roddens proporciona una solución aquí porque permite categorizar tareas adaptadas a colecciones privadas. Los sistemas pueden ser comparados entre tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe una taxonomía equivalente para otros tipos de objetos de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías; es poco probable que los participantes estén tan dispuestos a permitir a los investigadores explorar sus colecciones de correos electrónicos para crear tareas como lo estaban con las fotografías en [11]. Esto presenta un problema serio: ¿cómo pueden los investigadores diseñar tareas que se correspondan con colecciones privadas sin comprender los tipos de tareas que realizan las personas o poner en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda de correos electrónicos pidiendo a los participantes que volvieran a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento; permitiendo que las mismas tareas fueran utilizadas por todos los participantes del estudio. Este enfoque garantizó que se evitaran problemas de privacidad y que los participantes pudieran utilizar cosas que recordaban para completar las tareas. Sin embargo, los sistemas solo fueron probados utilizando un tipo de tarea: se pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la sección 4 mostramos que las personas realizan una gama más amplia de tareas de reencuentro de correos electrónicos que esta. En [4], las tareas de búsqueda genéricas fueron creadas artificialmente al realizar evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas laborales que implicaban encontrar cierta información desconocida. En la segunda sesión, los participantes completaron nuevamente las mismas tareas, lo que naturalmente implicó cierto comportamiento de reencuentro. Las limitaciones de esta técnica son que no permite a los participantes aprovechar ninguna conexión personal con la información, ya que la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo es utilizado por un sistema o interfaz que está siendo probado, el enfoque es inadecuado porque todos los objetos encontrados en la primera sesión habrán sido accedidos dentro del mismo período de tiempo. Nuestra revisión de enfoques de evaluación motiva la necesidad de experimentos de laboratorio controlados que permitan probar aspectos de sistemas o interfaces de forma precisa y definida. Desafortunadamente, también se ha demostrado que existen dificultades al realizar este tipo de evaluación: es difícil encontrar colecciones y diseñar tareas que se correspondan con colecciones privadas, al mismo tiempo que se protege la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio de diario sobre tareas de reencontrar correos electrónicos y páginas web. El resultado es una clasificación de tareas similar a la ideada por Rodden para fotografías personales [22]. En la sección 5 ampliamos este trabajo examinando métodos para crear tareas que no comprometan la privacidad de los participantes y discutimos cómo nuestro trabajo puede facilitar las evaluaciones de usuarios de PIM basadas en tareas. Mostramos que al recolectar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que también podemos aprender sobre el contenido de colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento puede ser utilizado para construir tareas para su uso en evaluaciones de PIM. 3. Los estudios de diario son una técnica naturalista que ofrece la capacidad de capturar datos factuales en un entorno natural, sin la influencia distractora de un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a estos de que la información aparentemente mundana es útil y debe ser reportada [19]. [12] sugieren que los efectos de los aspectos negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio de diario, seguimos las sugerencias en [12] para obtener los mejores datos posibles. Con este fin, restringimos las tareas registradas a la búsqueda web y de correos electrónicos. Al pedir a los usuarios que registren menos tareas, se anticipaba que la apatía de los participantes se reduciría y los niveles de dedicación se mantendrían. A los participantes se les proporcionó un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que estas necesidades se desarrollaron. Los formularios web fueron implementados en lugar de diarios en papel porque para volver a encontrar información en la web y en correos electrónicos, el usuario estaría en una computadora con conexión a Internet y no habría necesidad de buscar un diario en papel y un bolígrafo. El formulario del diario solicitaba la siguiente información: si la necesidad de información estaba relacionada con volver a encontrar una página web o un mensaje de correo electrónico, y una descripción de la tarea que estaban realizando. Esta descripción debía contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario proporcionó tres ejemplos de descripciones de tareas, que también fueron explicadas verbalmente a cada participante durante una sesión introductoria. El experimentador se aseguró de que los participantes entendieran que las tareas a ser registradas no se limitaban a los tipos mostrados en los ejemplos. Los ejemplos se proporcionaron únicamente para hacer que los participantes piensen en los tipos de cosas que podrían registrar y para mostrar el nivel y tipo de detalles esperados. El formulario también pedía a los participantes que calificaran cada tarea en términos de dificultad (en una escala del 1 al 5, donde 1 era muy fácil y 5 era muy difícil). Finalmente, se les preguntó cuándo fue la última vez que revisaron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información temporal se utilizó para examinar la frecuencia con la que los participantes volvían a encontrar información antigua y nueva, y cuando se combinaba con las calificaciones de dificultad, se creaba una imagen de si el período de tiempo entre el acceso y la re-accesibilidad afectaba la percepción de los participantes sobre la dificultad de las tareas. Se pidió a 36 participantes, reclutados a través de publicidad masiva en los canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reencuentro de información durante un período de aproximadamente 3 semanas. La población final consistió en 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59 años. Dado que se registraron tanto tareas personales como laborales, los resultados recopilados abarcan una amplia gama de tareas de reencuentro. 4. RESULTADOS Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reencuentro que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas: qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reencuentro que los participantes percibieron como difíciles. 4.1 Naturaleza de las tareas de reencuentro en la web y el correo electrónico. Durante el estudio se registraron 412 tareas. 150 (36.41%) de estas tareas eran basadas en correo electrónico, 262 (63.59%) eran basadas en la web. Como ocurre con la mayoría de los estudios de diario, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue de 8 (rango intercuartílico (IQR) = 9.5). Se registraron más tareas web (mediana=5, RIC=7.5) que tareas de correo electrónico (mediana=3, RIC=3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. A partir de las descripciones proporcionadas por los participantes, encontramos características similares en las tareas registradas tanto para el reencuentro de correos electrónicos como para el reencuentro en la web. Basándose en esta observación, se ideó un esquema de clasificación conjunto que abarca tanto las tareas de correo electrónico como las tareas web. Las tareas fueron clasificadas como uno de tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican buscar información específica dentro de un recurso, como por ejemplo un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos registrados de tareas de búsqueda fueron: • LU1: Buscar el código del curso para una clase, se utiliza en un script que se ejecuta para configurar una práctica. Había obtenido esto previamente hace aproximadamente 3 semanas de nuestro sitio web. • LU2: Estoy tratando de determinar la fecha en la que debo renunciar como examinador externo. Esto está en algún correo electrónico • LU3: Buscando la descripción del formato de registro del sistema R desarrollado para el proyecto de estudiante. Creo que me envió en un correo electrónico. Las tareas del ítem implican buscar un correo electrónico o página web en particular, tal vez para pasar a otra persona o cuando se necesitan los contenidos completos para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscar el artículo de SIGIR 2002 para dárselo a otro estudiante • I2: Encontrar el recibo de una compra de boletos de avión en línea necesario para reclamar gastos • I3: Necesito los formularios de evaluación de pares para la clase de MIA E, me los envió por correo electrónico. Para aclarar, las tareas de búsqueda difieren de las tareas de elementos en dos aspectos: en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña pieza de información, por ejemplo, un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de ítem, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos eran tareas que requerían información que estaba contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopilara la información para resolver la tarea. Algunos ejemplos registrados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien falleció el fin de semana. Accedido al Guradian en línea y a IMES • MI2: Intentando encontrar detalles sobre el marco gráfico Piccolo. Recordarme qué es y qué hace. Buscando construir una interfaz gráfica dentro de Eclipse • MI3: Estoy tratando de archivar mis correos electrónicos relacionados con IPM y estoy buscando cualquier correo electrónico de o sobre esta revista. Hubo varias tareas que fueron difíciles de clasificar. Por ejemplo, considera la siguiente tarea registrada: • LU4: volver a encontrar el artículo de AS sobre evaluaciones de relevancia graduada porque quiero ver cómo presentó sus resultados para un artículo que estoy escribiendo. Esta tarea en realidad consta de dos sub-tareas: 1 tarea de búsqueda de elemento (rebuscar el artículo) y 1 tarea de búsqueda de información específica dentro del artículo. Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y utilizar la información dentro del recurso. Hubo varios ejemplos de tareas combinadas, principalmente en la forma de elemento y búsqueda, pero también hubo ejemplos de elemento y múltiples elementos. Por ejemplo: • MI4: volver a encontrar el sitio web de Kelkoo para poder volver a verificar los precios de las planchas para el cabello para mi novia. Una segunda fuente de ambigüedad provenía de tareas como encontrar un correo electrónico que contenga una URL como medio para volver a acceder a una página web. También se decidió categorizar estas tareas como tareas de búsqueda, ya que en todos los casos los participantes las registraron como búsquedas de correo electrónico y, dentro de este contexto, lo que buscaban era información dentro de un correo electrónico. Otro problema fue que algunos de los registros carecían del detalle necesario para realizar una categorización, por ejemplo: • U1: buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió utilizar otros medios. Tales tareas fueron etiquetadas como U de no clasificables. Para verificar la consistencia de la taxonomía, las tareas fueron recategorizadas por el mismo investigador después de un retraso de dos semanas. La concordancia entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, pedimos a un investigador sin conocimiento del proyecto o del campo que clasificara una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que esta alta concordancia en un gran número de tareas por más de un investigador proporciona evidencia de la fiabilidad del esquema de clasificación. La distribución de tipos de tareas se muestra en la tabla 1. En general, las tareas de búsqueda y de elementos fueron las más comunes, con las tareas de múltiples elementos representando solo el 8.98% de las registradas. La distribución de los tipos de tarea fue diferente para la búsqueda en la web y en el correo electrónico. La mayoría de las tareas de correo electrónico (60%) implicaban buscar información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas multi-ítem registradas para web y correo electrónico. Las tareas de múltiples elementos eran muy raras para la relocalización de correos electrónicos (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de múltiples recursos), pero comparativamente comunes para la relocalización web (12.6%). Buscar Elemento Multi-elemento No Clasificado. Correo electrónico 90(60%) 52(34.67%) 4(2.67%) 4(2.67%) Web 87(33.21%) 138(52.67%) 33(12.60%) 4(1.53%) Todos 177(42.96%) 190(46.12%) 37(8.98%) 8(1.94%) Tabla 1: Distribución de tipos de tareas. Además de la clasificación tridimensional descrita anteriormente, las tareas registradas fueron clasificadas con respecto a la metáfora de temperatura propuesta por [24], que clasifica la información en una de tres temperaturas: caliente, templada y fría. Clasificamos las tareas utilizando los datos del formulario. La información que había sido vista menos de un día o menos de una semana antes de la tarea se definió como caliente, la información que había sido vista menos de un mes antes de la tarea como tibia, y la información que había sido vista menos de un año o más de un año antes de la tarea como fría. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto fueron definidos como U para no clasificables. Una tabla de contingencia de tipos de tareas y temperaturas se muestra en la tabla 2. Caliente Cálido Frío Sin clasificar. Correo electrónico 50(33.33%) 36(24.00%) 37(24.67%) 27(18%) Web 112(42.75%) 60(22.90%) 40(15.27%) 50(19.08%) Todos 162(39.32%) 96(23.30%) 77(18.69%) 77(18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que llevaron a las personas a volver a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implicaron la búsqueda de información que se había accedido en la última semana. Sin embargo, también hubo una serie de tareas de reencuentro que implicaban buscar información antigua: el 23.30% de las tareas registradas (24.00% para correo electrónico y 22.90% para web) implicaban buscar información accedida en el último mes y el 18.69% de las tareas registradas (24.67% para correo electrónico y 15.27% para web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque hay evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, por ejemplo [23]. Esto significa que los usuarios pueden encontrar más difícil buscar información antigua o quizás modificar su estrategia de búsqueda al buscar información actual, reciente o antigua. ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas eran percibidas como más difíciles que otras. Por ejemplo, examinamos si el tipo de medio afectaba la percepción de los participantes sobre la dificultad de la tarea. No hubo evidencia de que los participantes encontraran las tareas de correo electrónico (mediana=2 RIC=2) o web (mediana=2 RIC=2) más difíciles. También investigamos si el tipo de tarea o el tiempo transcurrido entre el acceso y la reaccesión hacían que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para tipos de tareas. A partir de la figura 1, no parece que ningún tipo de tarea en particular fuera percibido como difícil en comparación con los demás, aunque hay una sugerencia de que las tareas de búsqueda fueron percibidas como más difíciles al buscar información fría que caliente, y las tareas de elementos fueron percibidas como más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos pruebas de medianas de Moods para determinar si la clasificación de las puntuaciones de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p<0.05). Para los datos de la tarea de búsqueda, hubo evidencia de que las tareas calientes se percibían más fáciles que las frías (p=0.0001) y de que las tareas templadas se percibían más fáciles que las tareas frías (p=0.0041), pero no hubo evidencia para distinguir entre las calificaciones de dificultad de las tareas calientes y templadas (p=0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías fueron calificadas de manera diferente (p=0.024), pero no hubo evidencia para distinguir entre tareas calientes y cálidas (p=0.05) o cálidas y frías (p=0.272). Estas pruebas confirman que el tiempo transcurrido entre acceder y volver a acceder a la información buscada efectivamente influyó en la percepción de los participantes sobre la dificultad de la tarea. Sin embargo, el gran número de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, < 3, sugiere que hay otros factores que influyen en la percepción de la dificultad de una tarea. Para aprender sobre estos factores se requerirían el tipo de evaluaciones de usuario propuestas por [16, 6] - el tipo de evaluaciones facilitadas por nuestro trabajo. Resumen En la primera parte de este documento, describimos un estudio de diario sobre tareas de reencuentro en la web y el correo electrónico. Examinamos los tipos de tarea que llevaron a los participantes a buscar en sus almacenes personales y encontramos tres categorías principales de tarea: tareas en las que el usuario necesita información específica de un único recurso, tareas que requieren un único recurso, y tareas que requieren recuperar información de múltiples recursos. Se descubrió que las tareas de búsqueda y de elementos se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron pruebas de que las tareas web o de correo electrónico fueran más difíciles, hubo algunas pruebas que mostraron que el tiempo entre el acceso y la reentrada afectaba la percepción de la dificultad de las tareas por parte de los participantes. Estos hallazgos tienen implicaciones para evaluar el comportamiento de PIM a nivel de tarea. El resto de este documento se centra en esto, discutiendo lo que significan los hallazgos con respecto a la realización de evaluaciones de usuarios de PIM basadas en tareas. 5. Las conclusiones descritas en la sección 4 son útiles en cuanto a la evaluación porque proporcionan a los experimentadores el conocimiento suficiente para llevar a cabo evaluaciones de usuarios controladas en condiciones de laboratorio. Los diseños experimentales de cuadrados greco-latinos pueden ser construidos donde los participantes son asignados n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando x sistemas. Esto permitiría analizar el rendimiento de los sistemas o el comportamiento de los participantes que utilizan diferentes sistemas con respecto al tipo de tarea que se está realizando (búsqueda, elemento o múltiples elementos). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas. 5.1 Utilizando Tareas Reales Un método para crear tareas realistas de reencuentro sin comprometer la privacidad de los participantes es utilizar tareas reales. Los estudios de diario, similares a los descritos anteriormente, permitirían a los experimentadores capturar un conjunto de tareas para que los participantes las completen buscando en sus propias colecciones. Esto es sumamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras se encuentran en un entorno controlado. También existe el beneficio adicional de que las descripciones de la tarea no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real, ya que solo incluirían la información que había sido registrada, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios, primero debemos confirmar que las descripciones de las tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a realizar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio de diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas grabadas, 6 semanas después de que se completara el estudio de diario, pedimos a 6 de nuestros participantes, seleccionados al azar de entre aquellos que grabaron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas fueron seleccionadas al azar del conjunto de las disponibles. Las tareas asignadas consistieron en 10 tareas de correo electrónico y 20 tareas web, de las cuales 9 eran tareas de búsqueda, 12 eran tareas de artículo y 8 eran tareas de múltiples artículos. Las tareas emitidas representaron una muestra amplia del conjunto completo de tareas registradas. También incluyeron tareas con descripciones vagas, por ejemplo: • LU5: Encontrar una clave de software para una aplicación que necesitaba reinstalar. • LU6: Intentar encontrar una cita para usar en un trabajo. No puedo recordar a la persona o la cita exacta. La utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, ¿recordaría el registrador de la tarea LU5 a qué aplicación se refería y recordaría el registrador de LU6 lo suficiente sobre el contexto en el que tuvo lugar la tarea para volver a realizarla? Presentados con las tareas tal como las registraron, se pidió a los participantes que volvieran a realizar cada tarea con el sistema que eligieran. De las 30 tareas asignadas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea, y 2 tareas (6.67%) no se completaron porque la tarea era demasiado difícil o la página web requerida ya no existía. Los experimentadores probablemente estarán interesados en el último grupo de tareas porque es importante descubrir qué hace que una tarea sea difícil y cómo cambia el comportamiento del usuario en estas circunstancias. Por lo tanto, de las 30 tareas probadas, solo 2 tareas no tenían la calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema con el tipo, la temperatura o las calificaciones de dificultad que afectaran la calidad de las descripciones de la tarea. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio de diario también registraron tareas con calidad suficiente. ¿Sin embargo, el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 10 26 16 8 2 0 43 9 4 5 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 4 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Las tareas de participantes buscan elementos de búsqueda de múltiples elementos no clasificados. 26 32 7 20 5 0 32 31 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 10 1 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 2 1 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas Naturalmente, el número exacto de tareas requeridas para realizar una evaluación de usuario dependerá de los objetivos de la evaluación, el número de usuarios y el número de sistemas a ser probados, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. De las tablas 3 y 4, que muestran las cantidades de tareas de correo electrónico y web registradas para cada participante, podemos ver que de los 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registraron 5 o más tareas web. Esto significa que muchos de los participantes reclutados no pudieron participar realmente en la evaluación final. Esta es una limitación importante de utilizar tareas grabadas en evaluaciones, ya que la reclutación de participantes para pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo un desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda pero muy pocas tareas de elementos, y otros registraron varias tareas de elementos pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico con varios elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, aunque nuestro primer test sugiere que la calidad de las tareas grabadas fue suficiente para que los participantes las volvieran a realizar en una etapa posterior, es probable que el número de tareas grabadas fuera demasiado bajo para que esta fuera una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas recordando frecuentemente a los participantes o realizando visitas personales, etc. 5.2 Utilizando Tareas Simuladas Basadas en Tareas Reales Otro beneficio de los estudios de diario es que proporcionan información sobre el contenido y uso de colecciones privadas sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento adquirido de estudios de diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reencuentro correspondientes a la taxonomía definida en la sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuario que investiga el comportamiento de reencontrar correos electrónicos. Las limitaciones de espacio nos impiden informar sobre nuestros hallazgos; en cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio de diario, en el que 34 nuevos participantes, compuestos por 16 estudiantes de posgrado y 18 estudiantes de pregrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron en la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con las clases que estaban tomando en ese momento y a menudo diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes universitarios registraron tareas que incluían volver a encontrar información relacionada con vacantes de trabajo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, buscando un correo electrónico que vuelva a confirmar el código PIN necesario para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correos electrónicos de los participantes, pedimos a 2 participantes de cada grupo que proporcionaran recorridos por sus correos electrónicos. Estas consistían en sesiones cortas de 5 a 10 minutos, donde se pedía a los participantes que explicaran por qué usan el correo electrónico, quién les envía correos electrónicos y cuáles son sus estrategias organizativas. Este enfoque ha sido utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, teníamos planeado pedir a más participantes que proporcionaran recorridos, pero descubrimos que 2 recorridos por grupo eran suficientes para nuestras necesidades. Una vez más, surgieron patrones que ayudaron con la creación de tareas. Encontramos superposición de contenido dentro y entre grupos que confirmó muchas de nuestras observaciones de los datos del estudio de diario. Por ejemplo, los estudiantes que dieron recorridos revelaron que recibieron correos electrónicos de los profesores para tareas específicas de clase, recibos por tareas completadas y varios anuncios del soporte del sistema y sobre vacantes de trabajo. Importante, los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio de diario eran aplicables, no solo para el que las registraba, sino para todos los participantes en uno o ambos grupos. Basándonos en este trabajo investigativo inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistía en miembros del personal de investigación y académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Donde sea posible, utilizamos la información registrada en las descripciones del estudio de diario para proporcionar un contexto para la tarea, es decir, una tarea laboral o motivación que requeriría que la tarea se realizara. Cuando los datos del estudio de diario no proporcionaron suficiente información de contexto para suministrar a los participantes una descripción sólida de la necesidad de información, creamos situaciones simuladas de tareas laborales de acuerdo con las pautas de [2]. Una ventaja adicional de utilizar tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite examinar tareas que buscan información de diferentes niveles de dificultad. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio de diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reencontrar correos electrónicos de los usuarios con tres sistemas de correo electrónico diferentes. 21 usuarios (7 en cada grupo) realizaron 9 tareas cada uno (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de cuadrado latino grecolatino. Realizar una evaluación de PIM de esta manera permitió examinar el comportamiento de reencontrar de una manera no posible antes: pudimos observar las estrategias de reencontrar correos electrónicos empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento al completar tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de las tareas como para el análisis de los resultados fue nuestra taxonomía, la cual proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) realizando diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para llevar a cabo un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) Realizar un estudio de diario como se mencionó anteriormente. 2) Analizar las tareas registradas en busca de superposiciones entre los participantes. 3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de ellos que proporcionen un recorrido por su colección. 4) Utilizar el conocimiento adquirido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Más información sobre esto y los formularios necesarios se pueden encontrar en http://www.cis.strath.ac.uk/˜dce/PIMevaluations. Información detallada sobre cómo utilizar la investigación descrita en este documento para realizar evaluaciones de PIM basadas en tareas se puede encontrar en nuestro sitio web (ver nota al pie 1). 6. CONCLUSIONES Este artículo se ha centrado en superar las dificultades involucradas en realizar evaluaciones de PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen cada uno sus propias colecciones únicas que son generadas por ellos mismos al completar otras tareas. Sugerimos que para incorporar los aspectos personales de la PIM en las evaluaciones, se debe examinar el rendimiento de los sistemas o usuarios cuando estos completan tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reencuentro que realizan las personas y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de usuarios de PIM basadas en tareas. En la primera parte del artículo realizamos un estudio de diario que examinó las tareas que llevaban a las personas a volver a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas tanto con el trabajo como con actividades no laborales, y basándonos en los datos, creamos una taxonomía de tareas de reencuentro en la web y el correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reencuentro: tareas que requieren información específica de dentro de un único recurso, tareas que requieren un único recurso completo, y tareas que requieren que la información sea recuperada de múltiples recursos. En la segunda parte del artículo, discutimos la importancia de la taxonomía con respecto a la evaluación de PIM. Demostramos que se pueden realizar experimentos equilibrados comparando el rendimiento del sistema o del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se puedan completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, primero simulando una situación experimental: se pidió a los participantes que volvieran a realizar sus propias tareas tal como las habían registrado, y segundo, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá probar los sistemas que se han propuesto para mejorar la capacidad de los usuarios de gestionar y volver a encontrar su información, de modo que podamos conocer las necesidades y deseos de los usuarios. Por lo tanto, este artículo ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento de PIM a nivel de tarea y un método de evaluación que facilitará investigaciones adicionales. AGRADECIMIENTOS Nos gustaría agradecer al Dr. Mark Baillie por sus comentarios perspicaces y su ayuda en el análisis de los datos. 8. REFERENCIAS [1] R. Boardman, Mejorando el soporte de herramientas para la gestión de información personal, tesis doctoral, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación iir: Un marco para la evaluación de sistemas interactivos de recuperación de información, Information Research 8 (2003), no. 3, paper no. 152. [3] K. Byström y K. Järvelin, La complejidad de la tarea afecta la búsqueda y uso de información, Information Processing and Management 31 (1995), no. 2, 191-213. [4] R. G. Capra y M. A. Perez-Quinones, Reencontrar cosas encontradas: Un estudio exploratorio sobre cómo los usuarios vuelven a encontrar información, Informe técnico, Virginia Tech, 2003. [5] R. G. Capra y M. A. Perez-Quinones, Usar motores de búsqueda web para encontrar y reencontrar información, Computer 38 (2005), no. 10, 36-42. [6] R. G. Capra y M. A. Perez-Quinones, Factores y evaluación de comportamientos de reencontrar información, Taller SIGIR 2006 sobre Gestión de Información Personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D. Robbins, S. Dumais y R. Sarin, Filtrado rápido y flexible con Phlat, Proc. SIGCHI 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270. [8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio de diario sobre el cambio de tareas e interrupciones, Proc. SIGCHI 04, 2004, pp. 175-182. [9] S. Dumais, E. Cutrell, J. Cadiz, G. Jancke, R. Sarin, y D.C. Robbins, Cosas que he visto: un sistema para la recuperación y reutilización de información personal, Proc. SIGIR 03:, 2003, pp. 72-79. [10] D. Elsweiler and I. Ruthven, Memoria y reencuentro de correos electrónicos, En preparación para el número especial de ACM TOIS CFP sobre Mantenimiento, Reencuentro y Compartir Información Personal (2007). [11] D. Elsweiler, I. Ruthven y C. Jones, Tratando con la recopilación fragmentada de contexto en la gestión de información, Taller de Recuperación de Información Basada en Contexto (CIR-05) en CONTEXT-05, 2005. [12] D. Elsweiler, I. Ruthven y C. Jones, Hacia herramientas de gestión de información personal que apoyen la memoria, (por aparecer en) Revista de la Sociedad Americana de Ciencia de la Información y Tecnología (2007). [13] D. Harman, Lo que hemos aprendido, y no aprendido, de trec, Proc. ECIR 2000, 2000. [14] P. Ingwersen, Interacción en la recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds.), Informe del taller Pim: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (por aparecer en) gestión de información personal, cap. Comprendiendo lo que funciona: Evaluando herramientas de gestión de información personal, Seattle: Universidad de Washington Press., 2007. [17] B. H. Kwasnik, Cómo el uso o propósito previsto de un documento personal afecta su clasificación en una oficina, SIGIR89 23 (1989), no. Sí, 207-210. [18] M.W. Lansdale, La psicología de la gestión de la información personal., Appl Ergon 19 (1988), núm. 1, 55-66. [19] L. Palen y M. Salzman, Estudios de diario de voz para la captura de datos naturalista en condiciones móviles, CSCW 02: Actas de la conferencia ACM 2002 sobre trabajo cooperativo asistido por computadora, 2002. [20] M. Ringel, E. Cutrell, S. Dumais y E. Horvitz, Hitos en el tiempo: El valor de los puntos de referencia en la recuperación de información de almacenes personales., Proc. INTERACT 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel, y M. van Dantzich, Data mountain: utilizando la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías?, BCS IRSG 21st Annual Colloquium on Information Retrieval Research, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: Una descripción cuantitativa de la retención, Psychological Bulletin 103 (1996), 734-760. [24] A. J. Sellen y R. H. R. Harper, El mito de la oficina sin papel, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de la tarea, estructura del problema y acciones de información: Integrando estudios sobre búsqueda y recuperación de información., Information Processing and Management 35 (1999), 819-837. [26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), núm. 1, 44-60.