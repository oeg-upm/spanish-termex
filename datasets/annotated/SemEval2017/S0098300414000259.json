{
    "id": "S0098300414000259",
    "original_text": "Apache Pig is a platform for creating MapReduce workflows with Hadoop. These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs. Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems. In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java. We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013). Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten.",
    "original_translation": "",
    "original_sentences": [
        "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
        "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
        "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
        "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
        "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
        "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
    ],
    "error_count": 0,
    "keys": {
        "Apache Pig": {
            "translated_key": "",
            "original_annotated_sentences": [
                "<br>Apache Pig</br> is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "DAG processing": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized <br>DAG processing</br> (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "DAGs": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (<br>DAGs</br>) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "directed acyclic graphs": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as <br>directed acyclic graphs</br> (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "Hadoop": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with <br>Hadoop</br>.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the <br>Hadoop</br> community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of <br>Hadoop</br> are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "Java MapReduce": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit <br>Java MapReduce</br> jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "MapReduce": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating <br>MapReduce</br> workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of <br>MapReduce</br> jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from <br>MapReduce</br> towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than <br>MapReduce</br>, Pig scripts could take advantage of these advances without recoding, whereas explicit Java <br>MapReduce</br> jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "MapReduce workflows": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating <br>MapReduce workflows</br> with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "Pig": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache <br>Pig</br> is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "<br>Pig</br> Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, <br>Pig</br> can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted <br>Pig</br> for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, <br>Pig</br> scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "Pig Latin": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "<br>Pig Latin</br> is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "Pig scripts": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, <br>Pig scripts</br> could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "SQL": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative <br>SQL</br> commonly used for relational database systems.",
                "In addition to standard <br>SQL</br> operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "SQL operations": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard <br>SQL operations</br>, Pig can be extended with user-defined functions (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "UDFs": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with user-defined functions (<br>UDFs</br>) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "user-defined functions": {
            "translated_key": "",
            "original_annotated_sentences": [
                "Apache Pig is a platform for creating MapReduce workflows with Hadoop.",
                "These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs.",
                "Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems.",
                "In addition to standard SQL operations, Pig can be extended with <br>user-defined functions</br> (UDFs) commonly written in Java.",
                "We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013).",
                "Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}